{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Comparison of Fused Gromov-Wasserstein solvers\n\nThis example illustrates the computation of FGW for attributed graphs\nusing 3 different solvers to estimate the distance based on Conditional\nGradient [24] or Sinkhorn projections [12, 51].\n\nWe generate two graphs following Stochastic Block Models further endowed with\nnode features and compute their FGW matchings.\n\n[12] Gabriel Peyr\u00e9, Marco Cuturi, and Justin Solomon (2016),\n\"Gromov-Wasserstein averaging of kernel and distance matrices\".\nInternational Conference on Machine Learning (ICML).\n\n[24] Vayer Titouan, Chapel Laetitia, Flamary R\u00e9mi, Tavenard Romain\nand Courty Nicolas\n\"Optimal Transport for structured data with application on graphs\"\nInternational Conference on Machine Learning (ICML). 2019.\n\n[51] Xu, H., Luo, D., Zha, H., & Duke, L. C. (2019).\n\"Gromov-wasserstein learning for graph matching and node embedding\".\nIn International Conference on Machine Learning (ICML), 2019.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: C\u00e9dric Vincent-Cuaz <cedvincentcuaz@gmail.com>\n#\n# License: MIT License\n\n# sphinx_gallery_thumbnail_number = 1\n\nimport numpy as np\nimport matplotlib.pylab as pl\nfrom ot.gromov import fused_gromov_wasserstein, entropic_fused_gromov_wasserstein\nimport networkx\nfrom networkx.generators.community import stochastic_block_model as sbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate two graphs following Stochastic Block models of 2 and 3 clusters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n\nN2 = 20  # 2 communities\nN3 = 30  # 3 communities\np2 = [[1., 0.1],\n      [0.1, 0.9]]\np3 = [[1., 0.1, 0.],\n      [0.1, 0.95, 0.1],\n      [0., 0.1, 0.9]]\nG2 = sbm(seed=0, sizes=[N2 // 2, N2 // 2], p=p2)\nG3 = sbm(seed=0, sizes=[N3 // 3, N3 // 3, N3 // 3], p=p3)\npart_G2 = [G2.nodes[i]['block'] for i in range(N2)]\npart_G3 = [G3.nodes[i]['block'] for i in range(N3)]\n\nC2 = networkx.to_numpy_array(G2)\nC3 = networkx.to_numpy_array(G3)\n\n\n# We add node features with given mean - by clusters\n# and inversely proportional to clusters' intra-connectivity\n\nF2 = np.zeros((N2, 1))\nfor i, c in enumerate(part_G2):\n    F2[i, 0] = np.random.normal(loc=c, scale=0.01)\n\nF3 = np.zeros((N3, 1))\nfor i, c in enumerate(part_G3):\n    F3[i, 0] = np.random.normal(loc=2. - c, scale=0.01)\n\n# Compute pairwise euclidean distance between node features\nM = (F2 ** 2).dot(np.ones((1, N3))) + np.ones((N2, 1)).dot((F3 ** 2).T) - 2 * F2.dot(F3.T)\n\nh2 = np.ones(C2.shape[0]) / C2.shape[0]\nh3 = np.ones(C3.shape[0]) / C3.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute their Fused Gromov-Wasserstein distances\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "alpha = 0.5\n\n\n# Conditional Gradient algorithm\nfgw0, log0 = fused_gromov_wasserstein(\n    M, C2, C3, h2, h3, 'square_loss', alpha=alpha, verbose=True, log=True)\n\n# Proximal Point algorithm with Kullback-Leibler as proximal operator\nfgw, log = entropic_fused_gromov_wasserstein(\n    M, C2, C3, h2, h3, 'square_loss', alpha=alpha, epsilon=1., solver='PPA',\n    log=True, verbose=True, warmstart=False, numItermax=10)\n\n# Projected Gradient algorithm with entropic regularization\nfgwe, loge = entropic_fused_gromov_wasserstein(\n    M, C2, C3, h2, h3, 'square_loss', alpha=alpha, epsilon=0.01, solver='PGD',\n    log=True, verbose=True, warmstart=False, numItermax=10)\n\nprint('Fused Gromov-Wasserstein distance estimated with Conditional Gradient solver: ' + str(log0['fgw_dist']))\nprint('Fused Gromov-Wasserstein distance estimated with Proximal Point solver: ' + str(log['fgw_dist']))\nprint('Entropic Fused Gromov-Wasserstein distance estimated with Projected Gradient solver: ' + str(loge['fgw_dist']))\n\n# compute OT sparsity level\nfgw0_sparsity = 100 * (fgw0 == 0.).astype(np.float64).sum() / (N2 * N3)\nfgw_sparsity = 100 * (fgw == 0.).astype(np.float64).sum() / (N2 * N3)\nfgwe_sparsity = 100 * (fgwe == 0.).astype(np.float64).sum() / (N2 * N3)\n\n# Methods using Sinkhorn projections tend to produce feasibility errors on the\n# marginal constraints\n\nerr0 = np.linalg.norm(fgw0.sum(1) - h2) + np.linalg.norm(fgw0.sum(0) - h3)\nerr = np.linalg.norm(fgw.sum(1) - h2) + np.linalg.norm(fgw.sum(0) - h3)\nerre = np.linalg.norm(fgwe.sum(1) - h2) + np.linalg.norm(fgwe.sum(0) - h3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization of the Fused Gromov-Wasserstein matchings\n\nWe color nodes of the graph on the right - then project its node colors\nbased on the optimal transport plan from the FGW matchings\nWe adjust the intensity of links across domains proportionaly to the mass\nsent, adding a minimal intensity of 0.1 if mass sent is not zero.\nFor each matching, all node sizes are proportionnal to their mass computed\nfrom marginals of the OT plan to illustrate potential feasibility errors.\nNB: colors refer to clusters - not to node features\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Add weights on the edges for visualization later on\nweight_intra_G2 = 5\nweight_inter_G2 = 0.5\nweight_intra_G3 = 1.\nweight_inter_G3 = 1.5\n\nweightedG2 = networkx.Graph()\npart_G2 = [G2.nodes[i]['block'] for i in range(N2)]\n\nfor node in G2.nodes():\n    weightedG2.add_node(node)\nfor i, j in G2.edges():\n    if part_G2[i] == part_G2[j]:\n        weightedG2.add_edge(i, j, weight=weight_intra_G2)\n    else:\n        weightedG2.add_edge(i, j, weight=weight_inter_G2)\n\nweightedG3 = networkx.Graph()\npart_G3 = [G3.nodes[i]['block'] for i in range(N3)]\n\nfor node in G3.nodes():\n    weightedG3.add_node(node)\nfor i, j in G3.edges():\n    if part_G3[i] == part_G3[j]:\n        weightedG3.add_edge(i, j, weight=weight_intra_G3)\n    else:\n        weightedG3.add_edge(i, j, weight=weight_inter_G3)\n\n\ndef draw_graph(G, C, nodes_color_part, Gweights=None,\n               pos=None, edge_color='black', node_size=None,\n               shiftx=0, seed=0):\n\n    if (pos is None):\n        pos = networkx.spring_layout(G, scale=1., seed=seed)\n\n    if shiftx != 0:\n        for k, v in pos.items():\n            v[0] = v[0] + shiftx\n\n    alpha_edge = 0.7\n    width_edge = 1.8\n    if Gweights is None:\n        networkx.draw_networkx_edges(G, pos, width=width_edge, alpha=alpha_edge, edge_color=edge_color)\n    else:\n        # We make more visible connections between activated nodes\n        n = len(Gweights)\n        edgelist_activated = []\n        edgelist_deactivated = []\n        for i in range(n):\n            for j in range(n):\n                if Gweights[i] * Gweights[j] * C[i, j] > 0:\n                    edgelist_activated.append((i, j))\n                elif C[i, j] > 0:\n                    edgelist_deactivated.append((i, j))\n\n        networkx.draw_networkx_edges(G, pos, edgelist=edgelist_activated,\n                                     width=width_edge, alpha=alpha_edge,\n                                     edge_color=edge_color)\n        networkx.draw_networkx_edges(G, pos, edgelist=edgelist_deactivated,\n                                     width=width_edge, alpha=0.1,\n                                     edge_color=edge_color)\n\n    if Gweights is None:\n        for node, node_color in enumerate(nodes_color_part):\n            networkx.draw_networkx_nodes(G, pos, nodelist=[node],\n                                         node_size=node_size, alpha=1,\n                                         node_color=node_color)\n    else:\n        scaled_Gweights = Gweights / (0.5 * Gweights.max())\n        nodes_size = node_size * scaled_Gweights\n        for node, node_color in enumerate(nodes_color_part):\n            networkx.draw_networkx_nodes(G, pos, nodelist=[node],\n                                         node_size=nodes_size[node], alpha=1,\n                                         node_color=node_color)\n    return pos\n\n\ndef draw_transp_colored_GW(G1, C1, G2, C2, part_G1, p1, p2, T,\n                           pos1=None, pos2=None, shiftx=4, switchx=False,\n                           node_size=70, seed_G1=0, seed_G2=0):\n    starting_color = 0\n    # get graphs partition and their coloring\n    part1 = part_G1.copy()\n    unique_colors = ['C%s' % (starting_color + i) for i in np.unique(part1)]\n    nodes_color_part1 = []\n    for cluster in part1:\n        nodes_color_part1.append(unique_colors[cluster])\n\n    nodes_color_part2 = []\n    # T: getting colors assignment from argmin of columns\n    for i in range(len(G2.nodes())):\n        j = np.argmax(T[:, i])\n        nodes_color_part2.append(nodes_color_part1[j])\n    pos1 = draw_graph(G1, C1, nodes_color_part1, Gweights=p1,\n                      pos=pos1, node_size=node_size, shiftx=0, seed=seed_G1)\n    pos2 = draw_graph(G2, C2, nodes_color_part2, Gweights=p2, pos=pos2,\n                      node_size=node_size, shiftx=shiftx, seed=seed_G2)\n\n    for k1, v1 in pos1.items():\n        max_Tk1 = np.max(T[k1, :])\n        for k2, v2 in pos2.items():\n            if (T[k1, k2] > 0):\n                pl.plot([pos1[k1][0], pos2[k2][0]],\n                        [pos1[k1][1], pos2[k2][1]],\n                        '-', lw=0.7, alpha=min(T[k1, k2] / max_Tk1 + 0.1, 1.),\n                        color=nodes_color_part1[k1])\n    return pos1, pos2\n\n\nnode_size = 40\nfontsize = 13\nseed_G2 = 0\nseed_G3 = 4\n\npl.figure(2, figsize=(12, 3.5))\npl.clf()\npl.subplot(131)\npl.axis('off')\npl.axis\npl.title('(CG algo) FGW=%s \\n \\n OT sparsity = %s \\n feasibility error = %s' % (\n    np.round(log0['fgw_dist'], 3), str(np.round(fgw0_sparsity, 2)) + ' %',\n    np.round(err0, 4)), fontsize=fontsize)\n\np0, q0 = fgw0.sum(1), fgw0.sum(0)  # check marginals\n\npos1, pos2 = draw_transp_colored_GW(\n    weightedG2, C2, weightedG3, C3, part_G2, p1=p0, p2=q0, T=fgw0,\n    shiftx=1.5, node_size=node_size, seed_G1=seed_G2, seed_G2=seed_G3)\n\npl.subplot(132)\npl.axis('off')\n\np, q = fgw.sum(1), fgw.sum(0)  # check marginals\n\npl.title('(PP algo) FGW=%s\\n \\n OT sparsity = %s \\n feasibility error = %s' % (\n    np.round(log['fgw_dist'], 3), str(np.round(fgw_sparsity, 2)) + ' %',\n    np.round(err, 4)), fontsize=fontsize)\n\npos1, pos2 = draw_transp_colored_GW(\n    weightedG2, C2, weightedG3, C3, part_G2, p1=p, p2=q, T=fgw,\n    pos1=pos1, pos2=pos2, shiftx=0., node_size=node_size, seed_G1=0, seed_G2=0)\n\npl.subplot(133)\npl.axis('off')\n\npe, qe = fgwe.sum(1), fgwe.sum(0)  # check marginals\n\npl.title('Entropic FGW=%s\\n \\n OT sparsity = %s \\n feasibility error = %s' % (\n    np.round(loge['fgw_dist'], 3), str(np.round(fgwe_sparsity, 2)) + ' %',\n    np.round(erre, 4)), fontsize=fontsize)\n\npos1, pos2 = draw_transp_colored_GW(\n    weightedG2, C2, weightedG3, C3, part_G2, p1=pe, p2=qe, T=fgwe,\n    pos1=pos1, pos2=pos2, shiftx=0., node_size=node_size, seed_G1=0, seed_G2=0)\n\npl.tight_layout()\n\npl.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}