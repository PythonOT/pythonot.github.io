

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>ot.gromov &mdash; POT Python Optimal Transport 0.7.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-rendered-html.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> POT Python Optimal Transport
          

          
          </a>

          
            
            
              <div class="version">
                0.7.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">POT: Python Optimal Transport</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quick start guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../all.html">API and modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Examples gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../releases.html">Releases</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">POT Python Optimal Transport</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>ot.gromov</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for ot.gromov</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Gromov-Wasserstein and Fused-Gromov-Wasserstein solvers</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Author: Erwan Vautier &lt;erwan.vautier@gmail.com&gt;</span>
<span class="c1">#         Nicolas Courty &lt;ncourty@irisa.fr&gt;</span>
<span class="c1">#         Rémi Flamary &lt;remi.flamary@unice.fr&gt;</span>
<span class="c1">#         Titouan Vayer &lt;titouan.vayer@irisa.fr&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: MIT License</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="kn">from</span> <span class="nn">.bregman</span> <span class="kn">import</span> <span class="n">sinkhorn</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">dist</span><span class="p">,</span> <span class="n">UndefinedParameter</span>
<span class="kn">from</span> <span class="nn">.optim</span> <span class="kn">import</span> <span class="n">cg</span>


<div class="viewcode-block" id="init_matrix"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.init_matrix">[docs]</a><span class="k">def</span> <span class="nf">init_matrix</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="s1">&#39;square_loss&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return loss matrices and tensors for Gromov-Wasserstein fast computation</span>

<span class="sd">    Returns the value of \mathcal{L}(C1,C2) \otimes T with the selected loss</span>
<span class="sd">    function as the loss function of Gromow-Wasserstein discrepancy.</span>

<span class="sd">    The matrices are computed as described in Proposition 1 in [12]</span>

<span class="sd">    Where :</span>
<span class="sd">        * C1 : Metric cost matrix in the source space</span>
<span class="sd">        * C2 : Metric cost matrix in the target space</span>
<span class="sd">        * T : A coupling between those two spaces</span>

<span class="sd">    The square-loss function L(a,b)=|a-b|^2 is read as :</span>
<span class="sd">        L(a,b) = f1(a)+f2(b)-h1(a)*h2(b) with :</span>
<span class="sd">            * f1(a)=(a^2)</span>
<span class="sd">            * f2(b)=(b^2)</span>
<span class="sd">            * h1(a)=a</span>
<span class="sd">            * h2(b)=2*b</span>

<span class="sd">    The kl-loss function L(a,b)=a*log(a/b)-a+b is read as :</span>
<span class="sd">        L(a,b) = f1(a)+f2(b)-h1(a)*h2(b) with :</span>
<span class="sd">            * f1(a)=a*log(a)-a</span>
<span class="sd">            * f2(b)=b</span>
<span class="sd">            * h1(a)=a</span>
<span class="sd">            * h2(b)=log(b)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : ndarray, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : ndarray, shape (nt, nt)</span>
<span class="sd">        Metric costfr matrix in the target space</span>
<span class="sd">    T :  ndarray, shape (ns, nt)</span>
<span class="sd">        Coupling between source and target spaces</span>
<span class="sd">    p : ndarray, shape (ns,)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    constC : ndarray, shape (ns, nt)</span>
<span class="sd">        Constant C matrix in Eq. (6)</span>
<span class="sd">    hC1 : ndarray, shape (ns, ns)</span>
<span class="sd">        h1(C1) matrix in Eq. (6)</span>
<span class="sd">    hC2 : ndarray, shape (nt, nt)</span>
<span class="sd">        h2(C) matrix in Eq. (6)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;square_loss&#39;</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">f1</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">a</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">f2</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">b</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">h1</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">a</span>

        <span class="k">def</span> <span class="nf">h2</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">b</span>
    <span class="k">elif</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;kl_loss&#39;</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">f1</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="mf">1e-15</span><span class="p">)</span> <span class="o">-</span> <span class="n">a</span>

        <span class="k">def</span> <span class="nf">f2</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">b</span>

        <span class="k">def</span> <span class="nf">h1</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">a</span>

        <span class="k">def</span> <span class="nf">h2</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="mf">1e-15</span><span class="p">)</span>

    <span class="n">constC1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">f1</span><span class="p">(</span><span class="n">C1</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">constC2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">f2</span><span class="p">(</span><span class="n">C2</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
    <span class="n">constC</span> <span class="o">=</span> <span class="n">constC1</span> <span class="o">+</span> <span class="n">constC2</span>
    <span class="n">hC1</span> <span class="o">=</span> <span class="n">h1</span><span class="p">(</span><span class="n">C1</span><span class="p">)</span>
    <span class="n">hC2</span> <span class="o">=</span> <span class="n">h2</span><span class="p">(</span><span class="n">C2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span></div>


<div class="viewcode-block" id="tensor_product"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.tensor_product">[docs]</a><span class="k">def</span> <span class="nf">tensor_product</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return the tensor for Gromov-Wasserstein fast computation</span>

<span class="sd">    The tensor is computed as described in Proposition 1 Eq. (6) in [12].</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    constC : ndarray, shape (ns, nt)</span>
<span class="sd">        Constant C matrix in Eq. (6)</span>
<span class="sd">    hC1 : ndarray, shape (ns, ns)</span>
<span class="sd">        h1(C1) matrix in Eq. (6)</span>
<span class="sd">    hC2 : ndarray, shape (nt, nt)</span>
<span class="sd">        h2(C) matrix in Eq. (6)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tens : ndarray, shape (ns, nt)</span>
<span class="sd">        \mathcal{L}(C1,C2) \otimes T tensor-matrix multiplication result</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">A</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hC1</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hC2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">tens</span> <span class="o">=</span> <span class="n">constC</span> <span class="o">+</span> <span class="n">A</span>
    <span class="c1"># tens -= tens.min()</span>
    <span class="k">return</span> <span class="n">tens</span></div>


<div class="viewcode-block" id="gwloss"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.gwloss">[docs]</a><span class="k">def</span> <span class="nf">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return the Loss for Gromov-Wasserstein</span>

<span class="sd">    The loss is computed as described in Proposition 1 Eq. (6) in [12].</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    constC : ndarray, shape (ns, nt)</span>
<span class="sd">        Constant C matrix in Eq. (6)</span>
<span class="sd">    hC1 : ndarray, shape (ns, ns)</span>
<span class="sd">        h1(C1) matrix in Eq. (6)</span>
<span class="sd">    hC2 : ndarray, shape (nt, nt)</span>
<span class="sd">        h2(C) matrix in Eq. (6)</span>
<span class="sd">    T : ndarray, shape (ns, nt)</span>
<span class="sd">        Current value of transport matrix T</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    loss : float</span>
<span class="sd">        Gromov Wasserstein loss</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">tens</span> <span class="o">=</span> <span class="n">tensor_product</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tens</span> <span class="o">*</span> <span class="n">T</span><span class="p">)</span></div>


<div class="viewcode-block" id="gwggrad"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.gwggrad">[docs]</a><span class="k">def</span> <span class="nf">gwggrad</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return the gradient for Gromov-Wasserstein</span>

<span class="sd">    The gradient is computed as described in Proposition 2 in [12].</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    constC : ndarray, shape (ns, nt)</span>
<span class="sd">        Constant C matrix in Eq. (6)</span>
<span class="sd">    hC1 : ndarray, shape (ns, ns)</span>
<span class="sd">        h1(C1) matrix in Eq. (6)</span>
<span class="sd">    hC2 : ndarray, shape (nt, nt)</span>
<span class="sd">        h2(C) matrix in Eq. (6)</span>
<span class="sd">    T : ndarray, shape (ns, nt)</span>
<span class="sd">        Current value of transport matrix T</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    grad : ndarray, shape (ns, nt)</span>
<span class="sd">           Gromov Wasserstein gradient</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">tensor_product</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span>
                              <span class="n">T</span><span class="p">)</span>  <span class="c1"># [12] Prop. 2 misses a 2 factor</span></div>


<div class="viewcode-block" id="update_square_loss"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.update_square_loss">[docs]</a><span class="k">def</span> <span class="nf">update_square_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updates C according to the L2 Loss kernel with the S Ts couplings</span>
<span class="sd">    calculated at each iteration</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p : ndarray, shape (N,)</span>
<span class="sd">        Masses in the targeted barycenter.</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the S spaces&#39; weights.</span>
<span class="sd">    T : list of S np.ndarray of shape (ns,N)</span>
<span class="sd">        The S Ts couplings calculated at each iteration.</span>
<span class="sd">    Cs : list of S ndarray, shape(ns,ns)</span>
<span class="sd">        Metric cost matrices.</span>

<span class="sd">    Returns</span>
<span class="sd">    ----------</span>
<span class="sd">    C : ndarray, shape (nt, nt)</span>
<span class="sd">        Updated C matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tmpsum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">lambdas</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">])</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">s</span><span class="p">])</span>
                  <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">T</span><span class="p">))])</span>
    <span class="n">ppt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">tmpsum</span><span class="p">,</span> <span class="n">ppt</span><span class="p">)</span></div>


<div class="viewcode-block" id="update_kl_loss"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.update_kl_loss">[docs]</a><span class="k">def</span> <span class="nf">update_kl_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updates C according to the KL Loss kernel with the S Ts couplings calculated at each iteration</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p  : ndarray, shape (N,)</span>
<span class="sd">        Weights in the targeted barycenter.</span>
<span class="sd">    lambdas : list of the S spaces&#39; weights</span>
<span class="sd">    T : list of S np.ndarray of shape (ns,N)</span>
<span class="sd">        The S Ts couplings calculated at each iteration.</span>
<span class="sd">    Cs : list of S ndarray, shape(ns,ns)</span>
<span class="sd">        Metric cost matrices.</span>

<span class="sd">    Returns</span>
<span class="sd">    ----------</span>
<span class="sd">    C : ndarray, shape (ns,ns)</span>
<span class="sd">        updated C matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tmpsum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">lambdas</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">])</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">s</span><span class="p">])</span>
                  <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">T</span><span class="p">))])</span>
    <span class="n">ppt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">tmpsum</span><span class="p">,</span> <span class="n">ppt</span><span class="p">))</span></div>


<div class="viewcode-block" id="gromov_wasserstein"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.gromov_wasserstein">[docs]</a><span class="k">def</span> <span class="nf">gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the gromov-wasserstein transport between (C1,p) and (C2,q)</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        GW = \min_T \sum_{i,j,k,l} L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}</span>

<span class="sd">    Where :</span>
<span class="sd">    - C1 : Metric cost matrix in the source space</span>
<span class="sd">    - C2 : Metric cost matrix in the target space</span>
<span class="sd">    - p  : distribution in the source space</span>
<span class="sd">    - q  : distribution in the target space</span>
<span class="sd">    - L  : loss function to account for the misfit between the similarity matrices</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : ndarray, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : ndarray, shape (nt, nt)</span>
<span class="sd">        Metric costfr matrix in the target space</span>
<span class="sd">    p : ndarray, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q : ndarray, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    loss_fun : str</span>
<span class="sd">        loss function used for the solver either &#39;square_loss&#39; or &#39;kl_loss&#39;</span>

<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>
<span class="sd">    armijo : bool, optional</span>
<span class="sd">        If True the steps of the line-search is found via an armijo research. Else closed form is used.</span>
<span class="sd">        If there is convergence issues use False.</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        parameters can be directly passed to the ot.optim.cg solver</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    T : ndarray, shape (ns, nt)</span>
<span class="sd">        Doupling between the two spaces that minimizes:</span>
<span class="sd">            \sum_{i,j,k,l} L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}</span>
<span class="sd">    log : dict</span>
<span class="sd">        Convergence information and loss.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    .. [13] Mémoli, Facundo. Gromov–Wasserstein distances and the</span>
<span class="sd">        metric approach to object matching. Foundations of computational</span>
<span class="sd">        mathematics 11.4 (2011): 417-487.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span> <span class="o">=</span> <span class="n">init_matrix</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">)</span>

    <span class="n">G0</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwggrad</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">res</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="n">armijo</span><span class="p">,</span> <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">constC</span><span class="o">=</span><span class="n">constC</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span><span class="p">,</span> <span class="n">log</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cg</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="n">armijo</span><span class="p">,</span> <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">constC</span><span class="o">=</span><span class="n">constC</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="gromov_wasserstein2"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.gromov_wasserstein2">[docs]</a><span class="k">def</span> <span class="nf">gromov_wasserstein2</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the gromov-wasserstein discrepancy between (C1,p) and (C2,q)</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        GW = \min_T \sum_{i,j,k,l} L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}</span>

<span class="sd">    Where :</span>
<span class="sd">    - C1 : Metric cost matrix in the source space</span>
<span class="sd">    - C2 : Metric cost matrix in the target space</span>
<span class="sd">    - p  : distribution in the source space</span>
<span class="sd">    - q  : distribution in the target space</span>
<span class="sd">    - L  : loss function to account for the misfit between the similarity matrices</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : ndarray, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : ndarray, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix in the target space</span>
<span class="sd">    p : ndarray, shape (ns,)</span>
<span class="sd">        Distribution in the source space.</span>
<span class="sd">    q :  ndarray, shape (nt,)</span>
<span class="sd">        Distribution in the target space.</span>
<span class="sd">    loss_fun :  str</span>
<span class="sd">        loss function used for the solver either &#39;square_loss&#39; or &#39;kl_loss&#39;</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>
<span class="sd">    armijo : bool, optional</span>
<span class="sd">        If True the steps of the line-search is found via an armijo research. Else closed form is used.</span>
<span class="sd">        If there is convergence issues use False.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gw_dist : float</span>
<span class="sd">        Gromov-Wasserstein distance</span>
<span class="sd">    log : dict</span>
<span class="sd">        convergence information and Coupling marix</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    .. [13] Mémoli, Facundo. Gromov–Wasserstein distances and the</span>
<span class="sd">        metric approach to object matching. Foundations of computational</span>
<span class="sd">        mathematics 11.4 (2011): 417-487.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span> <span class="o">=</span> <span class="n">init_matrix</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">)</span>

    <span class="n">G0</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwggrad</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>
    <span class="n">res</span><span class="p">,</span> <span class="n">log_gw</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="n">armijo</span><span class="p">,</span> <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">constC</span><span class="o">=</span><span class="n">constC</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>
    <span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span>
    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">],</span> <span class="n">log_gw</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">]</span></div>


<div class="viewcode-block" id="fused_gromov_wasserstein"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.fused_gromov_wasserstein">[docs]</a><span class="k">def</span> <span class="nf">fused_gromov_wasserstein</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="s1">&#39;square_loss&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the FGW transport between two graphs see [24]</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = arg\min_\gamma (1-\\alpha)*&lt;\gamma,M&gt;_F + \\alpha* \sum_{i,j,k,l}</span>
<span class="sd">        L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}</span>

<span class="sd">        s.t. \gamma 1 = p</span>
<span class="sd">             \gamma^T 1= q</span>
<span class="sd">             \gamma\geq 0</span>

<span class="sd">    where :</span>
<span class="sd">    - M is the (ns,nt) metric cost matrix</span>
<span class="sd">    - p and q are source and target weights (sum to 1)</span>
<span class="sd">    - L is a loss function to account for the misfit between the similarity matrices</span>

<span class="sd">    The algorithm used for solving the problem is conditional gradient as discussed in  [24]_</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    M : ndarray, shape (ns, nt)</span>
<span class="sd">        Metric cost matrix between features across domains</span>
<span class="sd">    C1 : ndarray, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix representative of the structure in the source space</span>
<span class="sd">    C2 : ndarray, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix representative of the structure in the target space</span>
<span class="sd">    p : ndarray, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q : ndarray, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    loss_fun : str, optional</span>
<span class="sd">        Loss function used for the solver</span>
<span class="sd">    alpha : float, optional</span>
<span class="sd">        Trade-off parameter (0 &lt; alpha &lt; 1)</span>
<span class="sd">    armijo : bool, optional</span>
<span class="sd">        If True the steps of the line-search is found via an armijo research. Else closed form is used.</span>
<span class="sd">        If there is convergence issues use False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        parameters can be directly passed to the ot.optim.cg solver</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : ndarray, shape (ns, nt)</span>
<span class="sd">        Optimal transportation matrix for the given parameters.</span>
<span class="sd">    log : dict</span>
<span class="sd">        Log dictionary return only if log==True in parameters.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [24] Vayer Titouan, Chapel Laetitia, Flamary R{\&#39;e}mi, Tavenard Romain</span>
<span class="sd">        and Courty Nicolas &quot;Optimal Transport for structured data with</span>
<span class="sd">        application on graphs&quot;, International Conference on Machine Learning</span>
<span class="sd">        (ICML). 2019.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span> <span class="o">=</span> <span class="n">init_matrix</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">)</span>

    <span class="n">G0</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwggrad</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">res</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">M</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="n">armijo</span><span class="p">,</span> <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">constC</span><span class="o">=</span><span class="n">constC</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;fgw_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">res</span><span class="p">,</span> <span class="n">log</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cg</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">M</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="n">armijo</span><span class="p">,</span> <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">constC</span><span class="o">=</span><span class="n">constC</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="fused_gromov_wasserstein2"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.fused_gromov_wasserstein2">[docs]</a><span class="k">def</span> <span class="nf">fused_gromov_wasserstein2</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="s1">&#39;square_loss&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the FGW distance between two graphs see [24]</span>

<span class="sd">    .. math::</span>
<span class="sd">        \min_\gamma (1-\\alpha)*&lt;\gamma,M&gt;_F + \\alpha* \sum_{i,j,k,l}</span>
<span class="sd">        L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}</span>


<span class="sd">        s.t. \gamma 1 = p</span>
<span class="sd">             \gamma^T 1= q</span>
<span class="sd">             \gamma\geq 0</span>

<span class="sd">    where :</span>
<span class="sd">    - M is the (ns,nt) metric cost matrix</span>
<span class="sd">    - p and q are source and target weights (sum to 1)</span>
<span class="sd">    - L is a loss function to account for the misfit between the similarity matrices</span>
<span class="sd">    The algorithm used for solving the problem is conditional gradient as discussed in  [1]_</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    M : ndarray, shape (ns, nt)</span>
<span class="sd">        Metric cost matrix between features across domains</span>
<span class="sd">    C1 : ndarray, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix respresentative of the structure in the source space.</span>
<span class="sd">    C2 : ndarray, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix espresentative of the structure in the target space.</span>
<span class="sd">    p :  ndarray, shape (ns,)</span>
<span class="sd">        Distribution in the source space.</span>
<span class="sd">    q :  ndarray, shape (nt,)</span>
<span class="sd">        Distribution in the target space.</span>
<span class="sd">    loss_fun : str, optional</span>
<span class="sd">        Loss function used for the solver.</span>
<span class="sd">    alpha : float, optional</span>
<span class="sd">        Trade-off parameter (0 &lt; alpha &lt; 1)</span>
<span class="sd">    armijo : bool, optional</span>
<span class="sd">        If True the steps of the line-search is found via an armijo research.</span>
<span class="sd">        Else closed form is used. If there is convergence issues use False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Record log if True.</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        Parameters can be directly pased to the ot.optim.cg solver.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : ndarray, shape (ns, nt)</span>
<span class="sd">        Optimal transportation matrix for the given parameters.</span>
<span class="sd">    log : dict</span>
<span class="sd">        Log dictionary return only if log==True in parameters.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [24] Vayer Titouan, Chapel Laetitia, Flamary R{\&#39;e}mi, Tavenard Romain</span>
<span class="sd">        and Courty Nicolas</span>
<span class="sd">        &quot;Optimal Transport for structured data with application on graphs&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2019.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span> <span class="o">=</span> <span class="n">init_matrix</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">)</span>

    <span class="n">G0</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwggrad</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="n">res</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">M</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="n">armijo</span><span class="p">,</span> <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">constC</span><span class="o">=</span><span class="n">constC</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;fgw_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span>
        <span class="k">return</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;fgw_dist&#39;</span><span class="p">],</span> <span class="n">log</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;fgw_dist&#39;</span><span class="p">]</span></div>


<div class="viewcode-block" id="entropic_gromov_wasserstein"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.entropic_gromov_wasserstein">[docs]</a><span class="k">def</span> <span class="nf">entropic_gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span>
                                <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the gromov-wasserstein transport between (C1,p) and (C2,q)</span>

<span class="sd">    (C1,p) and (C2,q)</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        GW = arg\min_T \sum_{i,j,k,l} L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}-\epsilon(H(T))</span>

<span class="sd">        s.t. T 1 = p</span>

<span class="sd">             T^T 1= q</span>

<span class="sd">             T\geq 0</span>

<span class="sd">    Where :</span>
<span class="sd">    - C1 : Metric cost matrix in the source space</span>
<span class="sd">    - C2 : Metric cost matrix in the target space</span>
<span class="sd">    - p  : distribution in the source space</span>
<span class="sd">    - q  : distribution in the target space</span>
<span class="sd">    - L  : loss function to account for the misfit between the similarity matrices</span>
<span class="sd">    - H  : entropy</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : ndarray, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : ndarray, shape (nt, nt)</span>
<span class="sd">        Metric costfr matrix in the target space</span>
<span class="sd">    p :  ndarray, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q :  ndarray, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    loss_fun :  string</span>
<span class="sd">        Loss function used for the solver either &#39;square_loss&#39; or &#39;kl_loss&#39;</span>
<span class="sd">    epsilon : float</span>
<span class="sd">        Regularization term &gt;0</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Record log if True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    T : ndarray, shape (ns, nt)</span>
<span class="sd">        Optimal coupling between the two spaces</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">C1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">C2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">C2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>  <span class="c1"># Initialization</span>

    <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span> <span class="o">=</span> <span class="n">init_matrix</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">)</span>

    <span class="n">cpt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">err</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;err&#39;</span><span class="p">:</span> <span class="p">[]}</span>

    <span class="k">while</span> <span class="p">(</span><span class="n">err</span> <span class="o">&gt;</span> <span class="n">tol</span> <span class="ow">and</span> <span class="n">cpt</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">):</span>

        <span class="n">Tprev</span> <span class="o">=</span> <span class="n">T</span>

        <span class="c1"># compute the gradient</span>
        <span class="n">tens</span> <span class="o">=</span> <span class="n">gwggrad</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>

        <span class="n">T</span> <span class="o">=</span> <span class="n">sinkhorn</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">tens</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># we can speed up the process by checking for the error only all</span>
            <span class="c1"># the 10th iterations</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">T</span> <span class="o">-</span> <span class="n">Tprev</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="n">log</span><span class="p">[</span><span class="s1">&#39;err&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Err&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">19</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>

        <span class="n">cpt</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">T</span><span class="p">,</span> <span class="n">log</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">T</span></div>


<div class="viewcode-block" id="entropic_gromov_wasserstein2"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.entropic_gromov_wasserstein2">[docs]</a><span class="k">def</span> <span class="nf">entropic_gromov_wasserstein2</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span>
                                 <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the entropic gromov-wasserstein discrepancy between the two measured similarity matrices</span>

<span class="sd">    (C1,p) and (C2,q)</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        GW = \min_T \sum_{i,j,k,l} L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}-\epsilon(H(T))</span>

<span class="sd">    Where :</span>
<span class="sd">    - C1 : Metric cost matrix in the source space</span>
<span class="sd">    - C2 : Metric cost matrix in the target space</span>
<span class="sd">    - p  : distribution in the source space</span>
<span class="sd">    - q  : distribution in the target space</span>
<span class="sd">    - L  : loss function to account for the misfit between the similarity matrices</span>
<span class="sd">    - H  : entropy</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : ndarray, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : ndarray, shape (nt, nt)</span>
<span class="sd">        Metric costfr matrix in the target space</span>
<span class="sd">    p :  ndarray, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q :  ndarray, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    loss_fun : str</span>
<span class="sd">        Loss function used for the solver either &#39;square_loss&#39; or &#39;kl_loss&#39;</span>
<span class="sd">    epsilon : float</span>
<span class="sd">        Regularization term &gt;0</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Record log if True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gw_dist : float</span>
<span class="sd">        Gromov-Wasserstein distance</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">gw</span><span class="p">,</span> <span class="n">logv</span> <span class="o">=</span> <span class="n">entropic_gromov_wasserstein</span><span class="p">(</span>
        <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">logv</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gw</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">logv</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">],</span> <span class="n">logv</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">logv</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">]</span></div>


<div class="viewcode-block" id="entropic_gromov_barycenters"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.entropic_gromov_barycenters">[docs]</a><span class="k">def</span> <span class="nf">entropic_gromov_barycenters</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Cs</span><span class="p">,</span> <span class="n">ps</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span>
                                <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">init_C</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the gromov-wasserstein barycenters of S measured similarity matrices</span>

<span class="sd">    (Cs)_{s=1}^{s=S}</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        C = argmin_{C\in R^{NxN}} \sum_s \lambda_s GW(C,C_s,p,p_s)</span>


<span class="sd">    Where :</span>

<span class="sd">    - :math:`C_s` : metric cost matrix</span>
<span class="sd">    - :math:`p_s`  : distribution</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    N : int</span>
<span class="sd">        Size of the targeted barycenter</span>
<span class="sd">    Cs : list of S np.ndarray of shape (ns,ns)</span>
<span class="sd">        Metric cost matrices</span>
<span class="sd">    ps : list of S np.ndarray of shape (ns,)</span>
<span class="sd">        Sample weights in the S spaces</span>
<span class="sd">    p : ndarray, shape(N,)</span>
<span class="sd">        Weights in the targeted barycenter</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the S spaces&#39; weights.</span>
<span class="sd">    loss_fun : callable</span>
<span class="sd">        Tensor-matrix multiplication function based on specific loss function.</span>
<span class="sd">    update : callable</span>
<span class="sd">        function(p,lambdas,T,Cs) that updates C according to a specific Kernel</span>
<span class="sd">        with the S Ts couplings calculated at each iteration</span>
<span class="sd">    epsilon : float</span>
<span class="sd">        Regularization term &gt;0</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshol on error (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Record log if True.</span>
<span class="sd">    init_C : bool | ndarray, shape (N, N)</span>
<span class="sd">        Random initial value for the C matrix provided by user.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    C : ndarray, shape (N, N)</span>
<span class="sd">        Similarity matrix in the barycenter space (permutated arbitrarily)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">S</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Cs</span><span class="p">)</span>

    <span class="n">Cs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">)]</span>
    <span class="n">lambdas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">lambdas</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="c1"># Initialization of C : random SPD matrix (if not provided by user)</span>
    <span class="k">if</span> <span class="n">init_C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># XXX use random state</span>
        <span class="n">xalea</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">xalea</span><span class="p">,</span> <span class="n">xalea</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">/=</span> <span class="n">C</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">init_C</span>

    <span class="n">cpt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">err</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">error</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">while</span> <span class="p">(</span><span class="n">err</span> <span class="o">&gt;</span> <span class="n">tol</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">cpt</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">):</span>
        <span class="n">Cprev</span> <span class="o">=</span> <span class="n">C</span>

        <span class="n">T</span> <span class="o">=</span> <span class="p">[</span><span class="n">entropic_gromov_wasserstein</span><span class="p">(</span><span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">C</span><span class="p">,</span> <span class="n">ps</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">p</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span>
                                         <span class="n">max_iter</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;square_loss&#39;</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">update_square_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;kl_loss&#39;</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">update_kl_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># we can speed up the process by checking for the error only all</span>
            <span class="c1"># the 10th iterations</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">C</span> <span class="o">-</span> <span class="n">Cprev</span><span class="p">)</span>
            <span class="n">error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="n">log</span><span class="p">[</span><span class="s1">&#39;err&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Err&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">19</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>

        <span class="n">cpt</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">C</span></div>


<div class="viewcode-block" id="gromov_barycenters"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.gromov_barycenters">[docs]</a><span class="k">def</span> <span class="nf">gromov_barycenters</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Cs</span><span class="p">,</span> <span class="n">ps</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span>
                       <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">init_C</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the gromov-wasserstein barycenters of S measured similarity matrices</span>

<span class="sd">    (Cs)_{s=1}^{s=S}</span>

<span class="sd">    The function solves the following optimization problem with block</span>
<span class="sd">    coordinate descent:</span>

<span class="sd">    .. math::</span>
<span class="sd">        C = argmin_C\in R^NxN \sum_s \lambda_s GW(C,Cs,p,ps)</span>

<span class="sd">    Where :</span>

<span class="sd">    - Cs : metric cost matrix</span>
<span class="sd">    - ps  : distribution</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    N : int</span>
<span class="sd">        Size of the targeted barycenter</span>
<span class="sd">    Cs : list of S np.ndarray of shape (ns, ns)</span>
<span class="sd">        Metric cost matrices</span>
<span class="sd">    ps : list of S np.ndarray of shape (ns,)</span>
<span class="sd">        Sample weights in the S spaces</span>
<span class="sd">    p : ndarray, shape (N,)</span>
<span class="sd">        Weights in the targeted barycenter</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the S spaces&#39; weights</span>
<span class="sd">    loss_fun :  tensor-matrix multiplication function based on specific loss function</span>
<span class="sd">    update : function(p,lambdas,T,Cs) that updates C according to a specific Kernel</span>
<span class="sd">             with the S Ts couplings calculated at each iteration</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshol on error (&gt;0).</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Record log if True.</span>
<span class="sd">    init_C : bool | ndarray, shape(N,N)</span>
<span class="sd">        Random initial value for the C matrix provided by user.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    C : ndarray, shape (N, N)</span>
<span class="sd">        Similarity matrix in the barycenter space (permutated arbitrarily)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">S</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Cs</span><span class="p">)</span>

    <span class="n">Cs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">)]</span>
    <span class="n">lambdas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">lambdas</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="c1"># Initialization of C : random SPD matrix (if not provided by user)</span>
    <span class="k">if</span> <span class="n">init_C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># XXX : should use a random state and not use the global seed</span>
        <span class="n">xalea</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">xalea</span><span class="p">,</span> <span class="n">xalea</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">/=</span> <span class="n">C</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">init_C</span>

    <span class="n">cpt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">err</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">error</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">while</span><span class="p">(</span><span class="n">err</span> <span class="o">&gt;</span> <span class="n">tol</span> <span class="ow">and</span> <span class="n">cpt</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">):</span>
        <span class="n">Cprev</span> <span class="o">=</span> <span class="n">C</span>

        <span class="n">T</span> <span class="o">=</span> <span class="p">[</span><span class="n">gromov_wasserstein</span><span class="p">(</span><span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">C</span><span class="p">,</span> <span class="n">ps</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">p</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span>
                                <span class="n">numItermax</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;square_loss&#39;</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">update_square_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;kl_loss&#39;</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">update_kl_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># we can speed up the process by checking for the error only all</span>
            <span class="c1"># the 10th iterations</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">C</span> <span class="o">-</span> <span class="n">Cprev</span><span class="p">)</span>
            <span class="n">error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="n">log</span><span class="p">[</span><span class="s1">&#39;err&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Err&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">19</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>

        <span class="n">cpt</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">C</span></div>


<div class="viewcode-block" id="fgw_barycenters"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.fgw_barycenters">[docs]</a><span class="k">def</span> <span class="nf">fgw_barycenters</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Ys</span><span class="p">,</span> <span class="n">Cs</span><span class="p">,</span> <span class="n">ps</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">fixed_structure</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fixed_features</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">p</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="s1">&#39;square_loss&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">init_C</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init_X</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the fgw barycenter as presented eq (5) in [24].</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    N : integer</span>
<span class="sd">        Desired number of samples of the target barycenter</span>
<span class="sd">    Ys: list of ndarray, each element has shape (ns,d)</span>
<span class="sd">        Features of all samples</span>
<span class="sd">    Cs : list of ndarray, each element has shape (ns,ns)</span>
<span class="sd">        Structure matrices of all samples</span>
<span class="sd">    ps : list of ndarray, each element has shape (ns,)</span>
<span class="sd">        Masses of all samples.</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the S spaces&#39; weights</span>
<span class="sd">    alpha : float</span>
<span class="sd">        Alpha parameter for the fgw distance</span>
<span class="sd">    fixed_structure : bool</span>
<span class="sd">        Whether to fix the structure of the barycenter during the updates</span>
<span class="sd">    fixed_features : bool</span>
<span class="sd">        Whether to fix the feature of the barycenter during the updates</span>
<span class="sd">    loss_fun : str</span>
<span class="sd">        Loss function used for the solver either &#39;square_loss&#39; or &#39;kl_loss&#39;</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshol on error (&gt;0).</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Record log if True.</span>
<span class="sd">    init_C : ndarray, shape (N,N), optional</span>
<span class="sd">        Initialization for the barycenters&#39; structure matrix. If not set</span>
<span class="sd">        a random init is used.</span>
<span class="sd">    init_X : ndarray, shape (N,d), optional</span>
<span class="sd">        Initialization for the barycenters&#39; features. If not set a</span>
<span class="sd">        random init is used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    X : ndarray, shape (N, d)</span>
<span class="sd">        Barycenters&#39; features</span>
<span class="sd">    C : ndarray, shape (N, N)</span>
<span class="sd">        Barycenters&#39; structure matrix</span>
<span class="sd">    log_: dict</span>
<span class="sd">        Only returned when log=True. It contains the keys:</span>
<span class="sd">        T : list of (N,ns) transport matrices</span>
<span class="sd">        Ms : all distance matrices between the feature of the barycenter and the</span>
<span class="sd">        other features dist(X,Ys) shape (N,ns)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [24] Vayer Titouan, Chapel Laetitia, Flamary R{\&#39;e}mi, Tavenard Romain</span>
<span class="sd">        and Courty Nicolas</span>
<span class="sd">        &quot;Optimal Transport for structured data with application on graphs&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2019.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">S</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Cs</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">Ys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># dimension on the node features</span>
    <span class="k">if</span> <span class="n">p</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>

    <span class="n">Cs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">)]</span>
    <span class="n">Ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Ys</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">)]</span>

    <span class="n">lambdas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">lambdas</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">fixed_structure</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">init_C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">UndefinedParameter</span><span class="p">(</span><span class="s1">&#39;If C is fixed it must be initialized&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">init_C</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">init_C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">xalea</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">xalea</span><span class="p">,</span> <span class="n">xalea</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">init_C</span>

    <span class="k">if</span> <span class="n">fixed_features</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">init_X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">UndefinedParameter</span><span class="p">(</span><span class="s1">&#39;If X is fixed it must be initialized&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">init_X</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">init_X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">init_X</span>

    <span class="n">T</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">ps</span><span class="p">]</span>

    <span class="n">Ms</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">dist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Ys</span><span class="p">[</span><span class="n">s</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Ys</span><span class="p">))]</span>  <span class="c1"># Ms is N,ns</span>

    <span class="n">cpt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">err_feature</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">err_structure</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log_</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;err_feature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;err_structure&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;Ts_iter&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">while</span><span class="p">((</span><span class="n">err_feature</span> <span class="o">&gt;</span> <span class="n">tol</span> <span class="ow">or</span> <span class="n">err_structure</span> <span class="o">&gt;</span> <span class="n">tol</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cpt</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">):</span>
        <span class="n">Cprev</span> <span class="o">=</span> <span class="n">C</span>
        <span class="n">Xprev</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">fixed_features</span><span class="p">:</span>
            <span class="n">Ys_temp</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">T</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">Ys</span><span class="p">]</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">update_feature_matrix</span><span class="p">(</span><span class="n">lambdas</span><span class="p">,</span> <span class="n">Ys_temp</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

        <span class="n">Ms</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">dist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Ys</span><span class="p">[</span><span class="n">s</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Ys</span><span class="p">))]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">fixed_structure</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;square_loss&#39;</span><span class="p">:</span>
                <span class="n">T_temp</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">T</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">T</span><span class="p">]</span>
                <span class="n">C</span> <span class="o">=</span> <span class="n">update_sructure_matrix</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T_temp</span><span class="p">,</span> <span class="n">Cs</span><span class="p">)</span>

        <span class="n">T</span> <span class="o">=</span> <span class="p">[</span><span class="n">fused_gromov_wasserstein</span><span class="p">(</span><span class="n">Ms</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">C</span><span class="p">,</span> <span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">p</span><span class="p">,</span> <span class="n">ps</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span>
                                      <span class="n">numItermax</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">)]</span>

        <span class="c1"># T is N,ns</span>
        <span class="n">err_feature</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">Xprev</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
        <span class="n">err_structure</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">C</span> <span class="o">-</span> <span class="n">Cprev</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
            <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;err_feature&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err_feature</span><span class="p">)</span>
            <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;err_structure&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err_structure</span><span class="p">)</span>
            <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;Ts_iter&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Err&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">19</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err_structure</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err_feature</span><span class="p">))</span>

        <span class="n">cpt</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span>  <span class="c1"># from target to Ys</span>
        <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span>
        <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;Ms&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Ms</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">log_</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">C</span></div>


<div class="viewcode-block" id="update_sructure_matrix"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.update_sructure_matrix">[docs]</a><span class="k">def</span> <span class="nf">update_sructure_matrix</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Updates C according to the L2 Loss kernel with the S Ts couplings.</span>

<span class="sd">    It is calculated at each iteration</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p : ndarray, shape (N,)</span>
<span class="sd">        Masses in the targeted barycenter.</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the S spaces&#39; weights.</span>
<span class="sd">    T : list of S ndarray of shape (ns, N)</span>
<span class="sd">        The S Ts couplings calculated at each iteration.</span>
<span class="sd">    Cs : list of S ndarray, shape (ns, ns)</span>
<span class="sd">         Metric cost matrices.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    C : ndarray, shape (nt, nt)</span>
<span class="sd">        Updated C matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tmpsum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">lambdas</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">])</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">s</span><span class="p">])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">T</span><span class="p">))])</span>
    <span class="n">ppt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">tmpsum</span><span class="p">,</span> <span class="n">ppt</span><span class="p">)</span></div>


<div class="viewcode-block" id="update_feature_matrix"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.update_feature_matrix">[docs]</a><span class="k">def</span> <span class="nf">update_feature_matrix</span><span class="p">(</span><span class="n">lambdas</span><span class="p">,</span> <span class="n">Ys</span><span class="p">,</span> <span class="n">Ts</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Updates the feature with respect to the S Ts couplings.</span>


<span class="sd">    See &quot;Solving the barycenter problem with Block Coordinate Descent (BCD)&quot;</span>
<span class="sd">    in [24] calculated at each iteration</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p : ndarray, shape (N,)</span>
<span class="sd">        masses in the targeted barycenter</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the S spaces&#39; weights</span>
<span class="sd">    Ts : list of S np.ndarray(ns,N)</span>
<span class="sd">        the S Ts couplings calculated at each iteration</span>
<span class="sd">    Ys : list of S ndarray, shape(d,ns)</span>
<span class="sd">        The features.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    X : ndarray, shape (d, N)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [24] Vayer Titouan, Chapel Laetitia, Flamary R{\&#39;e}mi, Tavenard Romain</span>
<span class="sd">          and Courty Nicolas</span>
<span class="sd">        &quot;Optimal Transport for structured data with application on graphs&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2019.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>

    <span class="n">tmpsum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">lambdas</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ys</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">Ts</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Ts</span><span class="p">))])</span>

    <span class="k">return</span> <span class="n">tmpsum</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2016-2020, Rémi Flamary, Nicolas Courty.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>