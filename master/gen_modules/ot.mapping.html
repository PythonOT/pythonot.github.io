<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ot.mapping &mdash; POT Python Optimal Transport 0.9.3dev documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=8099e02f"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ot.optim" href="ot.optim.html" />
    <link rel="prev" title="ot.lp" href="ot.lp.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            POT Python Optimal Transport
              <img src="../_static/logo_dark.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.9.3dev
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">POT: Python Optimal Transport</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quick start guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../all.html">API and modules</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ot.backend.html">ot.backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.bregman.html">ot.bregman</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.coot.html">ot.coot</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.da.html">ot.da</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.datasets.html">ot.datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.dr.html">ot.dr</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.factored.html">ot.factored</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gaussian.html">ot.gaussian</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gnn.html">ot.gnn</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gromov.html">ot.gromov</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.lowrank.html">ot.lowrank</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.lp.html">ot.lp</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">ot.mapping</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#functions">Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#ot.mapping.joint_OT_mapping_kernel"><code class="docutils literal notranslate"><span class="pre">joint_OT_mapping_kernel()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#ot.mapping.joint_OT_mapping_linear"><code class="docutils literal notranslate"><span class="pre">joint_OT_mapping_linear()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#ot.mapping.nearest_brenier_potential_fit"><code class="docutils literal notranslate"><span class="pre">nearest_brenier_potential_fit()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#examples-using-ot-mapping-nearest-brenier-potential-fit">Examples using <code class="docutils literal notranslate"><span class="pre">ot.mapping.nearest_brenier_potential_fit</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#examples-using-ot-mapping-nearest-brenier-potential-predict-bounds">Examples using <code class="docutils literal notranslate"><span class="pre">ot.mapping.nearest_brenier_potential_predict_bounds</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ot.optim.html">ot.optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.partial.html">ot.partial</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.plot.html">ot.plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.regpath.html">ot.regpath</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.sliced.html">ot.sliced</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.smooth.html">ot.smooth</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.stochastic.html">ot.stochastic</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.unbalanced.html">ot.unbalanced</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.utils.html">ot.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.weak.html">ot.weak</a></li>
<li class="toctree-l2"><a class="reference internal" href="../all.html#module-ot">Main <code class="xref py py-mod docutils literal notranslate"><span class="pre">ot</span></code> functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributors.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to POT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code_of_conduct.html">Code of conduct</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">POT Python Optimal Transport</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../all.html">API and modules</a></li>
      <li class="breadcrumb-item active">ot.mapping</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/gen_modules/ot.mapping.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-ot.mapping">
<span id="ot-mapping"></span><h1>ot.mapping<a class="headerlink" href="#module-ot.mapping" title="Link to this heading"></a></h1>
<p>Optimal Transport maps and variants</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note that by default the module is not imported in <a class="reference internal" href="../all.html#module-ot" title="ot"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot</span></code></a>. In order to
use it you need to explicitly import <a class="reference internal" href="#module-ot.mapping" title="ot.mapping"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot.mapping</span></code></a></p>
</div>
<section id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="ot.mapping.joint_OT_mapping_kernel">
<span class="sig-prename descclassname"><span class="pre">ot.mapping.</span></span><span class="sig-name descname"><span class="pre">joint_OT_mapping_kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kerneltype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numInnerItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopInnerThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/mapping.html#joint_OT_mapping_kernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.mapping.joint_OT_mapping_kernel" title="Link to this definition"></a></dt>
<dd><p>Joint OT and nonlinear mapping estimation with kernels as proposed in
<span class="xref std std-ref">[8]</span>.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\min_{\gamma, L\in\mathcal{H}}\quad \|L(\mathbf{X_s}) -
n_s\gamma \mathbf{X_t}\|^2_F + \mu \langle \gamma, \mathbf{M} \rangle_F +
\eta \|L\|^2_\mathcal{H}\\s.t. \ \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) squared euclidean cost matrix between samples in
<span class="math notranslate nohighlight">\(\mathbf{X_s}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{X_t}\)</span> (scaled by <span class="math notranslate nohighlight">\(n_s\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(L\)</span> is a <span class="math notranslate nohighlight">\(n_s \times d\)</span> linear operator on a kernel matrix that
approximates the barycentric mapping</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are uniform source and target weights</p></li>
</ul>
<p>The problem consist in solving jointly an optimal transport matrix
<span class="math notranslate nohighlight">\(\gamma\)</span> and the nonlinear mapping that fits the barycentric mapping
<span class="math notranslate nohighlight">\(n_s\gamma \mathbf{X_t}\)</span>.</p>
<p>One can also estimate a mapping with constant bias (see supplementary
material of <span class="xref std std-ref">[8]</span>) using the bias optional argument.</p>
<p>The algorithm used for solving the problem is the block coordinate
descent that alternates between updates of <span class="math notranslate nohighlight">\(\mathbf{G}\)</span> (using conditional gradient)
and the update of <span class="math notranslate nohighlight">\(\mathbf{L}\)</span> using a classical kernel least square solver.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – samples in the source domain</p></li>
<li><p><strong>xt</strong> (<em>array-like</em><em> (</em><em>nt</em><em>,</em><em>d</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>mu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>,</em><em>optional</em>) – Weight for the linear OT loss (&gt;0)</p></li>
<li><p><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term  for the linear mapping L (&gt;0)</p></li>
<li><p><strong>kerneltype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>,</em><em>optional</em>) – kernel used by calling function <a class="reference internal" href="ot.utils.html#id59" title="ot.utils.kernel"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.utils.kernel()</span></code></a> (gaussian by default)</p></li>
<li><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Gaussian kernel bandwidth.</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>,</em><em>optional</em>) – Estimate linear mapping with constant bias</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>verbose2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of BCD iterations</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations (inner CG solver)</p></li>
<li><p><strong>stopInnerThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (inner CG solver) (&gt;0)</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative loss decrease (&gt;0)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns, nt) array-like</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>L</strong> (<em>(ns, d) array-like</em>) – Nonlinear mapping matrix ((<span class="math notranslate nohighlight">\(n_s+1\)</span>, <cite>d</cite>) if bias)</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-joint-ot-mapping-kernel">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id1" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></span>
<p>M. Perrot, N. Courty, R. Flamary, A. Habrard,
“Mapping estimation for discrete optimal transport”,
Neural Information Processing Systems (NIPS), 2016.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="ot.lp.html#id0" title="ot.lp.emd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.lp.emd</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="ot.optim.html#id0" title="ot.optim.cg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.optim.cg</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.mapping.joint_OT_mapping_linear">
<span class="sig-prename descclassname"><span class="pre">ot.mapping.</span></span><span class="sig-name descname"><span class="pre">joint_OT_mapping_linear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numInnerItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopInnerThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/mapping.html#joint_OT_mapping_linear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.mapping.joint_OT_mapping_linear" title="Link to this definition"></a></dt>
<dd><p>Joint OT and linear mapping estimation as proposed in
<span class="xref std std-ref">[8]</span>.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\min_{\gamma,L}\quad \|L(\mathbf{X_s}) - n_s\gamma \mathbf{X_t} \|^2_F +
  \mu \langle \gamma, \mathbf{M} \rangle_F + \eta \|L - \mathbf{I}\|^2_F\\s.t. \ \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) squared euclidean cost matrix between samples in
<span class="math notranslate nohighlight">\(\mathbf{X_s}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{X_t}\)</span> (scaled by <span class="math notranslate nohighlight">\(n_s\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(L\)</span> is a <span class="math notranslate nohighlight">\(d\times d\)</span> linear operator that approximates the barycentric
mapping</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{I}\)</span> is the identity matrix (neutral linear mapping)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are uniform source and target weights</p></li>
</ul>
<p>The problem consist in solving jointly an optimal transport matrix
<span class="math notranslate nohighlight">\(\gamma\)</span> and a linear mapping that fits the barycentric mapping
<span class="math notranslate nohighlight">\(n_s\gamma \mathbf{X_t}\)</span>.</p>
<p>One can also estimate a mapping with constant bias (see supplementary
material of <span class="xref std std-ref">[8]</span>) using the bias optional argument.</p>
<p>The algorithm used for solving the problem is the block coordinate
descent that alternates between updates of <span class="math notranslate nohighlight">\(\mathbf{G}\)</span> (using conditional gradient)
and the update of <span class="math notranslate nohighlight">\(\mathbf{L}\)</span> using a classical least square solver.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – samples in the source domain</p></li>
<li><p><strong>xt</strong> (<em>array-like</em><em> (</em><em>nt</em><em>,</em><em>d</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>mu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>,</em><em>optional</em>) – Weight for the linear OT loss (&gt;0)</p></li>
<li><p><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term  for the linear mapping L (&gt;0)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>,</em><em>optional</em>) – Estimate linear mapping with constant bias</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of BCD iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative loss decrease (&gt;0)</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations (inner CG solver)</p></li>
<li><p><strong>stopInnerThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (inner CG solver) (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns, nt) array-like</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>L</strong> (<em>(d, d) array-like</em>) – Linear mapping matrix ((<span class="math notranslate nohighlight">\(d+1\)</span>, <cite>d</cite>) if bias)</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-joint-ot-mapping-linear">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id2" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></span>
<p>M. Perrot, N. Courty, R. Flamary, A. Habrard,
“Mapping estimation for discrete optimal transport”,
Neural Information Processing Systems (NIPS), 2016.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="ot.lp.html#id0" title="ot.lp.emd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.lp.emd</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="ot.optim.html#id0" title="ot.optim.cg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.optim.cg</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.mapping.nearest_brenier_potential_fit">
<span class="sig-prename descclassname"><span class="pre">ot.mapping.</span></span><span class="sig-name descname"><span class="pre">nearest_brenier_potential_fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">V</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strongly_convex_constant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_lipschitz_constant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">its</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'barycentric'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/mapping.html#nearest_brenier_potential_fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.mapping.nearest_brenier_potential_fit" title="Link to this definition"></a></dt>
<dd><p>Computes optimal values and gradients at X for a strongly convex potential <span class="math notranslate nohighlight">\(\varphi\)</span> with Lipschitz gradients
on the partitions defined by <cite>X_classes</cite>, where <span class="math notranslate nohighlight">\(\varphi\)</span> is optimal such that
<span class="math notranslate nohighlight">\(\nabla \varphi \#\mu \approx \nu\)</span>, given samples <span class="math notranslate nohighlight">\(X = x_1, \cdots, x_n \sim \mu\)</span> and
<span class="math notranslate nohighlight">\(V = v_1, \cdots, v_n \sim \nu\)</span>. Finding such a potential that has the desired regularity on the
partition <span class="math notranslate nohighlight">\((E_k)_{k \in [K]}\)</span> (given by the classes <cite>X_classes</cite>) is equivalent to finding optimal values
<cite>phi</cite> for the <span class="math notranslate nohighlight">\(\varphi(x_i)\)</span> and its gradients <span class="math notranslate nohighlight">\(\nabla \varphi(x_i)\)</span> (variable`G`).
In practice, these optimal values are found by solving the following problem</p>
<div class="math notranslate nohighlight">
\begin{gather*}
\text{min} \sum_{i,j}\pi_{i,j}\|g_i - v_j\|_2^2 \\
g_1,\cdots, g_n \in \mathbb{R}^d,\; \varphi_1, \cdots, \varphi_n \in \mathbb{R},\; \pi \in \Pi(a, b) \\
\text{s.t.}\ \forall k \in [K],\; \forall i,j \in I_k: \\
\varphi_i-\varphi_j-\langle g_j, x_i-x_j\rangle \geq c_1\|g_i - g_j\|_2^2
+ c_2\|x_i-x_j\|_2^2 - c_3\langle g_j-g_i, x_j -x_i \rangle.
\end{gather*}</div><p>The constants <span class="math notranslate nohighlight">\(c_1, c_2, c_3\)</span> only depend on <cite>strongly_convex_constant</cite> and <cite>gradient_lipschitz_constant</cite>.
The constraint <span class="math notranslate nohighlight">\(\pi \in \Pi(a, b)\)</span> denotes the fact that the matrix <span class="math notranslate nohighlight">\(\pi\)</span> belong to the OT polytope
of marginals a and b. <span class="math notranslate nohighlight">\(I_k\)</span> is the subset of <span class="math notranslate nohighlight">\([n]\)</span> of the i such that <span class="math notranslate nohighlight">\(x_i\)</span> is in the
partition (or class) <span class="math notranslate nohighlight">\(E_k\)</span>, i.e. <cite>X_classes[i] == k</cite>.</p>
<p>This problem is solved by alternating over the variable <span class="math notranslate nohighlight">\(\pi\)</span> and the variables <span class="math notranslate nohighlight">\(\varphi_i, g_i\)</span>.
For <span class="math notranslate nohighlight">\(\pi\)</span>, the problem is the standard discrete OT problem, and for <span class="math notranslate nohighlight">\(\varphi_i, g_i\)</span>, the
problem is a convex QCQP solved using <code class="code docutils literal notranslate"><span class="pre">cvxpy</span></code> (ECOS solver).</p>
<p>Accepts any compatible backend, but will perform the QCQP optimisation on Numpy arrays, and convert back at the end.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This function requires the CVXPY library</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Accepts any backend but will convert to Numpy then back to the backend.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em>) – reference points used to compute the optimal values phi and G</p></li>
<li><p><strong>V</strong> (<em>array-like</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em>) – values of the gradients at the reference points X</p></li>
<li><p><strong>X_classes</strong> (<em>array-like</em><em> (</em><em>n</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – classes of the reference points, defaults to a single class</p></li>
<li><p><strong>a</strong> (<em>array-like</em><em> (</em><em>n</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – weights for the reference points X, defaults to uniform</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em> (</em><em>n</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – weights for the target points V, defaults to uniform</p></li>
<li><p><strong>strongly_convex_constant</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – constant for the strong convexity of the input potential phi, defaults to 0.6</p></li>
<li><p><strong>gradient_lipschitz_constant</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – constant for the Lipschitz property of the input gradient G, defaults to 1.4</p></li>
<li><p><strong>its</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – number of iterations, defaults to 100</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if true</p></li>
<li><p><strong>init_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional</em>) – ‘target’ initialises G=V, ‘barycentric’ initialises at the image of X by the barycentric projection</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>phi</strong> (<em>array-like (n,)</em>) – optimal values of the potential at the points X</p></li>
<li><p><strong>G</strong> (<em>array-like (n, d)</em>) – optimal values of the gradients at the points X</p></li>
<li><p><strong>log</strong> (<em>dict, optional</em>) – If input log is true, a dictionary containing the values of the variables at each iteration, as well
as solver information</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id3" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>58<span class="fn-bracket">]</span></span>
<p>François-Pierre Paty, Alexandre d’Aspremont, and Marco Cuturi. Regularity as regularization:
Smooth and strongly convex brenier potentials in optimal transport. In International Conference
on Artificial Intelligence and Statistics, pages 1222–1232. PMLR, 2020.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#id13" title="ot.mapping.nearest_brenier_potential_predict_bounds"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.mapping.nearest_brenier_potential_predict_bounds</span></code></a></dt><dd><p>Predicting SSNB images on new source data</p>
</dd>
<dt><a class="reference internal" href="ot.da.html#id90" title="ot.da.NearestBrenierPotential"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.da.NearestBrenierPotential</span></code></a></dt><dd><p>BaseTransport wrapper for SSNB</p>
</dd>
</dl>
</div>
</dd></dl>

<section id="examples-using-ot-mapping-nearest-brenier-potential-fit">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">ot.mapping.nearest_brenier_potential_fit</span></code><a class="headerlink" href="#examples-using-ot-mapping-nearest-brenier-potential-fit" title="Link to this heading"></a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example is designed to show how to use SSNB [58] in POT. SSNB computes an l-strongly conve..."><img alt="" src="../_images/sphx_glr_plot_SSNB_thumb.png" />
<p><a class="reference internal" href="../auto_examples/others/plot_SSNB.html#sphx-glr-auto-examples-others-plot-ssnb-py"><span class="std std-ref">Smooth and Strongly Convex Nearest Brenier Potentials</span></a></p>
  <div class="sphx-glr-thumbnail-title">Smooth and Strongly Convex Nearest Brenier Potentials</div>
</div></div><div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.mapping.nearest_brenier_potential_predict_bounds">
<span class="sig-prename descclassname"><span class="pre">ot.mapping.</span></span><span class="sig-name descname"><span class="pre">nearest_brenier_potential_predict_bounds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strongly_convex_constant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_lipschitz_constant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/mapping.html#nearest_brenier_potential_predict_bounds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.mapping.nearest_brenier_potential_predict_bounds" title="Link to this definition"></a></dt>
<dd><p>Compute the values of the lower and upper bounding potentials at the input points Y, using the potential optimal
values phi at X and their gradients G at X. The ‘lower’ potential corresponds to the method from <span class="xref std std-ref">[58]</span>,
Equation 2, while the bounding property and ‘upper’ potential come from <span class="xref std std-ref">[59]</span>, Theorem 3.14 (taking into
account the fact that this theorem’s statement has a min instead of a max, which is a typo). Both potentials are
optimal for the SSNB problem.</p>
<p>If <span class="math notranslate nohighlight">\(I_k\)</span> is the subset of <span class="math notranslate nohighlight">\([n]\)</span> of the i such that <span class="math notranslate nohighlight">\(x_i\)</span> is in the partition (or class)
<span class="math notranslate nohighlight">\(E_k\)</span>, for each <span class="math notranslate nohighlight">\(y \in E_k\)</span>, this function solves the convex QCQP problems,
respectively for l: ‘lower’ and u: ‘upper’:</p>
<div class="math notranslate nohighlight">
\begin{gather*}
(\varphi_{l}(x), \nabla \varphi_l(x)) = \text{argmin}\ t, \\
t\in \mathbb{R},\; g\in \mathbb{R}^d, \\
\text{s.t.} \forall j \in I_k,\; t-\varphi_j - \langle g_j, y-x_j \rangle \geq c_1\|g - g_j\|_2^2
+ c_2\|y-x_j\|_2^2 - c_3\langle g_j-g, x_j -y \rangle.
\end{gather*}</div><div class="math notranslate nohighlight">
\begin{gather*}
(\varphi_{u}(x), \nabla \varphi_u(x)) = \text{argmax}\ t, \\
t\in \mathbb{R},\; g\in \mathbb{R}^d, \\
\text{s.t.} \forall i \in I_k,\; \varphi_i^* -t - \langle g, x_i-y \rangle \geq c_1\|g_i - g\|_2^2
+ c_2\|x_i-y\|_2^2 - c_3\langle g-g_i, y -x_i \rangle.
\end{gather*}</div><p>The constants <span class="math notranslate nohighlight">\(c_1, c_2, c_3\)</span> only depend on <cite>strongly_convex_constant</cite> and <cite>gradient_lipschitz_constant</cite>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This function requires the CVXPY library</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Accepts any backend but will convert to Numpy then back to the backend.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em>) – reference points used to compute the optimal values phi and G</p></li>
<li><p><strong>X_classes</strong> (<em>array-like</em><em> (</em><em>n</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – classes of the reference points</p></li>
<li><p><strong>phi</strong> (<em>array-like</em><em> (</em><em>n</em><em>,</em><em>)</em>) – optimal values of the potential at the points X</p></li>
<li><p><strong>G</strong> (<em>array-like</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em>) – optimal values of the gradients at the points X</p></li>
<li><p><strong>Y</strong> (<em>array-like</em><em> (</em><em>m</em><em>, </em><em>d</em><em>)</em>) – input points</p></li>
<li><p><strong>X_classes</strong> – classes of the reference points, defaults to a single class</p></li>
<li><p><strong>Y_classes</strong> (<em>array_like</em><em> (</em><em>m</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – classes of the input points, defaults to a single class</p></li>
<li><p><strong>strongly_convex_constant</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – constant for the strong convexity of the input potential phi, defaults to 0.6</p></li>
<li><p><strong>gradient_lipschitz_constant</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – constant for the Lipschitz property of the input gradient G, defaults to 1.4</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if true</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>phi_lu</strong> (<em>array-like (2, m)</em>) – values of the lower and upper bounding potentials at Y</p></li>
<li><p><strong>G_lu</strong> (<em>array-like (2, m, d)</em>) – gradients of the lower and upper bounding potentials at Y</p></li>
<li><p><strong>log</strong> (<em>dict, optional</em>) – If input log is true, a dictionary containing solver information</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id4" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>58<span class="fn-bracket">]</span></span>
<p>François-Pierre Paty, Alexandre d’Aspremont, and Marco Cuturi. Regularity as regularization:
Smooth and strongly convex brenier potentials in optimal transport. In International Conference
on Artificial Intelligence and Statistics, pages 1222–1232. PMLR, 2020.</p>
</aside>
<aside class="footnote brackets" id="id5" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>59<span class="fn-bracket">]</span></span>
<p>Adrien B Taylor. Convex interpolation and performance estimation of first-order methods for
convex optimization. PhD thesis, Catholic University of Louvain, Louvain-la-Neuve, Belgium,
2017.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#id11" title="ot.mapping.nearest_brenier_potential_fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.mapping.nearest_brenier_potential_fit</span></code></a></dt><dd><p>Fitting the SSNB on source and target data</p>
</dd>
<dt><a class="reference internal" href="ot.da.html#id90" title="ot.da.NearestBrenierPotential"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.da.NearestBrenierPotential</span></code></a></dt><dd><p>BaseTransport wrapper for SSNB</p>
</dd>
</dl>
</div>
</dd></dl>

</section>
<section id="examples-using-ot-mapping-nearest-brenier-potential-predict-bounds">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">ot.mapping.nearest_brenier_potential_predict_bounds</span></code><a class="headerlink" href="#examples-using-ot-mapping-nearest-brenier-potential-predict-bounds" title="Link to this heading"></a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example is designed to show how to use SSNB [58] in POT. SSNB computes an l-strongly conve..."><img alt="" src="../_images/sphx_glr_plot_SSNB_thumb.png" />
<p><a class="reference internal" href="../auto_examples/others/plot_SSNB.html#sphx-glr-auto-examples-others-plot-ssnb-py"><span class="std std-ref">Smooth and Strongly Convex Nearest Brenier Potentials</span></a></p>
  <div class="sphx-glr-thumbnail-title">Smooth and Strongly Convex Nearest Brenier Potentials</div>
</div></div><div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="id0">
<span class="sig-prename descclassname"><span class="pre">ot.mapping.</span></span><span class="sig-name descname"><span class="pre">joint_OT_mapping_kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kerneltype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numInnerItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopInnerThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/mapping.html#joint_OT_mapping_kernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id0" title="Link to this definition"></a></dt>
<dd><p>Joint OT and nonlinear mapping estimation with kernels as proposed in
<span class="xref std std-ref">[8]</span>.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\min_{\gamma, L\in\mathcal{H}}\quad \|L(\mathbf{X_s}) -
n_s\gamma \mathbf{X_t}\|^2_F + \mu \langle \gamma, \mathbf{M} \rangle_F +
\eta \|L\|^2_\mathcal{H}\\s.t. \ \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) squared euclidean cost matrix between samples in
<span class="math notranslate nohighlight">\(\mathbf{X_s}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{X_t}\)</span> (scaled by <span class="math notranslate nohighlight">\(n_s\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(L\)</span> is a <span class="math notranslate nohighlight">\(n_s \times d\)</span> linear operator on a kernel matrix that
approximates the barycentric mapping</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are uniform source and target weights</p></li>
</ul>
<p>The problem consist in solving jointly an optimal transport matrix
<span class="math notranslate nohighlight">\(\gamma\)</span> and the nonlinear mapping that fits the barycentric mapping
<span class="math notranslate nohighlight">\(n_s\gamma \mathbf{X_t}\)</span>.</p>
<p>One can also estimate a mapping with constant bias (see supplementary
material of <span class="xref std std-ref">[8]</span>) using the bias optional argument.</p>
<p>The algorithm used for solving the problem is the block coordinate
descent that alternates between updates of <span class="math notranslate nohighlight">\(\mathbf{G}\)</span> (using conditional gradient)
and the update of <span class="math notranslate nohighlight">\(\mathbf{L}\)</span> using a classical kernel least square solver.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – samples in the source domain</p></li>
<li><p><strong>xt</strong> (<em>array-like</em><em> (</em><em>nt</em><em>,</em><em>d</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>mu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>,</em><em>optional</em>) – Weight for the linear OT loss (&gt;0)</p></li>
<li><p><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term  for the linear mapping L (&gt;0)</p></li>
<li><p><strong>kerneltype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>,</em><em>optional</em>) – kernel used by calling function <a class="reference internal" href="ot.utils.html#id59" title="ot.utils.kernel"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.utils.kernel()</span></code></a> (gaussian by default)</p></li>
<li><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Gaussian kernel bandwidth.</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>,</em><em>optional</em>) – Estimate linear mapping with constant bias</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>verbose2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of BCD iterations</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations (inner CG solver)</p></li>
<li><p><strong>stopInnerThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (inner CG solver) (&gt;0)</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative loss decrease (&gt;0)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns, nt) array-like</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>L</strong> (<em>(ns, d) array-like</em>) – Nonlinear mapping matrix ((<span class="math notranslate nohighlight">\(n_s+1\)</span>, <cite>d</cite>) if bias)</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id6">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id7" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></span>
<p>M. Perrot, N. Courty, R. Flamary, A. Habrard,
“Mapping estimation for discrete optimal transport”,
Neural Information Processing Systems (NIPS), 2016.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="ot.lp.html#id0" title="ot.lp.emd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.lp.emd</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="ot.optim.html#id0" title="ot.optim.cg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.optim.cg</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id8">
<span class="sig-prename descclassname"><span class="pre">ot.mapping.</span></span><span class="sig-name descname"><span class="pre">joint_OT_mapping_linear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numInnerItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopInnerThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/mapping.html#joint_OT_mapping_linear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id8" title="Link to this definition"></a></dt>
<dd><p>Joint OT and linear mapping estimation as proposed in
<span class="xref std std-ref">[8]</span>.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\min_{\gamma,L}\quad \|L(\mathbf{X_s}) - n_s\gamma \mathbf{X_t} \|^2_F +
  \mu \langle \gamma, \mathbf{M} \rangle_F + \eta \|L - \mathbf{I}\|^2_F\\s.t. \ \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) squared euclidean cost matrix between samples in
<span class="math notranslate nohighlight">\(\mathbf{X_s}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{X_t}\)</span> (scaled by <span class="math notranslate nohighlight">\(n_s\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(L\)</span> is a <span class="math notranslate nohighlight">\(d\times d\)</span> linear operator that approximates the barycentric
mapping</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{I}\)</span> is the identity matrix (neutral linear mapping)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are uniform source and target weights</p></li>
</ul>
<p>The problem consist in solving jointly an optimal transport matrix
<span class="math notranslate nohighlight">\(\gamma\)</span> and a linear mapping that fits the barycentric mapping
<span class="math notranslate nohighlight">\(n_s\gamma \mathbf{X_t}\)</span>.</p>
<p>One can also estimate a mapping with constant bias (see supplementary
material of <span class="xref std std-ref">[8]</span>) using the bias optional argument.</p>
<p>The algorithm used for solving the problem is the block coordinate
descent that alternates between updates of <span class="math notranslate nohighlight">\(\mathbf{G}\)</span> (using conditional gradient)
and the update of <span class="math notranslate nohighlight">\(\mathbf{L}\)</span> using a classical least square solver.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – samples in the source domain</p></li>
<li><p><strong>xt</strong> (<em>array-like</em><em> (</em><em>nt</em><em>,</em><em>d</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>mu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>,</em><em>optional</em>) – Weight for the linear OT loss (&gt;0)</p></li>
<li><p><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term  for the linear mapping L (&gt;0)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>,</em><em>optional</em>) – Estimate linear mapping with constant bias</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of BCD iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative loss decrease (&gt;0)</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations (inner CG solver)</p></li>
<li><p><strong>stopInnerThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (inner CG solver) (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns, nt) array-like</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>L</strong> (<em>(d, d) array-like</em>) – Linear mapping matrix ((<span class="math notranslate nohighlight">\(d+1\)</span>, <cite>d</cite>) if bias)</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id9">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id10" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></span>
<p>M. Perrot, N. Courty, R. Flamary, A. Habrard,
“Mapping estimation for discrete optimal transport”,
Neural Information Processing Systems (NIPS), 2016.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="ot.lp.html#id0" title="ot.lp.emd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.lp.emd</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="ot.optim.html#id0" title="ot.optim.cg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.optim.cg</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id11">
<span class="sig-prename descclassname"><span class="pre">ot.mapping.</span></span><span class="sig-name descname"><span class="pre">nearest_brenier_potential_fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">V</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strongly_convex_constant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_lipschitz_constant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">its</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'barycentric'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/mapping.html#nearest_brenier_potential_fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id11" title="Link to this definition"></a></dt>
<dd><p>Computes optimal values and gradients at X for a strongly convex potential <span class="math notranslate nohighlight">\(\varphi\)</span> with Lipschitz gradients
on the partitions defined by <cite>X_classes</cite>, where <span class="math notranslate nohighlight">\(\varphi\)</span> is optimal such that
<span class="math notranslate nohighlight">\(\nabla \varphi \#\mu \approx \nu\)</span>, given samples <span class="math notranslate nohighlight">\(X = x_1, \cdots, x_n \sim \mu\)</span> and
<span class="math notranslate nohighlight">\(V = v_1, \cdots, v_n \sim \nu\)</span>. Finding such a potential that has the desired regularity on the
partition <span class="math notranslate nohighlight">\((E_k)_{k \in [K]}\)</span> (given by the classes <cite>X_classes</cite>) is equivalent to finding optimal values
<cite>phi</cite> for the <span class="math notranslate nohighlight">\(\varphi(x_i)\)</span> and its gradients <span class="math notranslate nohighlight">\(\nabla \varphi(x_i)\)</span> (variable`G`).
In practice, these optimal values are found by solving the following problem</p>
<div class="math notranslate nohighlight">
\begin{gather*}
\text{min} \sum_{i,j}\pi_{i,j}\|g_i - v_j\|_2^2 \\
g_1,\cdots, g_n \in \mathbb{R}^d,\; \varphi_1, \cdots, \varphi_n \in \mathbb{R},\; \pi \in \Pi(a, b) \\
\text{s.t.}\ \forall k \in [K],\; \forall i,j \in I_k: \\
\varphi_i-\varphi_j-\langle g_j, x_i-x_j\rangle \geq c_1\|g_i - g_j\|_2^2
+ c_2\|x_i-x_j\|_2^2 - c_3\langle g_j-g_i, x_j -x_i \rangle.
\end{gather*}</div><p>The constants <span class="math notranslate nohighlight">\(c_1, c_2, c_3\)</span> only depend on <cite>strongly_convex_constant</cite> and <cite>gradient_lipschitz_constant</cite>.
The constraint <span class="math notranslate nohighlight">\(\pi \in \Pi(a, b)\)</span> denotes the fact that the matrix <span class="math notranslate nohighlight">\(\pi\)</span> belong to the OT polytope
of marginals a and b. <span class="math notranslate nohighlight">\(I_k\)</span> is the subset of <span class="math notranslate nohighlight">\([n]\)</span> of the i such that <span class="math notranslate nohighlight">\(x_i\)</span> is in the
partition (or class) <span class="math notranslate nohighlight">\(E_k\)</span>, i.e. <cite>X_classes[i] == k</cite>.</p>
<p>This problem is solved by alternating over the variable <span class="math notranslate nohighlight">\(\pi\)</span> and the variables <span class="math notranslate nohighlight">\(\varphi_i, g_i\)</span>.
For <span class="math notranslate nohighlight">\(\pi\)</span>, the problem is the standard discrete OT problem, and for <span class="math notranslate nohighlight">\(\varphi_i, g_i\)</span>, the
problem is a convex QCQP solved using <code class="code docutils literal notranslate"><span class="pre">cvxpy</span></code> (ECOS solver).</p>
<p>Accepts any compatible backend, but will perform the QCQP optimisation on Numpy arrays, and convert back at the end.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This function requires the CVXPY library</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Accepts any backend but will convert to Numpy then back to the backend.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em>) – reference points used to compute the optimal values phi and G</p></li>
<li><p><strong>V</strong> (<em>array-like</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em>) – values of the gradients at the reference points X</p></li>
<li><p><strong>X_classes</strong> (<em>array-like</em><em> (</em><em>n</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – classes of the reference points, defaults to a single class</p></li>
<li><p><strong>a</strong> (<em>array-like</em><em> (</em><em>n</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – weights for the reference points X, defaults to uniform</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em> (</em><em>n</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – weights for the target points V, defaults to uniform</p></li>
<li><p><strong>strongly_convex_constant</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – constant for the strong convexity of the input potential phi, defaults to 0.6</p></li>
<li><p><strong>gradient_lipschitz_constant</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – constant for the Lipschitz property of the input gradient G, defaults to 1.4</p></li>
<li><p><strong>its</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – number of iterations, defaults to 100</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if true</p></li>
<li><p><strong>init_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional</em>) – ‘target’ initialises G=V, ‘barycentric’ initialises at the image of X by the barycentric projection</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>phi</strong> (<em>array-like (n,)</em>) – optimal values of the potential at the points X</p></li>
<li><p><strong>G</strong> (<em>array-like (n, d)</em>) – optimal values of the gradients at the points X</p></li>
<li><p><strong>log</strong> (<em>dict, optional</em>) – If input log is true, a dictionary containing the values of the variables at each iteration, as well
as solver information</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id12" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>58<span class="fn-bracket">]</span></span>
<p>François-Pierre Paty, Alexandre d’Aspremont, and Marco Cuturi. Regularity as regularization:
Smooth and strongly convex brenier potentials in optimal transport. In International Conference
on Artificial Intelligence and Statistics, pages 1222–1232. PMLR, 2020.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#id13" title="ot.mapping.nearest_brenier_potential_predict_bounds"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.mapping.nearest_brenier_potential_predict_bounds</span></code></a></dt><dd><p>Predicting SSNB images on new source data</p>
</dd>
<dt><a class="reference internal" href="ot.da.html#id90" title="ot.da.NearestBrenierPotential"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.da.NearestBrenierPotential</span></code></a></dt><dd><p>BaseTransport wrapper for SSNB</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id13">
<span class="sig-prename descclassname"><span class="pre">ot.mapping.</span></span><span class="sig-name descname"><span class="pre">nearest_brenier_potential_predict_bounds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strongly_convex_constant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_lipschitz_constant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/mapping.html#nearest_brenier_potential_predict_bounds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id13" title="Link to this definition"></a></dt>
<dd><p>Compute the values of the lower and upper bounding potentials at the input points Y, using the potential optimal
values phi at X and their gradients G at X. The ‘lower’ potential corresponds to the method from <span class="xref std std-ref">[58]</span>,
Equation 2, while the bounding property and ‘upper’ potential come from <span class="xref std std-ref">[59]</span>, Theorem 3.14 (taking into
account the fact that this theorem’s statement has a min instead of a max, which is a typo). Both potentials are
optimal for the SSNB problem.</p>
<p>If <span class="math notranslate nohighlight">\(I_k\)</span> is the subset of <span class="math notranslate nohighlight">\([n]\)</span> of the i such that <span class="math notranslate nohighlight">\(x_i\)</span> is in the partition (or class)
<span class="math notranslate nohighlight">\(E_k\)</span>, for each <span class="math notranslate nohighlight">\(y \in E_k\)</span>, this function solves the convex QCQP problems,
respectively for l: ‘lower’ and u: ‘upper’:</p>
<div class="math notranslate nohighlight">
\begin{gather*}
(\varphi_{l}(x), \nabla \varphi_l(x)) = \text{argmin}\ t, \\
t\in \mathbb{R},\; g\in \mathbb{R}^d, \\
\text{s.t.} \forall j \in I_k,\; t-\varphi_j - \langle g_j, y-x_j \rangle \geq c_1\|g - g_j\|_2^2
+ c_2\|y-x_j\|_2^2 - c_3\langle g_j-g, x_j -y \rangle.
\end{gather*}</div><div class="math notranslate nohighlight">
\begin{gather*}
(\varphi_{u}(x), \nabla \varphi_u(x)) = \text{argmax}\ t, \\
t\in \mathbb{R},\; g\in \mathbb{R}^d, \\
\text{s.t.} \forall i \in I_k,\; \varphi_i^* -t - \langle g, x_i-y \rangle \geq c_1\|g_i - g\|_2^2
+ c_2\|x_i-y\|_2^2 - c_3\langle g-g_i, y -x_i \rangle.
\end{gather*}</div><p>The constants <span class="math notranslate nohighlight">\(c_1, c_2, c_3\)</span> only depend on <cite>strongly_convex_constant</cite> and <cite>gradient_lipschitz_constant</cite>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This function requires the CVXPY library</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Accepts any backend but will convert to Numpy then back to the backend.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em>) – reference points used to compute the optimal values phi and G</p></li>
<li><p><strong>X_classes</strong> (<em>array-like</em><em> (</em><em>n</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – classes of the reference points</p></li>
<li><p><strong>phi</strong> (<em>array-like</em><em> (</em><em>n</em><em>,</em><em>)</em>) – optimal values of the potential at the points X</p></li>
<li><p><strong>G</strong> (<em>array-like</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em>) – optimal values of the gradients at the points X</p></li>
<li><p><strong>Y</strong> (<em>array-like</em><em> (</em><em>m</em><em>, </em><em>d</em><em>)</em>) – input points</p></li>
<li><p><strong>X_classes</strong> – classes of the reference points, defaults to a single class</p></li>
<li><p><strong>Y_classes</strong> (<em>array_like</em><em> (</em><em>m</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – classes of the input points, defaults to a single class</p></li>
<li><p><strong>strongly_convex_constant</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – constant for the strong convexity of the input potential phi, defaults to 0.6</p></li>
<li><p><strong>gradient_lipschitz_constant</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – constant for the Lipschitz property of the input gradient G, defaults to 1.4</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if true</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>phi_lu</strong> (<em>array-like (2, m)</em>) – values of the lower and upper bounding potentials at Y</p></li>
<li><p><strong>G_lu</strong> (<em>array-like (2, m, d)</em>) – gradients of the lower and upper bounding potentials at Y</p></li>
<li><p><strong>log</strong> (<em>dict, optional</em>) – If input log is true, a dictionary containing solver information</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id14" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>58<span class="fn-bracket">]</span></span>
<p>François-Pierre Paty, Alexandre d’Aspremont, and Marco Cuturi. Regularity as regularization:
Smooth and strongly convex brenier potentials in optimal transport. In International Conference
on Artificial Intelligence and Statistics, pages 1222–1232. PMLR, 2020.</p>
</aside>
<aside class="footnote brackets" id="id15" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>59<span class="fn-bracket">]</span></span>
<p>Adrien B Taylor. Convex interpolation and performance estimation of first-order methods for
convex optimization. PhD thesis, Catholic University of Louvain, Louvain-la-Neuve, Belgium,
2017.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#id11" title="ot.mapping.nearest_brenier_potential_fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.mapping.nearest_brenier_potential_fit</span></code></a></dt><dd><p>Fitting the SSNB on source and target data</p>
</dd>
<dt><a class="reference internal" href="ot.da.html#id90" title="ot.da.NearestBrenierPotential"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.da.NearestBrenierPotential</span></code></a></dt><dd><p>BaseTransport wrapper for SSNB</p>
</dd>
</dl>
</div>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ot.lp.html" class="btn btn-neutral float-left" title="ot.lp" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ot.optim.html" class="btn btn-neutral float-right" title="ot.optim" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016-2023, POT Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note"
aria-label="versions">
  <!--  add shift_up to the class for force viewing ,
  data-toggle="rst-current-version" -->
    <span class="rst-current-version"  style="margin-bottom:1mm;">
      <span class="fa fa-book"> Python Optimal Transport</span>
      <hr  style="margin-bottom:1.5mm;margin-top:5mm;">
     <!--  versions
      <span class="fa fa-caret-down"></span>-->
      <span class="rst-current-version" style="display: inline-block;padding:
      0px;color:#fcfcfcab;float:left;font-size: 100%;">
        Versions: 
        <a href="https://pythonot.github.io/" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Release</a>
        <a href="https://pythonot.github.io/master" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Development</a>
        <a href="https://github.com/PythonOT/POT"
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Code</a>

      </span>

     
    </span>
  
     <!--
    <div class="rst-other-versions">

      

<div class="injected">

    
  <dl>
    <dt>Versions</dt>

    <dd><a href="https://pythonot.github.io/">Release</a></dd>
    
    <dd><a href="https://pythonot.github.io/master">Development</a></dd>
   
    

    <dt><a href="https://github.com/PythonOT/POT">Code on Github</a></dt>       

    
  </dl>
  <hr>

</div> 
</div>-->
  </div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>