

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ot.optim &mdash; POT Python Optimal Transport 0.9.6dev0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=6e3d2238"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ot.partial" href="ot.partial.html" />
    <link rel="prev" title="ot.mapping" href="ot.mapping.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            POT Python Optimal Transport
              <img src="../_static/logo_dark.svg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">POT: Python Optimal Transport</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quick start guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../all.html">API and modules</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ot.backend.html">ot.backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.bregman.html">ot.bregman</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.coot.html">ot.coot</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.da.html">ot.da</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.datasets.html">ot.datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.dr.html">ot.dr</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.factored.html">ot.factored</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gaussian.html">ot.gaussian</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gmm.html">ot.gmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gnn.html">ot.gnn</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gromov.html">ot.gromov</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.lowrank.html">ot.lowrank</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.lp.html">ot.lp</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.mapping.html">ot.mapping</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">ot.optim</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#functions">Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#ot.optim.cg"><code class="docutils literal notranslate"><span class="pre">cg()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#examples-using-ot-optim-cg">Examples using <code class="docutils literal notranslate"><span class="pre">ot.optim.cg</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#examples-using-ot-optim-gcg">Examples using <code class="docutils literal notranslate"><span class="pre">ot.optim.gcg</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ot.partial.html">ot.partial</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.plot.html">ot.plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.regpath.html">ot.regpath</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.sliced.html">ot.sliced</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.smooth.html">ot.smooth</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.stochastic.html">ot.stochastic</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.unbalanced.html">ot.unbalanced</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.utils.html">ot.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.weak.html">ot.weak</a></li>
<li class="toctree-l2"><a class="reference internal" href="../all.html#module-ot">Main <code class="xref py py-mod docutils literal notranslate"><span class="pre">ot</span></code> functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributors.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to POT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code_of_conduct.html">Code of conduct</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">POT Python Optimal Transport</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../all.html">API and modules</a></li>
      <li class="breadcrumb-item active">ot.optim</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/gen_modules/ot.optim.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-ot.optim">
<span id="ot-optim"></span><h1>ot.optim<a class="headerlink" href="#module-ot.optim" title="Link to this heading"></a></h1>
<p>Generic solvers for regularized OT or its semi-relaxed version.</p>
<section id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="ot.optim.cg">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">cg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_search</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermaxEmd</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#cg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.optim.cg" title="Link to this definition"></a></dt>
<dd><p>Solve the general regularized OT problem with conditional gradient</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot f(\gamma)\\s.t. \ \gamma \mathbf{1} &amp;= \mathbf{a}\\     \gamma^T \mathbf{1} &amp;= \mathbf{b}\\     \gamma &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the regularization term (and <cite>df</cite> is its gradient)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[1]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – initial guess (default is indep joint density)</p></li>
<li><p><strong>line_search</strong> (<em>function</em><em>,</em>) – Function to find the optimal step.
Default is None and calls a wrapper to line_search_armijo.</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>numItermaxEmd</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations for emd</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the relative variation (&gt;0)</p></li>
<li><p><strong>stopThr2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the absolute variation (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, the backend will be deduced from other inputs.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Parameters for linesearch</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-cg">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id1" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Ferradans, S., Papadakis, N., Peyré, G., &amp; Aujol, J. F. (2014). Regularized discrete optimal transport. SIAM Journal on Imaging Sciences, 7(3), 1853-1882.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="ot.lp.html#id0" title="ot.lp.emd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.lp.emd</span></code></a></dt><dd><p>Unregularized optimal transport</p>
</dd>
<dt><a class="reference internal" href="ot.bregman.html#ot.bregman.sinkhorn" title="ot.bregman.sinkhorn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn</span></code></a></dt><dd><p>Entropic regularized optimal transport</p>
</dd>
</dl>
</div>
</dd></dl>

<section id="examples-using-ot-optim-cg">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">ot.optim.cg</span></code><a class="headerlink" href="#examples-using-ot-optim-cg" title="Link to this heading"></a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Illustrates the use of the generic solver for regularized OT with user-designed regularization term. It uses Conditional gradient as in [6] and generalized Conditional Gradient as proposed in [5,7]."><img alt="" src="../_images/sphx_glr_plot_optim_OTreg_thumb.png" />
<p><a class="reference internal" href="../auto_examples/plot_optim_OTreg.html#sphx-glr-auto-examples-plot-optim-otreg-py"><span class="std std-ref">Regularized OT with generic solver</span></a></p>
  <div class="sphx-glr-thumbnail-title">Regularized OT with generic solver</div>
</div></div><div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.optim.gcg">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">gcg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numInnerItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#gcg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.optim.gcg" title="Link to this definition"></a></dt>
<dd><p>Solve the general regularized OT problem with the generalized conditional gradient</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg_1}\cdot\Omega(\gamma) + \mathrm{reg_2}\cdot f(\gamma)\\s.t. \ \gamma \mathbf{1} &amp;= \mathbf{a}\\     \gamma^T \mathbf{1} &amp;= \mathbf{b}\\     \gamma &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the regularization term (and <cite>df</cite> is its gradient)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the generalized conditional gradient as discussed in <span class="xref std std-ref">[5, 7]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em>, </em><em>(</em><em>nt</em><em>,</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Entropic Regularization term &gt;0</p></li>
<li><p><strong>reg2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Second Regularization term &gt;0</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – initial guess (default is indep joint density)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations of Sinkhorn</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the relative variation (&gt;0)</p></li>
<li><p><strong>stopThr2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the absolute variation (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (ns, nt)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-gcg">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id2" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="14">
<li><p>Courty; R. Flamary; D. Tuia; A. Rakotomamonjy, “Optimal Transport for Domain Adaptation,” in IEEE Transactions on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</p></li>
</ol>
</aside>
<aside class="footnote brackets" id="id3" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></span>
<p>Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015). Generalized conditional gradient: analysis of convergence and applications. arXiv preprint arXiv:1510.06567.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#id0" title="ot.optim.cg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.optim.cg</span></code></a></dt><dd><p>conditional gradient</p>
</dd>
</dl>
</div>
</dd></dl>

</section>
<section id="examples-using-ot-optim-gcg">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">ot.optim.gcg</span></code><a class="headerlink" href="#examples-using-ot-optim-gcg" title="Link to this heading"></a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Illustrates the use of the generic solver for regularized OT with user-designed regularization term. It uses Conditional gradient as in [6] and generalized Conditional Gradient as proposed in [5,7]."><img alt="" src="../_images/sphx_glr_plot_optim_OTreg_thumb.png" />
<p><a class="reference internal" href="../auto_examples/plot_optim_OTreg.html#sphx-glr-auto-examples-plot-optim-otreg-py"><span class="std std-ref">Regularized OT with generic solver</span></a></p>
  <div class="sphx-glr-thumbnail-title">Regularized OT with generic solver</div>
</div></div><div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.optim.generic_conditional_gradient">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">generic_conditional_gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lp_solver</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_search</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#generic_conditional_gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.optim.generic_conditional_gradient" title="Link to this definition"></a></dt>
<dd><p>Solve the general regularized OT problem or its semi-relaxed version with
conditional gradient or generalized conditional gradient depending on the
provided linear program solver.</p>
<blockquote>
<div><p>The function solves the following optimization problem if set as a conditional gradient:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg_1} \cdot f(\gamma)\\s.t. \ \gamma \mathbf{1} &amp;= \mathbf{a}\\     \gamma^T \mathbf{1} &amp;= \mathbf{b} (optional constraint)\\     \gamma &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the regularization term (and <cite>df</cite> is its gradient)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[1]</span></p>
<blockquote>
<div><p>The function solves the following optimization problem if set a generalized conditional gradient:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg_1}\cdot f(\gamma) + \mathrm{reg_2}\cdot\Omega(\gamma)\\s.t. \ \gamma \mathbf{1} &amp;= \mathbf{a}\\     \gamma^T \mathbf{1} &amp;= \mathbf{b}\\     \gamma &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
</ul>
<p>The algorithm used for solving the problem is the generalized conditional gradient as discussed in <span class="xref std std-ref">[5, 7]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – samples weights in the target domain</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>f</strong> (<em>function</em>) – Regularization function taking a transportation matrix as argument</p></li>
<li><p><strong>df</strong> (<em>function</em>) – Gradient of the regularization function taking a transportation matrix as argument</p></li>
<li><p><strong>reg1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>reg2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>,</em>) – Entropic Regularization term &gt;0. Ignored if set to None.</p></li>
<li><p><strong>lp_solver</strong> (<em>function</em><em>,</em>) – <p>linear program solver for direction finding of the (generalized) conditional gradient.
This function must take the form <cite>lp_solver(a, b, Mi, **kwargs)</cite> with p:
<cite>a</cite> and <cite>b</cite> are sample weights in both domains; <cite>Mi</cite> is the gradient of
the regularized objective; optimal arguments via kwargs.
It must output an admissible transport plan.</p>
<p>For instance, for the general regularized OT problem with conditional gradient <span class="xref std std-ref">[1]</span>:</p>
<blockquote>
<div><dl class="simple">
<dt>def lp_solver(a, b, M, <a href="#id4"><span class="problematic" id="id5">**</span></a>kwargs):</dt><dd><p>return ot.emd(a, b, M)</p>
</dd>
</dl>
</div></blockquote>
<p>or with the generalized conditional gradient instead <span class="xref std std-ref">[5, 7]</span>:</p>
<blockquote>
<div><dl class="simple">
<dt>def lp_solver(a, b, Mi, <a href="#id6"><span class="problematic" id="id7">**</span></a>kwargs):</dt><dd><p>return ot.sinkhorn(a, b, Mi)</p>
</dd>
</dl>
</div></blockquote>
</p></li>
<li><p><strong>line_search</strong> (<em>function</em><em>,</em>) – <p>Function to find the optimal step. This function must take the form
<cite>line_search(cost, G, deltaG, Mi, cost_G, df_G, **kwargs)</cite> with: <cite>cost</cite>
the cost function, <cite>G</cite> the transport plan, <cite>deltaG</cite> the conditional
gradient direction given by lp_solver, <cite>Mi</cite> the gradient of regularized
objective, <cite>cost_G</cite> the cost at G, <cite>df_G</cite> the gradient of the regularizer
at G. Two types of outputs are supported:</p>
<p>Instances such as <cite>ot.optim.line_search_armijo</cite> (generic solver),
<cite>ot.gromov.solve_gromov_linesearch</cite> (FGW problems),
<cite>solve_semirelaxed_gromov_linesearch</cite> (srFGW problems) and
<cite>gcg_linesearch</cite> (generalized cg), output : the line-search step alpha,
the number of iterations used in the solver if applicable and the loss
value at step alpha. These can be called e.g as:</p>
<blockquote>
<div><dl class="simple">
<dt>def line_search(cost, G, deltaG, Mi, cost_G, df_G, <a href="#id8"><span class="problematic" id="id9">**</span></a>kwargs):</dt><dd><p>return ot.optim.line_search_armijo(cost, G, deltaG, Mi, cost_G, <a href="#id10"><span class="problematic" id="id11">**</span></a>kwargs)</p>
</dd>
</dl>
</div></blockquote>
<p>Instances such as <cite>ot.gromov.solve_partial_gromov_linesearch</cite> for partial
(F)GW problems add as finale output, the next step gradient reading as
a convex combination of previously computed gradients, taking advantage of the regularizer
quadratic form.</p>
</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – initial guess (default is indep joint density)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the relative variation (&gt;0)</p></li>
<li><p><strong>stopThr2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the absolute variation (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, the backend will be deduced from other inputs.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Parameters for linesearch</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id13"><span id="id12"></span>References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id14" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Ferradans, S., Papadakis, N., Peyré, G., &amp; Aujol, J. F. (2014). Regularized discrete optimal transport. SIAM Journal on Imaging Sciences, 7(3), 1853-1882.</p>
</aside>
<aside class="footnote brackets" id="id15" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="14">
<li><p>Courty; R. Flamary; D. Tuia; A. Rakotomamonjy, “Optimal Transport for Domain Adaptation,” in IEEE Transactions on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</p></li>
</ol>
</aside>
<aside class="footnote brackets" id="id16" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></span>
<p>Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015). Generalized conditional gradient: analysis of convergence and applications. arXiv preprint arXiv:1510.06567.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="ot.lp.html#id0" title="ot.lp.emd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.lp.emd</span></code></a></dt><dd><p>Unregularized optimal transport</p>
</dd>
<dt><a class="reference internal" href="ot.bregman.html#ot.bregman.sinkhorn" title="ot.bregman.sinkhorn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn</span></code></a></dt><dd><p>Entropic regularized optimal transport</p>
</dd>
</dl>
</div>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.optim.line_search_armijo">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">line_search_armijo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xk</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pk</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gfk</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">old_fval</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#line_search_armijo"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.optim.line_search_armijo" title="Link to this definition"></a></dt>
<dd><p>Armijo linesearch function that works with matrices</p>
<p>Find an approximate minimum of <span class="math notranslate nohighlight">\(f(x_k + \alpha \cdot p_k)\)</span> that satisfies the
armijo conditions.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the loss function f returns a float (resp. a 1d array) then
the returned alpha and fa are float (resp. 1d arrays).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f</strong> (<em>callable</em>) – loss function</p></li>
<li><p><strong>xk</strong> (<em>array-like</em>) – initial position</p></li>
<li><p><strong>pk</strong> (<em>array-like</em>) – descent direction</p></li>
<li><p><strong>gfk</strong> (<em>array-like</em>) – gradient of <cite>f</cite> at <span class="math notranslate nohighlight">\(x_k\)</span></p></li>
<li><p><strong>old_fval</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><em>1d array</em>) – loss value at <span class="math notranslate nohighlight">\(x_k\)</span></p></li>
<li><p><strong>args</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><em>optional</em>) – arguments given to <cite>f</cite></p></li>
<li><p><strong>c1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – <span class="math notranslate nohighlight">\(c_1\)</span> const in armijo rule (&gt;0)</p></li>
<li><p><strong>alpha0</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – initial step (&gt;0)</p></li>
<li><p><strong>alpha_min</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>default=0.</em>) – minimum value for alpha</p></li>
<li><p><strong>alpha_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – maximum value for alpha</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>float or 1d array</em>) – step that satisfy armijo conditions</p></li>
<li><p><strong>fc</strong> (<em>int</em>) – nb of function call</p></li>
<li><p><strong>fa</strong> (<em>float or 1d array</em>) – loss value at step alpha</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.optim.partial_cg">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">partial_cg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a_extended</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b_extended</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_search=&lt;function</span> <span class="pre">line_search_armijo&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax=200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr=1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr2=1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warn=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#partial_cg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.optim.partial_cg" title="Link to this definition"></a></dt>
<dd><p>Solve the general regularized partial OT problem with conditional gradient</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot f(\gamma)\\s.t. \ \gamma \mathbf{1} &amp;= \mathbf{a}\\     \gamma \mathbf{1} &amp;= \mathbf{b}\\     \mathbf{1}^T \gamma^T \mathbf{1} = m &amp;\leq \min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\\     \gamma &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the regularization term (and <cite>df</cite> is its gradient)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights</p></li>
<li><p><cite>m</cite> is the amount of mass to be transported</p></li>
</ul>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[1]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – currently estimated samples weights in the target domain</p></li>
<li><p><strong>a_extended</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns + nb_dummies</em><em>,</em><em>)</em>) – samples weights in the source domain with added dummy nodes</p></li>
<li><p><strong>b_extended</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt + nb_dummies</em><em>,</em><em>)</em>) – currently estimated samples weights in the target domain with added dummy nodes</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – initial guess (default is indep joint density)</p></li>
<li><p><strong>line_search</strong> (<em>function</em><em>,</em>) – Function to find the optimal step.
Default is the armijo line-search.</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the relative variation (&gt;0)</p></li>
<li><p><strong>stopThr2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the absolute variation (&gt;0)</p></li>
<li><p><strong>warn</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional.</em>) – Whether to raise a warning when EMD did not converge.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Parameters for linesearch</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-partial-cg">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id17" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></span>
<p>Chapel, L., Alaya, M., Gasso, G. (2020). “Partial Optimal
Transport with Applications on Positive-Unlabeled Learning”.
NeurIPS.</p>
</aside>
</aside>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.optim.semirelaxed_cg">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_cg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_search</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#semirelaxed_cg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.optim.semirelaxed_cg" title="Link to this definition"></a></dt>
<dd><p>Solve the general regularized and semi-relaxed OT problem with conditional gradient</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot f(\gamma)\\s.t. \ \gamma \mathbf{1} &amp;= \mathbf{a}\\     \gamma &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the regularization term (and <cite>df</cite> is its gradient)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[1]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – currently estimated samples weights in the target domain</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – initial guess (default is indep joint density)</p></li>
<li><p><strong>line_search</strong> (<em>function</em><em>,</em>) – Function to find the optimal step.
Default is None and calls a wrapper to line_search_armijo.</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the relative variation (&gt;0)</p></li>
<li><p><strong>stopThr2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the absolute variation (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, the backend will be deduced from other inputs.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Parameters for linesearch</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id18">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id19" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2021.</p>
</aside>
</aside>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.optim.solve_1d_linesearch_quad">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">solve_1d_linesearch_quad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#solve_1d_linesearch_quad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.optim.solve_1d_linesearch_quad" title="Link to this definition"></a></dt>
<dd><p>For any convex or non-convex 1d quadratic function <cite>f</cite>, solve the following problem:</p>
<div class="math notranslate nohighlight">
\[\mathop{\arg \min}_{0 \leq x \leq 1} \quad f(x) = ax^{2} + bx + c\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><em>tensors</em><em> (</em><em>1</em><em>,</em><em>)</em>) – The coefficients of the quadratic function</p></li>
<li><p><strong>b</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><em>tensors</em><em> (</em><em>1</em><em>,</em><em>)</em>) – The coefficients of the quadratic function</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>x</strong> – The optimal value which leads to the minimal cost</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="id0">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">cg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_search</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermaxEmd</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#cg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id0" title="Link to this definition"></a></dt>
<dd><p>Solve the general regularized OT problem with conditional gradient</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot f(\gamma)\\s.t. \ \gamma \mathbf{1} &amp;= \mathbf{a}\\     \gamma^T \mathbf{1} &amp;= \mathbf{b}\\     \gamma &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the regularization term (and <cite>df</cite> is its gradient)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[1]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – initial guess (default is indep joint density)</p></li>
<li><p><strong>line_search</strong> (<em>function</em><em>,</em>) – Function to find the optimal step.
Default is None and calls a wrapper to line_search_armijo.</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>numItermaxEmd</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations for emd</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the relative variation (&gt;0)</p></li>
<li><p><strong>stopThr2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the absolute variation (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, the backend will be deduced from other inputs.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Parameters for linesearch</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id20">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id21" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Ferradans, S., Papadakis, N., Peyré, G., &amp; Aujol, J. F. (2014). Regularized discrete optimal transport. SIAM Journal on Imaging Sciences, 7(3), 1853-1882.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="ot.lp.html#id0" title="ot.lp.emd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.lp.emd</span></code></a></dt><dd><p>Unregularized optimal transport</p>
</dd>
<dt><a class="reference internal" href="ot.bregman.html#ot.bregman.sinkhorn" title="ot.bregman.sinkhorn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn</span></code></a></dt><dd><p>Entropic regularized optimal transport</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id22">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">gcg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numInnerItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#gcg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id22" title="Link to this definition"></a></dt>
<dd><p>Solve the general regularized OT problem with the generalized conditional gradient</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg_1}\cdot\Omega(\gamma) + \mathrm{reg_2}\cdot f(\gamma)\\s.t. \ \gamma \mathbf{1} &amp;= \mathbf{a}\\     \gamma^T \mathbf{1} &amp;= \mathbf{b}\\     \gamma &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the regularization term (and <cite>df</cite> is its gradient)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the generalized conditional gradient as discussed in <span class="xref std std-ref">[5, 7]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em>, </em><em>(</em><em>nt</em><em>,</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Entropic Regularization term &gt;0</p></li>
<li><p><strong>reg2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Second Regularization term &gt;0</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – initial guess (default is indep joint density)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations of Sinkhorn</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the relative variation (&gt;0)</p></li>
<li><p><strong>stopThr2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the absolute variation (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (ns, nt)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id23">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id24" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="14">
<li><p>Courty; R. Flamary; D. Tuia; A. Rakotomamonjy, “Optimal Transport for Domain Adaptation,” in IEEE Transactions on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</p></li>
</ol>
</aside>
<aside class="footnote brackets" id="id25" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></span>
<p>Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015). Generalized conditional gradient: analysis of convergence and applications. arXiv preprint arXiv:1510.06567.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#id0" title="ot.optim.cg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.optim.cg</span></code></a></dt><dd><p>conditional gradient</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id26">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">generic_conditional_gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lp_solver</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_search</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#generic_conditional_gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id26" title="Link to this definition"></a></dt>
<dd><p>Solve the general regularized OT problem or its semi-relaxed version with
conditional gradient or generalized conditional gradient depending on the
provided linear program solver.</p>
<blockquote>
<div><p>The function solves the following optimization problem if set as a conditional gradient:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg_1} \cdot f(\gamma)\\s.t. \ \gamma \mathbf{1} &amp;= \mathbf{a}\\     \gamma^T \mathbf{1} &amp;= \mathbf{b} (optional constraint)\\     \gamma &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the regularization term (and <cite>df</cite> is its gradient)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[1]</span></p>
<blockquote>
<div><p>The function solves the following optimization problem if set a generalized conditional gradient:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg_1}\cdot f(\gamma) + \mathrm{reg_2}\cdot\Omega(\gamma)\\s.t. \ \gamma \mathbf{1} &amp;= \mathbf{a}\\     \gamma^T \mathbf{1} &amp;= \mathbf{b}\\     \gamma &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
</ul>
<p>The algorithm used for solving the problem is the generalized conditional gradient as discussed in <span class="xref std std-ref">[5, 7]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – samples weights in the target domain</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>f</strong> (<em>function</em>) – Regularization function taking a transportation matrix as argument</p></li>
<li><p><strong>df</strong> (<em>function</em>) – Gradient of the regularization function taking a transportation matrix as argument</p></li>
<li><p><strong>reg1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>reg2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>,</em>) – Entropic Regularization term &gt;0. Ignored if set to None.</p></li>
<li><p><strong>lp_solver</strong> (<em>function</em><em>,</em>) – <p>linear program solver for direction finding of the (generalized) conditional gradient.
This function must take the form <cite>lp_solver(a, b, Mi, **kwargs)</cite> with p:
<cite>a</cite> and <cite>b</cite> are sample weights in both domains; <cite>Mi</cite> is the gradient of
the regularized objective; optimal arguments via kwargs.
It must output an admissible transport plan.</p>
<p>For instance, for the general regularized OT problem with conditional gradient <span class="xref std std-ref">[1]</span>:</p>
<blockquote>
<div><dl class="simple">
<dt>def lp_solver(a, b, M, <a href="#id27"><span class="problematic" id="id28">**</span></a>kwargs):</dt><dd><p>return ot.emd(a, b, M)</p>
</dd>
</dl>
</div></blockquote>
<p>or with the generalized conditional gradient instead <span class="xref std std-ref">[5, 7]</span>:</p>
<blockquote>
<div><dl class="simple">
<dt>def lp_solver(a, b, Mi, <a href="#id29"><span class="problematic" id="id30">**</span></a>kwargs):</dt><dd><p>return ot.sinkhorn(a, b, Mi)</p>
</dd>
</dl>
</div></blockquote>
</p></li>
<li><p><strong>line_search</strong> (<em>function</em><em>,</em>) – <p>Function to find the optimal step. This function must take the form
<cite>line_search(cost, G, deltaG, Mi, cost_G, df_G, **kwargs)</cite> with: <cite>cost</cite>
the cost function, <cite>G</cite> the transport plan, <cite>deltaG</cite> the conditional
gradient direction given by lp_solver, <cite>Mi</cite> the gradient of regularized
objective, <cite>cost_G</cite> the cost at G, <cite>df_G</cite> the gradient of the regularizer
at G. Two types of outputs are supported:</p>
<p>Instances such as <cite>ot.optim.line_search_armijo</cite> (generic solver),
<cite>ot.gromov.solve_gromov_linesearch</cite> (FGW problems),
<cite>solve_semirelaxed_gromov_linesearch</cite> (srFGW problems) and
<cite>gcg_linesearch</cite> (generalized cg), output : the line-search step alpha,
the number of iterations used in the solver if applicable and the loss
value at step alpha. These can be called e.g as:</p>
<blockquote>
<div><dl class="simple">
<dt>def line_search(cost, G, deltaG, Mi, cost_G, df_G, <a href="#id31"><span class="problematic" id="id32">**</span></a>kwargs):</dt><dd><p>return ot.optim.line_search_armijo(cost, G, deltaG, Mi, cost_G, <a href="#id33"><span class="problematic" id="id34">**</span></a>kwargs)</p>
</dd>
</dl>
</div></blockquote>
<p>Instances such as <cite>ot.gromov.solve_partial_gromov_linesearch</cite> for partial
(F)GW problems add as finale output, the next step gradient reading as
a convex combination of previously computed gradients, taking advantage of the regularizer
quadratic form.</p>
</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – initial guess (default is indep joint density)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the relative variation (&gt;0)</p></li>
<li><p><strong>stopThr2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the absolute variation (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, the backend will be deduced from other inputs.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Parameters for linesearch</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id36"><span id="id35"></span>References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id37" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Ferradans, S., Papadakis, N., Peyré, G., &amp; Aujol, J. F. (2014). Regularized discrete optimal transport. SIAM Journal on Imaging Sciences, 7(3), 1853-1882.</p>
</aside>
<aside class="footnote brackets" id="id38" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="14">
<li><p>Courty; R. Flamary; D. Tuia; A. Rakotomamonjy, “Optimal Transport for Domain Adaptation,” in IEEE Transactions on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</p></li>
</ol>
</aside>
<aside class="footnote brackets" id="id39" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></span>
<p>Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015). Generalized conditional gradient: analysis of convergence and applications. arXiv preprint arXiv:1510.06567.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="ot.lp.html#id0" title="ot.lp.emd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.lp.emd</span></code></a></dt><dd><p>Unregularized optimal transport</p>
</dd>
<dt><a class="reference internal" href="ot.bregman.html#ot.bregman.sinkhorn" title="ot.bregman.sinkhorn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn</span></code></a></dt><dd><p>Entropic regularized optimal transport</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id40">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">line_search_armijo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xk</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pk</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gfk</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">old_fval</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#line_search_armijo"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id40" title="Link to this definition"></a></dt>
<dd><p>Armijo linesearch function that works with matrices</p>
<p>Find an approximate minimum of <span class="math notranslate nohighlight">\(f(x_k + \alpha \cdot p_k)\)</span> that satisfies the
armijo conditions.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the loss function f returns a float (resp. a 1d array) then
the returned alpha and fa are float (resp. 1d arrays).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f</strong> (<em>callable</em>) – loss function</p></li>
<li><p><strong>xk</strong> (<em>array-like</em>) – initial position</p></li>
<li><p><strong>pk</strong> (<em>array-like</em>) – descent direction</p></li>
<li><p><strong>gfk</strong> (<em>array-like</em>) – gradient of <cite>f</cite> at <span class="math notranslate nohighlight">\(x_k\)</span></p></li>
<li><p><strong>old_fval</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><em>1d array</em>) – loss value at <span class="math notranslate nohighlight">\(x_k\)</span></p></li>
<li><p><strong>args</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><em>optional</em>) – arguments given to <cite>f</cite></p></li>
<li><p><strong>c1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – <span class="math notranslate nohighlight">\(c_1\)</span> const in armijo rule (&gt;0)</p></li>
<li><p><strong>alpha0</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – initial step (&gt;0)</p></li>
<li><p><strong>alpha_min</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>default=0.</em>) – minimum value for alpha</p></li>
<li><p><strong>alpha_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – maximum value for alpha</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>float or 1d array</em>) – step that satisfy armijo conditions</p></li>
<li><p><strong>fc</strong> (<em>int</em>) – nb of function call</p></li>
<li><p><strong>fa</strong> (<em>float or 1d array</em>) – loss value at step alpha</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id41">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">partial_cg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a_extended</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b_extended</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_search=&lt;function</span> <span class="pre">line_search_armijo&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax=200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr=1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr2=1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warn=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#partial_cg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id41" title="Link to this definition"></a></dt>
<dd><p>Solve the general regularized partial OT problem with conditional gradient</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot f(\gamma)\\s.t. \ \gamma \mathbf{1} &amp;= \mathbf{a}\\     \gamma \mathbf{1} &amp;= \mathbf{b}\\     \mathbf{1}^T \gamma^T \mathbf{1} = m &amp;\leq \min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\\     \gamma &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the regularization term (and <cite>df</cite> is its gradient)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights</p></li>
<li><p><cite>m</cite> is the amount of mass to be transported</p></li>
</ul>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[1]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – currently estimated samples weights in the target domain</p></li>
<li><p><strong>a_extended</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns + nb_dummies</em><em>,</em><em>)</em>) – samples weights in the source domain with added dummy nodes</p></li>
<li><p><strong>b_extended</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt + nb_dummies</em><em>,</em><em>)</em>) – currently estimated samples weights in the target domain with added dummy nodes</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – initial guess (default is indep joint density)</p></li>
<li><p><strong>line_search</strong> (<em>function</em><em>,</em>) – Function to find the optimal step.
Default is the armijo line-search.</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the relative variation (&gt;0)</p></li>
<li><p><strong>stopThr2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the absolute variation (&gt;0)</p></li>
<li><p><strong>warn</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional.</em>) – Whether to raise a warning when EMD did not converge.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Parameters for linesearch</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id42">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id43" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></span>
<p>Chapel, L., Alaya, M., Gasso, G. (2020). “Partial Optimal
Transport with Applications on Positive-Unlabeled Learning”.
NeurIPS.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id44">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_cg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">line_search</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#semirelaxed_cg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id44" title="Link to this definition"></a></dt>
<dd><p>Solve the general regularized and semi-relaxed OT problem with conditional gradient</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot f(\gamma)\\s.t. \ \gamma \mathbf{1} &amp;= \mathbf{a}\\     \gamma &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the regularization term (and <cite>df</cite> is its gradient)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[1]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – currently estimated samples weights in the target domain</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – initial guess (default is indep joint density)</p></li>
<li><p><strong>line_search</strong> (<em>function</em><em>,</em>) – Function to find the optimal step.
Default is None and calls a wrapper to line_search_armijo.</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the relative variation (&gt;0)</p></li>
<li><p><strong>stopThr2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on the absolute variation (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, the backend will be deduced from other inputs.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Parameters for linesearch</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id45">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id46" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id47">
<span class="sig-prename descclassname"><span class="pre">ot.optim.</span></span><span class="sig-name descname"><span class="pre">solve_1d_linesearch_quad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/optim.html#solve_1d_linesearch_quad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id47" title="Link to this definition"></a></dt>
<dd><p>For any convex or non-convex 1d quadratic function <cite>f</cite>, solve the following problem:</p>
<div class="math notranslate nohighlight">
\[\mathop{\arg \min}_{0 \leq x \leq 1} \quad f(x) = ax^{2} + bx + c\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><em>tensors</em><em> (</em><em>1</em><em>,</em><em>)</em>) – The coefficients of the quadratic function</p></li>
<li><p><strong>b</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><em>tensors</em><em> (</em><em>1</em><em>,</em><em>)</em>) – The coefficients of the quadratic function</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>x</strong> – The optimal value which leads to the minimal cost</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ot.mapping.html" class="btn btn-neutral float-left" title="ot.mapping" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ot.partial.html" class="btn btn-neutral float-right" title="ot.partial" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016-2023, POT Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note"
aria-label="versions">
  <!--  add shift_up to the class for force viewing ,
  data-toggle="rst-current-version" -->
    <span class="rst-current-version"  style="margin-bottom:1mm;">
      <span class="fa fa-book"> Python Optimal Transport</span> 0.9.6dev0
      <hr  style="margin-bottom:1.5mm;margin-top:5mm;">
     <!--  versions
      <span class="fa fa-caret-down"></span>-->
      <span class="rst-current-version" style="display: inline-block;padding:
      0px;color:#fcfcfcab;float:left;font-size: 100%;">
        Versions: 
        <a href="https://pythonot.github.io/" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Release</a>
        <a href="https://pythonot.github.io/master" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Development</a>
        <a href="https://github.com/PythonOT/POT"
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Code</a>

      </span>

     
    </span>
  
     <!--
    <div class="rst-other-versions">

      

<div class="injected">

    
  <dl>
    <dt>Versions</dt>

    <dd><a href="https://pythonot.github.io/">Release</a></dd>
    
    <dd><a href="https://pythonot.github.io/master">Development</a></dd>
   
    

    <dt><a href="https://github.com/PythonOT/POT">Code on Github</a></dt>       

    
  </dl>
  <hr>

</div> 
</div>-->
  </div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>