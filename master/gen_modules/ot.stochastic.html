<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ot.stochastic &mdash; POT Python Optimal Transport 0.9.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=9dc39874"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ot.unbalanced" href="ot.unbalanced.html" />
    <link rel="prev" title="ot.smooth" href="ot.smooth.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            POT Python Optimal Transport
              <img src="../_static/logo_dark.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.9.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">POT: Python Optimal Transport</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quick start guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../all.html">API and modules</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ot.backend.html">ot.backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.bregman.html">ot.bregman</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.coot.html">ot.coot</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.da.html">ot.da</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.datasets.html">ot.datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.dr.html">ot.dr</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.factored.html">ot.factored</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gaussian.html">ot.gaussian</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gnn.html">ot.gnn</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gromov.html">ot.gromov</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.lp.html">ot.lp</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.optim.html">ot.optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.partial.html">ot.partial</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.plot.html">ot.plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.regpath.html">ot.regpath</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.sliced.html">ot.sliced</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.smooth.html">ot.smooth</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">ot.stochastic</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#functions">Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#ot.stochastic.averaged_sgd_entropic_transport"><code class="docutils literal notranslate"><span class="pre">averaged_sgd_entropic_transport()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#ot.stochastic.batch_grad_dual"><code class="docutils literal notranslate"><span class="pre">batch_grad_dual()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#ot.stochastic.c_transform_entropic"><code class="docutils literal notranslate"><span class="pre">c_transform_entropic()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#ot.stochastic.coordinate_grad_semi_dual"><code class="docutils literal notranslate"><span class="pre">coordinate_grad_semi_dual()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#ot.stochastic.loss_dual_entropic"><code class="docutils literal notranslate"><span class="pre">loss_dual_entropic()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#examples-using-ot-stochastic-loss-dual-entropic">Examples using <code class="docutils literal notranslate"><span class="pre">ot.stochastic.loss_dual_entropic</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#examples-using-ot-stochastic-loss-dual-quadratic">Examples using <code class="docutils literal notranslate"><span class="pre">ot.stochastic.loss_dual_quadratic</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#examples-using-ot-stochastic-plan-dual-entropic">Examples using <code class="docutils literal notranslate"><span class="pre">ot.stochastic.plan_dual_entropic</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#examples-using-ot-stochastic-plan-dual-quadratic">Examples using <code class="docutils literal notranslate"><span class="pre">ot.stochastic.plan_dual_quadratic</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#examples-using-ot-stochastic-solve-dual-entropic">Examples using <code class="docutils literal notranslate"><span class="pre">ot.stochastic.solve_dual_entropic</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#examples-using-ot-stochastic-solve-semi-dual-entropic">Examples using <code class="docutils literal notranslate"><span class="pre">ot.stochastic.solve_semi_dual_entropic</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ot.unbalanced.html">ot.unbalanced</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.utils.html">ot.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.weak.html">ot.weak</a></li>
<li class="toctree-l2"><a class="reference internal" href="../all.html#main-ot-functions">Main <code class="xref py py-mod docutils literal notranslate"><span class="pre">ot</span></code> functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributors.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to POT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code_of_conduct.html">Code of conduct</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">POT Python Optimal Transport</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../all.html">API and modules</a></li>
      <li class="breadcrumb-item active">ot.stochastic</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/gen_modules/ot.stochastic.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="ot-stochastic">
<h1>ot.stochastic<a class="headerlink" href="#ot-stochastic" title="Link to this heading"></a></h1>
<p id="module-ot.stochastic">Stochastic solvers for regularized OT.</p>
<section id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="ot.stochastic.averaged_sgd_entropic_transport">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">averaged_sgd_entropic_transport</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">300000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#averaged_sgd_entropic_transport"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.stochastic.averaged_sgd_entropic_transport" title="Link to this definition"></a></dt>
<dd><p>Compute the ASGD algorithm to solve the regularized semi continous measures optimal transport max problem</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg}\cdot\Omega(\gamma)\\s.t. \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the ASGD algorithm
as proposed in <span class="xref std std-ref">[18]</span> [alg.2]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – Number of iteration.</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Learning rate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>ave_v</strong> (ndarray, shape (<cite>nt</cite>,)) – dual variable</p></li>
<li><p><em>.. _references-averaged-sgd-entropic-transport</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id1" role="note">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>Genevay, A., Cuturi, M., Peyré, G. &amp; Bach, F. (2016) Stochastic Optimization for Large-scale Optimal Transport. Advances in Neural Information Processing Systems (2016).</p>
</aside>
</aside>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.stochastic.batch_grad_dual">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">batch_grad_dual</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_beta</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#batch_grad_dual"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.stochastic.batch_grad_dual" title="Link to this definition"></a></dt>
<dd><p>Computes the partial gradient of the dual optimal transport problem.</p>
<p>For each <span class="math notranslate nohighlight">\((i,j)\)</span> in a batch of coordinates, the partial gradients are :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\partial_{\mathbf{u}_i} F = \frac{b_s}{l_v} \mathbf{u}_i -
\sum_{j \in B_v} \mathbf{a}_i \mathbf{b}_j
\exp\left( \frac{\mathbf{u}_i + \mathbf{v}_j - \mathbf{M}_{i,j}}{\mathrm{reg}} \right)\\\partial_{\mathbf{v}_j} F = \frac{b_s}{l_u} \mathbf{v}_j -
\sum_{i \in B_u} \mathbf{a}_i \mathbf{b}_j
\exp\left( \frac{\mathbf{u}_i + \mathbf{v}_j - \mathbf{M}_{i,j}}{\mathrm{reg}} \right)\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{u}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> are dual variables in <span class="math notranslate nohighlight">\(\mathbb{R}^{ns} \times \mathbb{R}^{nt}\)</span></p></li>
<li><p>reg is the regularization term</p></li>
<li><p><span class="math notranslate nohighlight">\(B_u\)</span> and <span class="math notranslate nohighlight">\(B_v\)</span> are lists of index</p></li>
<li><p><span class="math notranslate nohighlight">\(b_s\)</span> is the size of the batches <span class="math notranslate nohighlight">\(B_u\)</span> and <span class="math notranslate nohighlight">\(B_v\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(l_u\)</span> and <span class="math notranslate nohighlight">\(l_v\)</span> are the lengths of <span class="math notranslate nohighlight">\(B_u\)</span> and <span class="math notranslate nohighlight">\(B_v\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the dual problem is the SGD algorithm
as proposed in <span class="xref std std-ref">[19]</span> [alg.1]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – source measure</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>alpha</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – dual variable</p></li>
<li><p><strong>beta</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – dual variable</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – size of the batch</p></li>
<li><p><strong>batch_alpha</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>bs</em><em>,</em><em>)</em>) – batch of index of alpha</p></li>
<li><p><strong>batch_beta</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>bs</em><em>,</em><em>)</em>) – batch of index of beta</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>grad</strong> (ndarray, shape (<cite>ns</cite>,)) – partial grad F</p></li>
<li><p><em>.. _references-batch-grad-dual</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id2" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.stochastic.c_transform_entropic">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">c_transform_entropic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#c_transform_entropic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.stochastic.c_transform_entropic" title="Link to this definition"></a></dt>
<dd><p>The goal is to recover u from the c-transform.</p>
<p>The function computes the c-transform of a dual variable from the other
dual variable:</p>
<div class="math notranslate nohighlight">
\[\mathbf{u} = \mathbf{v}^{c,reg} = - \mathrm{reg} \sum_j \mathbf{b}_j
\exp\left( \frac{\mathbf{v} - \mathbf{M}}{\mathrm{reg}} \right)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{u}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> are dual variables in <span class="math notranslate nohighlight">\(\mathbb{R}^{ns} \times \mathbb{R}^{nt}\)</span></p></li>
<li><p>reg is the regularization term</p></li>
</ul>
<p>It is used to recover an optimal u from optimal v solving the semi dual
problem, see Proposition 2.1 of <span class="xref std std-ref">[18]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>v</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Dual variable.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>u</strong> (ndarray, shape (<cite>ns</cite>,)) – Dual variable.</p></li>
<li><p><em>.. _references-c-transform-entropic</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id3" role="note">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>Genevay, A., Cuturi, M., Peyré, G. &amp; Bach, F. (2016) Stochastic Optimization for Large-scale Optimal Transport. Advances in Neural Information Processing Systems (2016).</p>
</aside>
</aside>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.stochastic.coordinate_grad_semi_dual">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">coordinate_grad_semi_dual</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#coordinate_grad_semi_dual"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.stochastic.coordinate_grad_semi_dual" title="Link to this definition"></a></dt>
<dd><p>Compute the coordinate gradient update for regularized discrete distributions for <span class="math notranslate nohighlight">\((i, :)\)</span></p>
<p>The function computes the gradient of the semi dual problem:</p>
<div class="math notranslate nohighlight">
\[\max_\mathbf{v} \ \sum_i \mathbf{a}_i \left[ \sum_j \mathbf{v}_j \mathbf{b}_j - \mathrm{reg}
\cdot \log \left( \sum_j \mathbf{b}_j
\exp \left( \frac{\mathbf{v}_j - \mathbf{M}_{i,j}}{\mathrm{reg}}
\right) \right) \right]\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{v}\)</span> is a dual variable in <span class="math notranslate nohighlight">\(\mathbb{R}^{nt}\)</span></p></li>
<li><p>reg is the regularization term</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the ASGD &amp; SAG algorithms
as proposed in <span class="xref std std-ref">[18]</span> [alg.1 &amp; alg.2]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target measure.</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Cost matrix.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0.</p></li>
<li><p><strong>v</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Dual variable.</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – Picked number <cite>i</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>coordinate gradient</strong> (<em>ndarray, shape (nt,)</em>)</p></li>
<li><p><em>.. _references-coordinate-grad-semi-dual</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id4" role="note">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>Genevay, A., Cuturi, M., Peyré, G. &amp; Bach, F. (2016) Stochastic Optimization for Large-scale Optimal Transport. Advances in Neural Information Processing Systems (2016).</p>
</aside>
</aside>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.stochastic.loss_dual_entropic">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">loss_dual_entropic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ws</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sqeuclidean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#loss_dual_entropic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.stochastic.loss_dual_entropic" title="Link to this definition"></a></dt>
<dd><p>Compute the dual loss of the entropic OT as in equation (6)-(7) of [19]</p>
<p>This loss is backend compatible and can be used for stochastic optimization
of the dual potentials. It can be used on the full dataset (beware of
memory) or on minibatches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Source dual potential</p></li>
<li><p><strong>v</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target dual potential</p></li>
<li><p><strong>xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Source samples</p></li>
<li><p><strong>xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Target samples</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0 (default=1)</p></li>
<li><p><strong>ws</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Source sample weights (default unif)</p></li>
<li><p><strong>wt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Target sample weights (default unif)</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>callable</em>) – Ground metric for OT (default quadratic). Can be given as a callable
function taking (xs,xt) as parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>dual_loss</strong> – Dual loss (to maximize)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id5" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

<section id="examples-using-ot-stochastic-loss-dual-entropic">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">ot.stochastic.loss_dual_entropic</span></code><a class="headerlink" href="#examples-using-ot-stochastic-loss-dual-entropic" title="Link to this heading"></a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Dual OT solvers for entropic and quadratic regularized OT with Pytorch"><img alt="" src="../_images/sphx_glr_plot_dual_ot_pytorch_thumb.png" />
<p><a class="reference internal" href="../auto_examples/backends/plot_dual_ot_pytorch.html#sphx-glr-auto-examples-backends-plot-dual-ot-pytorch-py"><span class="std std-ref">Dual OT solvers for entropic and quadratic regularized OT with Pytorch</span></a></p>
  <div class="sphx-glr-thumbnail-title">Dual OT solvers for entropic and quadratic regularized OT with Pytorch</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Continuous OT plan estimation with Pytorch"><img alt="" src="../_images/sphx_glr_plot_stoch_continuous_ot_pytorch_thumb.png" />
<p><a class="reference internal" href="../auto_examples/backends/plot_stoch_continuous_ot_pytorch.html#sphx-glr-auto-examples-backends-plot-stoch-continuous-ot-pytorch-py"><span class="std std-ref">Continuous OT plan estimation with Pytorch</span></a></p>
  <div class="sphx-glr-thumbnail-title">Continuous OT plan estimation with Pytorch</div>
</div></div><div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.stochastic.loss_dual_quadratic">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">loss_dual_quadratic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ws</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sqeuclidean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#loss_dual_quadratic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.stochastic.loss_dual_quadratic" title="Link to this definition"></a></dt>
<dd><p>Compute the dual loss of the quadratic regularized OT as in equation (6)-(7) of [19]</p>
<p>This loss is backend compatible and can be used for stochastic optimization
of the dual potentials. It can be used on the full dataset (beware of
memory) or on minibatches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Source dual potential</p></li>
<li><p><strong>v</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target dual potential</p></li>
<li><p><strong>xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Source samples</p></li>
<li><p><strong>xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Target samples</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0 (default=1)</p></li>
<li><p><strong>ws</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Source sample weights (default unif)</p></li>
<li><p><strong>wt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Target sample weights (default unif)</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>callable</em>) – Ground metric for OT (default quadratic). Can be given as a callable
function taking (xs,xt) as parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>dual_loss</strong> – Dual loss (to maximize)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id6" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

</section>
<section id="examples-using-ot-stochastic-loss-dual-quadratic">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">ot.stochastic.loss_dual_quadratic</span></code><a class="headerlink" href="#examples-using-ot-stochastic-loss-dual-quadratic" title="Link to this heading"></a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Dual OT solvers for entropic and quadratic regularized OT with Pytorch"><img alt="" src="../_images/sphx_glr_plot_dual_ot_pytorch_thumb.png" />
<p><a class="reference internal" href="../auto_examples/backends/plot_dual_ot_pytorch.html#sphx-glr-auto-examples-backends-plot-dual-ot-pytorch-py"><span class="std std-ref">Dual OT solvers for entropic and quadratic regularized OT with Pytorch</span></a></p>
  <div class="sphx-glr-thumbnail-title">Dual OT solvers for entropic and quadratic regularized OT with Pytorch</div>
</div></div><div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.stochastic.plan_dual_entropic">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">plan_dual_entropic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ws</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sqeuclidean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#plan_dual_entropic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.stochastic.plan_dual_entropic" title="Link to this definition"></a></dt>
<dd><p>Compute the primal OT plan the entropic OT as in equation (8) of [19]</p>
<p>This loss is backend compatible and can be used for stochastic optimization
of the dual potentials. It can be used on the full dataset (beware of
memory) or on minibatches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Source dual potential</p></li>
<li><p><strong>v</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target dual potential</p></li>
<li><p><strong>xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Source samples</p></li>
<li><p><strong>xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Target samples</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0 (default=1)</p></li>
<li><p><strong>ws</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Source sample weights (default unif)</p></li>
<li><p><strong>wt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Target sample weights (default unif)</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>callable</em>) – Ground metric for OT (default quadratic). Can be given as a callable
function taking (xs,xt) as parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>G</strong> – Primal OT plan</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id7" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

</section>
<section id="examples-using-ot-stochastic-plan-dual-entropic">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">ot.stochastic.plan_dual_entropic</span></code><a class="headerlink" href="#examples-using-ot-stochastic-plan-dual-entropic" title="Link to this heading"></a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Dual OT solvers for entropic and quadratic regularized OT with Pytorch"><img alt="" src="../_images/sphx_glr_plot_dual_ot_pytorch_thumb.png" />
<p><a class="reference internal" href="../auto_examples/backends/plot_dual_ot_pytorch.html#sphx-glr-auto-examples-backends-plot-dual-ot-pytorch-py"><span class="std std-ref">Dual OT solvers for entropic and quadratic regularized OT with Pytorch</span></a></p>
  <div class="sphx-glr-thumbnail-title">Dual OT solvers for entropic and quadratic regularized OT with Pytorch</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Continuous OT plan estimation with Pytorch"><img alt="" src="../_images/sphx_glr_plot_stoch_continuous_ot_pytorch_thumb.png" />
<p><a class="reference internal" href="../auto_examples/backends/plot_stoch_continuous_ot_pytorch.html#sphx-glr-auto-examples-backends-plot-stoch-continuous-ot-pytorch-py"><span class="std std-ref">Continuous OT plan estimation with Pytorch</span></a></p>
  <div class="sphx-glr-thumbnail-title">Continuous OT plan estimation with Pytorch</div>
</div></div><div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.stochastic.plan_dual_quadratic">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">plan_dual_quadratic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ws</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sqeuclidean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#plan_dual_quadratic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.stochastic.plan_dual_quadratic" title="Link to this definition"></a></dt>
<dd><p>Compute the primal OT plan the quadratic regularized OT as in equation (8) of [19]</p>
<p>This loss is backend compatible and can be used for stochastic optimization
of the dual potentials. It can be used on the full dataset (beware of
memory) or on minibatches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Source dual potential</p></li>
<li><p><strong>v</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target dual potential</p></li>
<li><p><strong>xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Source samples</p></li>
<li><p><strong>xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Target samples</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0 (default=1)</p></li>
<li><p><strong>ws</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Source sample weights (default unif)</p></li>
<li><p><strong>wt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Target sample weights (default unif)</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>callable</em>) – Ground metric for OT (default quadratic). Can be given as a callable
function taking (xs,xt) as parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>G</strong> – Primal OT plan</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id8" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

</section>
<section id="examples-using-ot-stochastic-plan-dual-quadratic">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">ot.stochastic.plan_dual_quadratic</span></code><a class="headerlink" href="#examples-using-ot-stochastic-plan-dual-quadratic" title="Link to this heading"></a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Dual OT solvers for entropic and quadratic regularized OT with Pytorch"><img alt="" src="../_images/sphx_glr_plot_dual_ot_pytorch_thumb.png" />
<p><a class="reference internal" href="../auto_examples/backends/plot_dual_ot_pytorch.html#sphx-glr-auto-examples-backends-plot-dual-ot-pytorch-py"><span class="std std-ref">Dual OT solvers for entropic and quadratic regularized OT with Pytorch</span></a></p>
  <div class="sphx-glr-thumbnail-title">Dual OT solvers for entropic and quadratic regularized OT with Pytorch</div>
</div></div><div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.stochastic.sag_entropic_transport">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">sag_entropic_transport</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#sag_entropic_transport"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.stochastic.sag_entropic_transport" title="Link to this definition"></a></dt>
<dd><p>Compute the SAG algorithm to solve the regularized discrete measures optimal transport max problem</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot\Omega(\gamma)\\s.t. \ \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the SAG algorithm
as proposed in <span class="xref std std-ref">[18]</span> [alg.1]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>,</em>) – Source measure.</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>,</em>) – Target measure.</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>,</em>) – Cost matrix.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – Number of iteration.</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Learning rate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>v</strong> (ndarray, shape (<cite>nt</cite>,)) – Dual variable.</p></li>
<li><p><em>.. _references-sag-entropic-transport</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id9" role="note">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>Genevay, A., Cuturi, M., Peyré, G. &amp; Bach, F. (2016) Stochastic Optimization for Large-scale Optimal Transport. Advances in Neural Information Processing Systems (2016).</p>
</aside>
</aside>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.stochastic.sgd_entropic_regularization">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">sgd_entropic_regularization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#sgd_entropic_regularization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.stochastic.sgd_entropic_regularization" title="Link to this definition"></a></dt>
<dd><p>Compute the sgd algorithm to solve the regularized discrete measures optimal transport dual problem</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot\Omega(\gamma)\\s.t. \ \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – source measure</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – size of the batch</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – number of iteration</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – learning rate</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>ndarray, shape (ns,)</em>) – dual variable</p></li>
<li><p><strong>beta</strong> (<em>ndarray, shape (nt,)</em>) – dual variable</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id10" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

<div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.stochastic.solve_dual_entropic">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">solve_dual_entropic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#solve_dual_entropic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.stochastic.solve_dual_entropic" title="Link to this definition"></a></dt>
<dd><p>Compute the transportation matrix to solve the regularized discrete measures optimal transport dual problem</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot\Omega(\gamma)\\s.t. \ \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – source measure</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – size of the batch</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – number of iteration</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – learning rate</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pi</strong> (<em>ndarray, shape (ns, nt)</em>) – transportation matrix</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id11" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

</section>
<section id="examples-using-ot-stochastic-solve-dual-entropic">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">ot.stochastic.solve_dual_entropic</span></code><a class="headerlink" href="#examples-using-ot-stochastic-solve-dual-entropic" title="Link to this heading"></a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example is designed to show how to use the stochastic optimization algorithms for discrete..."><img alt="" src="../_images/sphx_glr_plot_stochastic_thumb.png" />
<p><a class="reference internal" href="../auto_examples/others/plot_stochastic.html#sphx-glr-auto-examples-others-plot-stochastic-py"><span class="std std-ref">Stochastic examples</span></a></p>
  <div class="sphx-glr-thumbnail-title">Stochastic examples</div>
</div></div><div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="ot.stochastic.solve_semi_dual_entropic">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">solve_semi_dual_entropic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#solve_semi_dual_entropic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.stochastic.solve_semi_dual_entropic" title="Link to this definition"></a></dt>
<dd><p>Compute the transportation matrix to solve the regularized discrete measures optimal transport max problem</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot\Omega(\gamma)\\s.t. \ \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the SAG or ASGD algorithms
as proposed in <span class="xref std std-ref">[18]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – source measure</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>methode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a>) – used method (SAG or ASGD)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – number of iteration</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – learning rate</p></li>
<li><p><strong>n_source</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – size of the source measure</p></li>
<li><p><strong>n_target</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – size of the target measure</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pi</strong> (<em>ndarray, shape (ns, nt)</em>) – transportation matrix</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
<li><p><em>.. _references-solve-semi-dual-entropic</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id12" role="note">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>Genevay, A., Cuturi, M., Peyré, G. &amp; Bach, F. (2016) Stochastic Optimization for Large-scale Optimal Transport. Advances in Neural Information Processing Systems (2016).</p>
</aside>
</aside>
</dd></dl>

</section>
<section id="examples-using-ot-stochastic-solve-semi-dual-entropic">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">ot.stochastic.solve_semi_dual_entropic</span></code><a class="headerlink" href="#examples-using-ot-stochastic-solve-semi-dual-entropic" title="Link to this heading"></a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example is designed to show how to use the stochastic optimization algorithms for discrete..."><img alt="" src="../_images/sphx_glr_plot_stochastic_thumb.png" />
<p><a class="reference internal" href="../auto_examples/others/plot_stochastic.html#sphx-glr-auto-examples-others-plot-stochastic-py"><span class="std std-ref">Stochastic examples</span></a></p>
  <div class="sphx-glr-thumbnail-title">Stochastic examples</div>
</div></div><div class="sphx-glr-clear"></div><dl class="py function">
<dt class="sig sig-object py" id="id0">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">averaged_sgd_entropic_transport</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">300000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#averaged_sgd_entropic_transport"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id0" title="Link to this definition"></a></dt>
<dd><p>Compute the ASGD algorithm to solve the regularized semi continous measures optimal transport max problem</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg}\cdot\Omega(\gamma)\\s.t. \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the ASGD algorithm
as proposed in <span class="xref std std-ref">[18]</span> [alg.2]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – Number of iteration.</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Learning rate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>ave_v</strong> (ndarray, shape (<cite>nt</cite>,)) – dual variable</p></li>
<li><p><em>.. _references-averaged-sgd-entropic-transport</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id13" role="note">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>Genevay, A., Cuturi, M., Peyré, G. &amp; Bach, F. (2016) Stochastic Optimization for Large-scale Optimal Transport. Advances in Neural Information Processing Systems (2016).</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id14">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">batch_grad_dual</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_beta</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#batch_grad_dual"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id14" title="Link to this definition"></a></dt>
<dd><p>Computes the partial gradient of the dual optimal transport problem.</p>
<p>For each <span class="math notranslate nohighlight">\((i,j)\)</span> in a batch of coordinates, the partial gradients are :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\partial_{\mathbf{u}_i} F = \frac{b_s}{l_v} \mathbf{u}_i -
\sum_{j \in B_v} \mathbf{a}_i \mathbf{b}_j
\exp\left( \frac{\mathbf{u}_i + \mathbf{v}_j - \mathbf{M}_{i,j}}{\mathrm{reg}} \right)\\\partial_{\mathbf{v}_j} F = \frac{b_s}{l_u} \mathbf{v}_j -
\sum_{i \in B_u} \mathbf{a}_i \mathbf{b}_j
\exp\left( \frac{\mathbf{u}_i + \mathbf{v}_j - \mathbf{M}_{i,j}}{\mathrm{reg}} \right)\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{u}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> are dual variables in <span class="math notranslate nohighlight">\(\mathbb{R}^{ns} \times \mathbb{R}^{nt}\)</span></p></li>
<li><p>reg is the regularization term</p></li>
<li><p><span class="math notranslate nohighlight">\(B_u\)</span> and <span class="math notranslate nohighlight">\(B_v\)</span> are lists of index</p></li>
<li><p><span class="math notranslate nohighlight">\(b_s\)</span> is the size of the batches <span class="math notranslate nohighlight">\(B_u\)</span> and <span class="math notranslate nohighlight">\(B_v\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(l_u\)</span> and <span class="math notranslate nohighlight">\(l_v\)</span> are the lengths of <span class="math notranslate nohighlight">\(B_u\)</span> and <span class="math notranslate nohighlight">\(B_v\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the dual problem is the SGD algorithm
as proposed in <span class="xref std std-ref">[19]</span> [alg.1]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – source measure</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>alpha</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – dual variable</p></li>
<li><p><strong>beta</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – dual variable</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – size of the batch</p></li>
<li><p><strong>batch_alpha</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>bs</em><em>,</em><em>)</em>) – batch of index of alpha</p></li>
<li><p><strong>batch_beta</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>bs</em><em>,</em><em>)</em>) – batch of index of beta</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>grad</strong> (ndarray, shape (<cite>ns</cite>,)) – partial grad F</p></li>
<li><p><em>.. _references-batch-grad-dual</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id15" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id16">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">c_transform_entropic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#c_transform_entropic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id16" title="Link to this definition"></a></dt>
<dd><p>The goal is to recover u from the c-transform.</p>
<p>The function computes the c-transform of a dual variable from the other
dual variable:</p>
<div class="math notranslate nohighlight">
\[\mathbf{u} = \mathbf{v}^{c,reg} = - \mathrm{reg} \sum_j \mathbf{b}_j
\exp\left( \frac{\mathbf{v} - \mathbf{M}}{\mathrm{reg}} \right)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{u}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> are dual variables in <span class="math notranslate nohighlight">\(\mathbb{R}^{ns} \times \mathbb{R}^{nt}\)</span></p></li>
<li><p>reg is the regularization term</p></li>
</ul>
<p>It is used to recover an optimal u from optimal v solving the semi dual
problem, see Proposition 2.1 of <span class="xref std std-ref">[18]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>v</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Dual variable.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>u</strong> (ndarray, shape (<cite>ns</cite>,)) – Dual variable.</p></li>
<li><p><em>.. _references-c-transform-entropic</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id17" role="note">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>Genevay, A., Cuturi, M., Peyré, G. &amp; Bach, F. (2016) Stochastic Optimization for Large-scale Optimal Transport. Advances in Neural Information Processing Systems (2016).</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id18">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">coordinate_grad_semi_dual</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#coordinate_grad_semi_dual"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id18" title="Link to this definition"></a></dt>
<dd><p>Compute the coordinate gradient update for regularized discrete distributions for <span class="math notranslate nohighlight">\((i, :)\)</span></p>
<p>The function computes the gradient of the semi dual problem:</p>
<div class="math notranslate nohighlight">
\[\max_\mathbf{v} \ \sum_i \mathbf{a}_i \left[ \sum_j \mathbf{v}_j \mathbf{b}_j - \mathrm{reg}
\cdot \log \left( \sum_j \mathbf{b}_j
\exp \left( \frac{\mathbf{v}_j - \mathbf{M}_{i,j}}{\mathrm{reg}}
\right) \right) \right]\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{v}\)</span> is a dual variable in <span class="math notranslate nohighlight">\(\mathbb{R}^{nt}\)</span></p></li>
<li><p>reg is the regularization term</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the ASGD &amp; SAG algorithms
as proposed in <span class="xref std std-ref">[18]</span> [alg.1 &amp; alg.2]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target measure.</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Cost matrix.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0.</p></li>
<li><p><strong>v</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Dual variable.</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – Picked number <cite>i</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>coordinate gradient</strong> (<em>ndarray, shape (nt,)</em>)</p></li>
<li><p><em>.. _references-coordinate-grad-semi-dual</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id19" role="note">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>Genevay, A., Cuturi, M., Peyré, G. &amp; Bach, F. (2016) Stochastic Optimization for Large-scale Optimal Transport. Advances in Neural Information Processing Systems (2016).</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id20">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">loss_dual_entropic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ws</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sqeuclidean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#loss_dual_entropic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id20" title="Link to this definition"></a></dt>
<dd><p>Compute the dual loss of the entropic OT as in equation (6)-(7) of [19]</p>
<p>This loss is backend compatible and can be used for stochastic optimization
of the dual potentials. It can be used on the full dataset (beware of
memory) or on minibatches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Source dual potential</p></li>
<li><p><strong>v</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target dual potential</p></li>
<li><p><strong>xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Source samples</p></li>
<li><p><strong>xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Target samples</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0 (default=1)</p></li>
<li><p><strong>ws</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Source sample weights (default unif)</p></li>
<li><p><strong>wt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Target sample weights (default unif)</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>callable</em>) – Ground metric for OT (default quadratic). Can be given as a callable
function taking (xs,xt) as parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>dual_loss</strong> – Dual loss (to maximize)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id21" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id22">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">loss_dual_quadratic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ws</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sqeuclidean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#loss_dual_quadratic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id22" title="Link to this definition"></a></dt>
<dd><p>Compute the dual loss of the quadratic regularized OT as in equation (6)-(7) of [19]</p>
<p>This loss is backend compatible and can be used for stochastic optimization
of the dual potentials. It can be used on the full dataset (beware of
memory) or on minibatches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Source dual potential</p></li>
<li><p><strong>v</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target dual potential</p></li>
<li><p><strong>xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Source samples</p></li>
<li><p><strong>xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Target samples</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0 (default=1)</p></li>
<li><p><strong>ws</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Source sample weights (default unif)</p></li>
<li><p><strong>wt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Target sample weights (default unif)</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>callable</em>) – Ground metric for OT (default quadratic). Can be given as a callable
function taking (xs,xt) as parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>dual_loss</strong> – Dual loss (to maximize)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id23" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id24">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">plan_dual_entropic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ws</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sqeuclidean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#plan_dual_entropic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id24" title="Link to this definition"></a></dt>
<dd><p>Compute the primal OT plan the entropic OT as in equation (8) of [19]</p>
<p>This loss is backend compatible and can be used for stochastic optimization
of the dual potentials. It can be used on the full dataset (beware of
memory) or on minibatches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Source dual potential</p></li>
<li><p><strong>v</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target dual potential</p></li>
<li><p><strong>xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Source samples</p></li>
<li><p><strong>xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Target samples</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0 (default=1)</p></li>
<li><p><strong>ws</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Source sample weights (default unif)</p></li>
<li><p><strong>wt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Target sample weights (default unif)</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>callable</em>) – Ground metric for OT (default quadratic). Can be given as a callable
function taking (xs,xt) as parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>G</strong> – Primal OT plan</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id25" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id26">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">plan_dual_quadratic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ws</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sqeuclidean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#plan_dual_quadratic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id26" title="Link to this definition"></a></dt>
<dd><p>Compute the primal OT plan the quadratic regularized OT as in equation (8) of [19]</p>
<p>This loss is backend compatible and can be used for stochastic optimization
of the dual potentials. It can be used on the full dataset (beware of
memory) or on minibatches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>u</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Source dual potential</p></li>
<li><p><strong>v</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target dual potential</p></li>
<li><p><strong>xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Source samples</p></li>
<li><p><strong>xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Target samples</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0 (default=1)</p></li>
<li><p><strong>ws</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Source sample weights (default unif)</p></li>
<li><p><strong>wt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Target sample weights (default unif)</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>callable</em>) – Ground metric for OT (default quadratic). Can be given as a callable
function taking (xs,xt) as parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>G</strong> – Primal OT plan</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id27" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id28">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">sag_entropic_transport</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#sag_entropic_transport"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id28" title="Link to this definition"></a></dt>
<dd><p>Compute the SAG algorithm to solve the regularized discrete measures optimal transport max problem</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot\Omega(\gamma)\\s.t. \ \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the SAG algorithm
as proposed in <span class="xref std std-ref">[18]</span> [alg.1]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>,</em>) – Source measure.</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>,</em>) – Target measure.</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>,</em>) – Cost matrix.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – Number of iteration.</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Learning rate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>v</strong> (ndarray, shape (<cite>nt</cite>,)) – Dual variable.</p></li>
<li><p><em>.. _references-sag-entropic-transport</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id29" role="note">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>Genevay, A., Cuturi, M., Peyré, G. &amp; Bach, F. (2016) Stochastic Optimization for Large-scale Optimal Transport. Advances in Neural Information Processing Systems (2016).</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id30">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">sgd_entropic_regularization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#sgd_entropic_regularization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id30" title="Link to this definition"></a></dt>
<dd><p>Compute the sgd algorithm to solve the regularized discrete measures optimal transport dual problem</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot\Omega(\gamma)\\s.t. \ \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – source measure</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – size of the batch</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – number of iteration</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – learning rate</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>ndarray, shape (ns,)</em>) – dual variable</p></li>
<li><p><strong>beta</strong> (<em>ndarray, shape (nt,)</em>) – dual variable</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id31" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id32">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">solve_dual_entropic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#solve_dual_entropic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id32" title="Link to this definition"></a></dt>
<dd><p>Compute the transportation matrix to solve the regularized discrete measures optimal transport dual problem</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot\Omega(\gamma)\\s.t. \ \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – source measure</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – size of the batch</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – number of iteration</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – learning rate</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pi</strong> (<em>ndarray, shape (ns, nt)</em>) – transportation matrix</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id33" role="note">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.&amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation. International Conference on Learning Representation (2018)</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id34">
<span class="sig-prename descclassname"><span class="pre">ot.stochastic.</span></span><span class="sig-name descname"><span class="pre">solve_semi_dual_entropic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/stochastic.html#solve_semi_dual_entropic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id34" title="Link to this definition"></a></dt>
<dd><p>Compute the transportation matrix to solve the regularized discrete measures optimal transport max problem</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +
\mathrm{reg} \cdot\Omega(\gamma)\\s.t. \ \gamma \mathbf{1} = \mathbf{a}\\     \gamma^T \mathbf{1} = \mathbf{b}\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the SAG or ASGD algorithms
as proposed in <span class="xref std std-ref">[18]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – source measure</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>methode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a>) – used method (SAG or ASGD)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – number of iteration</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a>) – learning rate</p></li>
<li><p><strong>n_source</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – size of the source measure</p></li>
<li><p><strong>n_target</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – size of the target measure</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pi</strong> (<em>ndarray, shape (ns, nt)</em>) – transportation matrix</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
<li><p><em>.. _references-solve-semi-dual-entropic</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id35" role="note">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>Genevay, A., Cuturi, M., Peyré, G. &amp; Bach, F. (2016) Stochastic Optimization for Large-scale Optimal Transport. Advances in Neural Information Processing Systems (2016).</p>
</aside>
</aside>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ot.smooth.html" class="btn btn-neutral float-left" title="ot.smooth" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ot.unbalanced.html" class="btn btn-neutral float-right" title="ot.unbalanced" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016-2021, Rémi Flamary, Nicolas Courty.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note"
aria-label="versions">
  <!--  add shift_up to the class for force viewing ,
  data-toggle="rst-current-version" -->
    <span class="rst-current-version"  style="margin-bottom:1mm;">
      <span class="fa fa-book"> Python Optimal Transport</span>
      <hr  style="margin-bottom:1.5mm;margin-top:5mm;">
     <!--  versions
      <span class="fa fa-caret-down"></span>-->
      <span class="rst-current-version" style="display: inline-block;padding:
      0px;color:#fcfcfcab;float:left;font-size: 100%;">
        Versions: 
        <a href="https://pythonot.github.io/" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Release</a>
        <a href="https://pythonot.github.io/master" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Development</a>
        <a href="https://github.com/PythonOT/POT"
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Code</a>

      </span>

     
    </span>
  
     <!--
    <div class="rst-other-versions">

      

<div class="injected">

    
  <dl>
    <dt>Versions</dt>

    <dd><a href="https://pythonot.github.io/">Release</a></dd>
    
    <dd><a href="https://pythonot.github.io/master">Development</a></dd>
   
    

    <dt><a href="https://github.com/PythonOT/POT">Code on Github</a></dt>       

    
  </dl>
  <hr>

</div> 
</div>-->
  </div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>