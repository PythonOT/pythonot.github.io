<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ot.gromov &mdash; POT Python Optimal Transport 0.9.2dev documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=925fdc35"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ot.lp" href="ot.lp.html" />
    <link rel="prev" title="ot.gnn" href="ot.gnn.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            POT Python Optimal Transport
              <img src="../_static/logo_dark.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.9.2dev
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">POT: Python Optimal Transport</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quick start guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../all.html">API and modules</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ot.backend.html">ot.backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.bregman.html">ot.bregman</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.coot.html">ot.coot</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.da.html">ot.da</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.datasets.html">ot.datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.dr.html">ot.dr</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.factored.html">ot.factored</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gaussian.html">ot.gaussian</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gnn.html">ot.gnn</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">ot.gromov</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.BAPG_fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">BAPG_fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.BAPG_fused_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">BAPG_fused_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.BAPG_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">BAPG_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.BAPG_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">BAPG_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.GW_distance_estimation"><code class="docutils literal notranslate"><span class="pre">GW_distance_estimation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_fused_gromov_barycenters"><code class="docutils literal notranslate"><span class="pre">entropic_fused_gromov_barycenters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">entropic_fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_fused_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">entropic_fused_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_gromov_barycenters"><code class="docutils literal notranslate"><span class="pre">entropic_gromov_barycenters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">entropic_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">entropic_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_semirelaxed_fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">entropic_semirelaxed_fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_semirelaxed_fused_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">entropic_semirelaxed_fused_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_semirelaxed_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">entropic_semirelaxed_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_semirelaxed_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">entropic_semirelaxed_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fgw_barycenters"><code class="docutils literal notranslate"><span class="pre">fgw_barycenters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fused_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">fused_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fused_gromov_wasserstein_dictionary_learning"><code class="docutils literal notranslate"><span class="pre">fused_gromov_wasserstein_dictionary_learning()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fused_gromov_wasserstein_linear_unmixing"><code class="docutils literal notranslate"><span class="pre">fused_gromov_wasserstein_linear_unmixing()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gromov_barycenters"><code class="docutils literal notranslate"><span class="pre">gromov_barycenters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gromov_wasserstein_dictionary_learning"><code class="docutils literal notranslate"><span class="pre">gromov_wasserstein_dictionary_learning()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gromov_wasserstein_linear_unmixing"><code class="docutils literal notranslate"><span class="pre">gromov_wasserstein_linear_unmixing()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gwggrad"><code class="docutils literal notranslate"><span class="pre">gwggrad()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gwloss"><code class="docutils literal notranslate"><span class="pre">gwloss()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.init_matrix"><code class="docutils literal notranslate"><span class="pre">init_matrix()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.init_matrix_semirelaxed"><code class="docutils literal notranslate"><span class="pre">init_matrix_semirelaxed()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.pointwise_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">pointwise_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.sampled_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">sampled_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.semirelaxed_fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">semirelaxed_fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.semirelaxed_fused_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">semirelaxed_fused_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.semirelaxed_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">semirelaxed_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.semirelaxed_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">semirelaxed_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.solve_gromov_linesearch"><code class="docutils literal notranslate"><span class="pre">solve_gromov_linesearch()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.solve_semirelaxed_gromov_linesearch"><code class="docutils literal notranslate"><span class="pre">solve_semirelaxed_gromov_linesearch()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.tensor_product"><code class="docutils literal notranslate"><span class="pre">tensor_product()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.update_feature_matrix"><code class="docutils literal notranslate"><span class="pre">update_feature_matrix()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.update_kl_loss"><code class="docutils literal notranslate"><span class="pre">update_kl_loss()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.update_square_loss"><code class="docutils literal notranslate"><span class="pre">update_square_loss()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ot.lp.html">ot.lp</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.mapping.html">ot.mapping</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.optim.html">ot.optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.partial.html">ot.partial</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.plot.html">ot.plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.regpath.html">ot.regpath</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.sliced.html">ot.sliced</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.smooth.html">ot.smooth</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.stochastic.html">ot.stochastic</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.unbalanced.html">ot.unbalanced</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.utils.html">ot.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.weak.html">ot.weak</a></li>
<li class="toctree-l2"><a class="reference internal" href="../all.html#module-ot">Main <code class="xref py py-mod docutils literal notranslate"><span class="pre">ot</span></code> functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributors.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to POT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code_of_conduct.html">Code of conduct</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">POT Python Optimal Transport</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../all.html">API and modules</a></li>
      <li class="breadcrumb-item active">ot.gromov</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/gen_modules/ot.gromov.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-ot.gromov">
<span id="ot-gromov"></span><h1>ot.gromov<a class="headerlink" href="#module-ot.gromov" title="Link to this heading"></a></h1>
<p>Solvers related to Gromov-Wasserstein problems.</p>
<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.BAPG_fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">BAPG_fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginal_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#BAPG_fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.BAPG_fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{Y_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{Y_2}, \mathbf{q})\)</span>
with pairwise distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices <span class="math notranslate nohighlight">\(\mathbf{Y_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y_2}\)</span>,
estimated using Bregman Alternated Projected Gradient method.</p>
<p>If <cite>marginal_loss=True</cite>, the function solves the following Fused Gromov-Wasserstein
optimization problem :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in\mathop{\arg\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else, the function solves an equivalent problem [63, 64], where constant terms only
depending on the marginals <span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: are
discarded while assuming that L decomposes as in Proposition 1 in [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in\mathop{\arg\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F -
\alpha \langle h_1(\mathbf{C}_1) \mathbf{T} h_2(\mathbf{C_2})^\top , \mathbf{T} \rangle_F
s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: pairwise relation matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><dl class="simple">
<dt><cite>L</cite>: loss function to account for the misfit between the similarity and feature matrices</dt><dd><p>satisfying <span class="math notranslate nohighlight">\(L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\)</span></p>
</dd>
</dl>
</li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: trade-off parameter</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By algorithmic design the optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>
returned by this function does not necessarily satisfy the marginal
constraints <span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned Fused
Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Pairwise relation matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>marginal_loss</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional. Default is False.</em>) – Include constant marginal terms or not in the objective function.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two joint spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id1" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>63<span class="fn-bracket">]</span></span>
<p>Li, J., Tang, J., Kong, L., Liu, H., Li, J., So, A. M. C., &amp; Blanchet, J.
“A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein
in Graph Data”. International Conference on Learning Representations (ICLR), 2023.</p>
</aside>
<aside class="footnote brackets" id="id2" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>64<span class="fn-bracket">]</span></span>
<p>Ma, X., Chu, X., Wang, Y., Lin, Y., Zhao, J., Ma, L., &amp; Zhu, W.
“Fused Gromov-Wasserstein Graph Mixup for Graph-level Classifications”.
In Thirty-seventh Conference on Neural Information Processing Systems.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.BAPG_fused_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">BAPG_fused_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginal_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#BAPG_fused_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.BAPG_fused_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein loss between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{Y_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{Y_2}, \mathbf{q})\)</span>
with pairwise distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices <span class="math notranslate nohighlight">\(\mathbf{Y_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y_2}\)</span>,
estimated using Bregman Alternated Projected Gradient method.</p>
<p>If <cite>marginal_loss=True</cite>, the function solves the following Fused Gromov-Wasserstein
optimization problem :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{FGW} = \mathop{\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else, the function solves an equivalent problem [63, 64], where constant terms only
depending on the marginals <span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: are
discarded while assuming that L decomposes as in Proposition 1 in [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathop{\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F -
\alpha \langle h_1(\mathbf{C}_1) \mathbf{T} h_2(\mathbf{C_2})^\top , \mathbf{T} \rangle_F
s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><dl class="simple">
<dt><cite>L</cite>: loss function to account for the misfit between the similarity and feature matrices</dt><dd><p>satisfying <span class="math notranslate nohighlight">\(L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\)</span></p>
</dd>
</dl>
</li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: trade-off parameter</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By algorithmic design the optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>
returned by this function does not necessarily satisfy the marginal
constraints <span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned Fused
Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>marginal_loss</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional. Default is False.</em>) – Include constant marginal terms or not in the objective function.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two joint spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id3" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>63<span class="fn-bracket">]</span></span>
<p>Li, J., Tang, J., Kong, L., Liu, H., Li, J., So, A. M. C., &amp; Blanchet, J.
“A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein
in Graph Data”. International Conference on Learning Representations (ICLR), 2023.</p>
</aside>
<aside class="footnote brackets" id="id4" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>64<span class="fn-bracket">]</span></span>
<p>Ma, X., Chu, X., Wang, Y., Lin, Y., Zhao, J., Ma, L., &amp; Zhu, W.
“Fused Gromov-Wasserstein Graph Mixup for Graph-level Classifications”.
In Thirty-seventh Conference on Neural Information Processing Systems.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.BAPG_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">BAPG_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginal_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#BAPG_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.BAPG_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>
estimated using Bregman Alternated Projected Gradient method.</p>
<p>If <cite>marginal_loss=True</cite>, the function solves the following Gromov-Wasserstein
optimization problem :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else, the function solves an equivalent problem [63], where constant terms only
depending on the marginals <span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: are
discarded while assuming that L decomposes as in Proposition 1 in [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in\mathop{\arg\min}_\mathbf{T} \quad - \langle h_1(\mathbf{C}_1) \mathbf{T} h_2(\mathbf{C_2})^\top , \mathbf{T} \rangle_F\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><dl class="simple">
<dt><cite>L</cite>: loss function to account for the misfit between the similarity matrices</dt><dd><p>satisfying <span class="math notranslate nohighlight">\(L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\)</span></p>
</dd>
</dl>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By algorithmic design the optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>
returned by this function does not necessarily satisfy the marginal
constraints <span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned
Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>marginal_loss</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional. Default is False.</em>) – Include constant marginal terms or not in the objective function.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id5" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>63<span class="fn-bracket">]</span></span>
<p>Li, J., Tang, J., Kong, L., Liu, H., Li, J., So, A. M. C., &amp; Blanchet, J.
“A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein
in Graph Data”. International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.BAPG_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">BAPG_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginal_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#BAPG_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.BAPG_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein loss <span class="math notranslate nohighlight">\(\mathbf{GW}\)</span> between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>
estimated using Bregman Alternated Projected Gradient method.</p>
<p>If <cite>marginal_loss=True</cite>, the function solves the following Gromov-Wasserstein
optimization problem :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{GW} = \mathop{\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else, the function solves an equivalent problem [63, 64], where constant terms only
depending on the marginals <span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: are
discarded while assuming that L decomposes as in Proposition 1 in [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathop{\min}_\mathbf{T}  \quad - \langle h_1(\mathbf{C}_1) \mathbf{T} h_2(\mathbf{C_2})^\top , \mathbf{T} \rangle_F\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><dl class="simple">
<dt><cite>L</cite>: loss function to account for the misfit between the similarity matrices</dt><dd><p>satisfying <span class="math notranslate nohighlight">\(L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\)</span></p>
</dd>
</dl>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By algorithmic design the optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>
returned by this function does not necessarily satisfy the marginal
constraints <span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned
Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommand it
to correcly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>marginal_loss</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional. Default is False.</em>) – Include constant marginal terms or not in the objective function.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>gw_dist</strong> – Gromov-Wasserstein distance</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a></p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id6" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>63<span class="fn-bracket">]</span></span>
<p>Li, J., Tang, J., Kong, L., Liu, H., Li, J., So, A. M. C., &amp; Blanchet, J.
“A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein
in Graph Data”. International Conference on Learning Representations (ICLR), 2023.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.GW_distance_estimation">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">GW_distance_estimation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_samples_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_samples_q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_estimators.html#GW_distance_estimation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.GW_distance_estimation" title="Link to this definition"></a></dt>
<dd><p>Returns an approximation of the Gromov-Wasserstein loss between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>
with a fixed transport plan <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>. To recover an approximation of the Gromov-Wasserstein distance as defined in [13] compute <span class="math notranslate nohighlight">\(d_{GW} = \frac{1}{2} \sqrt{\mathbf{GW}}\)</span>.</p>
<p>The function gives an unbiased approximation of the following equation:</p>
<div class="math notranslate nohighlight">
\[\mathbf{GW} = \sum_{i,j,k,l} L(\mathbf{C_{1}}_{i,k}, \mathbf{C_{2}}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><cite>L</cite> : Loss function to account for the misfit between the similarity matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: Matrix with marginal <span class="math notranslate nohighlight">\(\mathbf{p}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>loss_fun</strong> (function: <span class="math notranslate nohighlight">\(\mathbb{R} \times \mathbb{R} \mapsto \mathbb{R}\)</span>) – Loss function used for the distance, the transport plan does not depend on the loss function</p></li>
<li><p><strong>T</strong> (<em>csr</em><em> or </em><em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Transport plan matrix, either a sparse csr or a dense matrix</p></li>
<li><p><strong>nb_samples_p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – <cite>nb_samples_p</cite> is the number of samples (without replacement) along the first dimension of <span class="math notranslate nohighlight">\(\mathbf{T}\)</span></p></li>
<li><p><strong>nb_samples_q</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – <cite>nb_samples_q</cite> is the number of samples along the second dimension of <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>, for each sample along the first</p></li>
<li><p><strong>std</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Standard deviation associated with the prediction of the gromov-wasserstein cost</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Gromov-wasserstein cost</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a></p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id7" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></span>
<p>Kerdoncuff, Tanguy, Emonet, Rémi, Sebban, Marc
“Sampled Gromov Wasserstein.”
Machine Learning Journal (MLJ). 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_fused_gromov_barycenters">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_fused_gromov_barycenters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ys</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'barycenter'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstartT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_Y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_structure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#entropic_fused_gromov_barycenters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_fused_gromov_barycenters" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein barycenters of <cite>S</cite> measurable networks with node features <span class="math notranslate nohighlight">\((\mathbf{C}_s, \mathbf{Y}_s, \mathbf{p}_s)_{1 \leq s \leq S}\)</span>
estimated using Fused Gromov-Wasserstein transports from Sinkhorn projections.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^*, \mathbf{Y}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}, \mathbf{Y}\in \mathbb{Y}^{N \times d}} \quad \sum_s \lambda_s \mathrm{FGW}_{\alpha}(\mathbf{C}, \mathbf{C}_s, \mathbf{Y}, \mathbf{Y}_s, \mathbf{p}, \mathbf{p}_s)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}_s\)</span>: feature matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}_s\)</span>: metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}_s\)</span>: distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Size of the targeted barycenter</p></li>
<li><p><strong>Ys</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>array-like</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Features of all samples</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Metric cost matrices</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Sample weights in the <cite>S</cite> spaces.
If let to its default value None, uniform distributions are taken.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Weights in the targeted barycenter.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – List of the <cite>S</cite> spaces’ weights.
If let to its default value None, uniform weights are taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional.</em>) – Either structures are to be assumed symmetric or not. Default value is True.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>stop_criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional. Default is 'barycenter'.</em>) – Stop criterion taking values in [‘barycenter’, ‘loss’]. If set to ‘barycenter’
uses absolute norm variations of estimated barycenters. Else if set to ‘loss’
uses the relative variations of the loss.</p></li>
<li><p><strong>warmstartT</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of transport plans in the successive
fused gromov-wasserstein transport problems.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em> | </em><em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>, </em><em>N</em><em>)</em>) – Random initial value for the <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix provided by user.</p></li>
<li><p><strong>init_Y</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>d</em><em>)</em><em>, </em><em>optional</em>) – Initialization for the barycenters’ features. If not set a
random init is used.</p></li>
<li><p><strong>fixed_structure</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to fix the structure of the barycenter during the updates.</p></li>
<li><p><strong>fixed_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to fix the feature of the barycenter during the updates</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the <cite>ot.entropic_fused_gromov_wasserstein</cite> solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>Y</strong> (array-like, shape (<cite>N</cite>, <cite>d</cite>)) – Feature matrix in the barycenter space (permutated arbitrarily)</p></li>
<li><p><strong>C</strong> (array-like, shape (<cite>N</cite>, <cite>N</cite>)) – Similarity matrix in the barycenter space (permutated as Y’s rows)</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Only returned when log=True. It contains the keys:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: list of (<cite>N</cite>, <cite>ns</cite>) transport matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: (<cite>N</cite>,) barycenter weights</p></li>
<li><p><span class="math notranslate nohighlight">\((\mathbf{M}_s)_s\)</span>: all distance matrices between the feature of the barycenter and the other features <span class="math notranslate nohighlight">\((dist(\mathbf{X}, \mathbf{Y}_s))_s\)</span> shape (<cite>N</cite>, <cite>ns</cite>)</p></li>
<li><p>values used in convergence evaluation.</p></li>
</ul>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id8" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id9" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas
“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PGD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstart</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#entropic_fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{Y_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{Y_2}, \mathbf{q})\)</span>
with pairwise distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices <span class="math notranslate nohighlight">\(\mathbf{Y_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y_2}\)</span>,
estimated using Sinkhorn projections.</p>
<p>If <cite>solver=”PGD”</cite>, the function solves the following entropic-regularized
Fused Gromov-Wasserstein optimization problem using Projected Gradient Descent [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l} - \epsilon H(\mathbf{T})\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else if <cite>solver=”PPA”</cite>, the function solves the following Fused Gromov-Wasserstein
optimization problem using Proximal Point Algorithm [51]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in\mathop{\arg\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity and feature matrices</p></li>
<li><p><cite>H</cite>: entropy</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: trade-off parameter</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the inner solver <cite>ot.sinkhorn</cite> did not convergence, the
optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span> returned by this function does not
necessarily satisfy the marginal constraints
<span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned
Fused Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>solver</strong> (<em>string</em><em>, </em><em>optional</em>) – Solver to use either ‘PGD’ for Projected Gradient Descent or ‘PPA’
for Proximal Point Algorithm.
Default value is ‘PGD’.</p></li>
<li><p><strong>warmstart</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of dual potentials in the successive
Sinkhorn projections.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the ot.sinkhorn solver.
Such as <cite>numItermax</cite> and <cite>stopThr</cite> to control its estimation precision,
e.g [51] suggests to use <cite>numItermax=1</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two joint spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id10" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id11" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., &amp; Mémoli, F. (2019). The gromov–wasserstein
distance between networks and stable network invariants.
Information and Inference: A Journal of the IMA, 8(4), 757-787.</p>
</aside>
<aside class="footnote brackets" id="id12" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>51<span class="fn-bracket">]</span></span>
<p>Xu, H., Luo, D., Zha, H., &amp; Duke, L. C. (2019). Gromov-wasserstein
learning for graph matching and node embedding. In International
Conference on Machine Learning (ICML), 2019.</p>
</aside>
<aside class="footnote brackets" id="id13" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_fused_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_fused_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PGD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstart</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#entropic_fused_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_fused_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein distance between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{Y_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{Y_2}, \mathbf{q})\)</span>
with pairwise distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices <span class="math notranslate nohighlight">\(\mathbf{Y_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y_2}\)</span>,
estimated using Sinkhorn projections.</p>
<p>If <cite>solver=”PGD”</cite>, the function solves the following entropic-regularized
Fused Gromov-Wasserstein optimization problem using Projected Gradient Descent [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{FGW} = \mathop{\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l} - \epsilon H(\mathbf{T})\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else if <cite>solver=”PPA”</cite>, the function solves the following Fused Gromov-Wasserstein
optimization problem using Proximal Point Algorithm [51]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{FGW} = \mathop{\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity and feature matrices</p></li>
<li><p><cite>H</cite>: entropy</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: trade-off parameter</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the inner solver <cite>ot.sinkhorn</cite> did not convergence, the
optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span> returned by this function does not
necessarily satisfy the marginal constraints
<span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned
Fused Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>fgw_dist</strong> – Fused Gromov-Wasserstein distance</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a></p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id14" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id15" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>51<span class="fn-bracket">]</span></span>
<p>Xu, H., Luo, D., Zha, H., &amp; Duke, L. C. (2019). Gromov-wasserstein
learning for graph matching and node embedding. In International
Conference on Machine Learning (ICML), 2019.</p>
</aside>
<aside class="footnote brackets" id="id16" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_gromov_barycenters">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_gromov_barycenters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'barycenter'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstartT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#entropic_gromov_barycenters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_gromov_barycenters" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein barycenters of <cite>S</cite> measured similarity matrices <span class="math notranslate nohighlight">\((\mathbf{C}_s)_{1 \leq s \leq S}\)</span>
estimated using Gromov-Wasserstein transports from Sinkhorn projections.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}} \quad \sum_s \lambda_s \mathrm{GW}(\mathbf{C}, \mathbf{C}_s, \mathbf{p}, \mathbf{p}_s)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}_s\)</span>: metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}_s\)</span>: distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Size of the targeted barycenter</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Metric cost matrices</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Sample weights in the <cite>S</cite> spaces.
If let to its default value None, uniform distributions are taken.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Weights in the targeted barycenter.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – List of the <cite>S</cite> spaces’ weights.
If let to its default value None, uniform weights are taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional.</em>) – Either structures are to be assumed symmetric or not. Default value is True.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>stop_criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional. Default is 'barycenter'.</em>) – Convergence criterion taking values in [‘barycenter’, ‘loss’]. If set to ‘barycenter’
uses absolute norm variations of estimated barycenters. Else if set to ‘loss’
uses the relative variations of the loss.</p></li>
<li><p><strong>warmstartT</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of transport plans in the successive
gromov-wasserstein transport problems.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em> | </em><em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>, </em><em>N</em><em>)</em>) – Random initial value for the <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix provided by user.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the <cite>ot.entropic_gromov_wasserstein</cite> solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>C</strong> (array-like, shape (<cite>N</cite>, <cite>N</cite>)) – Similarity matrix in the barycenter space (permutated arbitrarily)</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Only returned when log=True. It contains the keys:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: list of (<cite>N</cite>, <cite>ns</cite>) transport matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: (<cite>N</cite>,) barycenter weights</p></li>
<li><p>values used in convergence evaluation.</p></li>
</ul>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id17" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PGD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstart</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#entropic_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>
estimated using Sinkhorn projections.</p>
<p>If <cite>solver=”PGD”</cite>, the function solves the following entropic-regularized
Gromov-Wasserstein optimization problem using Projected Gradient Descent [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l} - \epsilon H(\mathbf{T})\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else if <cite>solver=”PPA”</cite>, the function solves the following Gromov-Wasserstein
optimization problem using Proximal Point Algorithm [51]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
<li><p><cite>H</cite>: entropy</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the inner solver <cite>ot.sinkhorn</cite> did not convergence, the
optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span> returned by this function does not
necessarily satisfy the marginal constraints
<span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned
Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>solver</strong> (<em>string</em><em>, </em><em>optional</em>) – Solver to use either ‘PGD’ for Projected Gradient Descent or ‘PPA’
for Proximal Point Algorithm.
Default value is ‘PGD’.</p></li>
<li><p><strong>warmstart</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of dual potentials in the successive
Sinkhorn projections.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the ot.sinkhorn solver.
Such as <cite>numItermax</cite> and <cite>stopThr</cite> to control its estimation precision,
e.g [51] suggests to use <cite>numItermax=1</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id18" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id19" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., &amp; Mémoli, F. (2019). The gromov–wasserstein
distance between networks and stable network invariants.
Information and Inference: A Journal of the IMA, 8(4), 757-787.</p>
</aside>
<aside class="footnote brackets" id="id20" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>51<span class="fn-bracket">]</span></span>
<p>Xu, H., Luo, D., Zha, H., &amp; Duke, L. C. (2019). Gromov-wasserstein
learning for graph matching and node embedding. In International
Conference on Machine Learning (ICML), 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PGD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstart</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#entropic_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein loss <span class="math notranslate nohighlight">\(\mathbf{GW}\)</span> between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>
estimated using Sinkhorn projections. To recover the Gromov-Wasserstein distance as defined in [13] compute <span class="math notranslate nohighlight">\(d_{GW} = \frac{1}{2} \sqrt{\mathbf{GW}}\)</span>.</p>
<p>If <cite>solver=”PGD”</cite>, the function solves the following entropic-regularized
Gromov-Wasserstein optimization problem using Projected Gradient Descent [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{GW} = \mathop{\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l} - \epsilon H(\mathbf{T})\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else if <cite>solver=”PPA”</cite>, the function solves the following Gromov-Wasserstein
optimization problem using Proximal Point Algorithm [51]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{GW} = \mathop{\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
<li><p><cite>H</cite>: entropy</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the inner solver <cite>ot.sinkhorn</cite> did not convergence, the
optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span> returned by this function does not
necessarily satisfy the marginal constraints
<span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned
Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommand it
to correcly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>solver</strong> (<em>string</em><em>, </em><em>optional</em>) – Solver to use either ‘PGD’ for Projected Gradient Descent or ‘PPA’
for Proximal Point Algorithm.
Default value is ‘PGD’.</p></li>
<li><p><strong>warmstart</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of dual potentials in the successive
Sinkhorn projections.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the ot.sinkhorn solver.
Such as <cite>numItermax</cite> and <cite>stopThr</cite> to control its estimation precision,
e.g [51] suggests to use <cite>numItermax=1</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>gw_dist</strong> – Gromov-Wasserstein distance</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a></p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id21" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id22" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>51<span class="fn-bracket">]</span></span>
<p>Xu, H., Luo, D., Zha, H., &amp; Duke, L. C. (2019). Gromov-wasserstein
learning for graph matching and node embedding. In International
Conference on Machine Learning (ICML), 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_semirelaxed_fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_semirelaxed_fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#entropic_semirelaxed_fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_semirelaxed_fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Computes the entropic-regularized semi-relaxed FGW transport between two graphs (see <span class="xref std std-ref">[48]</span>)
estimated using a Mirror Descent algorithm following the KL geometry.</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_{\mathbf{T}} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix between features</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> source weights (sum to 1)</p></li>
<li><p><cite>L</cite> is a loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[48]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error computed on transport plans</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>G</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) – Optimal transportation matrix for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-semirelaxed-fused-gromov-wasserstein">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id23" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_semirelaxed_fused_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_semirelaxed_fused_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#entropic_semirelaxed_fused_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_semirelaxed_fused_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Computes the entropic-regularized semi-relaxed FGW divergence between two graphs (see <span class="xref std std-ref">[48]</span>)
estimated using a Mirror Descent algorithm following the KL geometry.</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{srFGW}_{\alpha} = \min_{\mathbf{T}} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix between features</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> source weights (sum to 1)</p></li>
<li><p><cite>L</cite> is a loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[48]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space.</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional</em>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error computed on transport plans</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – Parameters can be directly passed to the ot.optim.cg solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>srfgw-divergence</strong> (<em>float</em>) – Semi-relaxed Fused gromov wasserstein divergence for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-semirelaxed-fused-gromov-wasserstein2">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id24" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_semirelaxed_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_semirelaxed_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#entropic_semirelaxed_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_semirelaxed_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the entropic-regularized semi-relaxed gromov-wasserstein divergence
transport plan from <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> to <span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>
estimated using a Mirror Descent algorithm following the KL geometry.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_\mathbf{T} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymetric).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error computed on transport plans</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>verbose</strong> – Print information along iterations</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><p><strong>G</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) –</p>
<p>Coupling between the two spaces that minimizes:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\)</span></p>
</div></blockquote>
</li>
<li><p><strong>log</strong> (<em>dict</em>) – Convergence information and loss.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id25" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_semirelaxed_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_semirelaxed_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#entropic_semirelaxed_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_semirelaxed_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the entropic-regularized semi-relaxed gromov-wasserstein divergence
from <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> to <span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>
estimated using a Mirror Descent algorithm following the KL geometry.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{srGW} = \min_{\mathbf{T}} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity
matrices</p></li>
</ul>
<p>Note that when using backends, this loss function is differentiable wrt the
matrices (C1, C2) but not yet for the weights p.
.. note:: This function is backend-compatible and will work on arrays</p>
<blockquote>
<div><p>from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymetric).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error computed on transport plans</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>verbose</strong> – Print information along iterations</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>srgw</strong> (<em>float</em>) – Semi-relaxed Gromov-Wasserstein divergence</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – convergence information and Coupling matrix</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id26" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fgw_barycenters">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fgw_barycenters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ys</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_structure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'barycenter'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstartT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#fgw_barycenters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fgw_barycenters" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein barycenters of <cite>S</cite> measurable networks with node features <span class="math notranslate nohighlight">\((\mathbf{C}_s, \mathbf{Y}_s, \mathbf{p}_s)_{1 \leq s \leq S}\)</span>
(see eq (5) in <span class="xref std std-ref">[24]</span>), estimated using Fused Gromov-Wasserstein transports from Conditional Gradient solvers.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^*, \mathbf{Y}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}, \mathbf{Y}\in \mathbb{Y}^{N \times d}} \quad \sum_s \lambda_s \mathrm{FGW}_{\alpha}(\mathbf{C}, \mathbf{C}_s, \mathbf{Y}, \mathbf{Y}_s, \mathbf{p}, \mathbf{p}_s)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}_s\)</span>: feature matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}_s\)</span>: metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}_s\)</span>: distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Desired number of samples of the target barycenter</p></li>
<li><p><strong>Ys</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>array-like</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Features of all samples</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>array-like</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Structure matrices of all samples</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>array-like</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Masses of all samples.
If let to its default value None, uniform distributions are taken.</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – List of the <cite>S</cite> spaces’ weights.
If let to its default value None, uniform weights are taken.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Alpha parameter for the fgw distance.</p></li>
<li><p><strong>fixed_structure</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to fix the structure of the barycenter during the updates.</p></li>
<li><p><strong>fixed_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to fix the feature of the barycenter during the updates</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Weights in the targeted barycenter.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research.
Else closed form is used. If there are convergence issues use False.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either structures are to be assumed symmetric or not. Default value is True.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>stop_criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional. Default is 'barycenter'.</em>) – Stop criterion taking values in [‘barycenter’, ‘loss’]. If set to ‘barycenter’
uses absolute norm variations of estimated barycenters. Else if set to ‘loss’
uses the relative variations of the loss.</p></li>
<li><p><strong>warmstartT</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of transport plans in the successive
fused gromov-wasserstein transport problems.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>N</em><em>)</em><em>, </em><em>optional</em>) – Initialization for the barycenters’ structure matrix. If not set
a random init is used.</p></li>
<li><p><strong>init_X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>d</em><em>)</em><em>, </em><em>optional</em>) – Initialization for the barycenters’ features. If not set a
random init is used.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X</strong> (array-like, shape (<cite>N</cite>, <cite>d</cite>)) – Barycenters’ features</p></li>
<li><p><strong>C</strong> (array-like, shape (<cite>N</cite>, <cite>N</cite>)) – Barycenters’ structure matrix</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Only returned when log=True. It contains the keys:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: list of (<cite>N</cite>, <cite>ns</cite>) transport matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: (<cite>N</cite>,) barycenter weights</p></li>
<li><p><span class="math notranslate nohighlight">\((\mathbf{M}_s)_s\)</span>: all distance matrices between the feature of the barycenter and the other features <span class="math notranslate nohighlight">\((dist(\mathbf{X}, \mathbf{Y}_s))_s\)</span> shape (<cite>N</cite>, <cite>ns</cite>)</p></li>
<li><p>values used in convergence evaluation.</p></li>
</ul>
</li>
<li><p><em>.. _references-fgw-barycenters</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id27" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas
“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{Y_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{Y_2}, \mathbf{q})\)</span>
with pairwise distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices <span class="math notranslate nohighlight">\(\mathbf{Y_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y_2}\)</span> (see <a class="reference internal" href="#references-fused-gromov-wasserstein"><span class="std std-ref">[24]</span></a>).</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in\mathop{\arg\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity and feature matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: trade-off parameter</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conjugate gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will cast the computed transport plan to the data
type of the provided input <span class="math notranslate nohighlight">\(\mathbf{M}\)</span>. Casting to an integer
tensor might result in a loss of precision. If this behaviour is
unwanted, please make sure to provide a floating point input.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research. Else closed form is used.
If there are convergence issues use False.</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>T</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) – Optimal transportation matrix for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-fused-gromov-wasserstein">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id28" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id29" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., &amp; Mémoli, F. (2019). The gromov–wasserstein
distance between networks and stable network invariants.
Information and Inference: A Journal of the IMA, 8(4), 757-787.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fused_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fused_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#fused_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fused_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein distance between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{Y_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{Y_2}, \mathbf{q})\)</span>
with pairwise distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices <span class="math notranslate nohighlight">\(\mathbf{Y_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y_2}\)</span> (see <a class="reference internal" href="#references-fused-gromov-wasserstein"><span class="std std-ref">[24]</span></a>).</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{FGW} = \mathop{\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity and feature matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: trade-off parameter</p></li>
</ul>
<p>Note that when using backends, this loss function is differentiable wrt the
matrices (C1, C2, M) and weights (p, q) for quadratic loss using the gradients from <a href="#id79"><span class="problematic" id="id30">[38]_</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conjugate gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will cast the computed transport plan to the data
type of the provided input <span class="math notranslate nohighlight">\(\mathbf{M}\)</span>. Casting to an integer
tensor might result in a loss of precision. If this behaviour is
unwanted, please make sure to provide a floating point input.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space.</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research.
Else closed form is used. If there are convergence issues use False.</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – Parameters can be directly passed to the ot.optim.cg solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>fgw-distance</strong> (<em>float</em>) – Fused Gromov-Wasserstein distance for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-fused-gromov-wasserstein2">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id31" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas
“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id32" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online
Graph Dictionary Learning, International Conference on Machine Learning
(ICML), 2021.</p>
</aside>
<aside class="footnote brackets" id="id33" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., &amp; Mémoli, F. (2019). The gromov–wasserstein
distance between networks and stable network invariants.
Information and Inference: A Journal of the IMA, 8(4), 757-787.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fused_gromov_wasserstein_dictionary_learning">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fused_gromov_wasserstein_dictionary_learning</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ys</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate_C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate_Y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cdict_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ydict_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projection</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nonnegative_symmetric'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_adam_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_dictionary.html#fused_gromov_wasserstein_dictionary_learning"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fused_gromov_wasserstein_dictionary_learning" title="Link to this definition"></a></dt>
<dd><p>Infer Fused Gromov-Wasserstein linear dictionary <span class="math notranslate nohighlight">\(\{ (\mathbf{C_{dict}[d]}, \mathbf{Y_{dict}[d]}, \mathbf{q}) \}_{d \in [D]}\)</span>  from the list of S attributed structures <span class="math notranslate nohighlight">\(\{ (\mathbf{C_s}, \mathbf{Y_s},\mathbf{p_s}) \}_s\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}\min_{\mathbf{C_{dict}},\mathbf{Y_{dict}}, \{\mathbf{w_s}\}_{s}} \sum_{s=1}^S  FGW_{2,\alpha}(\mathbf{C_s}, \mathbf{Y_s}, \sum_{d=1}^D w_{s,d}\mathbf{C_{dict}[d]},\sum_{d=1}^D w_{s,d}\mathbf{Y_{dict}[d]}, \mathbf{p_s}, \mathbf{q}) \\ - reg\| \mathbf{w_s}  \|_2^2\end{split}\]</div>
<p>Such that <span class="math notranslate nohighlight">\(\forall s \leq S\)</span> :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_s}^\top \mathbf{1}_D = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_s} \geq \mathbf{0}_D\)</span></p></li>
</ul>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\forall s \leq S, \mathbf{C_s}\)</span> is a (ns,ns) pairwise similarity matrix of variable size ns.</p></li>
<li><p><span class="math notranslate nohighlight">\(\forall s \leq S, \mathbf{Y_s}\)</span> is a (ns,d) features matrix of variable size ns and fixed dimension d.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_{dict}}\)</span> is a (D, nt, nt) tensor of D pairwise similarity matrix of fixed size nt.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y_{dict}}\)</span> is a (D, nt, d) tensor of D features matrix of fixed size nt and fixed dimension d.</p></li>
<li><p><span class="math notranslate nohighlight">\(\forall s \leq S, \mathbf{p_s}\)</span> is the source distribution corresponding to <span class="math notranslate nohighlight">\(\mathbf{C_s}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span> is the target distribution assigned to every structures in the embedding space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span> is the trade-off parameter of Fused Gromov-Wasserstein</p></li>
<li><p>reg is the regularization coefficient.</p></li>
</ul>
<p>The stochastic algorithm used for estimating the attributed graph dictionary atoms as proposed in <a href="#id80"><span class="problematic" id="id34">[38]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S symmetric array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – List of Metric/Graph cost matrices of variable size (ns,ns).</p></li>
<li><p><strong>Ys</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>d</em><em>)</em>) – List of feature matrix of variable size (ns,d) with d fixed.</p></li>
<li><p><strong>D</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Number of dictionary atoms to learn</p></li>
<li><p><strong>nt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Number of samples within each dictionary atoms</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Trade-off parameter of Fused Gromov-Wasserstein</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Coefficient of the negative quadratic regularization used to promote sparsity of w. The default is 0.</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in each source space C of Cs. Default is None and corresponds to uniform distibutions.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the embedding space whose structure will be learned. Default is None and corresponds to uniform distributions.</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Number of epochs used to learn the dictionary. Default is 32.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Batch size for each stochastic gradient update of the dictionary. Set to the dataset size if the provided batch_size is higher than the dataset size. Default is 32.</p></li>
<li><p><strong>learning_rate_C</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Learning rate used for the stochastic gradient descent on Cdict. Default is 1.</p></li>
<li><p><strong>learning_rate_Y</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Learning rate used for the stochastic gradient descent on Ydict. Default is 1.</p></li>
<li><p><strong>Cdict_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>D array-like with shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Used to initialize the dictionary structures Cdict.
If set to None (Default), the dictionary will be initialized randomly.
Else Cdict must have shape (D, nt, nt) i.e match provided shape features.</p></li>
<li><p><strong>Ydict_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>D array-like with shape</em><em> (</em><em>nt</em><em>, </em><em>d</em><em>)</em><em>, </em><em>optional</em>) – Used to initialize the dictionary features Ydict.
If set to None, the dictionary features will be initialized randomly.
Else Ydict must have shape (D, nt, d) where d is the features dimension of inputs Ys and also match provided shape features.</p></li>
<li><p><strong>projection</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional</em>) – If ‘nonnegative’ and/or ‘symmetric’ is in projection, the corresponding projection will be performed at each stochastic update of the dictionary
Else the set of atoms is <span class="math notranslate nohighlight">\(R^{nt * nt}\)</span>. Default is ‘nonnegative_symmetric’</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to True, losses evolution by batches and epochs are tracked. Default is False.</p></li>
<li><p><strong>use_adam_optimizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to True, adam optimizer with default settings is used as adaptative learning rate strategy.
Else perform SGD with fixed learning rate. Default is True.</p></li>
<li><p><strong>tol_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the BCD algorithm, measured by absolute relative error on consecutive losses. Default is <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p></li>
<li><p><strong>tol_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the Conjugate Gradient algorithm used to get optimal w at a fixed transport, measured by absolute relative error on consecutive losses. Default is <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p></li>
<li><p><strong>max_iter_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the BCD. Default is 20.</p></li>
<li><p><strong>max_iter_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the Conjugate Gradient. Default is 200.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print the reconstruction loss every epoch. Default is False.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Determines random number generation. Pass an int for reproducible
output across multiple function calls.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>Cdict_best_state</strong> (<em>D array-like, shape (D,nt,nt)</em>) – Metric/Graph cost matrices composing the dictionary.
The dictionary leading to the best loss over an epoch is saved and returned.</p></li>
<li><p><strong>Ydict_best_state</strong> (<em>D array-like, shape (D,nt,d)</em>) – Feature matrices composing the dictionary.
The dictionary leading to the best loss over an epoch is saved and returned.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – If use_log is True, contains loss evolutions by batches and epochs.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id35" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online
Graph Dictionary Learning, International Conference on Machine Learning
(ICML), 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fused_gromov_wasserstein_linear_unmixing">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fused_gromov_wasserstein_linear_unmixing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cdict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ydict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_dictionary.html#fused_gromov_wasserstein_linear_unmixing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fused_gromov_wasserstein_linear_unmixing" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein linear unmixing of <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{Y},\mathbf{p})\)</span> onto the attributed dictionary atoms <span class="math notranslate nohighlight">\(\{ (\mathbf{C_{dict}[d]},\mathbf{Y_{dict}[d]}, \mathbf{q}) \}_{d \in [D]}\)</span></p>
<div class="math notranslate nohighlight">
\[\min_{\mathbf{w}}  FGW_{2,\alpha}(\mathbf{C},\mathbf{Y}, \sum_{d=1}^D w_d\mathbf{C_{dict}[d]},\sum_{d=1}^D w_d\mathbf{Y_{dict}[d]}, \mathbf{p}, \mathbf{q}) - reg \| \mathbf{w}  \|_2^2\]</div>
<p>such that, <span class="math notranslate nohighlight">\(\forall s \leq S\)</span> :</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_s}^\top \mathbf{1}_D = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_s} \geq \mathbf{0}_D\)</span></p></li>
</ul>
</div></blockquote>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}\)</span> is a (ns,ns) pairwise similarity matrix of variable size ns.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}\)</span> is a (ns,d) features matrix of variable size ns and fixed dimension d.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_{dict}}\)</span> is a (D, nt, nt) tensor of D pairwise similarity matrix of fixed size nt.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y_{dict}}\)</span> is a (D, nt, d) tensor of D features matrix of fixed size nt and fixed dimension d.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> is the source distribution corresponding to <span class="math notranslate nohighlight">\(\mathbf{C_s}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span> is the target distribution assigned to every structures in the embedding space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span> is the trade-off parameter of Fused Gromov-Wasserstein</p></li>
<li><p>reg is the regularization coefficient.</p></li>
</ul>
<p>The algorithm used for solving the problem is a Block Coordinate Descent as discussed in <a href="#id81"><span class="problematic" id="id36">[38]_</span></a>, algorithm 6.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric/Graph cost matrix.</p></li>
<li><p><strong>Y</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>d</em><em>)</em>) – Feature matrix.</p></li>
<li><p><strong>Cdict</strong> (<em>D array-like</em><em>, </em><em>shape</em><em> (</em><em>D</em><em>,</em><em>nt</em><em>,</em><em>nt</em><em>)</em>) – Metric/Graph cost matrices composing the dictionary on which to embed (C,Y).</p></li>
<li><p><strong>Ydict</strong> (<em>D array-like</em><em>, </em><em>shape</em><em> (</em><em>D</em><em>,</em><em>nt</em><em>,</em><em>d</em><em>)</em>) – Feature matrices composing the dictionary on which to embed (C,Y).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>,</em>) – Trade-off parameter of Fused Gromov-Wasserstein.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Coefficient of the negative quadratic regularization used to promote sparsity of w. The default is 0.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space C. Default is None and corresponds to uniform distribution.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the space depicted by the dictionary. Default is None and corresponds to uniform distribution.</p></li>
<li><p><strong>tol_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the BCD algorithm.</p></li>
<li><p><strong>tol_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the Conjugate Gradient algorithm used to get optimal w at a fixed transport. Default is <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p></li>
<li><p><strong>max_iter_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the BCD. Default is 20.</p></li>
<li><p><strong>max_iter_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the Conjugate Gradient. Default is 200.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>w</strong> (<em>array-like, shape (D,)</em>) – fused Gromov-Wasserstein linear unmixing of (C,Y,p) onto the span of the dictionary.</p></li>
<li><p><strong>Cembedded</strong> (<em>array-like, shape (nt,nt)</em>) – embedded structure of <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{Y}, \mathbf{p})\)</span> onto the dictionary, <span class="math notranslate nohighlight">\(\sum_d w_d\mathbf{C_{dict}[d]}\)</span>.</p></li>
<li><p><strong>Yembedded</strong> (<em>array-like, shape (nt,d)</em>) – embedded features of <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{Y}, \mathbf{p})\)</span> onto the dictionary, <span class="math notranslate nohighlight">\(\sum_d w_d\mathbf{Y_{dict}[d]}\)</span>.</p></li>
<li><p><strong>T</strong> (<em>array-like (ns,nt)</em>) – Fused Gromov-Wasserstein transport plan between <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\sum_d w_d\mathbf{C_{dict}[d]}, \sum_d w_d\mathbf{Y_{dict}[d]},\mathbf{q})\)</span>.</p></li>
<li><p><strong>current_loss</strong> (<em>float</em>) – reconstruction error</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id37" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online
Graph Dictionary Learning, International Conference on Machine Learning
(ICML), 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gromov_barycenters">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gromov_barycenters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'barycenter'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstartT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#gromov_barycenters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gromov_barycenters" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein barycenters of <cite>S</cite> measured similarity matrices <span class="math notranslate nohighlight">\((\mathbf{C}_s)_{1 \leq s \leq S}\)</span></p>
<p>The function solves the following optimization problem with block coordinate descent:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}} \quad \sum_s \lambda_s \mathrm{GW}(\mathbf{C}, \mathbf{C}_s, \mathbf{p}, \mathbf{p}_s)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}_s\)</span>: metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}_s\)</span>: distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Size of the targeted barycenter</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrices</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Sample weights in the <cite>S</cite> spaces.
If let to its default value None, uniform distributions are taken.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Weights in the targeted barycenter.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – List of the <cite>S</cite> spaces’ weights.
If let to its default value None, uniform weights are taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>callable</em><em>, </em><em>optional</em>) – tensor-matrix multiplication function based on specific loss function</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional.</em>) – Either structures are to be assumed symmetric or not. Default value is True.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research.
Else closed form is used. If there are convergence issues use False.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>stop_criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional. Default is 'barycenter'.</em>) – Stop criterion taking values in [‘barycenter’, ‘loss’]. If set to ‘barycenter’
uses absolute norm variations of estimated barycenters. Else if set to ‘loss’
uses the relative variations of the loss.</p></li>
<li><p><strong>warmstartT</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of transport plans in the successive
fused gromov-wasserstein transport problems.s</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em> | </em><em>array-like</em><em>, </em><em>shape</em><em>(</em><em>N</em><em>,</em><em>N</em><em>)</em>) – Random initial value for the <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix provided by user.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>C</strong> (array-like, shape (<cite>N</cite>, <cite>N</cite>)) – Similarity matrix in the barycenter space (permutated arbitrarily)</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Only returned when log=True. It contains the keys:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: list of (<cite>N</cite>, <cite>ns</cite>) transport matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: (<cite>N</cite>,) barycenter weights</p></li>
<li><p>values used in convergence evaluation.</p></li>
</ul>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id38" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>.</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_\mathbf{T} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{\gamma} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{\gamma}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{\gamma} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conjugate gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will cast the computed transport plan to the data
type of the provided input <span class="math notranslate nohighlight">\(\mathbf{C}_1\)</span>. Casting to an integer
tensor might result in a loss of precision. If this behaviour is
unwanted, please make sure to provide a floating point input.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional</em>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research. Else closed form is used.
If there are convergence issues use False.</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><p><strong>T</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) –</p>
<p>Coupling between the two spaces that minimizes:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\)</span></p>
</div></blockquote>
</li>
<li><p><strong>log</strong> (<em>dict</em>) – Convergence information and loss.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id39" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id40" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></span>
<p>Mémoli, Facundo. Gromov–Wasserstein distances and the
metric approach to object matching. Foundations of computational
mathematics 11.4 (2011): 417-487.</p>
</aside>
<aside class="footnote brackets" id="id41" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., &amp; Mémoli, F. (2019). The gromov–wasserstein
distance between networks and stable network invariants.
Information and Inference: A Journal of the IMA, 8(4), 757-787.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein loss <span class="math notranslate nohighlight">\(\mathbf{GW}\)</span> between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>.
To recover the Gromov-Wasserstein distance as defined in [13] compute <span class="math notranslate nohighlight">\(d_{GW} = \frac{1}{2} \sqrt{\mathbf{GW}}\)</span>.</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{GW} = \min_\mathbf{T} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{\gamma} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{\gamma}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{\gamma} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity
matrices</p></li>
</ul>
<p>Note that when using backends, this loss function is differentiable wrt the
matrices (C1, C2) and weights (p, q) for quadratic loss using the gradients from <a href="#id82"><span class="problematic" id="id42">[38]_</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conjugate gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will cast the computed transport plan to the data
type of the provided input <span class="math notranslate nohighlight">\(\mathbf{C}_1\)</span>. Casting to an integer
tensor might result in a loss of precision. If this behaviour is
unwanted, please make sure to provide a floating point input.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research. Else closed form is used.
If there are convergence issues use False.</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gw_dist</strong> (<em>float</em>) – Gromov-Wasserstein distance</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – convergence information and Coupling matrix</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id43" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id44" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></span>
<p>Mémoli, Facundo. Gromov–Wasserstein distances and the
metric approach to object matching. Foundations of computational
mathematics 11.4 (2011): 417-487.</p>
</aside>
<aside class="footnote brackets" id="id45" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online
Graph Dictionary Learning, International Conference on Machine Learning
(ICML), 2021.</p>
</aside>
<aside class="footnote brackets" id="id46" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., &amp; Mémoli, F. (2019). The gromov–wasserstein
distance between networks and stable network invariants.
Information and Inference: A Journal of the IMA, 8(4), 757-787.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gromov_wasserstein_dictionary_learning">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gromov_wasserstein_dictionary_learning</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cdict_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projection</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nonnegative_symmetric'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_adam_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_dictionary.html#gromov_wasserstein_dictionary_learning"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gromov_wasserstein_dictionary_learning" title="Link to this definition"></a></dt>
<dd><p>Infer Gromov-Wasserstein linear dictionary <span class="math notranslate nohighlight">\(\{ (\mathbf{C_{dict}[d]}, q) \}_{d \in [D]}\)</span>  from the list of structures <span class="math notranslate nohighlight">\(\{ (\mathbf{C_s},\mathbf{p_s}) \}_s\)</span></p>
<div class="math notranslate nohighlight">
\[\min_{\mathbf{C_{dict}}, \{\mathbf{w_s} \}_{s \leq S}} \sum_{s=1}^S  GW_2(\mathbf{C_s}, \sum_{d=1}^D w_{s,d}\mathbf{C_{dict}[d]}, \mathbf{p_s}, \mathbf{q}) - reg\| \mathbf{w_s}  \|_2^2\]</div>
<p>such that, <span class="math notranslate nohighlight">\(\forall s \leq S\)</span> :</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_s}^\top \mathbf{1}_D = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_s} \geq \mathbf{0}_D\)</span></p></li>
</ul>
</div></blockquote>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\forall s \leq S, \mathbf{C_s}\)</span> is a (ns,ns) pairwise similarity matrix of variable size ns.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_{dict}}\)</span> is a (D, nt, nt) tensor of D pairwise similarity matrix of fixed size nt.</p></li>
<li><p><span class="math notranslate nohighlight">\(\forall s \leq S, \mathbf{p_s}\)</span> is the source distribution corresponding to <span class="math notranslate nohighlight">\(\mathbf{C_s}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span> is the target distribution assigned to every structures in the embedding space.</p></li>
<li><p>reg is the regularization coefficient.</p></li>
</ul>
<p>The stochastic algorithm used for estimating the graph dictionary atoms as proposed in <a href="#id83"><span class="problematic" id="id47">[38]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S symmetric array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – List of Metric/Graph cost matrices of variable size (ns, ns).</p></li>
<li><p><strong>D</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Number of dictionary atoms to learn</p></li>
<li><p><strong>nt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Number of samples within each dictionary atoms</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Coefficient of the negative quadratic regularization used to promote sparsity of w. The default is 0.</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in each source space C of Cs. Default is None and corresponds to uniform distibutions.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the embedding space whose structure will be learned. Default is None and corresponds to uniform distributions.</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Number of epochs used to learn the dictionary. Default is 32.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Batch size for each stochastic gradient update of the dictionary. Set to the dataset size if the provided batch_size is higher than the dataset size. Default is 32.</p></li>
<li><p><strong>learning_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Learning rate used for the stochastic gradient descent. Default is 1.</p></li>
<li><p><strong>Cdict_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>D array-like with shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Used to initialize the dictionary.
If set to None (Default), the dictionary will be initialized randomly.
Else Cdict must have shape (D, nt, nt) i.e match provided shape features.</p></li>
<li><p><strong>projection</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> , </em><em>optional</em>) – If ‘nonnegative’ and/or ‘symmetric’ is in projection, the corresponding projection will be performed at each stochastic update of the dictionary
Else the set of atoms is <span class="math notranslate nohighlight">\(R^{nt * nt}\)</span>. Default is ‘nonnegative_symmetric’</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to True, losses evolution by batches and epochs are tracked. Default is False.</p></li>
<li><p><strong>use_adam_optimizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to True, adam optimizer with default settings is used as adaptative learning rate strategy.
Else perform SGD with fixed learning rate. Default is True.</p></li>
<li><p><strong>tol_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the BCD algorithm, measured by absolute relative error on consecutive losses. Default is <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p></li>
<li><p><strong>tol_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the Conjugate Gradient algorithm used to get optimal w at a fixed transport, measured by absolute relative error on consecutive losses. Default is <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p></li>
<li><p><strong>max_iter_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the BCD. Default is 20.</p></li>
<li><p><strong>max_iter_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the Conjugate Gradient. Default is 200.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print the reconstruction loss every epoch. Default is False.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Determines random number generation. Pass an int for reproducible
output across multiple function calls.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>Cdict_best_state</strong> (<em>D array-like, shape (D,nt,nt)</em>) – Metric/Graph cost matrices composing the dictionary.
The dictionary leading to the best loss over an epoch is saved and returned.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – If use_log is True, contains loss evolutions by batches and epochs.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id48" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online
Graph Dictionary Learning, International Conference on Machine Learning
(ICML), 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gromov_wasserstein_linear_unmixing">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gromov_wasserstein_linear_unmixing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cdict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_dictionary.html#gromov_wasserstein_linear_unmixing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gromov_wasserstein_linear_unmixing" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein linear unmixing of <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{p})\)</span> onto the dictionary <span class="math notranslate nohighlight">\(\{ (\mathbf{C_{dict}[d]}, \mathbf{q}) \}_{d \in [D]}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\min_{ \mathbf{w}}  GW_2(\mathbf{C}, \sum_{d=1}^D w_d\mathbf{C_{dict}[d]}, \mathbf{p}, \mathbf{q}) - reg \| \mathbf{w}  \|_2^2\]</div>
<p>such that:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}^\top \mathbf{1}_D = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w} \geq \mathbf{0}_D\)</span></p></li>
</ul>
</div></blockquote>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}\)</span> is the (ns,ns) pairwise similarity matrix.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_{dict}}\)</span> is a (D, nt, nt) tensor of D pairwise similarity matrices of size nt.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> are source and target weights.</p></li>
<li><p>reg is the regularization coefficient.</p></li>
</ul>
<p>The algorithm used for solving the problem is a Block Coordinate Descent as discussed in <a href="#id84"><span class="problematic" id="id49">[38]_</span></a> , algorithm 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric/Graph cost matrix.</p></li>
<li><p><strong>Cdict</strong> (<em>D array-like</em><em>, </em><em>shape</em><em> (</em><em>D</em><em>,</em><em>nt</em><em>,</em><em>nt</em><em>)</em>) – Metric/Graph cost matrices composing the dictionary on which to embed C.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional.</em>) – Coefficient of the negative quadratic regularization used to promote sparsity of w. Default is 0.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space C. Default is None and corresponds to uniform distribution.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the space depicted by the dictionary. Default is None and corresponds to uniform distribution.</p></li>
<li><p><strong>tol_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the BCD algorithm.</p></li>
<li><p><strong>tol_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the Conjugate Gradient algorithm used to get optimal w at a fixed transport. Default is <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p></li>
<li><p><strong>max_iter_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the BCD. Default is 20.</p></li>
<li><p><strong>max_iter_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the Conjugate Gradient. Default is 200.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>w</strong> (<em>array-like, shape (D,)</em>) – Gromov-Wasserstein linear unmixing of <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{p})\)</span> onto the span of the dictionary.</p></li>
<li><p><strong>Cembedded</strong> (<em>array-like, shape (nt,nt)</em>) – embedded structure of <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{p})\)</span> onto the dictionary, <span class="math notranslate nohighlight">\(\sum_d w_d\mathbf{C_{dict}[d]}\)</span>.</p></li>
<li><p><strong>T</strong> (<em>array-like (ns, nt)</em>) – Gromov-Wasserstein transport plan between <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\sum_d w_d\mathbf{C_{dict}[d]}, \mathbf{q})\)</span></p></li>
<li><p><strong>current_loss</strong> (<em>float</em>) – reconstruction error</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id50" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online
Graph Dictionary Learning, International Conference on Machine Learning
(ICML), 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gwggrad">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gwggrad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constC</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hC1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hC2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#gwggrad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gwggrad" title="Link to this definition"></a></dt>
<dd><p>Return the gradient for Gromov-Wasserstein</p>
<p>The gradient is computed as described in Proposition 2 in <a class="reference internal" href="#references-gwggrad"><span class="std std-ref">[12]</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constC</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Constant <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h1}(\mathbf{C1})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h2}(\mathbf{C2})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>T</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Current value of transport matrix <span class="math notranslate nohighlight">\(\mathbf{T}\)</span></p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>grad</strong> – Gromov-Wasserstein gradient</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric" id="references-gwggrad">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id51" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gwloss">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gwloss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constC</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hC1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hC2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#gwloss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gwloss" title="Link to this definition"></a></dt>
<dd><p>Return the Loss for Gromov-Wasserstein</p>
<p>The loss is computed as described in Proposition 1 Eq. (6) in <a class="reference internal" href="#references-gwloss"><span class="std std-ref">[12]</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constC</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Constant <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h1}(\mathbf{C1})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h2}(\mathbf{C2})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>T</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Current value of transport matrix <span class="math notranslate nohighlight">\(\mathbf{T}\)</span></p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>loss</strong> – Gromov-Wasserstein loss</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a></p>
</dd>
</dl>
<p class="rubric" id="references-gwloss">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id52" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.init_matrix">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">init_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#init_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.init_matrix" title="Link to this definition"></a></dt>
<dd><p>Return loss matrices and tensors for Gromov-Wasserstein fast computation</p>
<p>Returns the value of <span class="math notranslate nohighlight">\(\mathcal{L}(\mathbf{C_1}, \mathbf{C_2}) \otimes \mathbf{T}\)</span> with the
selected loss function as the loss function of Gromov-Wasserstein discrepancy.</p>
<p>The matrices are computed as described in Proposition 1 in <span class="xref std std-ref">[12]</span></p>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: A coupling between those two spaces</p></li>
</ul>
<p>The square-loss function <span class="math notranslate nohighlight">\(L(a, b) = |a - b|^2\)</span> is read as :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\\\mathrm{with} \ f_1(a) &amp;= a^2\\                f_2(b) &amp;= b^2\\                h_1(a) &amp;= a\\                h_2(b) &amp;= 2b\end{aligned}\end{align} \]</div>
<p>The kl-loss function <span class="math notranslate nohighlight">\(L(a, b) = a \log\left(\frac{a}{b}\right) - a + b\)</span> is read as :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\\\mathrm{with} \ f_1(a) &amp;= a \log(a) - a\\                f_2(b) &amp;= b\\                h_1(a) &amp;= a\\                h_2(b) &amp;= \log(b)\end{aligned}\end{align} \]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Probability distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Probability distribution in the target space</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional</em>) – Name of loss function to use: either ‘square_loss’ or ‘kl_loss’ (default=’square_loss’)</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>constC</strong> (<em>array-like, shape (ns, nt)</em>) – Constant <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC1</strong> (<em>array-like, shape (ns, ns)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h1}(\mathbf{C1})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>array-like, shape (nt, nt)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h2}(\mathbf{C2})\)</span> matrix in Eq. (6)</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-init-matrix">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id53" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.init_matrix_semirelaxed">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">init_matrix_semirelaxed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#init_matrix_semirelaxed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.init_matrix_semirelaxed" title="Link to this definition"></a></dt>
<dd><p>Return loss matrices and tensors for semi-relaxed Gromov-Wasserstein fast computation</p>
<p>Returns the value of <span class="math notranslate nohighlight">\(\mathcal{L}(\mathbf{C_1}, \mathbf{C_2}) \otimes \mathbf{T}\)</span> with the
selected loss function as the loss function of semi-relaxed Gromov-Wasserstein discrepancy.</p>
<p>The matrices are computed as described in Proposition 1 in <span class="xref std std-ref">[12]</span>
and adapted to the semi-relaxed problem where the second marginal is not a constant anymore.</p>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: A coupling between those two spaces</p></li>
</ul>
<p>The square-loss function <span class="math notranslate nohighlight">\(L(a, b) = |a - b|^2\)</span> is read as :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\\\mathrm{with} \ f_1(a) &amp;= a^2\\                f_2(b) &amp;= b^2\\                h_1(a) &amp;= a\\                h_2(b) &amp;= 2b\end{aligned}\end{align} \]</div>
<p>The kl-loss function <span class="math notranslate nohighlight">\(L(a, b) = a \log\left(\frac{a}{b}\right) - a + b\)</span> is read as :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\\\mathrm{with} \ f_1(a) &amp;= a \log(a) - a\\                f_2(b) &amp;= b\\                h_1(a) &amp;= a\\                h_2(b) &amp;= \log(b)\end{aligned}\end{align} \]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – </p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional</em>) – Name of loss function to use: either ‘square_loss’ or ‘kl_loss’ (default=’square_loss’)</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>constC</strong> (<em>array-like, shape (ns, nt)</em>) – Constant <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix in Eq. (6) adapted to srGW</p></li>
<li><p><strong>hC1</strong> (<em>array-like, shape (ns, ns)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h1}(\mathbf{C1})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>array-like, shape (nt, nt)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h2}(\mathbf{C2})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>fC2t</strong> (<em>array-like, shape (nt, nt)</em>) – <span class="math notranslate nohighlight">\(\mathbf{f2}(\mathbf{C2})^\top\)</span> matrix in Eq. (6)</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id54">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id55" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id56" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.pointwise_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">pointwise_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold_plan</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_estimators.html#pointwise_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.pointwise_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the gromov-wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span> using a stochastic Frank-Wolfe.
This method has a <span class="math notranslate nohighlight">\(\mathcal{O}(\mathrm{max\_iter} \times PN^2)\)</span> time complexity with <cite>P</cite> the number of Sinkhorn iterations.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{GW} = \mathop{\arg \min}_\mathbf{T} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\        \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\        \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>loss_fun</strong> (function: <span class="math notranslate nohighlight">\(\mathbb{R} \times \mathbb{R} \mapsto \mathbb{R}\)</span>) – Loss function used for the distance, the transport plan does not depend on the loss function</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Step of the Frank-Wolfe algorithm, should be between 0 and 1</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>threshold_plan</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Deleting very small values in the transport plan. If above zero, it violates the marginal constraints.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Gives the distance estimated and the standard deviation</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id57" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></span>
<p>Kerdoncuff, Tanguy, Emonet, Rémi, Sebban, Marc
“Sampled Gromov Wasserstein.”
Machine Learning Journal (MLJ). 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.sampled_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">sampled_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_samples_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_estimators.html#sampled_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.sampled_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the gromov-wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span> using a 1-stochastic Frank-Wolfe.
This method has a <span class="math notranslate nohighlight">\(\mathcal{O}(\mathrm{max\_iter} \times N \log(N))\)</span> time complexity by relying on the 1D Optimal Transport solver.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{GW} = \mathop{\arg \min}_\mathbf{T} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\        \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\        \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>loss_fun</strong> (function: <span class="math notranslate nohighlight">\(\mathbb{R} \times \mathbb{R} \mapsto \mathbb{R}\)</span>) – Loss function used for the distance, the transport plan does not depend on the loss function</p></li>
<li><p><strong>nb_samples_grad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Number of samples to approximate the gradient</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Weight of the Kullback-Leibler regularization</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Gives the distance estimated and the standard deviation</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id58" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></span>
<p>Kerdoncuff, Tanguy, Emonet, Rémi, Sebban, Marc
“Sampled Gromov Wasserstein.”
Machine Learning Journal (MLJ). 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.semirelaxed_fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#semirelaxed_fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.semirelaxed_fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Computes the semi-relaxed Fused Gromov-Wasserstein transport between two graphs (see [48]).</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_{\mathbf{T}} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) T_{i,j} T_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> source weights (sum to 1)</p></li>
<li><p><cite>L</cite> is a loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[48]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) – Optimal transportation matrix for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id59">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id60" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id61" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
<aside class="footnote brackets" id="id62" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>62<span class="fn-bracket">]</span></span>
<p>H. Van Assel, C. Vincent-Cuaz, T. Vayer, R. Flamary, N. Courty.
“Interpolating between Clustering and Dimensionality Reduction with
Gromov-Wasserstein”. NeurIPS 2023 Workshop OTML.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.semirelaxed_fused_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_fused_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#semirelaxed_fused_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.semirelaxed_fused_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Computes the semi-relaxed FGW divergence between two graphs (see [48]).</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{srFGW}_{\alpha} = \min_{\mathbf{T}} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) T_{i,j} T_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> source weights (sum to 1)</p></li>
<li><p><cite>L</cite> is a loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<p>The algorithm used for solving the problem is conditional gradient as
discussed in <span class="xref std std-ref">[48]</span></p>
<p>Note that when using backends, this loss function is differentiable wrt the
matrices (C1, C2) but not yet for the weights p.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space.</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>, </em><em>optional</em>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – Parameters can be directly passed to the ot.optim.cg solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>srfgw-divergence</strong> (<em>float</em>) – Semi-relaxed Fused Gromov-Wasserstein divergence for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id63">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id64" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id65" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
<aside class="footnote brackets" id="id66" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>62<span class="fn-bracket">]</span></span>
<p>H. Van Assel, C. Vincent-Cuaz, T. Vayer, R. Flamary, N. Courty.
“Interpolating between Clustering and Dimensionality Reduction with
Gromov-Wasserstein”. NeurIPS 2023 Workshop OTML.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.semirelaxed_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#semirelaxed_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.semirelaxed_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the semi-relaxed Gromov-Wasserstein divergence transport from <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> to <span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span> (see [48]).</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_{\mathbf{T}} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><p><strong>T</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) –</p>
<p>Coupling between the two spaces that minimizes:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\)</span></p>
</div></blockquote>
</li>
<li><p><strong>log</strong> (<em>dict</em>) – Convergence information and loss.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id67" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
<aside class="footnote brackets" id="id68" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>62<span class="fn-bracket">]</span></span>
<p>H. Van Assel, C. Vincent-Cuaz, T. Vayer, R. Flamary, N. Courty.
“Interpolating between Clustering and Dimensionality Reduction with
Gromov-Wasserstein”. NeurIPS 2023 Workshop OTML.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.semirelaxed_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#semirelaxed_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.semirelaxed_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the semi-relaxed Gromov-Wasserstein divergence from <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> to <span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span> (see [48]).</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\text{srGW} = \min_{\mathbf{T}} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity
matrices</p></li>
</ul>
<p>Note that when using backends, this loss function is differentiable wrt the
matrices (C1, C2) but not yet for the weights p.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>srgw</strong> (<em>float</em>) – Semi-relaxed Gromov-Wasserstein divergence</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – convergence information and Coupling matrix</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id69" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
<aside class="footnote brackets" id="id70" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>62<span class="fn-bracket">]</span></span>
<p>H. Van Assel, C. Vincent-Cuaz, T. Vayer, R. Flamary, N. Courty.
“Interpolating between Clustering and Dimensionality Reduction with
Gromov-Wasserstein”. NeurIPS 2023 Workshop OTML.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.solve_gromov_linesearch">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">solve_gromov_linesearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltaG</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#solve_gromov_linesearch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.solve_gromov_linesearch" title="Link to this definition"></a></dt>
<dd><p>Solve the linesearch in the FW iterations for any inner loss that decomposes as in Proposition 1 in <a class="reference internal" href="#references-solve-linesearch"><span class="std std-ref">[12]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>G</strong> (<em>array-like</em><em>, </em><em>shape</em><em>(</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – The transport map at a given iteration of the FW</p></li>
<li><p><strong>deltaG</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – Difference between the optimal map found by linearization in the FW algorithm and the value at a given iteration</p></li>
<li><p><strong>cost_G</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Value of the cost at <cite>G</cite></p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em><em>, </em><em>optional</em>) – Transformed Structure matrix in the source domain.
For the ‘square_loss’ and ‘kl_loss’, we provide hC1 from ot.gromov.init_matrix</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em> (</em><em>nt</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Transformed Structure matrix in the source domain.
For the ‘square_loss’ and ‘kl_loss’, we provide hC2 from ot.gromov.init_matrix</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – Cost matrix between the features.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Regularization parameter.</p></li>
<li><p><strong>alpha_min</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Minimum value for alpha</p></li>
<li><p><strong>alpha_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Maximum value for alpha</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>) – The optimal step size of the FW</p></li>
<li><p><strong>fc</strong> (<em>int</em>) – nb of function call. Useless here</p></li>
<li><p><strong>cost_G</strong> (<em>float</em>) – The value of the cost for the next iteration</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-solve-linesearch">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id71" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain and Courty Nicolas
“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id72" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.solve_semirelaxed_gromov_linesearch">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">solve_semirelaxed_gromov_linesearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltaG</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ones_p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fC2t</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#solve_semirelaxed_gromov_linesearch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.solve_semirelaxed_gromov_linesearch" title="Link to this definition"></a></dt>
<dd><p>Solve the linesearch in the Conditional Gradient iterations for the semi-relaxed Gromov-Wasserstein divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>G</strong> (<em>array-like</em><em>, </em><em>shape</em><em>(</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – The transport map at a given iteration of the FW</p></li>
<li><p><strong>deltaG</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – Difference between the optimal map found by linearization in the FW algorithm and the value at a given iteration</p></li>
<li><p><strong>cost_G</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Value of the cost at <cite>G</cite></p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em><em>, </em><em>optional</em>) – Transformed Structure matrix in the source domain.
Note that for the ‘square_loss’ and ‘kl_loss’, we provide hC1 from ot.gromov.init_matrix_semirelaxed</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em> (</em><em>nt</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Transformed Structure matrix in the source domain.
Note that for the ‘square_loss’ and ‘kl_loss’, we provide hC2 from ot.gromov.init_matrix_semirelaxed</p></li>
<li><p><strong>ones_p</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>1</em><em>)</em>) – Array of ones of size ns</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – Cost matrix between the features.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Regularization parameter.</p></li>
<li><p><strong>fC2t</strong> (<em>array-like</em><em> (</em><em>nt</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Transformed Structure matrix in the source domain.
Note that for the ‘square_loss’ and ‘kl_loss’, we provide fC2t from ot.gromov.init_matrix_semirelaxed.
If fC2t is not provided, it is by default fC2t corresponding to the ‘square_loss’.</p></li>
<li><p><strong>alpha_min</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Minimum value for alpha</p></li>
<li><p><strong>alpha_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em>, </em><em>optional</em>) – Maximum value for alpha</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>) – The optimal step size of the FW</p></li>
<li><p><strong>fc</strong> (<em>int</em>) – nb of function call. Useless here</p></li>
<li><p><strong>cost_G</strong> (<em>float</em>) – The value of the cost for the next iteration</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id73" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2021.</p>
</aside>
<aside class="footnote brackets" id="id74" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>62<span class="fn-bracket">]</span></span>
<p>H. Van Assel, C. Vincent-Cuaz, T. Vayer, R. Flamary, N. Courty.
“Interpolating between Clustering and Dimensionality Reduction with
Gromov-Wasserstein”. NeurIPS 2023 Workshop OTML.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.tensor_product">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">tensor_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constC</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hC1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hC2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#tensor_product"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.tensor_product" title="Link to this definition"></a></dt>
<dd><p>Return the tensor for Gromov-Wasserstein fast computation</p>
<p>The tensor is computed as described in Proposition 1 Eq. (6) in <a class="reference internal" href="#references-tensor-product"><span class="std std-ref">[12]</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constC</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Constant <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h1}(\mathbf{C1})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h2}(\mathbf{C2})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>tens</strong> – <span class="math notranslate nohighlight">\(\mathcal{L}(\mathbf{C_1}, \mathbf{C_2}) \otimes \mathbf{T}\)</span> tensor-matrix multiplication result</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric" id="references-tensor-product">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id75" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.update_feature_matrix">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">update_feature_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lambdas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ys</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#update_feature_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.update_feature_matrix" title="Link to this definition"></a></dt>
<dd><p>Updates the feature with respect to the <cite>S</cite> <span class="math notranslate nohighlight">\(\mathbf{T}_s\)</span> couplings.</p>
<p>See “Solving the barycenter problem with Block Coordinate Descent (BCD)”
in <a class="reference internal" href="#references-update-feature-matrix"><span class="std std-ref">[24]</span></a> calculated at each iteration</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em>) – masses in the targeted barycenter</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – List of the <cite>S</cite> spaces’ weights</p></li>
<li><p><strong>Ts</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>, </em><em>ns</em><em>)</em>) – The <cite>S</cite> <span class="math notranslate nohighlight">\(\mathbf{T}_s\)</span> couplings calculated at each iteration</p></li>
<li><p><strong>Ys</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em>, </em><em>shape</em><em> (</em><em>d</em><em>,</em><em>ns</em><em>)</em>) – The features.</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>X</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>d</cite>, <cite>N</cite>)</p>
</dd>
</dl>
<p class="rubric" id="references-update-feature-matrix">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id76" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain and Courty Nicolas
“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.update_kl_loss">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">update_kl_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#update_kl_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.update_kl_loss" title="Link to this definition"></a></dt>
<dd><p>Updates <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> according to the KL Loss kernel with the <cite>S</cite>
<span class="math notranslate nohighlight">\(\mathbf{T}_s\)</span> couplings calculated at each iteration of the GW
barycenter problem in <span class="xref std std-ref">[12]</span>:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}} \quad \sum_s \lambda_s \mathrm{GW}(\mathbf{C}, \mathbf{C}_s, \mathbf{p}, \mathbf{p}_s)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}_s\)</span>: metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}_s\)</span>: distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em>) – Weights in the targeted barycenter.</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – List of the <cite>S</cite> spaces’ weights</p></li>
<li><p><strong>T</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>N</em><em>, </em><em>ns</em><em>)</em>) – The <cite>S</cite> <span class="math notranslate nohighlight">\(\mathbf{T}_s\)</span> couplings calculated at each iteration.</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em>, </em><em>shape</em><em>(</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Metric cost matrices.</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>C</strong> – updated <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>ns</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id77" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.update_square_loss">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">update_square_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#update_square_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.update_square_loss" title="Link to this definition"></a></dt>
<dd><p>Updates <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> according to the L2 Loss kernel with the <cite>S</cite>
<span class="math notranslate nohighlight">\(\mathbf{T}_s\)</span> couplings calculated at each iteration of the GW
barycenter problem in <span class="xref std std-ref">[12]</span>:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}} \quad \sum_s \lambda_s \mathrm{GW}(\mathbf{C}, \mathbf{C}_s, \mathbf{p}, \mathbf{p}_s)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}_s\)</span>: metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}_s\)</span>: distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em>) – Masses in the targeted barycenter.</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – List of the <cite>S</cite> spaces’ weights.</p></li>
<li><p><strong>T</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>N</em><em>, </em><em>ns</em><em>)</em>) – The <cite>S</cite> <span class="math notranslate nohighlight">\(\mathbf{T}_s\)</span> couplings calculated at each iteration.</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> of </em><em>S array-like</em><em>, </em><em>shape</em><em>(</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Metric cost matrices.</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>C</strong> – Updated <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>nt</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id78" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ot.gnn.html" class="btn btn-neutral float-left" title="ot.gnn" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ot.lp.html" class="btn btn-neutral float-right" title="ot.lp" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016-2023, POT Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note"
aria-label="versions">
  <!--  add shift_up to the class for force viewing ,
  data-toggle="rst-current-version" -->
    <span class="rst-current-version"  style="margin-bottom:1mm;">
      <span class="fa fa-book"> Python Optimal Transport</span>
      <hr  style="margin-bottom:1.5mm;margin-top:5mm;">
     <!--  versions
      <span class="fa fa-caret-down"></span>-->
      <span class="rst-current-version" style="display: inline-block;padding:
      0px;color:#fcfcfcab;float:left;font-size: 100%;">
        Versions: 
        <a href="https://pythonot.github.io/" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Release</a>
        <a href="https://pythonot.github.io/master" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Development</a>
        <a href="https://github.com/PythonOT/POT"
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Code</a>

      </span>

     
    </span>
  
     <!--
    <div class="rst-other-versions">

      

<div class="injected">

    
  <dl>
    <dt>Versions</dt>

    <dd><a href="https://pythonot.github.io/">Release</a></dd>
    
    <dd><a href="https://pythonot.github.io/master">Development</a></dd>
   
    

    <dt><a href="https://github.com/PythonOT/POT">Code on Github</a></dt>       

    
  </dl>
  <hr>

</div> 
</div>-->
  </div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>