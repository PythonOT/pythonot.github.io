

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ot.gromov &mdash; POT Python Optimal Transport 0.9.6dev0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=6e3d2238"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ot.lowrank" href="ot.lowrank.html" />
    <link rel="prev" title="ot.gnn" href="ot.gnn.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            POT Python Optimal Transport
              <img src="../_static/logo_dark.svg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">POT: Python Optimal Transport</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/plot_quickstart_guide.html">Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide.html">User guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../all.html">API and modules</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ot.backend.html">ot.backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.bregman.html">ot.bregman</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.coot.html">ot.coot</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.da.html">ot.da</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.datasets.html">ot.datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.dr.html">ot.dr</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.factored.html">ot.factored</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gaussian.html">ot.gaussian</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gmm.html">ot.gmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.gnn.html">ot.gnn</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">ot.gromov</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.BAPG_fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">BAPG_fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.BAPG_fused_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">BAPG_fused_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.BAPG_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">BAPG_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.BAPG_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">BAPG_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.GW_distance_estimation"><code class="docutils literal notranslate"><span class="pre">GW_distance_estimation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.div_between_product"><code class="docutils literal notranslate"><span class="pre">div_between_product()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.div_to_product"><code class="docutils literal notranslate"><span class="pre">div_to_product()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_fused_gromov_barycenters"><code class="docutils literal notranslate"><span class="pre">entropic_fused_gromov_barycenters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">entropic_fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_fused_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">entropic_fused_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_gromov_barycenters"><code class="docutils literal notranslate"><span class="pre">entropic_gromov_barycenters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">entropic_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">entropic_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_partial_fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">entropic_partial_fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_partial_fused_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">entropic_partial_fused_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_partial_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">entropic_partial_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_partial_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">entropic_partial_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_semirelaxed_fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">entropic_semirelaxed_fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_semirelaxed_fused_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">entropic_semirelaxed_fused_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_semirelaxed_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">entropic_semirelaxed_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.entropic_semirelaxed_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">entropic_semirelaxed_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fgw_barycenters"><code class="docutils literal notranslate"><span class="pre">fgw_barycenters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.format_partitioned_graph"><code class="docutils literal notranslate"><span class="pre">format_partitioned_graph()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.format_partitioned_samples"><code class="docutils literal notranslate"><span class="pre">format_partitioned_samples()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fused_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">fused_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fused_gromov_wasserstein_dictionary_learning"><code class="docutils literal notranslate"><span class="pre">fused_gromov_wasserstein_dictionary_learning()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fused_gromov_wasserstein_linear_unmixing"><code class="docutils literal notranslate"><span class="pre">fused_gromov_wasserstein_linear_unmixing()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fused_unbalanced_across_spaces_cost"><code class="docutils literal notranslate"><span class="pre">fused_unbalanced_across_spaces_cost()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fused_unbalanced_across_spaces_divergence"><code class="docutils literal notranslate"><span class="pre">fused_unbalanced_across_spaces_divergence()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fused_unbalanced_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">fused_unbalanced_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.fused_unbalanced_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">fused_unbalanced_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.get_graph_partition"><code class="docutils literal notranslate"><span class="pre">get_graph_partition()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.get_graph_representants"><code class="docutils literal notranslate"><span class="pre">get_graph_representants()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.get_partition_and_representants_samples"><code class="docutils literal notranslate"><span class="pre">get_partition_and_representants_samples()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gromov_barycenters"><code class="docutils literal notranslate"><span class="pre">gromov_barycenters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gromov_wasserstein_dictionary_learning"><code class="docutils literal notranslate"><span class="pre">gromov_wasserstein_dictionary_learning()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gromov_wasserstein_linear_unmixing"><code class="docutils literal notranslate"><span class="pre">gromov_wasserstein_linear_unmixing()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gwggrad"><code class="docutils literal notranslate"><span class="pre">gwggrad()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.gwloss"><code class="docutils literal notranslate"><span class="pre">gwloss()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.init_matrix"><code class="docutils literal notranslate"><span class="pre">init_matrix()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.init_matrix_semirelaxed"><code class="docutils literal notranslate"><span class="pre">init_matrix_semirelaxed()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.lowrank_gromov_wasserstein_samples"><code class="docutils literal notranslate"><span class="pre">lowrank_gromov_wasserstein_samples()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.partial_fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">partial_fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.partial_fused_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">partial_fused_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.partial_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">partial_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.partial_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">partial_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.pointwise_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">pointwise_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.quantized_fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">quantized_fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.quantized_fused_gromov_wasserstein_partitioned"><code class="docutils literal notranslate"><span class="pre">quantized_fused_gromov_wasserstein_partitioned()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.quantized_fused_gromov_wasserstein_samples"><code class="docutils literal notranslate"><span class="pre">quantized_fused_gromov_wasserstein_samples()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.sampled_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">sampled_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.semirelaxed_fgw_barycenters"><code class="docutils literal notranslate"><span class="pre">semirelaxed_fgw_barycenters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.semirelaxed_fused_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">semirelaxed_fused_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.semirelaxed_fused_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">semirelaxed_fused_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.semirelaxed_gromov_barycenters"><code class="docutils literal notranslate"><span class="pre">semirelaxed_gromov_barycenters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.semirelaxed_gromov_wasserstein"><code class="docutils literal notranslate"><span class="pre">semirelaxed_gromov_wasserstein()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.semirelaxed_gromov_wasserstein2"><code class="docutils literal notranslate"><span class="pre">semirelaxed_gromov_wasserstein2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.semirelaxed_init_plan"><code class="docutils literal notranslate"><span class="pre">semirelaxed_init_plan()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.solve_gromov_linesearch"><code class="docutils literal notranslate"><span class="pre">solve_gromov_linesearch()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.solve_partial_gromov_linesearch"><code class="docutils literal notranslate"><span class="pre">solve_partial_gromov_linesearch()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.solve_semirelaxed_gromov_linesearch"><code class="docutils literal notranslate"><span class="pre">solve_semirelaxed_gromov_linesearch()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.tensor_product"><code class="docutils literal notranslate"><span class="pre">tensor_product()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.unbalanced_co_optimal_transport"><code class="docutils literal notranslate"><span class="pre">unbalanced_co_optimal_transport()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.unbalanced_co_optimal_transport2"><code class="docutils literal notranslate"><span class="pre">unbalanced_co_optimal_transport2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.uot_cost_matrix"><code class="docutils literal notranslate"><span class="pre">uot_cost_matrix()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.uot_parameters_and_measures"><code class="docutils literal notranslate"><span class="pre">uot_parameters_and_measures()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.update_barycenter_feature"><code class="docutils literal notranslate"><span class="pre">update_barycenter_feature()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ot.gromov.update_barycenter_structure"><code class="docutils literal notranslate"><span class="pre">update_barycenter_structure()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ot.lowrank.html">ot.lowrank</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.lp.html">ot.lp</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.mapping.html">ot.mapping</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.optim.html">ot.optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.partial.html">ot.partial</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.plot.html">ot.plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.regpath.html">ot.regpath</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.sliced.html">ot.sliced</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.smooth.html">ot.smooth</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.stochastic.html">ot.stochastic</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.unbalanced.html">ot.unbalanced</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.utils.html">ot.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="ot.weak.html">ot.weak</a></li>
<li class="toctree-l2"><a class="reference internal" href="../all.html#module-ot">Main <code class="xref py py-mod docutils literal notranslate"><span class="pre">ot</span></code> functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributors.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to POT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code_of_conduct.html">Code of conduct</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">POT Python Optimal Transport</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../all.html">API and modules</a></li>
      <li class="breadcrumb-item active">ot.gromov</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/gen_modules/ot.gromov.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-ot.gromov">
<span id="ot-gromov"></span><h1>ot.gromov<a class="headerlink" href="#module-ot.gromov" title="Link to this heading"></a></h1>
<p>Solvers related to Gromov-Wasserstein problems.</p>
<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.BAPG_fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">BAPG_fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginal_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#BAPG_fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.BAPG_fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{Y_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{Y_2}, \mathbf{q})\)</span>
with pairwise distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices <span class="math notranslate nohighlight">\(\mathbf{Y_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y_2}\)</span>,
estimated using Bregman Alternated Projected Gradient method.</p>
<p>If <cite>marginal_loss=True</cite>, the function solves the following Fused Gromov-Wasserstein
optimization problem :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in\mathop{\arg\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else, the function solves an equivalent problem [63, 64], where constant terms only
depending on the marginals <span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: are
discarded while assuming that L decomposes as in Proposition 1 in [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in\mathop{\arg\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F -
\alpha \langle h_1(\mathbf{C}_1) \mathbf{T} h_2(\mathbf{C_2})^\top , \mathbf{T} \rangle_F
s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: pairwise relation matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><dl class="simple">
<dt><cite>L</cite>: loss function to account for the misfit between the similarity and feature matrices</dt><dd><p>satisfying <span class="math notranslate nohighlight">\(L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\)</span></p>
</dd>
</dl>
</li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: trade-off parameter</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By algorithmic design the optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>
returned by this function does not necessarily satisfy the marginal
constraints <span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned Fused
Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Pairwise relation matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>marginal_loss</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional. Default is False.</em>) – Include constant marginal terms or not in the objective function.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two joint spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id1" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>63<span class="fn-bracket">]</span></span>
<p>Li, J., Tang, J., Kong, L., Liu, H., Li, J., So, A. M. C., &amp; Blanchet, J.
“A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein
in Graph Data”. International Conference on Learning Representations (ICLR), 2023.</p>
</aside>
<aside class="footnote brackets" id="id2" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>64<span class="fn-bracket">]</span></span>
<p>Ma, X., Chu, X., Wang, Y., Lin, Y., Zhao, J., Ma, L., &amp; Zhu, W.
“Fused Gromov-Wasserstein Graph Mixup for Graph-level Classifications”.
In Thirty-seventh Conference on Neural Information Processing Systems.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.BAPG_fused_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">BAPG_fused_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginal_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#BAPG_fused_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.BAPG_fused_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein loss between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{Y_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{Y_2}, \mathbf{q})\)</span>
with pairwise distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices <span class="math notranslate nohighlight">\(\mathbf{Y_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y_2}\)</span>,
estimated using Bregman Alternated Projected Gradient method.</p>
<p>If <cite>marginal_loss=True</cite>, the function solves the following Fused Gromov-Wasserstein
optimization problem :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{FGW} = \mathop{\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else, the function solves an equivalent problem [63, 64], where constant terms only
depending on the marginals <span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: are
discarded while assuming that L decomposes as in Proposition 1 in [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathop{\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F -
\alpha \langle h_1(\mathbf{C}_1) \mathbf{T} h_2(\mathbf{C_2})^\top , \mathbf{T} \rangle_F
s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><dl class="simple">
<dt><cite>L</cite>: loss function to account for the misfit between the similarity and feature matrices</dt><dd><p>satisfying <span class="math notranslate nohighlight">\(L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\)</span></p>
</dd>
</dl>
</li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: trade-off parameter</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By algorithmic design the optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>
returned by this function does not necessarily satisfy the marginal
constraints <span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned Fused
Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>marginal_loss</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional. Default is False.</em>) – Include constant marginal terms or not in the objective function.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two joint spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id3" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>63<span class="fn-bracket">]</span></span>
<p>Li, J., Tang, J., Kong, L., Liu, H., Li, J., So, A. M. C., &amp; Blanchet, J.
“A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein
in Graph Data”. International Conference on Learning Representations (ICLR), 2023.</p>
</aside>
<aside class="footnote brackets" id="id4" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>64<span class="fn-bracket">]</span></span>
<p>Ma, X., Chu, X., Wang, Y., Lin, Y., Zhao, J., Ma, L., &amp; Zhu, W.
“Fused Gromov-Wasserstein Graph Mixup for Graph-level Classifications”.
In Thirty-seventh Conference on Neural Information Processing Systems.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.BAPG_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">BAPG_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginal_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#BAPG_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.BAPG_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>
estimated using Bregman Alternated Projected Gradient method.</p>
<p>If <cite>marginal_loss=True</cite>, the function solves the following Gromov-Wasserstein
optimization problem :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else, the function solves an equivalent problem [63], where constant terms only
depending on the marginals <span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: are
discarded while assuming that L decomposes as in Proposition 1 in [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in\mathop{\arg\min}_\mathbf{T} \quad - \langle h_1(\mathbf{C}_1) \mathbf{T} h_2(\mathbf{C_2})^\top , \mathbf{T} \rangle_F\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><dl class="simple">
<dt><cite>L</cite>: loss function to account for the misfit between the similarity matrices</dt><dd><p>satisfying <span class="math notranslate nohighlight">\(L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\)</span></p>
</dd>
</dl>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By algorithmic design the optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>
returned by this function does not necessarily satisfy the marginal
constraints <span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned
Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>marginal_loss</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional. Default is False.</em>) – Include constant marginal terms or not in the objective function.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id5" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>63<span class="fn-bracket">]</span></span>
<p>Li, J., Tang, J., Kong, L., Liu, H., Li, J., So, A. M. C., &amp; Blanchet, J.
“A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein
in Graph Data”. International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.BAPG_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">BAPG_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">marginal_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#BAPG_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.BAPG_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein loss <span class="math notranslate nohighlight">\(\mathbf{GW}\)</span> between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>
estimated using Bregman Alternated Projected Gradient method.</p>
<p>If <cite>marginal_loss=True</cite>, the function solves the following Gromov-Wasserstein
optimization problem :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{GW} = \mathop{\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else, the function solves an equivalent problem [63, 64], where constant terms only
depending on the marginals <span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: are
discarded while assuming that L decomposes as in Proposition 1 in [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathop{\min}_\mathbf{T}  \quad - \langle h_1(\mathbf{C}_1) \mathbf{T} h_2(\mathbf{C_2})^\top , \mathbf{T} \rangle_F\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><dl class="simple">
<dt><cite>L</cite>: loss function to account for the misfit between the similarity matrices</dt><dd><p>satisfying <span class="math notranslate nohighlight">\(L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\)</span></p>
</dd>
</dl>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By algorithmic design the optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>
returned by this function does not necessarily satisfy the marginal
constraints <span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned
Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>marginal_loss</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional. Default is False.</em>) – Include constant marginal terms or not in the objective function.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>gw_dist</strong> – Gromov-Wasserstein distance</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id6" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>63<span class="fn-bracket">]</span></span>
<p>Li, J., Tang, J., Kong, L., Liu, H., Li, J., So, A. M. C., &amp; Blanchet, J.
“A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein
in Graph Data”. International Conference on Learning Representations (ICLR), 2023.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.GW_distance_estimation">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">GW_distance_estimation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_samples_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_samples_q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_estimators.html#GW_distance_estimation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.GW_distance_estimation" title="Link to this definition"></a></dt>
<dd><p>Returns an approximation of the Gromov-Wasserstein loss between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>
with a fixed transport plan <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>. To recover an approximation of the Gromov-Wasserstein distance as defined in [13] compute <span class="math notranslate nohighlight">\(d_{GW} = \frac{1}{2} \sqrt{\mathbf{GW}}\)</span>.</p>
<p>The function gives an unbiased approximation of the following equation:</p>
<div class="math notranslate nohighlight">
\[\mathbf{GW} = \sum_{i,j,k,l} L(\mathbf{C_{1}}_{i,k}, \mathbf{C_{2}}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><cite>L</cite> : Loss function to account for the misfit between the similarity matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: Matrix with marginal <span class="math notranslate nohighlight">\(\mathbf{p}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>loss_fun</strong> (function: <span class="math notranslate nohighlight">\(\mathbb{R} \times \mathbb{R} \mapsto \mathbb{R}\)</span>) – Loss function used for the distance, the transport plan does not depend on the loss function</p></li>
<li><p><strong>T</strong> (<em>csr</em><em> or </em><em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Transport plan matrix, either a sparse csr or a dense matrix</p></li>
<li><p><strong>nb_samples_p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – <cite>nb_samples_p</cite> is the number of samples (without replacement) along the first dimension of <span class="math notranslate nohighlight">\(\mathbf{T}\)</span></p></li>
<li><p><strong>nb_samples_q</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – <cite>nb_samples_q</cite> is the number of samples along the second dimension of <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>, for each sample along the first</p></li>
<li><p><strong>std</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Standard deviation associated with the prediction of the gromov-wasserstein cost</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Gromov-wasserstein cost</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id7" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></span>
<p>Kerdoncuff, Tanguy, Emonet, Rémi, Sebban, Marc
“Sampled Gromov Wasserstein.”
Machine Learning Journal (MLJ). 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.div_between_product">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">div_between_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">divergence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#div_between_product"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.div_between_product" title="Link to this definition"></a></dt>
<dd><p>Fast computation of the Bregman divergence between two product measures.
Only support for Kullback-Leibler and half-squared L2 divergences.</p>
<p>For half-squared L2 divergence:</p>
<div class="math notranslate nohighlight">
\[\frac{1}{2} || \mu \otimes \nu, \alpha \otimes \beta ||^2
= \frac{1}{2} \Big[ ||\alpha||^2 ||\beta||^2 + ||\mu||^2 ||\nu||^2 - 2 \langle \alpha, \mu \rangle \langle \beta, \nu \rangle \Big]\]</div>
<p>For Kullback-Leibler divergence:</p>
<div class="math notranslate nohighlight">
\[KL(\mu \otimes \nu, \alpha \otimes \beta)
= m(\mu) * KL(\nu, \beta) + m(\nu) * KL(\mu, \alpha) + (m(\mu) - m(\alpha)) * (m(\nu) - m(\beta))\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\alpha\)</span> are two measures having the same shape.</p></li>
<li><p><span class="math notranslate nohighlight">\(\nu\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> are two measures having the same shape.</p></li>
<li><p><span class="math notranslate nohighlight">\(m\)</span> denotes the mass of the measure</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<em>array-like</em>) – vector or matrix</p></li>
<li><p><strong>nu</strong> (<em>array-like</em>) – vector or matrix</p></li>
<li><p><strong>alpha</strong> (<em>array-like</em>) – vector or matrix with the same shape as <cite>mu</cite></p></li>
<li><p><strong>beta</strong> (<em>array-like</em>) – vector or matrix with the same shape as <cite>nu</cite></p></li>
<li><p><strong>divergence</strong> (<em>string</em><em>, </em><em>default = &quot;kl&quot;</em>) – Bregman divergence, either “kl” (Kullback-Leibler divergence) or “l2” (half-squared L2 divergence)</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Bregman divergence between two product measures.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.div_to_product">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">div_to_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pi1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pi2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">divergence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'kl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mass</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#div_to_product"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.div_to_product" title="Link to this definition"></a></dt>
<dd><p>Fast computation of the Bregman divergence between an arbitrary measure and a product measure.
Only support for Kullback-Leibler and half-squared L2 divergences.</p>
<ul class="simple">
<li><p>For half-squared L2 divergence:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\frac{1}{2} || \pi - a \otimes b ||^2
= \frac{1}{2} \Big[ \sum_{i, j} \pi_{ij}^2 + (\sum_i a_i^2) ( \sum_j b_j^2) - 2 \sum_{i, j} a_i \pi_{ij} b_j \Big]\]</div>
<ul class="simple">
<li><p>For Kullback-Leibler divergence:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[KL(\pi | a \otimes b)
= \langle \pi, \log \pi \rangle - \langle \pi_1, \log a \rangle
- \langle \pi_2, \log b \rangle - m(\pi) + m(a) m(b)\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\pi\)</span> is the (<cite>dim_a</cite>, <cite>dim_b</cite>) transport plan</p></li>
<li><p><span class="math notranslate nohighlight">\(\pi_1\)</span> and <span class="math notranslate nohighlight">\(\pi_2\)</span> are the marginal distributions</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target unbalanced distributions</p></li>
<li><p><span class="math notranslate nohighlight">\(m\)</span> denotes the mass of the measure</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pi</strong> (<em>array-like</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – Transport plan</p></li>
<li><p><strong>a</strong> (<em>array-like</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – Unnormalized histogram of dimension <cite>dim_a</cite></p></li>
<li><p><strong>b</strong> (<em>array-like</em><em> (</em><em>dim_b</em><em>,</em><em>)</em>) – Unnormalized histogram of dimension <cite>dim_b</cite></p></li>
<li><p><strong>pi1</strong> (<em>array-like</em><em> (</em><em>dim_a</em><em>,</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Marginal distribution with respect to the first dimension of the transport plan
Only used in case of Kullback-Leibler divergence.</p></li>
<li><p><strong>pi2</strong> (<em>array-like</em><em> (</em><em>dim_a</em><em>,</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Marginal distribution with respect to the second dimension of the transport plan
Only used in case of Kullback-Leibler divergence.</p></li>
<li><p><strong>divergence</strong> (<em>string</em><em>, </em><em>default = &quot;kl&quot;</em>) – Bregman divergence, either “kl” (Kullback-Leibler divergence) or “l2” (half-squared L2 divergence)</p></li>
<li><p><strong>mass</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional. Default is False.</em>) – Only used in case of Kullback-Leibler divergence.
If False, calculate the relative entropy.
If True, calculate the Kullback-Leibler divergence.</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Bregman divergence between an arbitrary measure and a product measure.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_fused_gromov_barycenters">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_fused_gromov_barycenters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ys</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'barycenter'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstartT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_Y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_structure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#entropic_fused_gromov_barycenters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_fused_gromov_barycenters" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein barycenters of <cite>S</cite> measurable networks with node features <span class="math notranslate nohighlight">\((\mathbf{C}_s, \mathbf{Y}_s, \mathbf{p}_s)_{1 \leq s \leq S}\)</span>
estimated using Fused Gromov-Wasserstein transports from Sinkhorn projections.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^*, \mathbf{Y}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}, \mathbf{Y}\in \mathbb{Y}^{N \times d}} \quad \sum_s \lambda_s \mathrm{FGW}_{\alpha}(\mathbf{C}, \mathbf{C}_s, \mathbf{Y}, \mathbf{Y}_s, \mathbf{p}, \mathbf{p}_s)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}_s\)</span>: feature matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}_s\)</span>: metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}_s\)</span>: distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size of the targeted barycenter</p></li>
<li><p><strong>Ys</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>array-like</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Features of all samples</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Metric cost matrices</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Sample weights in the <cite>S</cite> spaces.
If let to its default value None, uniform distributions are taken.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Weights in the targeted barycenter.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – List of the <cite>S</cite> spaces’ weights.
If let to its default value None, uniform weights are taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional.</em>) – Either structures are to be assumed symmetric or not. Default value is True.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>stop_criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'barycenter'.</em>) – Stop criterion taking values in [‘barycenter’, ‘loss’]. If set to ‘barycenter’
uses absolute norm variations of estimated barycenters. Else if set to ‘loss’
uses the relative variations of the loss.</p></li>
<li><p><strong>warmstartT</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of transport plans in the successive
fused gromov-wasserstein transport problems.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em> | </em><em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>, </em><em>N</em><em>)</em>) – Random initial value for the <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix provided by user.</p></li>
<li><p><strong>init_Y</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>d</em><em>)</em><em>, </em><em>optional</em>) – Initialization for the barycenters’ features. If not set a
random init is used.</p></li>
<li><p><strong>fixed_structure</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to fix the structure of the barycenter during the updates.</p></li>
<li><p><strong>fixed_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to fix the feature of the barycenter during the updates</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the <cite>ot.entropic_fused_gromov_wasserstein</cite> solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>Y</strong> (array-like, shape (<cite>N</cite>, <cite>d</cite>)) – Feature matrix in the barycenter space (permutated arbitrarily)</p></li>
<li><p><strong>C</strong> (array-like, shape (<cite>N</cite>, <cite>N</cite>)) – Similarity matrix in the barycenter space (permutated as Y’s rows)</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Only returned when log=True. It contains the keys:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: list of (<cite>N</cite>, <cite>ns</cite>) transport matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: (<cite>N</cite>,) barycenter weights</p></li>
<li><p><span class="math notranslate nohighlight">\((\mathbf{M}_s)_s\)</span>: all distance matrices between the feature of the barycenter and the other features <span class="math notranslate nohighlight">\((dist(\mathbf{X}, \mathbf{Y}_s))_s\)</span> shape (<cite>N</cite>, <cite>ns</cite>)</p></li>
<li><p>values used in convergence evaluation.</p></li>
</ul>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id8" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id9" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas
“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PGD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstart</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#entropic_fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{Y_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{Y_2}, \mathbf{q})\)</span>
with pairwise distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices <span class="math notranslate nohighlight">\(\mathbf{Y_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y_2}\)</span>,
estimated using Sinkhorn projections.</p>
<p>If <cite>solver=”PGD”</cite>, the function solves the following entropic-regularized
Fused Gromov-Wasserstein optimization problem using Projected Gradient Descent [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l} - \epsilon H(\mathbf{T})\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else if <cite>solver=”PPA”</cite>, the function solves the following Fused Gromov-Wasserstein
optimization problem using Proximal Point Algorithm [51]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in\mathop{\arg\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity and feature matrices</p></li>
<li><p><cite>H</cite>: entropy</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: trade-off parameter</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the inner solver <cite>ot.sinkhorn</cite> did not convergence, the
optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span> returned by this function does not
necessarily satisfy the marginal constraints
<span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned
Fused Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>solver</strong> (<em>string</em><em>, </em><em>optional</em>) – Solver to use either ‘PGD’ for Projected Gradient Descent or ‘PPA’
for Proximal Point Algorithm.
Default value is ‘PGD’.</p></li>
<li><p><strong>warmstart</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of dual potentials in the successive
Sinkhorn projections.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the ot.sinkhorn solver.
Such as <cite>numItermax</cite> and <cite>stopThr</cite> to control its estimation precision,
e.g [51] suggests to use <cite>numItermax=1</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two joint spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id10" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id11" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., &amp; Mémoli, F. (2019). The gromov–wasserstein
distance between networks and stable network invariants.
Information and Inference: A Journal of the IMA, 8(4), 757-787.</p>
</aside>
<aside class="footnote brackets" id="id12" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>51<span class="fn-bracket">]</span></span>
<p>Xu, H., Luo, D., Zha, H., &amp; Duke, L. C. (2019). Gromov-wasserstein
learning for graph matching and node embedding. In International
Conference on Machine Learning (ICML), 2019.</p>
</aside>
<aside class="footnote brackets" id="id13" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_fused_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_fused_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PGD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstart</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#entropic_fused_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_fused_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein distance between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{Y_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{Y_2}, \mathbf{q})\)</span>
with pairwise distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices <span class="math notranslate nohighlight">\(\mathbf{Y_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y_2}\)</span>,
estimated using Sinkhorn projections.</p>
<p>If <cite>solver=”PGD”</cite>, the function solves the following entropic-regularized
Fused Gromov-Wasserstein optimization problem using Projected Gradient Descent [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{FGW} = \mathop{\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l} - \epsilon H(\mathbf{T})\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else if <cite>solver=”PPA”</cite>, the function solves the following Fused Gromov-Wasserstein
optimization problem using Proximal Point Algorithm [51]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{FGW} = \mathop{\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity and feature matrices</p></li>
<li><p><cite>H</cite>: entropy</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: trade-off parameter</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the inner solver <cite>ot.sinkhorn</cite> did not convergence, the
optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span> returned by this function does not
necessarily satisfy the marginal constraints
<span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned
Fused Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>fgw_dist</strong> – Fused Gromov-Wasserstein distance</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id14" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id15" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>51<span class="fn-bracket">]</span></span>
<p>Xu, H., Luo, D., Zha, H., &amp; Duke, L. C. (2019). Gromov-wasserstein
learning for graph matching and node embedding. In International
Conference on Machine Learning (ICML), 2019.</p>
</aside>
<aside class="footnote brackets" id="id16" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_gromov_barycenters">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_gromov_barycenters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'barycenter'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstartT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#entropic_gromov_barycenters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_gromov_barycenters" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein barycenters of <cite>S</cite> measured similarity matrices <span class="math notranslate nohighlight">\((\mathbf{C}_s)_{1 \leq s \leq S}\)</span>
estimated using Gromov-Wasserstein transports from Sinkhorn projections.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}} \quad \sum_s \lambda_s \mathrm{GW}(\mathbf{C}, \mathbf{C}_s, \mathbf{p}, \mathbf{p}_s)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}_s\)</span>: metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}_s\)</span>: distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size of the targeted barycenter</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Metric cost matrices</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Sample weights in the <cite>S</cite> spaces.
If let to its default value None, uniform distributions are taken.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Weights in the targeted barycenter.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – List of the <cite>S</cite> spaces’ weights.
If let to its default value None, uniform weights are taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional.</em>) – Either structures are to be assumed symmetric or not. Default value is True.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>stop_criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'barycenter'.</em>) – Convergence criterion taking values in [‘barycenter’, ‘loss’]. If set to ‘barycenter’
uses absolute norm variations of estimated barycenters. Else if set to ‘loss’
uses the relative variations of the loss.</p></li>
<li><p><strong>warmstartT</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of transport plans in the successive
gromov-wasserstein transport problems.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em> | </em><em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>, </em><em>N</em><em>)</em>) – Random initial value for the <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix provided by user.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the <cite>ot.entropic_gromov_wasserstein</cite> solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>C</strong> (array-like, shape (<cite>N</cite>, <cite>N</cite>)) – Similarity matrix in the barycenter space (permutated arbitrarily)</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Only returned when log=True. It contains the keys:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: list of (<cite>N</cite>, <cite>ns</cite>) transport matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: (<cite>N</cite>,) barycenter weights</p></li>
<li><p>values used in convergence evaluation.</p></li>
</ul>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id17" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PGD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstart</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#entropic_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>
estimated using Sinkhorn projections.</p>
<p>If <cite>solver=”PGD”</cite>, the function solves the following entropic-regularized
Gromov-Wasserstein optimization problem using Projected Gradient Descent [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l} - \epsilon H(\mathbf{T})\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else if <cite>solver=”PPA”</cite>, the function solves the following Gromov-Wasserstein
optimization problem using Proximal Point Algorithm [51]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
<li><p><cite>H</cite>: entropy</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the inner solver <cite>ot.sinkhorn</cite> did not convergence, the
optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span> returned by this function does not
necessarily satisfy the marginal constraints
<span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned
Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>solver</strong> (<em>string</em><em>, </em><em>optional</em>) – Solver to use either ‘PGD’ for Projected Gradient Descent or ‘PPA’
for Proximal Point Algorithm.
Default value is ‘PGD’.</p></li>
<li><p><strong>warmstart</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of dual potentials in the successive
Sinkhorn projections.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the ot.sinkhorn solver.
Such as <cite>numItermax</cite> and <cite>stopThr</cite> to control its estimation precision,
e.g [51] suggests to use <cite>numItermax=1</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id18" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id19" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., &amp; Mémoli, F. (2019). The gromov–wasserstein
distance between networks and stable network invariants.
Information and Inference: A Journal of the IMA, 8(4), 757-787.</p>
</aside>
<aside class="footnote brackets" id="id20" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>51<span class="fn-bracket">]</span></span>
<p>Xu, H., Luo, D., Zha, H., &amp; Duke, L. C. (2019). Gromov-wasserstein
learning for graph matching and node embedding. In International
Conference on Machine Learning (ICML), 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PGD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstart</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_bregman.html#entropic_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein loss <span class="math notranslate nohighlight">\(\mathbf{GW}\)</span> between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>
estimated using Sinkhorn projections. To recover the Gromov-Wasserstein distance as defined in [13] compute <span class="math notranslate nohighlight">\(d_{GW} = \frac{1}{2} \sqrt{\mathbf{GW}}\)</span>.</p>
<p>If <cite>solver=”PGD”</cite>, the function solves the following entropic-regularized
Gromov-Wasserstein optimization problem using Projected Gradient Descent [12]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{GW} = \mathop{\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l} - \epsilon H(\mathbf{T})\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Else if <cite>solver=”PPA”</cite>, the function solves the following Gromov-Wasserstein
optimization problem using Proximal Point Algorithm [51]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{GW} = \mathop{\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
<li><p><cite>H</cite>: entropy</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the inner solver <cite>ot.sinkhorn</cite> did not convergence, the
optimal coupling <span class="math notranslate nohighlight">\(\mathbf{T}\)</span> returned by this function does not
necessarily satisfy the marginal constraints
<span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{1}=\mathbf{p}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{T}^T\mathbf{1}=\mathbf{q}\)</span>. So the returned
Gromov-Wasserstein loss does not necessarily satisfy distance
properties and may be negative.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default='square_loss'</em><em>)</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 will be used as initial transport of the solver. G0 is not
required to satisfy marginal constraints but we strongly recommend it
to correctly estimate the GW distance.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>solver</strong> (<em>string</em><em>, </em><em>optional</em>) – Solver to use either ‘PGD’ for Projected Gradient Descent or ‘PPA’
for Proximal Point Algorithm.
Default value is ‘PGD’.</p></li>
<li><p><strong>warmstart</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of dual potentials in the successive
Sinkhorn projections.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the ot.sinkhorn solver.
Such as <cite>numItermax</cite> and <cite>stopThr</cite> to control its estimation precision,
e.g [51] suggests to use <cite>numItermax=1</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>gw_dist</strong> – Gromov-Wasserstein distance</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id21" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id22" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>51<span class="fn-bracket">]</span></span>
<p>Xu, H., Luo, D., Zha, H., &amp; Duke, L. C. (2019). Gromov-wasserstein
learning for graph matching and node embedding. In International
Conference on Machine Learning (ICML), 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_partial_fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_partial_fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_partial.html#entropic_partial_fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_partial_fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the entropic partial Fused Gromov-Wasserstein transport between
<span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{F_1}, \mathbf{p})\)</span> and
<span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{F_2}, \mathbf{q})\)</span>, with pairwise
distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[\mathbf{T} = \mathop{\arg \min}_{\mathbf{T}} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F
+ \alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l})
T_{i,j} T_{k,l} + \mathrm{reg} \Omega(\mathbf{T})\]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}s.t. \ \mathbf{T} &amp;\geq 0\\     \mathbf{T} \mathbf{1} &amp;\leq \mathbf{a}\\     \mathbf{T}^T \mathbf{1} &amp;\leq \mathbf{b}\\     \mathbf{1}^T \mathbf{T}^T \mathbf{1} = m
     &amp;\leq \min\{\|\mathbf{a}\|_1, \|\mathbf{b}\|_1\}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span> is the metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span> is the metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> are the sample weights</p></li>
<li><p><cite>L</cite>: quadratic loss function</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term,
<span class="math notranslate nohighlight">\(\Omega(\mathbf{T})=\sum_{i,j} T_{i,j}\log(T_{i,j})\)</span></p></li>
<li><p><cite>m</cite> is the amount of mass to be transported</p></li>
</ul>
<p>The formulation of the FGW problem has been proposed in
<a class="reference internal" href="#references-entropic-partial-fused-gromov-wasserstein"><span class="std std-ref">[24]</span></a> and the
partial GW in <a class="reference internal" href="#references-entropic-partial-fused-gromov-wasserstein"><span class="std std-ref">[29]</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional. Default is 1.</em>) – entropic regularization parameter</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported (default:
<span class="math notranslate nohighlight">\(\min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\)</span>)</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Initialization of the transportation matrix</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – return log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>T</strong> (<em>ndarray, shape (dim_a, dim_b)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-entropic-partial-fused-gromov-wasserstein">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id23" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id24" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></span>
<p>Chapel, L., Alaya, M., Gasso, G. (2020). “Partial Optimal
Transport with Applications on Positive-Unlabeled Learning”.
NeurIPS.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.gromov.partial_fused_gromov_wasserstein" title="ot.gromov.partial_fused_gromov_wasserstein"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.gromov.partial_fused_gromov_wasserstein</span></code></a></dt><dd><p>exact Partial Fused Gromov-Wasserstein</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_partial_fused_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_partial_fused_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_partial.html#entropic_partial_fused_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_partial_fused_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the entropic partial Fused Gromov-Wasserstein discrepancy between
<span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{F_1}, \mathbf{p})\)</span> and
<span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{F_2}, \mathbf{q})\)</span>, with pairwise
distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[PGW = \min_{\mathbf{T}} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F
+ \alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) T_{i,j} T_{k,l}
+ \mathrm{reg} \cdot\Omega(\mathbf{T})\]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}s.t. \ \mathbf{T} &amp;\geq 0\\     \mathbf{T} \mathbf{1} &amp;\leq \mathbf{a}\\     \mathbf{T}^T \mathbf{1} &amp;\leq \mathbf{b}\\     \mathbf{1}^T \mathbf{T}^T \mathbf{1} = m &amp;\leq \min\{\|\mathbf{a}\|_1, \|\mathbf{b}\|_1\}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span> is the metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span> is the metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> are the sample weights</p></li>
<li><p><cite>L</cite>: Loss function to account for the misfit between the similarity matrices.</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term,
<span class="math notranslate nohighlight">\(\Omega(\mathbf{T})=\sum_{i,j} T_{i,j}\log(T_{i,j})\)</span></p></li>
<li><p><cite>m</cite> is the amount of mass to be transported</p></li>
</ul>
<p>The formulation of the FGW problem has been proposed in
<span class="xref std std-ref">[24]</span> and the
partial GW in <span class="xref std std-ref">[29]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – entropic regularization parameter</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported (default:
<span class="math notranslate nohighlight">\(\min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\)</span>)</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Initialization of the transportation matrix</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – return log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>partial_fgw_dist</strong> (<em>float</em>) – Partial Entropic Fused Gromov-Wasserstein discrepancy</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
<li><p><em>.. _references-entropic-partial-fused-gromov-wasserstein2</em></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id25" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id26" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></span>
<p>Chapel, L., Alaya, M., Gasso, G. (2020). “Partial Optimal
Transport with Applications on Positive-Unlabeled Learning”.
NeurIPS.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_partial_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_partial_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_partial.html#entropic_partial_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_partial_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the partial Gromov-Wasserstein transport between
<span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span></p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[\mathbf{T} = \mathop{\arg \min}_{\mathbf{T}} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l})
T_{i,j} T_{k,l} + \mathrm{reg} \Omega(\mathbf{T})\]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}s.t. \ \mathbf{T} &amp;\geq 0\\     \mathbf{T} \mathbf{1} &amp;\leq \mathbf{a}\\     \mathbf{T}^T \mathbf{1} &amp;\leq \mathbf{b}\\     \mathbf{1}^T \mathbf{T}^T \mathbf{1} = m
     &amp;\leq \min\{\|\mathbf{a}\|_1, \|\mathbf{b}\|_1\}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span> is the metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span> is the metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> are the sample weights</p></li>
<li><p><cite>L</cite>: quadratic loss function</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term,
<span class="math notranslate nohighlight">\(\Omega(\mathbf{T})=\sum_{i,j} T_{i,j}\log(T_{i,j})\)</span></p></li>
<li><p><cite>m</cite> is the amount of mass to be transported</p></li>
</ul>
<p>The formulation of the GW problem has been proposed in
<a class="reference internal" href="ot.partial.html#references-entropic-partial-gromov-wasserstein"><span class="std std-ref">[12]</span></a> and the
partial GW in <a class="reference internal" href="ot.partial.html#references-entropic-partial-gromov-wasserstein"><span class="std std-ref">[29]</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional. Default is 1.</em>) – entropic regularization parameter</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported (default:
<span class="math notranslate nohighlight">\(\min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\)</span>)</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Initialization of the transportation matrix</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – return log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ot.gromov</span><span class="w"> </span><span class="kn">import</span> <span class="n">entropic_partial_gromov_wasserstein</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">98</span><span class="p">,</span><span class="mi">199</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C2</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">entropic_partial_gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.12, 0.13, 0.  , 0.  ],</span>
<span class="go">       [0.13, 0.12, 0.  , 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.25, 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.  , 0.25]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">entropic_partial_gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">,</span><span class="mf">0.25</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.02, 0.03, 0.  , 0.03],</span>
<span class="go">       [0.03, 0.03, 0.  , 0.03],</span>
<span class="go">       [0.  , 0.  , 0.03, 0.  ],</span>
<span class="go">       [0.02, 0.02, 0.  , 0.03]])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>T</strong> (<em>ndarray, shape (dim_a, dim_b)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-entropic-partial-gromov-wasserstein">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id27" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id28" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></span>
<p>Chapel, L., Alaya, M., Gasso, G. (2020). “Partial Optimal
Transport with Applications on Positive-Unlabeled Learning”.
NeurIPS.</p>
</aside>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="ot.partial.html#ot.partial.partial_gromov_wasserstein" title="ot.partial.partial_gromov_wasserstein"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ot.partial.partial_gromov_wasserstein</span></code></a></dt><dd><p>exact Partial Gromov-Wasserstein</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_partial_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_partial_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_partial.html#entropic_partial_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_partial_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the partial Gromov-Wasserstein discrepancy between
<span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span></p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[PGW = \min_{\mathbf{T}} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k},
     \mathbf{C_2}_{j,l})
     T_{i,j}T_{k,l} + \mathrm{reg} \Omega(\mathbf{T})\]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}s.t. \ \mathbf{T} &amp;\geq 0\\     \mathbf{T} \mathbf{1} &amp;\leq \mathbf{a}\\     \mathbf{T}^T \mathbf{1} &amp;\leq \mathbf{b}\\     \mathbf{1}^T \mathbf{T}^T \mathbf{1} = m &amp;\leq \min\{\|\mathbf{a}\|_1, \|\mathbf{b}\|_1\}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span> is the metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span> is the metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> are the sample weights</p></li>
<li><p><cite>L</cite>: Loss function to account for the misfit between the similarity matrices.</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term,
<span class="math notranslate nohighlight">\(\Omega(\mathbf{T})=\sum_{i,j} T_{i,j}\log(T_{i,j})\)</span></p></li>
<li><p><cite>m</cite> is the amount of mass to be transported</p></li>
</ul>
<p>The formulation of the GW problem has been proposed in
<a class="reference internal" href="ot.partial.html#references-entropic-partial-gromov-wasserstein2"><span class="std std-ref">[12]</span></a> and the
partial GW in <a class="reference internal" href="ot.partial.html#references-entropic-partial-gromov-wasserstein2"><span class="std std-ref">[29]</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – entropic regularization parameter</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported (default:
<span class="math notranslate nohighlight">\(\min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\)</span>)</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>G0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Initialization of the transportation matrix</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – return log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>partial_gw_dist</strong> (<em>float</em>) – Partial Gromov-Wasserstein distance</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ot.gromov</span><span class="w"> </span><span class="kn">import</span> <span class="n">entropic_partial_gromov_wasserstein2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">98</span><span class="p">,</span><span class="mi">199</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C2</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">entropic_partial_gromov_wasserstein2</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">3.75</span>
</pre></div>
</div>
<p class="rubric" id="references-entropic-partial-gromov-wasserstein2">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id29" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id30" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></span>
<p>Chapel, L., Alaya, M., Gasso, G. (2020). “Partial Optimal
Transport with Applications on Positive-Unlabeled Learning”.
NeurIPS.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_semirelaxed_fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_semirelaxed_fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#entropic_semirelaxed_fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_semirelaxed_fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Computes the entropic-regularized semi-relaxed FGW transport between two graphs (see <span class="xref std std-ref">[48]</span>)
estimated using a Mirror Descent algorithm following the KL geometry.</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_{\mathbf{T}} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix between features</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> source weights (sum to 1)</p></li>
<li><p><cite>L</cite> is a loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[48]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>) or </em><em>string</em><em>, </em><em>optional</em>) – If <cite>G0=None</cite> the initial transport plan of the solver is <span class="math notranslate nohighlight">\(\mathbf{p} \frac{\mathbf{1}_{nt}}{nt}^\top\)</span>.
If G0 is a tensor it must satisfy marginal constraints and will be
used as initial transport of the solver.
if G0 is a string it will be interpreted as a method for
<a class="reference internal" href="#ot.gromov.semirelaxed_init_plan" title="ot.gromov.semirelaxed_init_plan"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.gromov.semirelaxed_init_plan()</span></code></a> taking values in “product”,
“random_product”, “random”, “fluid”, “fluid_soft”, “spectral”,
“spectral_soft”, “kmeans”, “kmeans_soft”.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error computed on transport plans</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed used in stochastic initialization methods.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>G</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) – Optimal transportation matrix for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-semirelaxed-fused-gromov-wasserstein">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id31" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_semirelaxed_fused_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_semirelaxed_fused_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#entropic_semirelaxed_fused_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_semirelaxed_fused_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Computes the entropic-regularized semi-relaxed FGW divergence between two graphs (see <span class="xref std std-ref">[48]</span>)
estimated using a Mirror Descent algorithm following the KL geometry.</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{srFGW}_{\alpha} = \min_{\mathbf{T}} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix between features</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> source weights (sum to 1)</p></li>
<li><p><cite>L</cite> is a loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[48]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space.</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>) or </em><em>string</em><em>, </em><em>optional</em>) – If <cite>G0=None</cite> the initial transport plan of the solver is <span class="math notranslate nohighlight">\(\mathbf{p} \frac{\mathbf{1}_{nt}}{nt}^\top\)</span>.
If G0 is a tensor it must satisfy marginal constraints and will be
used as initial transport of the solver.
if G0 is a string it will be interpreted as a method for
<a class="reference internal" href="#ot.gromov.semirelaxed_init_plan" title="ot.gromov.semirelaxed_init_plan"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.gromov.semirelaxed_init_plan()</span></code></a> taking values in “product”,
“random_product”, “random”, “fluid”, “fluid_soft”, “spectral”,
“spectral_soft”, “kmeans”, “kmeans_soft”.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error computed on transport plans</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed used in stochastic initialization methods.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>srfgw-divergence</strong> (<em>float</em>) – Semi-relaxed Fused gromov wasserstein divergence for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-semirelaxed-fused-gromov-wasserstein2">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id32" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_semirelaxed_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_semirelaxed_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#entropic_semirelaxed_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_semirelaxed_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the entropic-regularized semi-relaxed gromov-wasserstein divergence
transport plan from <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> to <span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>
estimated using a Mirror Descent algorithm following the KL geometry.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_\mathbf{T} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>) or </em><em>string</em><em>, </em><em>optional</em>) – If <cite>G0=None</cite> the initial transport plan of the solver is <span class="math notranslate nohighlight">\(\mathbf{p} \frac{\mathbf{1}_{nt}}{nt}^\top\)</span>.
If G0 is a tensor it must satisfy marginal constraints and will be
used as initial transport of the solver.
if G0 is a string it will be interpreted as a method for
<a class="reference internal" href="#ot.gromov.semirelaxed_init_plan" title="ot.gromov.semirelaxed_init_plan"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.gromov.semirelaxed_init_plan()</span></code></a> taking values in “product”,
“random_product”, “random”, “fluid”, “fluid_soft”, “spectral”,
“spectral_soft”, “kmeans”, “kmeans_soft”.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error computed on transport plans</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>verbose</strong> – Print information along iterations</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed used in stochastic initialization methods.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><p><strong>G</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) –</p>
<p>Coupling between the two spaces that minimizes:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\)</span></p>
</div></blockquote>
</li>
<li><p><strong>log</strong> (<em>dict</em>) – Convergence information and loss.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id33" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.entropic_semirelaxed_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">entropic_semirelaxed_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#entropic_semirelaxed_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.entropic_semirelaxed_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the entropic-regularized semi-relaxed gromov-wasserstein divergence
from <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> to <span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>
estimated using a Mirror Descent algorithm following the KL geometry.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{srGW} = \min_{\mathbf{T}} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity
matrices</p></li>
</ul>
<p>Note that when using backends, this loss function is differentiable wrt the
matrices (C1, C2) but not yet for the weights p.
.. note:: This function is backend-compatible and will work on arrays</p>
<blockquote>
<div><p>from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>) or </em><em>string</em><em>, </em><em>optional</em>) – If <cite>G0=None</cite> the initial transport plan of the solver is <span class="math notranslate nohighlight">\(\mathbf{p} \frac{\mathbf{1}_{nt}}{nt}^\top\)</span>.
If G0 is a tensor it must satisfy marginal constraints and will be
used as initial transport of the solver.
if G0 is a string it will be interpreted as a method for
<a class="reference internal" href="#ot.gromov.semirelaxed_init_plan" title="ot.gromov.semirelaxed_init_plan"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.gromov.semirelaxed_init_plan()</span></code></a> taking values in “product”,
“random_product”, “random”, “fluid”, “fluid_soft”, “spectral”,
“spectral_soft”, “kmeans”, “kmeans_soft”.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error computed on transport plans</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>verbose</strong> – Print information along iterations</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed used in stochastic initialization methods.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>srgw</strong> (<em>float</em>) – Semi-relaxed Gromov-Wasserstein divergence</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – convergence information and Coupling matrix</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id34" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fgw_barycenters">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fgw_barycenters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ys</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_structure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'barycenter'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstartT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#fgw_barycenters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fgw_barycenters" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein barycenters of <cite>S</cite> measurable networks with node features <span class="math notranslate nohighlight">\((\mathbf{C}_s, \mathbf{Y}_s, \mathbf{p}_s)_{1 \leq s \leq S}\)</span>
(see eq (5) in <a class="reference internal" href="#references-fgw-barycenters"><span class="std std-ref">[24]</span></a>), estimated using Fused Gromov-Wasserstein transports from Conditional Gradient solvers.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^*, \mathbf{Y}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}, \mathbf{Y}\in \mathbb{Y}^{N \times d}} \quad \sum_s \lambda_s \mathrm{FGW}_{\alpha}(\mathbf{C}, \mathbf{C}_s, \mathbf{Y}, \mathbf{Y}_s, \mathbf{p}, \mathbf{p}_s)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}_s\)</span>: feature matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}_s\)</span>: metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}_s\)</span>: distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Desired number of samples of the target barycenter</p></li>
<li><p><strong>Ys</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>array-like</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Features of all samples</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>array-like</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Structure matrices of all samples</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>array-like</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Masses of all samples.
If let to its default value None, uniform distributions are taken.</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – List of the <cite>S</cite> spaces’ weights.
If let to its default value None, uniform weights are taken.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Alpha parameter for the fgw distance.</p></li>
<li><p><strong>fixed_structure</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to fix the structure of the barycenter during the updates.</p></li>
<li><p><strong>fixed_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to fix the feature of the barycenter during the updates</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Weights in the targeted barycenter.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research.
Else closed form is used. If there are convergence issues use False.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either structures are to be assumed symmetric or not. Default value is True.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>stop_criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'barycenter'.</em>) – Stop criterion taking values in [‘barycenter’, ‘loss’]. If set to ‘barycenter’
uses absolute norm variations of estimated barycenters. Else if set to ‘loss’
uses the relative variations of the loss.</p></li>
<li><p><strong>warmstartT</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of transport plans in the successive
fused gromov-wasserstein transport problems.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>N</em><em>)</em><em>, </em><em>optional</em>) – Initialization for the barycenters’ structure matrix. If not set
a random init is used.</p></li>
<li><p><strong>init_X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>d</em><em>)</em><em>, </em><em>optional</em>) – Initialization for the barycenters’ features. If not set a
random init is used.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X</strong> (array-like, shape (<cite>N</cite>, <cite>d</cite>)) – Barycenters’ features</p></li>
<li><p><strong>C</strong> (array-like, shape (<cite>N</cite>, <cite>N</cite>)) – Barycenters’ structure matrix</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Only returned when log=True. It contains the keys:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: list of (<cite>N</cite>, <cite>ns</cite>) transport matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: (<cite>N</cite>,) barycenter weights</p></li>
<li><p><span class="math notranslate nohighlight">\((\mathbf{M}_s)_s\)</span>: all distance matrices between the feature of the barycenter and the other features <span class="math notranslate nohighlight">\((dist(\mathbf{X}, \mathbf{Y}_s))_s\)</span> shape (<cite>N</cite>, <cite>ns</cite>)</p></li>
<li><p>values used in convergence evaluation.</p></li>
</ul>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-fgw-barycenters">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id35" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas
“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.format_partitioned_graph">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">format_partitioned_graph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">part</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rep_indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_quantized.html#format_partitioned_graph"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.format_partitioned_graph" title="Link to this definition"></a></dt>
<dd><p>Format an attributed graph <span class="math notranslate nohighlight">\((\mathbf{C}, \mathbf{F}, \mathbf{p})\)</span>
with structure matrix <span class="math notranslate nohighlight">\((\mathbf{C} \in R^{n \times n}\)</span>, feature matrix
<span class="math notranslate nohighlight">\((\mathbf{F} \in R^{n \times d}\)</span> and node relative importance
<span class="math notranslate nohighlight">\((\mathbf{p} \in \Sigma_n\)</span>, into a partitioned attributed graph
taking into account partitions and representants <span class="math notranslate nohighlight">\(\mathcal{P} = \left{(\mathbf{P_{i}}, \mathbf{r_{i}})\right}_i\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>, </em><em>n</em><em>)</em>) – Structure matrix.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>,</em><em>)</em><em>,</em>) – Node distribution.</p></li>
<li><p><strong>part</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>,</em><em>)</em>) – Array of partition assignment for each node.</p></li>
<li><p><strong>rep_indices</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>array-like</em><em> of </em><em>ints</em><em>, </em><em>shape</em><em> (</em><em>npart</em><em>,</em><em>)</em>) – indices for representative node of each partition sorted according to
partition identifiers.</p></li>
<li><p><strong>F</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em><em>, </em><em>optional.</em><em> (</em><em>Default is None</em><em>)</em>) – Optional feature matrix aligned with the graph structure.</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>, </em><em>n</em><em>)</em><em>, </em><em>optional.</em><em> (</em><em>Default is None</em><em>)</em>) – Optional pairwise similarity matrix between features.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional. Default is 1.</em>) – Trade-off parameter in <span class="math notranslate nohighlight">\(]0, 1]\)</span> between structure and features.
If <cite>alpha = 1</cite> features are ignored. This trade-off is taken into account
into the outputted relations between nodes and representants.</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – POT backend</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>CR</strong> (<em>array-like, shape (npart, npart)</em>) – Structure matrix between partition representants.</p></li>
<li><p><strong>list_R</strong> (<em>list of npart arrays,</em>) – List of relations between a representant and nodes in its partition,
for each partition.</p></li>
<li><p><strong>list_p</strong> (<em>list of npart arrays,</em>) – List of node distributions within each partition.</p></li>
<li><p><strong>FR</strong> (array-like, shape (npart, d), if <cite>F != None</cite>.) – Feature matrix of representants.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id36" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>68<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., Miller, D., &amp; Needham, T. (2021).
Quantized gromov-wasserstein. ECML PKDD 2021. Springer International Publishing.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.format_partitioned_samples">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">format_partitioned_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">part</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rep_indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_quantized.html#format_partitioned_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.format_partitioned_samples" title="Link to this definition"></a></dt>
<dd><p>Format an attributed graph <span class="math notranslate nohighlight">\((\mathbf{D}(\mathbf{X}), \mathbf{F}, \mathbf{p})\)</span>
with euclidean structure matrix <span class="math notranslate nohighlight">\((\mathbf{D}(\mathbf{X}) \in R^{n \times n}\)</span>,
feature matrix <span class="math notranslate nohighlight">\((\mathbf{F} \in R^{n \times d}\)</span> and node relative importance
<span class="math notranslate nohighlight">\((\mathbf{p} \in \Sigma_n\)</span>, into a partitioned attributed graph
taking into account partitions and representants <span class="math notranslate nohighlight">\(\mathcal{P} = \left{(\mathbf{P_{i}}, \mathbf{r_{i}})\right}_i\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em>) – Structure matrix.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>,</em><em>)</em><em>,</em>) – Node distribution.</p></li>
<li><p><strong>part</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>,</em><em>)</em>) – Array of partition assignment for each node.</p></li>
<li><p><strong>rep_indices</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>array-like</em><em> of </em><em>ints</em><em>, </em><em>shape</em><em> (</em><em>npart</em><em>,</em><em>)</em>) – indices for representative node of each partition sorted according to
partition identifiers.</p></li>
<li><p><strong>F</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>, </em><em>p</em><em>)</em><em>, </em><em>optional.</em><em> (</em><em>Default is None</em><em>)</em>) – Optional feature matrix aligned with the samples.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional. Default is 1.</em>) – Trade-off parameter in <span class="math notranslate nohighlight">\(]0, 1]\)</span> between structure and features.
If <cite>alpha = 1</cite> features are ignored. This trade-off is taken into account
into the outputted relations between nodes and representants.</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – POT backend</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>CR</strong> (<em>array-like, shape (npart, npart)</em>) – Structure matrix between partition representants.</p></li>
<li><p><strong>list_R</strong> (<em>list of npart arrays,</em>) – List of relations between a representant and nodes in its partition,
for each partition.</p></li>
<li><p><strong>list_p</strong> (<em>list of npart arrays,</em>) – List of node distributions within each partition.</p></li>
<li><p><strong>FR</strong> (array-like, shape (npart, d), if <cite>F != None</cite>.) – Feature matrix of representants.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id37" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>68<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., Miller, D., &amp; Needham, T. (2021).
Quantized gromov-wasserstein. ECML PKDD 2021. Springer International Publishing.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{Y_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{Y_2}, \mathbf{q})\)</span>
with pairwise distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices <span class="math notranslate nohighlight">\(\mathbf{Y_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y_2}\)</span> (see <a class="reference internal" href="#references-fused-gromov-wasserstein"><span class="std std-ref">[24]</span></a>).</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in\mathop{\arg\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity and feature matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: trade-off parameter</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conditional gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will cast the computed transport plan to the data
type of the provided input <span class="math notranslate nohighlight">\(\mathbf{M}\)</span>. Casting to an integer
tensor might result in a loss of precision. If this behaviour is
unwanted, please make sure to provide a floating point input.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research. Else closed form is used.
If there are convergence issues use False.</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>T</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) – Optimal transportation matrix for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-fused-gromov-wasserstein">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id38" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id39" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., &amp; Mémoli, F. (2019). The gromov–wasserstein
distance between networks and stable network invariants.
Information and Inference: A Journal of the IMA, 8(4), 757-787.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fused_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fused_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#fused_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fused_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein distance between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{Y_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{Y_2}, \mathbf{q})\)</span>
with pairwise distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices <span class="math notranslate nohighlight">\(\mathbf{Y_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Y_2}\)</span> (see <a class="reference internal" href="#references-fused-gromov-wasserstein"><span class="std std-ref">[24]</span></a>).</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{FGW} = \mathop{\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity and feature matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: trade-off parameter</p></li>
</ul>
<p>Note that when using backends, this loss function is differentiable wrt the
matrices (C1, C2, M) and weights (p, q) for quadratic loss using the gradients from <a href="#id115"><span class="problematic" id="id40">[38]_</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conditional gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will cast the computed transport plan to the data
type of the provided input <span class="math notranslate nohighlight">\(\mathbf{M}\)</span>. Casting to an integer
tensor might result in a loss of precision. If this behaviour is
unwanted, please make sure to provide a floating point input.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space.</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research.
Else closed form is used. If there are convergence issues use False.</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Parameters can be directly passed to the ot.optim.cg solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>fgw-distance</strong> (<em>float</em>) – Fused Gromov-Wasserstein distance for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-fused-gromov-wasserstein2">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id41" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas
“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id42" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online
Graph Dictionary Learning, International Conference on Machine Learning
(ICML), 2021.</p>
</aside>
<aside class="footnote brackets" id="id43" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., &amp; Mémoli, F. (2019). The gromov–wasserstein
distance between networks and stable network invariants.
Information and Inference: A Journal of the IMA, 8(4), 757-787.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fused_gromov_wasserstein_dictionary_learning">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fused_gromov_wasserstein_dictionary_learning</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ys</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate_C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate_Y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cdict_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ydict_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projection</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nonnegative_symmetric'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_adam_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_dictionary.html#fused_gromov_wasserstein_dictionary_learning"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fused_gromov_wasserstein_dictionary_learning" title="Link to this definition"></a></dt>
<dd><p>Infer Fused Gromov-Wasserstein linear dictionary <span class="math notranslate nohighlight">\(\{ (\mathbf{C_{dict}[d]}, \mathbf{Y_{dict}[d]}, \mathbf{q}) \}_{d \in [D]}\)</span>  from the list of S attributed structures <span class="math notranslate nohighlight">\(\{ (\mathbf{C_s}, \mathbf{Y_s},\mathbf{p_s}) \}_s\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}\min_{\mathbf{C_{dict}},\mathbf{Y_{dict}}, \{\mathbf{w_s}\}_{s}} \sum_{s=1}^S  FGW_{2,\alpha}(\mathbf{C_s}, \mathbf{Y_s}, \sum_{d=1}^D w_{s,d}\mathbf{C_{dict}[d]},\sum_{d=1}^D w_{s,d}\mathbf{Y_{dict}[d]}, \mathbf{p_s}, \mathbf{q}) \\ - reg\| \mathbf{w_s}  \|_2^2\end{split}\]</div>
<p>Such that <span class="math notranslate nohighlight">\(\forall s \leq S\)</span> :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_s}^\top \mathbf{1}_D = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_s} \geq \mathbf{0}_D\)</span></p></li>
</ul>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\forall s \leq S, \mathbf{C_s}\)</span> is a (ns,ns) pairwise similarity matrix of variable size ns.</p></li>
<li><p><span class="math notranslate nohighlight">\(\forall s \leq S, \mathbf{Y_s}\)</span> is a (ns,d) features matrix of variable size ns and fixed dimension d.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_{dict}}\)</span> is a (D, nt, nt) tensor of D pairwise similarity matrix of fixed size nt.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y_{dict}}\)</span> is a (D, nt, d) tensor of D features matrix of fixed size nt and fixed dimension d.</p></li>
<li><p><span class="math notranslate nohighlight">\(\forall s \leq S, \mathbf{p_s}\)</span> is the source distribution corresponding to <span class="math notranslate nohighlight">\(\mathbf{C_s}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span> is the target distribution assigned to every structures in the embedding space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span> is the trade-off parameter of Fused Gromov-Wasserstein</p></li>
<li><p>reg is the regularization coefficient.</p></li>
</ul>
<p>The stochastic algorithm used for estimating the attributed graph dictionary atoms as proposed in <a href="#id116"><span class="problematic" id="id44">[38]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S symmetric array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – List of Metric/Graph cost matrices of variable size (ns,ns).</p></li>
<li><p><strong>Ys</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>d</em><em>)</em>) – List of feature matrix of variable size (ns,d) with d fixed.</p></li>
<li><p><strong>D</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Number of dictionary atoms to learn</p></li>
<li><p><strong>nt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Number of samples within each dictionary atoms</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Trade-off parameter of Fused Gromov-Wasserstein</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Coefficient of the negative quadratic regularization used to promote sparsity of w. The default is 0.</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in each source space C of Cs. Default is None and corresponds to uniform distributions.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the embedding space whose structure will be learned. Default is None and corresponds to uniform distributions.</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of epochs used to learn the dictionary. Default is 32.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Batch size for each stochastic gradient update of the dictionary. Set to the dataset size if the provided batch_size is higher than the dataset size. Default is 32.</p></li>
<li><p><strong>learning_rate_C</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Learning rate used for the stochastic gradient descent on Cdict. Default is 1.</p></li>
<li><p><strong>learning_rate_Y</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Learning rate used for the stochastic gradient descent on Ydict. Default is 1.</p></li>
<li><p><strong>Cdict_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>D array-like with shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Used to initialize the dictionary structures Cdict.
If set to None (Default), the dictionary will be initialized randomly.
Else Cdict must have shape (D, nt, nt) i.e match provided shape features.</p></li>
<li><p><strong>Ydict_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>D array-like with shape</em><em> (</em><em>nt</em><em>, </em><em>d</em><em>)</em><em>, </em><em>optional</em>) – Used to initialize the dictionary features Ydict.
If set to None, the dictionary features will be initialized randomly.
Else Ydict must have shape (D, nt, d) where d is the features dimension of inputs Ys and also match provided shape features.</p></li>
<li><p><strong>projection</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – If ‘nonnegative’ and/or ‘symmetric’ is in projection, the corresponding projection will be performed at each stochastic update of the dictionary
Else the set of atoms is <span class="math notranslate nohighlight">\(R^{nt * nt}\)</span>. Default is ‘nonnegative_symmetric’</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to True, losses evolution by batches and epochs are tracked. Default is False.</p></li>
<li><p><strong>use_adam_optimizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to True, adam optimizer with default settings is used as adaptative learning rate strategy.
Else perform SGD with fixed learning rate. Default is True.</p></li>
<li><p><strong>tol_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the BCD algorithm, measured by absolute relative error on consecutive losses. Default is <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p></li>
<li><p><strong>tol_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the Conjugate Gradient algorithm used to get optimal w at a fixed transport, measured by absolute relative error on consecutive losses. Default is <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p></li>
<li><p><strong>max_iter_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the BCD. Default is 20.</p></li>
<li><p><strong>max_iter_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the Conjugate Gradient. Default is 200.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print the reconstruction loss every epoch. Default is False.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Determines random number generation. Pass an int for reproducible
output across multiple function calls.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>Cdict_best_state</strong> (<em>D array-like, shape (D,nt,nt)</em>) – Metric/Graph cost matrices composing the dictionary.
The dictionary leading to the best loss over an epoch is saved and returned.</p></li>
<li><p><strong>Ydict_best_state</strong> (<em>D array-like, shape (D,nt,d)</em>) – Feature matrices composing the dictionary.
The dictionary leading to the best loss over an epoch is saved and returned.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – If use_log is True, contains loss evolutions by batches and epochs.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id45" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online
Graph Dictionary Learning, International Conference on Machine Learning
(ICML), 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fused_gromov_wasserstein_linear_unmixing">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fused_gromov_wasserstein_linear_unmixing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cdict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ydict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_dictionary.html#fused_gromov_wasserstein_linear_unmixing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fused_gromov_wasserstein_linear_unmixing" title="Link to this definition"></a></dt>
<dd><p>Returns the Fused Gromov-Wasserstein linear unmixing of <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{Y},\mathbf{p})\)</span> onto the attributed dictionary atoms <span class="math notranslate nohighlight">\(\{ (\mathbf{C_{dict}[d]},\mathbf{Y_{dict}[d]}, \mathbf{q}) \}_{d \in [D]}\)</span></p>
<div class="math notranslate nohighlight">
\[\min_{\mathbf{w}}  FGW_{2,\alpha}(\mathbf{C},\mathbf{Y}, \sum_{d=1}^D w_d\mathbf{C_{dict}[d]},\sum_{d=1}^D w_d\mathbf{Y_{dict}[d]}, \mathbf{p}, \mathbf{q}) - reg \| \mathbf{w}  \|_2^2\]</div>
<p>such that, <span class="math notranslate nohighlight">\(\forall s \leq S\)</span> :</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_s}^\top \mathbf{1}_D = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_s} \geq \mathbf{0}_D\)</span></p></li>
</ul>
</div></blockquote>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}\)</span> is a (ns,ns) pairwise similarity matrix of variable size ns.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}\)</span> is a (ns,d) features matrix of variable size ns and fixed dimension d.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_{dict}}\)</span> is a (D, nt, nt) tensor of D pairwise similarity matrix of fixed size nt.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y_{dict}}\)</span> is a (D, nt, d) tensor of D features matrix of fixed size nt and fixed dimension d.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> is the source distribution corresponding to <span class="math notranslate nohighlight">\(\mathbf{C_s}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span> is the target distribution assigned to every structures in the embedding space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span> is the trade-off parameter of Fused Gromov-Wasserstein</p></li>
<li><p>reg is the regularization coefficient.</p></li>
</ul>
<p>The algorithm used for solving the problem is a Block Coordinate Descent as discussed in <a href="#id117"><span class="problematic" id="id46">[38]_</span></a>, algorithm 6.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric/Graph cost matrix.</p></li>
<li><p><strong>Y</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>d</em><em>)</em>) – Feature matrix.</p></li>
<li><p><strong>Cdict</strong> (<em>D array-like</em><em>, </em><em>shape</em><em> (</em><em>D</em><em>,</em><em>nt</em><em>,</em><em>nt</em><em>)</em>) – Metric/Graph cost matrices composing the dictionary on which to embed (C,Y).</p></li>
<li><p><strong>Ydict</strong> (<em>D array-like</em><em>, </em><em>shape</em><em> (</em><em>D</em><em>,</em><em>nt</em><em>,</em><em>d</em><em>)</em>) – Feature matrices composing the dictionary on which to embed (C,Y).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>,</em>) – Trade-off parameter of Fused Gromov-Wasserstein.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Coefficient of the negative quadratic regularization used to promote sparsity of w. The default is 0.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space C. Default is None and corresponds to uniform distribution.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the space depicted by the dictionary. Default is None and corresponds to uniform distribution.</p></li>
<li><p><strong>tol_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the BCD algorithm.</p></li>
<li><p><strong>tol_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the Conjugate Gradient algorithm used to get optimal w at a fixed transport. Default is <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p></li>
<li><p><strong>max_iter_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the BCD. Default is 20.</p></li>
<li><p><strong>max_iter_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the Conjugate Gradient. Default is 200.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>w</strong> (<em>array-like, shape (D,)</em>) – fused Gromov-Wasserstein linear unmixing of (C,Y,p) onto the span of the dictionary.</p></li>
<li><p><strong>Cembedded</strong> (<em>array-like, shape (nt,nt)</em>) – embedded structure of <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{Y}, \mathbf{p})\)</span> onto the dictionary, <span class="math notranslate nohighlight">\(\sum_d w_d\mathbf{C_{dict}[d]}\)</span>.</p></li>
<li><p><strong>Yembedded</strong> (<em>array-like, shape (nt,d)</em>) – embedded features of <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{Y}, \mathbf{p})\)</span> onto the dictionary, <span class="math notranslate nohighlight">\(\sum_d w_d\mathbf{Y_{dict}[d]}\)</span>.</p></li>
<li><p><strong>T</strong> (<em>array-like (ns,nt)</em>) – Fused Gromov-Wasserstein transport plan between <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\sum_d w_d\mathbf{C_{dict}[d]}, \sum_d w_d\mathbf{Y_{dict}[d]},\mathbf{q})\)</span>.</p></li>
<li><p><strong>current_loss</strong> (<em>float</em>) – reconstruction error</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id47" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online
Graph Dictionary Learning, International Conference on Machine Learning
(ICML), 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fused_unbalanced_across_spaces_cost">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fused_unbalanced_across_spaces_cost</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M_linear</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tuple_pxy_samp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tuple_pxy_feat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pi_samp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pi_feat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">divergence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#fused_unbalanced_across_spaces_cost"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fused_unbalanced_across_spaces_cost" title="Link to this definition"></a></dt>
<dd><p>Return the fused unbalanced across-space divergence between two spaces</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M_linear</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>arrays</em>) – Pair of cost matrices corresponding to the Wasserstein terms w.r.t sample and feature couplings</p></li>
<li><p><strong>data</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>arrays</em>) – Tuple of input spaces represented as matrices</p></li>
<li><p><strong>tuple_pxy_samp</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>arrays</em>) – Tuple of reference measures in the marginal-relaxation and regularization terms
w.r.t the sample coupling</p></li>
<li><p><strong>tuple_pxy_feat</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>arrays</em>) – Tuple of reference measures in the marginal-relaxation and regularization terms
w.r.t the feature coupling</p></li>
<li><p><strong>pi_samp</strong> (<em>array-like</em>) – Sample coupling</p></li>
<li><p><strong>pi_feat</strong> (<em>array-like</em>) – Feature coupling</p></li>
<li><p><strong>hyperparams</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>floats</em>) – Hyperparameters of marginal-relaxation and regularization terms
in the fused unbalanced across-domain divergence</p></li>
<li><p><strong>divergence</strong> (<em>string</em><em>, </em><em>default = &quot;kl&quot;</em>) – Bregman divergence, either “kl” (Kullback-Leibler divergence) or “l2” (half-squared L2 divergence)</p></li>
<li><p><strong>reg_type</strong> (<em>string</em><em>,</em>) – <p>Type of regularization term in the fused unbalanced across-domain divergence</p>
<ul>
<li><p><cite>reg_type = “joint”</cite> corresponds to FUGW</p></li>
<li><p><cite>reg_type = “independent”</cite> corresponds to UCOOT</p></li>
</ul>
</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Fused unbalanced across-space divergence between two spaces</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fused_unbalanced_across_spaces_divergence">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fused_unbalanced_across_spaces_divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wx_samp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wx_feat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wy_samp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wy_feat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_marginals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'joint'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">divergence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'kl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unbalanced_solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sinkhorn'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M_samp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M_feat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rescale_plan</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_pi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_duals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_ot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_ot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs_solver</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_unbalanced.html#fused_unbalanced_across_spaces_divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fused_unbalanced_across_spaces_divergence" title="Link to this definition"></a></dt>
<dd><p>Compute the fused unbalanced cross-spaces divergence between two matrices equipped
with the distributions on rows and columns. We consider two cases of matrix:</p>
<ul class="simple">
<li><p>(Squared) similarity matrix in Gromov-Wasserstein setting,</p></li>
</ul>
<p>whose rows and columns represent the samples.</p>
<ul class="simple">
<li><p>Arbitrary-size matrix in Co-Optimal Transport setting,</p></li>
</ul>
<p>whose rows represent samples, and columns represent corresponding features/dimensions.</p>
<p>More precisely, this function returns the sample and feature transport plans between
<span class="math notranslate nohighlight">\((\mathbf{X}, \mathbf{w}_{xs}, \mathbf{w}_{xf})\)</span> and
<span class="math notranslate nohighlight">\((\mathbf{Y}, \mathbf{w}_{ys}, \mathbf{w}_{yf})\)</span>,
by solving the following problem using Block Coordinate Descent algorithm:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathop{\arg \min}_{\mathbf{P}, \mathbf{Q}}
&amp;\quad \sum_{i,j,k,l}
(\mathbf{X}_{i,k} - \mathbf{Y}_{j,l})^2 \mathbf{P}_{i,j} \mathbf{Q}_{k,l} \\
&amp;+ \rho_s \mathbf{Div}(\mathbf{P}_{\# 1} \mathbf{Q}_{\# 1}^T | \mathbf{w}_{xs} \mathbf{w}_{ys}^T)
+ \rho_f \mathbf{Div}(\mathbf{P}_{\# 2} \mathbf{Q}_{\# 2}^T | \mathbf{w}_{xf} \mathbf{w}_{yf}^T) \\
&amp;+ \alpha_s \sum_{i,j} \mathbf{P}_{i,j} \mathbf{M^{(s)}}_{i, j}
+ \alpha_f \sum_{k, l} \mathbf{Q}_{k,l} \mathbf{M^{(f)}}_{k, l}
+ \mathbf{Reg}(\mathbf{P}, \mathbf{Q})\end{split}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{X}\)</span>: Source input (arbitrary-size) matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}\)</span>: Target input (arbitrary-size) matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M^{(s)}}\)</span>: Additional sample matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M^{(f)}}\)</span>: Additional feature matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}_{xs}\)</span>: Distribution of the samples in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}_{xf}\)</span>: Distribution of the features in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}_{ys}\)</span>: Distribution of the samples in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}_{yf}\)</span>: Distribution of the features in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Div}\)</span>: Either Kullback-Leibler divergence or half-squared L2 norm.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Reg}\)</span>: Regularizer for sample and feature couplings.</p></li>
</ul>
<dl>
<dt>We consider two types of regularizer:</dt><dd><ul class="simple">
<li><p>Independent regularization used in unbalanced Co-Optimal Transport</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{Reg}(\mathbf{P}, \mathbf{Q}) =
\varepsilon_s \mathbf{Div}(\mathbf{P} | \mathbf{w}_{xs} \mathbf{w}_{ys}^T)
+ \varepsilon_f \mathbf{Div}(\mathbf{Q} | \mathbf{w}_{xf} \mathbf{w}_{yf}^T)\]</div>
<ul class="simple">
<li><p>Joint regularization used in fused unbalanced Gromov-Wasserstein</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{Reg}(\mathbf{P}, \mathbf{Q}) =
\varepsilon \mathbf{Div}(\mathbf{P} \otimes \mathbf{Q} | (\mathbf{w}_{xs} \mathbf{w}_{ys}^T) \otimes (\mathbf{w}_{xf} \mathbf{w}_{yf}^T) )\]</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function allows epsilon to be zero. In that case, <cite>unbalanced_method</cite> must be either “mm” or “lbfgsb”.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>n_feature_x</em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Source input matrix.</p></li>
<li><p><strong>Y</strong> (<em>(</em><em>n_sample_y</em><em>, </em><em>n_feature_y</em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Target input matrix.</p></li>
<li><p><strong>wx_samp</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on rows (samples) of matrix X.
Uniform distribution by default.</p></li>
<li><p><strong>wx_feat</strong> (<em>(</em><em>n_feature_x</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on columns (features) of matrix X.
Uniform distribution by default.</p></li>
<li><p><strong>wy_samp</strong> (<em>(</em><em>n_sample_y</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on rows (samples) of matrix Y.
Uniform distribution by default.</p></li>
<li><p><strong>wy_feat</strong> (<em>(</em><em>n_feature_y</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on columns (features) of matrix Y.
Uniform distribution by default.</p></li>
<li><p><strong>reg_marginals</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><em>indexable object</em><em> of </em><em>length 1</em><em> or </em><em>2</em>) – Marginal relaxation terms for sample and feature couplings.
If <cite>reg_marginals</cite> is a scalar or an indexable object of length 1,
then the same value is applied to both marginal relaxations.</p></li>
<li><p><strong>epsilon</strong> (<em>scalar</em><em> or </em><em>indexable object</em><em> of </em><em>length 2</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 0</em><em>)</em>) – Regularization parameters for entropic approximation of sample and feature couplings.
Allow the case where <cite>epsilon</cite> contains 0. In that case, the MM solver is used by default
instead of Sinkhorn solver. If <cite>epsilon</cite> is scalar, then the same value is applied to
both regularization of sample and feature couplings.</p></li>
<li><p><strong>reg_type</strong> (<em>string</em><em>, </em><em>optional</em>) – <ul>
<li><p>If <cite>reg_type</cite> = “joint”: then use joint regularization for couplings.</p></li>
<li><p>If <cite>reg_type</cite> = “independent”: then use independent regularization for couplings.</p></li>
</ul>
</p></li>
<li><p><strong>divergence</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default = &quot;kl&quot;</em><em>)</em>) – <ul>
<li><p>If <cite>divergence</cite> = “kl”, then Div is the Kullback-Leibler divergence.</p></li>
<li><p>If <cite>divergence</cite> = “l2”, then Div is the half squared Euclidean norm.</p></li>
</ul>
</p></li>
<li><p><strong>unbalanced_solver</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default = &quot;sinkhorn&quot;</em><em>)</em>) – <p>Solver for the unbalanced OT subroutine.</p>
<ul>
<li><p>If <cite>divergence</cite> = “kl”, then <cite>unbalanced_solver</cite> can be: “sinkhorn”, “sinkhorn_log”, “mm”, “lbfgsb”</p></li>
<li><p>If <cite>divergence</cite> = “l2”, then <cite>unbalanced_solver</cite> can be “mm”, “lbfgsb”</p></li>
</ul>
</p></li>
<li><p><strong>alpha</strong> (<em>scalar</em><em> or </em><em>indexable object</em><em> of </em><em>length 2</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 0</em><em>)</em>) – Coeffficient parameter of linear terms with respect to the sample and feature couplings.
If alpha is scalar, then the same alpha is applied to both linear terms.</p></li>
<li><p><strong>M_samp</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>n_sample_y</em><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Sample matrix associated to the Wasserstein linear term on sample coupling.</p></li>
<li><p><strong>M_feat</strong> (<em>(</em><em>n_feature_x</em><em>, </em><em>n_feature_y</em><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Feature matrix associated to the Wasserstein linear term on feature coupling.</p></li>
<li><p><strong>rescale_plan</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default = True</em><em>)</em>) – If True, then rescale the sample and feature transport plans within each BCD iteration,
so that they always have equal mass.</p></li>
<li><p><strong>init_pi</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>two matrices</em><em> of </em><em>size</em><em> (</em><em>n_sample_x</em><em>, </em><em>n_sample_y</em><em>) </em><em>and</em>) – (n_feature_x, n_feature_y), optional (default = None).
Initialization of sample and feature couplings.
Uniform distributions by default.</p></li>
<li><p><strong>init_duals</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>two tuples</em><em> (</em><em>(</em><em>n_sample_x</em><em>, </em><em>)</em><em>, </em><em>(</em><em>n_sample_y</em><em>, </em><em>)</em><em>) </em><em>and</em><em> (</em><em>(</em><em>n_feature_x</em><em>, </em><em>)</em><em>, </em><em>(</em><em>n_feature_y</em><em>, </em><em>)</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em><em>.</em>) – Initialization of sample and feature dual vectors
if using Sinkhorn algorithm. Zero vectors by default.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 100</em><em>)</em>) – Number of Block Coordinate Descent (BCD) iterations.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = 1e-7</em><em>)</em>) – Tolerance of BCD scheme. If the L1-norm between the current and previous
sample couplings is under this threshold, then stop BCD scheme.</p></li>
<li><p><strong>max_iter_ot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 100</em><em>)</em>) – Number of iterations to solve each of the
two unbalanced optimal transport problems in each BCD iteration.</p></li>
<li><p><strong>tol_ot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = 1e-7</em><em>)</em>) – Tolerance of unbalanced solver for each of the
two unbalanced optimal transport problems in each BCD iteration.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default = False</em><em>)</em>) – If True then the cost and four dual vectors, including
two from sample and two from feature couplings, are recorded.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default = False</em><em>)</em>) – If True then print the COOT cost at every multiplier of <cite>eval_bcd</cite>-th iteration.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><p><strong>pi_samp</strong> (<em>(n_sample_x, n_sample_y) array-like, float</em>) – Sample coupling matrix.</p></li>
<li><p><strong>pi_feat</strong> (<em>(n_feature_x, n_feature_y) array-like, float</em>) – Feature coupling matrix.</p></li>
<li><p><strong>log</strong> (<em>dictionary, optional</em>) –</p>
<p>Returned if <cite>log</cite> is True. The keys are:</p>
<blockquote>
<div><dl class="simple">
<dt>error<span class="classifier">array-like, float</span></dt><dd><p>list of L1 norms between the current and previous sample coupling.</p>
</dd>
<dt>duals_sample<span class="classifier">(n_sample_x, n_sample_y) tuple, float</span></dt><dd><p>Pair of dual vectors when solving OT problem w.r.t the sample coupling.</p>
</dd>
<dt>duals_feature<span class="classifier">(n_feature_x, n_feature_y) tuple, float</span></dt><dd><p>Pair of dual vectors when solving OT problem w.r.t the feature coupling.</p>
</dd>
<dt>linear<span class="classifier">float</span></dt><dd><p>Linear part of the cost.</p>
</dd>
<dt>ucoot<span class="classifier">float</span></dt><dd><p>Total cost.</p>
</dd>
<dt>backend</dt><dd><p>The proper backend for all input arrays</p>
</dd>
</dl>
</div></blockquote>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fused_unbalanced_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fused_unbalanced_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Cx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_marginals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">divergence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'kl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unbalanced_solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_duals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_pi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_ot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_ot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs_solve</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_unbalanced.html#fused_unbalanced_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fused_unbalanced_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Compute the lower bound of the fused unbalanced Gromov-Wasserstein (FUGW) between two similarity matrices.
In practice, this lower bound is used interchangeably with the true FUGW.</p>
<p>More precisely, this function returns the transport plan between
<span class="math notranslate nohighlight">\((\mathbf{C^X}, \mathbf{w_X})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C^Y}, \mathbf{w_Y})\)</span>,
by solving the following problem using Block Coordinate Descent algorithm:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathop{\arg \min}_{\substack{\mathbf{P}, \mathbf{Q}: \\ mass(P) = mass(Q)}}
&amp;\quad \sum_{i,j,k,l} (\mathbf{C^X}_{i,k} - \mathbf{C^Y}_{j,l})^2 \mathbf{P}_{i,j} \mathbf{Q}_{k,l}
+ \frac{\alpha}{2} \sum_{i,j} (\mathbf{P}_{i,j} + \mathbf{Q}_{i,j}) \mathbf{M}_{i, j} \\
&amp;+ \rho_1 \mathbf{Div}(\mathbf{P}_{\# 1} \mathbf{Q}_{\# 1}^T | \mathbf{w_X} \mathbf{w_X}^T)
+ \rho_2 \mathbf{Div}(\mathbf{P}_{\# 2} \mathbf{Q}_{\# 2}^T | \mathbf{w_Y} \mathbf{w_Y}^T) \\
&amp;+ \varepsilon \mathbf{Div}(\mathbf{P} \otimes \mathbf{Q} | (\mathbf{w_X} \mathbf{w_Y}^T) \otimes (\mathbf{w_X} \mathbf{w_Y}^T))\end{split}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C^X}\)</span>: Source similarity matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C^Y}\)</span>: Target similarity matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: Sample matrix corresponding to the Wasserstein term</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_X}\)</span>: Distribution of the samples in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_Y}\)</span>: Distribution of the samples in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Div}\)</span>: Either Kullback-Leibler divergence or half-squared L2 norm.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function allows epsilon to be zero. In that case, <cite>unbalanced_method</cite> must be either “mm” or “lbfgsb”.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Cx</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>n_feature_x</em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Source similarity matrix.</p></li>
<li><p><strong>Cy</strong> (<em>(</em><em>n_sample_y</em><em>, </em><em>n_feature_y</em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Target similarity matrix.</p></li>
<li><p><strong>wx</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on rows (samples) of matrix Cx.
Uniform distribution by default.</p></li>
<li><p><strong>wy</strong> (<em>(</em><em>n_sample_y</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on rows (samples) of matrix Cy.
Uniform distribution by default.</p></li>
<li><p><strong>reg_marginals</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><em>indexable object</em><em> of </em><em>length 1</em><em> or </em><em>2</em>) – Marginal relaxation terms for sample and feature couplings.
If <cite>reg_marginals</cite> is a scalar or an indexable object of length 1,
then the same value is applied to both marginal relaxations.</p></li>
<li><p><strong>epsilon</strong> (<em>scalar</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 0</em><em>)</em>) – Regularization parameters for entropic approximation of sample and feature couplings.
Allow the case where <cite>epsilon</cite> contains 0. In that case, the MM solver is used by default
instead of Sinkhorn solver. If <cite>epsilon</cite> is scalar, then the same value is applied to
both regularization of sample and feature couplings.</p></li>
<li><p><strong>divergence</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default = &quot;kl&quot;</em><em>)</em>) – <ul>
<li><p>If <cite>divergence</cite> = “kl”, then Div is the Kullback-Leibler divergence.</p></li>
<li><p>If <cite>divergence</cite> = “l2”, then Div is the half squared Euclidean norm.</p></li>
</ul>
</p></li>
<li><p><strong>unbalanced_solver</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default = &quot;sinkhorn&quot;</em><em>)</em>) – <p>Solver for the unbalanced OT subroutine.</p>
<ul>
<li><p>If <cite>divergence</cite> = “kl”, then <cite>unbalanced_solver</cite> can be: “sinkhorn”, “sinkhorn_log”, “mm”, “lbfgsb”</p></li>
<li><p>If <cite>divergence</cite> = “l2”, then <cite>unbalanced_solver</cite> can be “mm”, “lbfgsb”</p></li>
</ul>
</p></li>
<li><p><strong>alpha</strong> (<em>scalar</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 0</em><em>)</em>) – Coeffficient parameter of linear terms with respect to the sample and feature couplings.
If alpha is scalar, then the same alpha is applied to both linear terms.</p></li>
<li><p><strong>M</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>n_sample_y</em><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Sample matrix associated to the Wasserstein linear term on sample coupling.</p></li>
<li><p><strong>init_pi</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>n_sample_y</em><em>) </em><em>array-like</em><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Initialization of sample coupling. By default = <span class="math notranslate nohighlight">\(w_X w_Y^T\)</span>.</p></li>
<li><p><strong>init_duals</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>vectors</em><em> (</em><em>(</em><em>n_sample_x</em><em>, </em><em>)</em><em>, </em><em>(</em><em>n_sample_y</em><em>, </em><em>)</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em><em>.</em>) – Initialization of sample and feature dual vectors
if using Sinkhorn algorithm. Zero vectors by default.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 100</em><em>)</em>) – Number of Block Coordinate Descent (BCD) iterations.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = 1e-7</em><em>)</em>) – Tolerance of BCD scheme. If the L1-norm between the current and previous
sample couplings is under this threshold, then stop BCD scheme.</p></li>
<li><p><strong>max_iter_ot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 100</em><em>)</em>) – Number of iterations to solve each of the
two unbalanced optimal transport problems in each BCD iteration.</p></li>
<li><p><strong>tol_ot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = 1e-7</em><em>)</em>) – Tolerance of unbalanced solver for each of the
two unbalanced optimal transport problems in each BCD iteration.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default = False</em><em>)</em>) – If True then the cost and four dual vectors, including
two from sample and two from feature couplings, are recorded.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default = False</em><em>)</em>) – If True then print the COOT cost at every multiplier of <cite>eval_bcd</cite>-th iteration.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><p><strong>pi_samp</strong> (<em>(n_sample_x, n_sample_y) array-like, float</em>) – Sample coupling matrix.
In practice, we use this matrix as solution of FUGW.</p></li>
<li><p><strong>pi_samp2</strong> (<em>(n_sample_x, n_sample_y) array-like, float</em>) – Second sample coupling matrix.
In practice, we usually ignore this output.</p></li>
<li><p><strong>log</strong> (<em>dictionary, optional</em>) –</p>
<p>Returned if <cite>log</cite> is True. The keys are:</p>
<blockquote>
<div><dl class="simple">
<dt>error<span class="classifier">array-like, float</span></dt><dd><p>list of L1 norms between the current and previous sample couplings.</p>
</dd>
<dt>duals<span class="classifier">(n_sample_x, n_sample_y)-tuple, float</span></dt><dd><p>Pair of dual vectors when solving OT problem w.r.t the sample coupling.</p>
</dd>
<dt>linear<span class="classifier">float</span></dt><dd><p>Linear part of FUGW cost.</p>
</dd>
<dt>fugw_cost<span class="classifier">float</span></dt><dd><p>Total FUGW cost.</p>
</dd>
<dt>backend</dt><dd><p>The proper backend for all input arrays</p>
</dd>
</dl>
</div></blockquote>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id48" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>70<span class="fn-bracket">]</span></span>
<p>Thual, A., Tran, H., Zemskova, T., Courty, N., Flamary, R., Dehaene, S., &amp; Thirion, B.
Aligning individual brains with Fused Unbalanced Gromov-Wasserstein.
Advances in Neural Information Systems, 35 (2022).</p>
</aside>
<aside class="footnote brackets" id="id49" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>72<span class="fn-bracket">]</span></span>
<p>Thibault Séjourné, François-Xavier Vialard, &amp; Gabriel Peyré.
The Unbalanced Gromov Wasserstein Distance: Conic Formulation and Relaxation.
Neural Information Processing Systems, 34 (2021).</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.fused_unbalanced_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">fused_unbalanced_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Cx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_marginals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">divergence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'kl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unbalanced_solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_duals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_pi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_ot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_ot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs_solve</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_unbalanced.html#fused_unbalanced_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.fused_unbalanced_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Compute the lower bound of the fused unbalanced Gromov-Wasserstein (FUGW) between two similarity matrices.
In practice, this lower bound is used interchangeably with the true FUGW.</p>
<p>More precisely, this function returns the lower bound of the fused unbalanced Gromov-Wasserstein cost between
<span class="math notranslate nohighlight">\((\mathbf{C^X}, \mathbf{w_X})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C^Y}, \mathbf{w_Y})\)</span>,
by solving the following problem using Block Coordinate Descent algorithm:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathop{\min}_{\substack{\mathbf{P}, \mathbf{Q}: \\ mass(P) = mass(Q)}}
&amp;\quad \sum_{i,j,k,l} (\mathbf{C^X}_{i,k} - \mathbf{C^Y}_{j,l})^2 \mathbf{P}_{i,j} \mathbf{Q}_{k,l}
+ \frac{\alpha}{2} \sum_{i,j} (\mathbf{P}_{i,j} + \mathbf{Q}_{i,j}) \mathbf{M}_{i, j} \\
&amp;+ \rho_1 \mathbf{Div}(\mathbf{P}_{\# 1} \mathbf{Q}_{\# 1}^T | \mathbf{w_X} \mathbf{w_X}^T)
+ \rho_2 \mathbf{Div}(\mathbf{P}_{\# 2} \mathbf{Q}_{\# 2}^T | \mathbf{w_Y} \mathbf{w_Y}^T) \\
&amp;+ \varepsilon \mathbf{Div}(\mathbf{P} \otimes \mathbf{Q} | (\mathbf{w_X} \mathbf{w_Y}^T) \otimes (\mathbf{w_X} \mathbf{w_Y}^T))\end{split}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C^X}\)</span>: Source similarity matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C^Y}\)</span>: Target similarity matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: Sample matrix corresponding to the Wasserstein term</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_X}\)</span>: Distribution of the samples in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_Y}\)</span>: Distribution of the samples in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Div}\)</span>: Either Kullback-Leibler divergence or half-squared L2 norm.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function allows <cite>epsilon</cite> to be zero. In that case, unbalanced_method must be either “mm” or “lbfgsb”.
Also the computation of gradients is only supported for KL divergence, but not for half squared-L2 norm. In case of half squared-L2 norm, the calculation of KL divergence will be used.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Cx</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>n_feature_x</em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Source similarity matrix.</p></li>
<li><p><strong>Cy</strong> (<em>(</em><em>n_sample_y</em><em>, </em><em>n_feature_y</em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Target similarity matrix.</p></li>
<li><p><strong>wx</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on rows (samples) of matrix Cx.
Uniform distribution by default.</p></li>
<li><p><strong>wy</strong> (<em>(</em><em>n_sample_y</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on rows (samples) of matrix Cy.
Uniform distribution by default.</p></li>
<li><p><strong>reg_marginals</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><em>indexable object</em><em> of </em><em>length 1</em><em> or </em><em>2</em>) – Marginal relaxation terms for sample and feature couplings.
If <cite>reg_marginals</cite> is a scalar or an indexable object of length 1,
then the same value is applied to both marginal relaxations.</p></li>
<li><p><strong>epsilon</strong> (<em>scalar</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 0</em><em>)</em>) – Regularization parameters for entropic approximation of sample and feature couplings.
Allow the case where <cite>epsilon</cite> contains 0. In that case, the MM solver is used by default
instead of Sinkhorn solver. If <cite>epsilon</cite> is scalar, then the same value is applied to
both regularization of sample and feature couplings.</p></li>
<li><p><strong>divergence</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default = &quot;kl&quot;</em><em>)</em>) – <ul>
<li><p>If <cite>divergence</cite> = “kl”, then Div is the Kullback-Leibler divergence.</p></li>
<li><p>If <cite>divergence</cite> = “l2”, then Div is the half squared Euclidean norm.</p></li>
</ul>
</p></li>
<li><p><strong>unbalanced_solver</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default = &quot;sinkhorn&quot;</em><em>)</em>) – <p>Solver for the unbalanced OT subroutine.</p>
<ul>
<li><p>If <cite>divergence</cite> = “kl”, then <cite>unbalanced_solver</cite> can be: “sinkhorn”, “sinkhorn_log”, “mm”, “lbfgsb”</p></li>
<li><p>If <cite>divergence</cite> = “l2”, then <cite>unbalanced_solver</cite> can be “mm”, “lbfgsb”</p></li>
</ul>
</p></li>
<li><p><strong>alpha</strong> (<em>scalar</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 0</em><em>)</em>) – Coeffficient parameter of linear terms with respect to the sample and feature couplings.
If alpha is scalar, then the same alpha is applied to both linear terms.</p></li>
<li><p><strong>M</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>n_sample_y</em><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Sample matrix associated to the Wasserstein linear term on sample coupling.</p></li>
<li><p><strong>init_pi</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>n_sample_y</em><em>) </em><em>array-like</em><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Initialization of sample coupling. By default = <span class="math notranslate nohighlight">\(w_X w_Y^T\)</span>.</p></li>
<li><p><strong>init_duals</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>vectors</em><em> (</em><em>(</em><em>n_sample_x</em><em>, </em><em>)</em><em>, </em><em>(</em><em>n_sample_y</em><em>, </em><em>)</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em><em>.</em>) – Initialization of sample and feature dual vectors
if using Sinkhorn algorithm. Zero vectors by default.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 100</em><em>)</em>) – Number of Block Coordinate Descent (BCD) iterations.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = 1e-7</em><em>)</em>) – Tolerance of BCD scheme. If the L1-norm between the current and previous
sample couplings is under this threshold, then stop BCD scheme.</p></li>
<li><p><strong>max_iter_ot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 100</em><em>)</em>) – Number of iterations to solve each of the
two unbalanced optimal transport problems in each BCD iteration.</p></li>
<li><p><strong>tol_ot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = 1e-7</em><em>)</em>) – Tolerance of unbalanced solver for each of the
two unbalanced optimal transport problems in each BCD iteration.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default = False</em><em>)</em>) – If True then the cost and four dual vectors, including
two from sample and two from feature couplings, are recorded.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default = False</em><em>)</em>) – If True then print the COOT cost at every multiplier of <cite>eval_bcd</cite>-th iteration.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><p><strong>fugw</strong> (<em>float</em>) – Total FUGW cost</p></li>
<li><p><strong>log</strong> (<em>dictionary, optional</em>) –</p>
<p>Returned if <cite>log</cite> is True. The keys are:</p>
<blockquote>
<div><dl class="simple">
<dt>error<span class="classifier">array-like, float</span></dt><dd><p>list of L1 norms between the current and previous sample couplings.</p>
</dd>
<dt>duals<span class="classifier">(n_sample_x, n_sample_y)-tuple, float</span></dt><dd><p>Pair of dual vectors when solving OT problem w.r.t the sample coupling.</p>
</dd>
<dt>linear<span class="classifier">float</span></dt><dd><p>Linear part of FUGW cost.</p>
</dd>
<dt>fugw_cost<span class="classifier">float</span></dt><dd><p>Total FUGW cost.</p>
</dd>
<dt>backend</dt><dd><p>The proper backend for all input arrays</p>
</dd>
</dl>
</div></blockquote>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id50" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>70<span class="fn-bracket">]</span></span>
<p>Thual, A., Tran, H., Zemskova, T., Courty, N., Flamary, R., Dehaene, S., &amp; Thirion, B.
Aligning individual brains with Fused Unbalanced Gromov-Wasserstein.
Advances in Neural Information Systems, 35 (2022).</p>
</aside>
<aside class="footnote brackets" id="id51" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>72<span class="fn-bracket">]</span></span>
<p>Thibault Séjourné, François-Xavier Vialard, &amp; Gabriel Peyré.
The Unbalanced Gromov Wasserstein Distance: Conic Formulation and Relaxation.
Neural Information Processing Systems, 34 (2021).</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.get_graph_partition">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">get_graph_partition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">npart</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">part_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'random'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_quantized.html#get_graph_partition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.get_graph_partition" title="Link to this definition"></a></dt>
<dd><p>Partitioning a given graph with structure matrix <span class="math notranslate nohighlight">\(\mathbf{C} \in R^{n \times n}\)</span>
into <cite>npart</cite> partitions either ‘random’, or using one of {‘louvain’, ‘fluid’}
algorithms from networkx, or ‘spectral’ clustering from scikit-learn,
or (Fused) Gromov-Wasserstein projections from POT.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>, </em><em>n</em><em>)</em>) – Structure matrix.</p></li>
<li><p><strong>npart</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>,</em>) – number of partitions/clusters smaller than the number of nodes in
<span class="math notranslate nohighlight">\(\mathbf{C}\)</span>.</p></li>
<li><p><strong>part_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'random'.</em>) – Partitioning algorithm to use among {‘random’, ‘louvain’, ‘fluid’, ‘spectral’, ‘GW’, ‘FGW’}.
‘random’ for random sampling of points; ‘louvain’ and ‘fluid’ for graph
partitioning algorithm that works well on adjacency matrix, If the
louvain algorithm is used, <cite>npart</cite> is ignored; ‘spectral’ for spectral
clustering; ‘(F)GW’ for (F)GW projection using sr(F)GW solvers.</p></li>
<li><p><strong>F</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em><em>, </em><em>optional.</em><em> (</em><em>Default is None</em><em>)</em>) – Optional feature matrix aligned with the graph structure. Only used if
<cite>part_method=”FGW”</cite>.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional.</em><em> (</em><em>Default is 1.</em><em>)</em>) – Trade-off parameter between feature and structure matrices, taking
values in [0, 1] and only used if <cite>F != None</cite> and <cite>part_method=”FGW”</cite>.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed for the partitioning algorithm.</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – POT backend.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>part</strong> – Array of partition assignment for each node.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (npart,)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id52" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>68<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., Miller, D., &amp; Needham, T. (2021).
Quantized gromov-wasserstein. ECML PKDD 2021. Springer International Publishing.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.get_graph_representants">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">get_graph_representants</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">part</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rep_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'pagerank'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_quantized.html#get_graph_representants"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.get_graph_representants" title="Link to this definition"></a></dt>
<dd><p>Get representative node for each partition given by <span class="math notranslate nohighlight">\(\mathbf{part} \in R^{n}\)</span>
of a graph with structure matrix <span class="math notranslate nohighlight">\(\mathbf{C} \in R^{n \times n}\)</span>.
Selection is either done randomly or using ‘pagerank’ algorithm from networkx.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>, </em><em>n</em><em>)</em>) – structure matrix.</p></li>
<li><p><strong>part</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>,</em><em>)</em>) – Array of partition assignment for each node.</p></li>
<li><p><strong>rep_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'pagerank'.</em>) – Selection method for representant in each partition. Can be either ‘random’
i.e random sampling within each partition, or ‘pagerank’ to select a
node with maximal pagerank.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed for the partitioning algorithm</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – POT backend</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>rep_indices</strong> – indices for representative node of each partition sorted
according to partition identifiers.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>, shape (npart,)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id53" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>68<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., Miller, D., &amp; Needham, T. (2021).
Quantized gromov-wasserstein. ECML PKDD 2021. Springer International Publishing.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.get_partition_and_representants_samples">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">get_partition_and_representants_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">npart</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'kmeans'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_quantized.html#get_partition_and_representants_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.get_partition_and_representants_samples" title="Link to this definition"></a></dt>
<dd><p>Compute <cite>npart</cite> partitions and representants over samples <span class="math notranslate nohighlight">\(\mathbf{X} \in R^{n \times d}\)</span>
using either a random or a kmeans algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em>) – Samples endowed with an euclidean geometry.</p></li>
<li><p><strong>npart</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>,</em>) – number of partitions smaller than the number of samples in
<span class="math notranslate nohighlight">\(\mathbf{X}\)</span>.</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'kmeans'.</em>) – Partitioning and representant selection algorithms to use among
{‘random’, ‘kmeans’}. ‘random’ for random sampling of points; ‘kmeans’
for k-means clustering using scikit-learn implementation where closest
points to centroids are considered as representants.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed for the partitioning algorithm.</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – POT backend.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>part</strong> (<em>array-like, shape (npart,)</em>) – Array of partition assignment for each node.</p></li>
<li><p><strong>rep_indices</strong> (<em>list, shape (npart,)</em>) – indices for representative node of each partition sorted
according to partition identifiers.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id54" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>68<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., Miller, D., &amp; Needham, T. (2021).
Quantized gromov-wasserstein. ECML PKDD 2021. Springer International Publishing.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gromov_barycenters">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gromov_barycenters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'barycenter'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstartT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#gromov_barycenters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gromov_barycenters" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein barycenters of <cite>S</cite> measured similarity matrices <span class="math notranslate nohighlight">\((\mathbf{C}_s)_{1 \leq s \leq S}\)</span></p>
<p>The function solves the following optimization problem with block coordinate descent:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}} \quad \sum_s \lambda_s \mathrm{GW}(\mathbf{C}, \mathbf{C}_s, \mathbf{p}, \mathbf{p}_s)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}_s\)</span>: metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}_s\)</span>: distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size of the targeted barycenter</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrices</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Sample weights in the <cite>S</cite> spaces.
If let to its default value None, uniform distributions are taken.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Weights in the targeted barycenter.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – List of the <cite>S</cite> spaces’ weights.
If let to its default value None, uniform weights are taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>callable</em><em>, </em><em>optional</em>) – tensor-matrix multiplication function based on specific loss function</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional.</em>) – Either structures are to be assumed symmetric or not. Default value is True.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research.
Else closed form is used. If there are convergence issues use False.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>stop_criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'barycenter'.</em>) – Stop criterion taking values in [‘barycenter’, ‘loss’]. If set to ‘barycenter’
uses absolute norm variations of estimated barycenters. Else if set to ‘loss’
uses the relative variations of the loss.</p></li>
<li><p><strong>warmstartT</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of transport plans in the successive
fused gromov-wasserstein transport problems.s</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em> | </em><em>array-like</em><em>, </em><em>shape</em><em>(</em><em>N</em><em>,</em><em>N</em><em>)</em>) – Random initial value for the <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix provided by user.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>C</strong> (array-like, shape (<cite>N</cite>, <cite>N</cite>)) – Similarity matrix in the barycenter space (permutated arbitrarily)</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Only returned when log=True. It contains the keys:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: list of (<cite>N</cite>, <cite>ns</cite>) transport matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: (<cite>N</cite>,) barycenter weights</p></li>
<li><p>values used in convergence evaluation.</p></li>
</ul>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id55" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>.</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_\mathbf{T} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: Distribution in the source space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: Distribution in the target space.</p></li>
<li><p><cite>L</cite>: Loss function to account for the misfit between the similarity matrices.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conditional gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will cast the computed transport plan to the data
type of the provided input <span class="math notranslate nohighlight">\(\mathbf{C}_1\)</span>. Casting to an integer
tensor might result in a loss of precision. If this behaviour is
unwanted, please make sure to provide a floating point input.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space.</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, the step of the line-search is found via an armijo search. Else closed form is used.
If there are convergence issues, use False.</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None, the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations.</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0).</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0).</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Parameters can be directly passed to the ot.optim.cg solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><p><strong>T</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) –</p>
<p>Coupling between the two spaces that minimizes:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\)</span></p>
</div></blockquote>
</li>
<li><p><strong>log</strong> (<em>dict</em>) – Convergence information and loss.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id56" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id57" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></span>
<p>Mémoli, Facundo. Gromov–Wasserstein distances and the
metric approach to object matching. Foundations of computational
mathematics 11.4 (2011): 417-487.</p>
</aside>
<aside class="footnote brackets" id="id58" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., &amp; Mémoli, F. (2019). The gromov–wasserstein
distance between networks and stable network invariants.
Information and Inference: A Journal of the IMA, 8(4), 757-787.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein loss <span class="math notranslate nohighlight">\(\mathbf{GW}\)</span> between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>.
To recover the Gromov-Wasserstein distance as defined in [13] compute <span class="math notranslate nohighlight">\(d_{GW} = \frac{1}{2} \sqrt{\mathbf{GW}}\)</span>.</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{GW} = \min_\mathbf{T} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity
matrices</p></li>
</ul>
<p>Note that when using backends, this loss function is differentiable wrt the
matrices (C1, C2) and weights (p, q) for quadratic loss using the gradients from <a href="#id118"><span class="problematic" id="id59">[38]_</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conditional gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will cast the computed transport plan to the data
type of the provided input <span class="math notranslate nohighlight">\(\mathbf{C}_1\)</span>. Casting to an integer
tensor might result in a loss of precision. If this behaviour is
unwanted, please make sure to provide a floating point input.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research. Else closed form is used.
If there are convergence issues use False.</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – If None the initial transport plan of the solver is pq^T.
Otherwise G0 must satisfy marginal constraints and will be used as initial transport of the solver.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gw_dist</strong> (<em>float</em>) – Gromov-Wasserstein distance</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – convergence information and Coupling matrix</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id60" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id61" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></span>
<p>Mémoli, Facundo. Gromov–Wasserstein distances and the
metric approach to object matching. Foundations of computational
mathematics 11.4 (2011): 417-487.</p>
</aside>
<aside class="footnote brackets" id="id62" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online
Graph Dictionary Learning, International Conference on Machine Learning
(ICML), 2021.</p>
</aside>
<aside class="footnote brackets" id="id63" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., &amp; Mémoli, F. (2019). The gromov–wasserstein
distance between networks and stable network invariants.
Information and Inference: A Journal of the IMA, 8(4), 757-787.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gromov_wasserstein_dictionary_learning">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gromov_wasserstein_dictionary_learning</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">D</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cdict_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projection</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nonnegative_symmetric'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_adam_optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_dictionary.html#gromov_wasserstein_dictionary_learning"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gromov_wasserstein_dictionary_learning" title="Link to this definition"></a></dt>
<dd><p>Infer Gromov-Wasserstein linear dictionary <span class="math notranslate nohighlight">\(\{ (\mathbf{C_{dict}[d]}, q) \}_{d \in [D]}\)</span>  from the list of structures <span class="math notranslate nohighlight">\(\{ (\mathbf{C_s},\mathbf{p_s}) \}_s\)</span></p>
<div class="math notranslate nohighlight">
\[\min_{\mathbf{C_{dict}}, \{\mathbf{w_s} \}_{s \leq S}} \sum_{s=1}^S  GW_2(\mathbf{C_s}, \sum_{d=1}^D w_{s,d}\mathbf{C_{dict}[d]}, \mathbf{p_s}, \mathbf{q}) - reg\| \mathbf{w_s}  \|_2^2\]</div>
<p>such that, <span class="math notranslate nohighlight">\(\forall s \leq S\)</span> :</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_s}^\top \mathbf{1}_D = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_s} \geq \mathbf{0}_D\)</span></p></li>
</ul>
</div></blockquote>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\forall s \leq S, \mathbf{C_s}\)</span> is a (ns,ns) pairwise similarity matrix of variable size ns.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_{dict}}\)</span> is a (D, nt, nt) tensor of D pairwise similarity matrix of fixed size nt.</p></li>
<li><p><span class="math notranslate nohighlight">\(\forall s \leq S, \mathbf{p_s}\)</span> is the source distribution corresponding to <span class="math notranslate nohighlight">\(\mathbf{C_s}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span> is the target distribution assigned to every structures in the embedding space.</p></li>
<li><p>reg is the regularization coefficient.</p></li>
</ul>
<p>The stochastic algorithm used for estimating the graph dictionary atoms as proposed in <a href="#id119"><span class="problematic" id="id64">[38]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S symmetric array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – List of Metric/Graph cost matrices of variable size (ns, ns).</p></li>
<li><p><strong>D</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Number of dictionary atoms to learn</p></li>
<li><p><strong>nt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Number of samples within each dictionary atoms</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Coefficient of the negative quadratic regularization used to promote sparsity of w. The default is 0.</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in each source space C of Cs. Default is None and corresponds to uniform distributions.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the embedding space whose structure will be learned. Default is None and corresponds to uniform distributions.</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of epochs used to learn the dictionary. Default is 32.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Batch size for each stochastic gradient update of the dictionary. Set to the dataset size if the provided batch_size is higher than the dataset size. Default is 32.</p></li>
<li><p><strong>learning_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Learning rate used for the stochastic gradient descent. Default is 1.</p></li>
<li><p><strong>Cdict_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>D array-like with shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Used to initialize the dictionary.
If set to None (Default), the dictionary will be initialized randomly.
Else Cdict must have shape (D, nt, nt) i.e match provided shape features.</p></li>
<li><p><strong>projection</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em> , </em><em>optional</em>) – If ‘nonnegative’ and/or ‘symmetric’ is in projection, the corresponding projection will be performed at each stochastic update of the dictionary
Else the set of atoms is <span class="math notranslate nohighlight">\(R^{nt * nt}\)</span>. Default is ‘nonnegative_symmetric’</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to True, losses evolution by batches and epochs are tracked. Default is False.</p></li>
<li><p><strong>use_adam_optimizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to True, adam optimizer with default settings is used as adaptative learning rate strategy.
Else perform SGD with fixed learning rate. Default is True.</p></li>
<li><p><strong>tol_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the BCD algorithm, measured by absolute relative error on consecutive losses. Default is <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p></li>
<li><p><strong>tol_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the Conjugate Gradient algorithm used to get optimal w at a fixed transport, measured by absolute relative error on consecutive losses. Default is <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p></li>
<li><p><strong>max_iter_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the BCD. Default is 20.</p></li>
<li><p><strong>max_iter_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the Conjugate Gradient. Default is 200.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print the reconstruction loss every epoch. Default is False.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Determines random number generation. Pass an int for reproducible
output across multiple function calls.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>Cdict_best_state</strong> (<em>D array-like, shape (D,nt,nt)</em>) – Metric/Graph cost matrices composing the dictionary.
The dictionary leading to the best loss over an epoch is saved and returned.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – If use_log is True, contains loss evolutions by batches and epochs.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id65" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online
Graph Dictionary Learning, International Conference on Machine Learning
(ICML), 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gromov_wasserstein_linear_unmixing">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gromov_wasserstein_linear_unmixing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cdict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_outer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_inner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_dictionary.html#gromov_wasserstein_linear_unmixing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gromov_wasserstein_linear_unmixing" title="Link to this definition"></a></dt>
<dd><p>Returns the Gromov-Wasserstein linear unmixing of <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{p})\)</span> onto the dictionary <span class="math notranslate nohighlight">\(\{ (\mathbf{C_{dict}[d]}, \mathbf{q}) \}_{d \in [D]}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\min_{ \mathbf{w}}  GW_2(\mathbf{C}, \sum_{d=1}^D w_d\mathbf{C_{dict}[d]}, \mathbf{p}, \mathbf{q}) - reg \| \mathbf{w}  \|_2^2\]</div>
<p>such that:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}^\top \mathbf{1}_D = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w} \geq \mathbf{0}_D\)</span></p></li>
</ul>
</div></blockquote>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}\)</span> is the (ns,ns) pairwise similarity matrix.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_{dict}}\)</span> is a (D, nt, nt) tensor of D pairwise similarity matrices of size nt.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> are source and target weights.</p></li>
<li><p>reg is the regularization coefficient.</p></li>
</ul>
<p>The algorithm used for solving the problem is a Block Coordinate Descent as discussed in <a href="#id120"><span class="problematic" id="id66">[38]_</span></a> , algorithm 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric/Graph cost matrix.</p></li>
<li><p><strong>Cdict</strong> (<em>D array-like</em><em>, </em><em>shape</em><em> (</em><em>D</em><em>,</em><em>nt</em><em>,</em><em>nt</em><em>)</em>) – Metric/Graph cost matrices composing the dictionary on which to embed C.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional.</em>) – Coefficient of the negative quadratic regularization used to promote sparsity of w. Default is 0.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space C. Default is None and corresponds to uniform distribution.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the space depicted by the dictionary. Default is None and corresponds to uniform distribution.</p></li>
<li><p><strong>tol_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the BCD algorithm.</p></li>
<li><p><strong>tol_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Solver precision for the Conjugate Gradient algorithm used to get optimal w at a fixed transport. Default is <span class="math notranslate nohighlight">\(10^{-5}\)</span>.</p></li>
<li><p><strong>max_iter_outer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the BCD. Default is 20.</p></li>
<li><p><strong>max_iter_inner</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for the Conjugate Gradient. Default is 200.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>w</strong> (<em>array-like, shape (D,)</em>) – Gromov-Wasserstein linear unmixing of <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{p})\)</span> onto the span of the dictionary.</p></li>
<li><p><strong>Cembedded</strong> (<em>array-like, shape (nt,nt)</em>) – embedded structure of <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{p})\)</span> onto the dictionary, <span class="math notranslate nohighlight">\(\sum_d w_d\mathbf{C_{dict}[d]}\)</span>.</p></li>
<li><p><strong>T</strong> (<em>array-like (ns, nt)</em>) – Gromov-Wasserstein transport plan between <span class="math notranslate nohighlight">\((\mathbf{C},\mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\sum_d w_d\mathbf{C_{dict}[d]}, \mathbf{q})\)</span></p></li>
<li><p><strong>current_loss</strong> (<em>float</em>) – reconstruction error</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id67" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online
Graph Dictionary Learning, International Conference on Machine Learning
(ICML), 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gwggrad">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gwggrad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constC</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hC1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hC2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#gwggrad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gwggrad" title="Link to this definition"></a></dt>
<dd><p>Return the gradient for Gromov-Wasserstein</p>
<p>The gradient is computed as described in Proposition 2 in <a class="reference internal" href="#references-gwggrad"><span class="std std-ref">[12]</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constC</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Constant <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h1}(\mathbf{C1})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h2}(\mathbf{C2})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>T</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Current value of transport matrix <span class="math notranslate nohighlight">\(\mathbf{T}\)</span></p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>grad</strong> – Gromov-Wasserstein gradient</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric" id="references-gwggrad">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id68" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.gwloss">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">gwloss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constC</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hC1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hC2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#gwloss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.gwloss" title="Link to this definition"></a></dt>
<dd><p>Return the Loss for Gromov-Wasserstein</p>
<p>The loss is computed as described in Proposition 1 Eq. (6) in <a class="reference internal" href="#references-gwloss"><span class="std std-ref">[12]</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constC</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Constant <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h1}(\mathbf{C1})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h2}(\mathbf{C2})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>T</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Current value of transport matrix <span class="math notranslate nohighlight">\(\mathbf{T}\)</span></p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>loss</strong> – Gromov-Wasserstein loss</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric" id="references-gwloss">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id69" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.init_matrix">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">init_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#init_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.init_matrix" title="Link to this definition"></a></dt>
<dd><p>Return loss matrices and tensors for Gromov-Wasserstein fast computation</p>
<p>Returns the value of <span class="math notranslate nohighlight">\(\mathcal{L}(\mathbf{C_1}, \mathbf{C_2}) \otimes \mathbf{T}\)</span> with the
selected loss function as the loss function of Gromov-Wasserstein discrepancy.</p>
<p>The matrices are computed as described in Proposition 1 in <span class="xref std std-ref">[12]</span></p>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: A coupling between those two spaces</p></li>
</ul>
<p>The square-loss function <span class="math notranslate nohighlight">\(L(a, b) = |a - b|^2\)</span> is read as :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\\\mathrm{with} \ f_1(a) &amp;= a^2\\                f_2(b) &amp;= b^2\\                h_1(a) &amp;= a\\                h_2(b) &amp;= 2b\end{aligned}\end{align} \]</div>
<p>The kl-loss function <span class="math notranslate nohighlight">\(L(a, b) = a \log\left(\frac{a}{b}\right) - a + b\)</span> is read as :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\\\mathrm{with} \ f_1(a) &amp;= a \log(a) - a\\                f_2(b) &amp;= b\\                h_1(a) &amp;= a\\                h_2(b) &amp;= \log(b)\end{aligned}\end{align} \]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Probability distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Probability distribution in the target space</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Name of loss function to use: either ‘square_loss’ or ‘kl_loss’ (default=’square_loss’)</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>constC</strong> (<em>array-like, shape (ns, nt)</em>) – Constant <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC1</strong> (<em>array-like, shape (ns, ns)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h1}(\mathbf{C1})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>array-like, shape (nt, nt)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h2}(\mathbf{C2})\)</span> matrix in Eq. (6)</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-init-matrix">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id70" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.init_matrix_semirelaxed">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">init_matrix_semirelaxed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#init_matrix_semirelaxed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.init_matrix_semirelaxed" title="Link to this definition"></a></dt>
<dd><p>Return loss matrices and tensors for semi-relaxed Gromov-Wasserstein fast computation</p>
<p>Returns the value of <span class="math notranslate nohighlight">\(\mathcal{L}(\mathbf{C_1}, \mathbf{C_2}) \otimes \mathbf{T}\)</span> with the
selected loss function as the loss function of semi-relaxed Gromov-Wasserstein discrepancy.</p>
<p>The matrices are computed as described in Proposition 1 in <span class="xref std std-ref">[12]</span>
and adapted to the semi-relaxed problem where the second marginal is not a constant anymore.</p>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: A coupling between those two spaces</p></li>
</ul>
<p>The square-loss function <span class="math notranslate nohighlight">\(L(a, b) = |a - b|^2\)</span> is read as :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\\\mathrm{with} \ f_1(a) &amp;= a^2\\                f_2(b) &amp;= b^2\\                h_1(a) &amp;= a\\                h_2(b) &amp;= 2b\end{aligned}\end{align} \]</div>
<p>The kl-loss function <span class="math notranslate nohighlight">\(L(a, b) = a \log\left(\frac{a}{b}\right) - a + b\)</span> is read as :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)\\\mathrm{with} \ f_1(a) &amp;= a \log(a) - a\\                f_2(b) &amp;= b\\                h_1(a) &amp;= a\\                h_2(b) &amp;= \log(b)\end{aligned}\end{align} \]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Probability distribution in the source space</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Name of loss function to use: either ‘square_loss’ or ‘kl_loss’ (default=’square_loss’)</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>constC</strong> (<em>array-like, shape (ns, nt)</em>) – Constant <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix in Eq. (6) adapted to srGW</p></li>
<li><p><strong>hC1</strong> (<em>array-like, shape (ns, ns)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h1}(\mathbf{C1})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>array-like, shape (nt, nt)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h2}(\mathbf{C2})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>fC2t</strong> (<em>array-like, shape (nt, nt)</em>) – <span class="math notranslate nohighlight">\(\mathbf{f2}(\mathbf{C2})^\top\)</span> matrix in Eq. (6)</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id71">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id72" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id73" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.lowrank_gromov_wasserstein_samples">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">lowrank_gromov_wasserstein_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rescale'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rescale_cost</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_factorized_Xs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_factorized_Xt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopThr_dykstra</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax_dykstra</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">49</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warn_dykstra</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_lowrank.html#lowrank_gromov_wasserstein_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.lowrank_gromov_wasserstein_samples" title="Link to this definition"></a></dt>
<dd><p>Solve the entropic regularization Gromov-Wasserstein transport problem under low-nonnegative rank constraints
on the couplings and cost matrices.</p>
<p>Squared euclidean distance matrices are considered for the target and source distributions.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[\mathop{\min_{(Q,R,g) \in \mathcal{C(a,b,r)}}} \mathcal{Q}_{A,B}(Q\mathrm{diag}(1/g)R^T) -
    \epsilon \cdot H((Q,R,g))\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(A\)</span> is the (<cite>dim_a</cite>, <cite>dim_a</cite>) square pairwise cost matrix of the source domain.</p></li>
<li><p><span class="math notranslate nohighlight">\(B\)</span> is the (<cite>dim_a</cite>, <cite>dim_a</cite>) square pairwise cost matrix of the target domain.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{Q}_{A,B}\)</span> is quadratic objective function of the Gromov Wasserstein plan.</p></li>
<li><p><span class="math notranslate nohighlight">\(Q\)</span> and <cite>R</cite> are the low-rank matrix decomposition of the Gromov-Wasserstein plan.</p></li>
<li><p><span class="math notranslate nohighlight">\(g\)</span> is the weight vector for the low-rank decomposition of the Gromov-Wasserstein plan.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> are source and target weights (histograms, both sum to 1).</p></li>
<li><p><span class="math notranslate nohighlight">\(r\)</span> is the rank of the Gromov-Wasserstein plan.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{C(a,b,r)}\)</span> are the low-rank couplings of the OT problem.</p></li>
<li><p><span class="math notranslate nohighlight">\(H((Q,R,g))\)</span> is the values of the three respective entropies evaluated for each term.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_s</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples_a</em><em>, </em><em>dim_Xs</em><em>)</em>) – Samples in the source domain</p></li>
<li><p><strong>X_t</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples_b</em><em>, </em><em>dim_Xt</em><em>)</em>) – Samples in the target domain</p></li>
<li><p><strong>a</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples_a</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Samples weights in the source domain
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>b</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples_b</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Samples weights in the target domain
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;=0</p></li>
<li><p><strong>rank</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional. Default is None.</em><em> (</em><em>&gt;0</em><em>)</em>) – Nonnegative rank of the OT plan. If None, min(ns, nt) is considered.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional. Default is 1e-10.</em><em> (</em><em>&gt;0 and &lt;1/r</em><em>)</em>) – Lower bound for the weight vector g.</p></li>
<li><p><strong>rescale_cost</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional. Default is False</em>) – Rescale the low rank factorization of the sqeuclidean cost matrix</p></li>
<li><p><strong>seed_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional. Default is 49.</em><em> (</em><em>&gt;0</em><em>)</em>) – Random state for the ‘random’ initialization of low rank couplings</p></li>
<li><p><strong>gamma_init</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is &quot;rescale&quot;.</em>) – Initialization strategy for gamma. ‘rescale’, or ‘theory’
Gamma is a constant that scales the convergence criterion of the Mirror Descent
optimization scheme used to compute the low-rank couplings (Q, R and g)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional. Default is 1000.</em>) – Max number of iterations for Low Rank GW</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional. Default is 1e-4.</em>) – Stop threshold on error (&gt;0) for Low Rank GW
The error is the sum of Kullback Divergences computed for each low rank
coupling (Q, R and g) and scaled using gamma.</p></li>
<li><p><strong>numItermax_dykstra</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional. Default is 2000.</em>) – Max number of iterations for the Dykstra algorithm</p></li>
<li><p><strong>stopThr_dykstra</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional. Default is 1e-7.</em>) – Stop threshold on error (&gt;0) in Dykstra</p></li>
<li><p><strong>cost_factorized_Xs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><em>optional. Default is None</em>) – Tuple with two pre-computed low rank decompositions (A1, A2) of the source cost
matrix. Both matrices should have a shape of (n_samples_a, dim_Xs + 2).
If None, the low rank cost matrices will be computed as sqeuclidean cost matrices.</p></li>
<li><p><strong>cost_factorized_Xt</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><em>optional. Default is None</em>) – Tuple with two pre-computed low rank decompositions (B1, B2) of the target cost
matrix. Both matrices should have a shape of (n_samples_b, dim_Xt + 2).
If None, the low rank cost matrices will be computed as sqeuclidean cost matrices.</p></li>
<li><p><strong>warn</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, raises a warning if the low rank GW algorithm doesn’t convergence.</p></li>
<li><p><strong>warn_dykstra</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, raises a warning if the Dykstra algorithm doesn’t convergence.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>Q</strong> (<em>array-like, shape (n_samples_a, r)</em>) – First low-rank matrix decomposition of the OT plan</p></li>
<li><p><strong>R</strong> (<em>array-like, shape (n_samples_b, r)</em>) – Second low-rank matrix decomposition of the OT plan</p></li>
<li><p><strong>g</strong> (<em>array-like, shape (r, )</em>) – Weight vector for the low-rank decomposition of the OT</p></li>
<li><p><strong>log</strong> (<em>dict (lazy_plan, value and value_linear)</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id74" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>67<span class="fn-bracket">]</span></span>
<p>Scetbon, M., Peyré, G. &amp; Cuturi, M. (2022).
“Linear-Time GromovWasserstein Distances using Low Rank Couplings and Costs”.
In International Conference on Machine Learning (ICML), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.partial_fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">partial_fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_dummies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thres</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_partial.html#partial_fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.partial_fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Partial Fused Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{F_1}, \mathbf{p})\)</span>
and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{F_2}, \mathbf{q})\)</span>, with pairwise
distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices.</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) T_{i,j} T_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\\     \mathbf{1}^T \mathbf{T}^T \mathbf{1} = m &amp;\leq \min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: Distribution in the source space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: Distribution in the target space.</p></li>
<li><p><cite>m</cite> is the amount of mass to be transported</p></li>
<li><p><cite>L</cite>: Loss function to account for the misfit between the similarity matrices.</p></li>
</ul>
<p>The formulation of the problem has been proposed in
<a class="reference internal" href="ot.partial.html#references-partial-gromov-wasserstein"><span class="std std-ref">[29]</span></a></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conjugate gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will cast the computed transport plan to the data
type of the provided input <span class="math notranslate nohighlight">\(\mathbf{C}_1\)</span>. Casting to an integer
tensor might result in a loss of precision. If this behaviour is
unwanted, please make sure to provide a floating point input.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric costfr matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported
(default: <span class="math notranslate nohighlight">\(\min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\)</span>)</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>nb_dummies</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of dummy points to add (avoid instabilities in the EMD solver)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Initialization of the transportation matrix</p></li>
<li><p><strong>thres</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – quantile of the gradient matrix to populate the cost matrix when 0
(default: 1)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – tolerance for stopping iterations</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>warn</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional.</em>) – Whether to raise a warning when EMD did not converge.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – return log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the emd solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>T</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) – Optimal transport matrix between the two spaces.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Convergence information and loss.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-partial-gromov-wasserstein">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id75" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></span>
<p>Chapel, L., Alaya, M., Gasso, G. (2020). “Partial Optimal
Transport with Applications on Positive-Unlabeled Learning”.
NeurIPS.</p>
</aside>
<aside class="footnote brackets" id="id76" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.partial_fused_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">partial_fused_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_dummies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thres</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_partial.html#partial_fused_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.partial_fused_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Partial Fused Gromov-Wasserstein discrepancy between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{F_1}, \mathbf{p})\)</span>
and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{F_2}, \mathbf{q})\)</span>, with pairwise
distance matrix <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> between node feature matrices.</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{PFGW}_{\alpha} = \mathop{\min}_\mathbf{T} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) T_{i,j} T_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\\     \mathbf{1}^T \mathbf{T}^T \mathbf{1} = m &amp;\leq \min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: metric cost matrix between features across domains</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: Distribution in the source space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: Distribution in the target space.</p></li>
<li><p><cite>m</cite> is the amount of mass to be transported</p></li>
<li><p><cite>L</cite>: Loss function to account for the misfit between the similarity matrices.</p></li>
</ul>
<p>The formulation of the problem has been proposed in
<a class="reference internal" href="ot.partial.html#references-partial-gromov-wasserstein2"><span class="std std-ref">[29]</span></a></p>
<p>Note that when using backends, this loss function is differentiable wrt the
matrices (M, C1, C2).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conjugate gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will cast the computed transport plan to the data
type of the provided input <span class="math notranslate nohighlight">\(\mathbf{C}_1\)</span>. Casting to an integer
tensor might result in a loss of precision. If this behaviour is
unwanted, please make sure to provide a floating point input.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported
(default: <span class="math notranslate nohighlight">\(\min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\)</span>)</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>nb_dummies</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of dummy points to add (avoid instabilities in the EMD solver)</p></li>
<li><p><strong>G0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Initialization of the transportation matrix</p></li>
<li><p><strong>thres</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – quantile of the gradient matrix to populate the cost matrix when 0
(default: 1)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – tolerance for stopping iterations</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>warn</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional.</em>) – Whether to raise a warning when EMD did not converge.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – return log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the emd solver</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When dealing with a large number of points, the EMD solver may face
some instabilities, especially when the mass associated to the dummy
point is large. To avoid them, increase the number of dummy points
(allows a smoother repartition of the mass over the points).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>partial_fgw_dist</strong> (<em>float</em>) – partial FGW discrepancy</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-partial-gromov-wasserstein2">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id77" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></span>
<p>Chapel, L., Alaya, M., Gasso, G. (2020). “Partial Optimal
Transport with Applications on Positive-Unlabeled Learning”.
NeurIPS.</p>
</aside>
<aside class="footnote brackets" id="id78" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.partial_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">partial_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_dummies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thres</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_partial.html#partial_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.partial_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the Partial Gromov-Wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span>
and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>.</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_\mathbf{T} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) T_{i,j} T_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\\     \mathbf{1}^T \mathbf{T}^T \mathbf{1} = m &amp;\leq \min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: Distribution in the source space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: Distribution in the target space.</p></li>
<li><p><cite>m</cite> is the amount of mass to be transported</p></li>
<li><p><cite>L</cite>: Loss function to account for the misfit between the similarity matrices.</p></li>
</ul>
<p>The formulation of the problem has been proposed in
<a class="reference internal" href="ot.partial.html#references-partial-gromov-wasserstein"><span class="std std-ref">[29]</span></a></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conjugate gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will cast the computed transport plan to the data
type of the provided input <span class="math notranslate nohighlight">\(\mathbf{C}_1\)</span>. Casting to an integer
tensor might result in a loss of precision. If this behaviour is
unwanted, please make sure to provide a floating point input.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric costfr matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported
(default: <span class="math notranslate nohighlight">\(\min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\)</span>)</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>nb_dummies</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of dummy points to add (avoid instabilities in the EMD solver)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Initialization of the transportation matrix</p></li>
<li><p><strong>thres</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – quantile of the gradient matrix to populate the cost matrix when 0
(default: 1)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – tolerance for stopping iterations</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>warn</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional.</em>) – Whether to raise a warning when EMD did not converge.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – return log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the emd solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>T</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) – Optimal transport matrix between the two spaces.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Convergence information and loss.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ot.gromov</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial_gromov_wasserstein</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">98</span><span class="p">,</span><span class="mi">199</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C2</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.  , 0.25, 0.  , 0.  ],</span>
<span class="go">       [0.25, 0.  , 0.  , 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.25, 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.  , 0.25]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mf">0.25</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.  , 0.  , 0.  , 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.  , 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.25, 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.  , 0.  ]])</span>
</pre></div>
</div>
<p class="rubric" id="id79">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id80" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></span>
<p>Chapel, L., Alaya, M., Gasso, G. (2020). “Partial Optimal
Transport with Applications on Positive-Unlabeled Learning”.
NeurIPS.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.partial_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">partial_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_dummies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thres</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numItermax</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_partial.html#partial_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.partial_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the Partial Gromov-Wasserstein discrepancy between
<span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span>.</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{PGW} = \mathop{\min}_\mathbf{T} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) T_{i,j} T_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\\     \mathbf{1}^T \mathbf{T}^T \mathbf{1} = m &amp;\leq \min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: Distribution in the source space.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: Distribution in the target space.</p></li>
<li><p><cite>m</cite> is the amount of mass to be transported</p></li>
<li><p><cite>L</cite>: Loss function to account for the misfit between the similarity matrices.</p></li>
</ul>
<p>The formulation of the problem has been proposed in
<a class="reference internal" href="ot.partial.html#references-partial-gromov-wasserstein2"><span class="std std-ref">[29]</span></a></p>
<p>Note that when using backends, this loss function is differentiable wrt the
matrices (C1, C2).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conjugate gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function will cast the computed transport plan to the data
type of the provided input <span class="math notranslate nohighlight">\(\mathbf{C}_1\)</span>. Casting to an integer
tensor might result in a loss of precision. If this behaviour is
unwanted, please make sure to provide a floating point input.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported
(default: <span class="math notranslate nohighlight">\(\min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}\)</span>)</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>nb_dummies</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Number of dummy points to add (avoid instabilities in the EMD solver)</p></li>
<li><p><strong>G0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Initialization of the transportation matrix</p></li>
<li><p><strong>thres</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – quantile of the gradient matrix to populate the cost matrix when 0
(default: 1)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – tolerance for stopping iterations</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>warn</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional.</em>) – Whether to raise a warning when EMD did not converge.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – return log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the emd solver</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When dealing with a large number of points, the EMD solver may face
some instabilities, especially when the mass associated to the dummy
point is large. To avoid them, increase the number of dummy points
(allows a smoother repartition of the mass over the points).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>partial_gw_dist</strong> (<em>float</em>) – partial GW discrepancy</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ot.gromov</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial_gromov_wasserstein2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">98</span><span class="p">,</span><span class="mi">199</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C2</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_gromov_wasserstein2</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="go">3.38</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_gromov_wasserstein2</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mf">0.25</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p class="rubric" id="id81">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id82" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></span>
<p>Chapel, L., Alaya, M., Gasso, G. (2020). “Partial Optimal
Transport with Applications on Positive-Unlabeled Learning”.
NeurIPS.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.pointwise_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">pointwise_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold_plan</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_estimators.html#pointwise_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.pointwise_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the gromov-wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span> using a stochastic Frank-Wolfe.
This method has a <span class="math notranslate nohighlight">\(\mathcal{O}(\mathrm{max\_iter} \times PN^2)\)</span> time complexity with <cite>P</cite> the number of Sinkhorn iterations.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{GW} = \mathop{\arg \min}_\mathbf{T} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\        \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\        \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>loss_fun</strong> (function: <span class="math notranslate nohighlight">\(\mathbb{R} \times \mathbb{R} \mapsto \mathbb{R}\)</span>) – Loss function used for the distance, the transport plan does not depend on the loss function</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Step of the Frank-Wolfe algorithm, should be between 0 and 1</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>threshold_plan</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Deleting very small values in the transport plan. If above zero, it violates the marginal constraints.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Gives the distance estimated and the standard deviation</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id83" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></span>
<p>Kerdoncuff, Tanguy, Emonet, Rémi, Sebban, Marc
“Sampled Gromov Wasserstein.”
Machine Learning Journal (MLJ). 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.quantized_fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">quantized_fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">npart1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">npart2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1_aux</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2_aux</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">part_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'fluid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rep_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'random'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_quantized.html#quantized_fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.quantized_fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the quantized Fused Gromov-Wasserstein transport between
<span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{F_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2},
\mathbf{F_2}, \mathbf{q})\)</span>, whose samples are assigned to partitions and
representants <span class="math notranslate nohighlight">\(\mathcal{P_1} = \{(\mathbf{P_{1, i}}, \mathbf{r_{1, i}})\}_{i \leq npart1}\)</span>
and <span class="math notranslate nohighlight">\(\mathcal{P_2} = \{(\mathbf{P_{2, j}}, \mathbf{r_{2, j}})\}_{j \leq npart2}\)</span>.</p>
<p>The function estimates the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_\mathbf{T} \quad \alpha \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}
+ (1-\alpha) \langle \mathbf{T}, \mathbf{D}(\mathbf{F_1}, \mathbf{F}_2) \rangle_F
s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\\     \mathbf{T}_{|\mathbf{P_{1, i}}, \mathbf{P_{2, j}}} &amp;= T^{g}_{ij} \mathbf{T}^{(i,j)}\end{aligned}\end{align} \]</div>
<p>using a two-step strategy computing: i) a global alignment <span class="math notranslate nohighlight">\(\mathbf{T}^{g}\)</span>
between representants across joint structure and feature spaces;
ii) local alignments <span class="math notranslate nohighlight">\(\mathbf{T}^{(i, j)}\)</span> between partitions
<span class="math notranslate nohighlight">\(\mathbf{P_{1, i}}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{P_{2, j}}\)</span> seen as 1D measures.</p>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{F_1}\)</span>: Feature matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{F_2}\)</span>: Feature matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{D}(\mathbf{F_1}, \mathbf{F_2})\)</span>: Pairwise euclidean distance matrix between features</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(L\)</span>: quadratic loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conjugate gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Structure matrix in the source space.</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Structure matrix in the target space.</p></li>
<li><p><strong>npart1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>,</em>) – number of partition in the source space.</p></li>
<li><p><strong>npart2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>,</em>) – number of partition in the target space.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>C1_aux</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em><em>, </em><em>optional. Default is None.</em>) – Auxiliary structure matrix in the source space to perform the partitioning
and representant selection.</p></li>
<li><p><strong>C2_aux</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional. Default is None.</em>) – Auxiliary structure matrix in the target space to perform the partitioning
and representant selection.</p></li>
<li><p><strong>F1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>d</em><em>)</em><em>, </em><em>optional. Default is None.</em>) – Feature matrix in the source space.</p></li>
<li><p><strong>F2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>d</em><em>)</em><em>, </em><em>optional. Default is None.</em>) – Feature matrix in the target space</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional. Default is 1.</em>) – FGW trade-off parameter in <span class="math notranslate nohighlight">\(]0, 1]\)</span> between structure and features.
If <cite>alpha = 1</cite> features are ignored hence computing qGW, if <cite>alpha=0</cite>
structures are ignored and we compute the quantized Wasserstein transport.</p></li>
<li><p><strong>part_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'spectral'.</em>) – Partitioning algorithm to use among {‘random’, ‘louvain’, ‘fluid’,
‘spectral’, ‘louvain_fused’, ‘fluid_fused’, ‘spectral_fused’, ‘GW’, ‘FGW’}.
If part_method in {‘louvain_fused’, ‘fluid_fused’, ‘spectral_fused’},
corresponding graph partitioning algorithm {‘louvain’, ‘fluid’, ‘spectral’}
will be used on the modified structure matrix
<span class="math notranslate nohighlight">\(\alpha \mathbf{C} + (1 - \alpha) \mathbf{D}(\mathbf{F})\)</span> where
<span class="math notranslate nohighlight">\(\mathbf{D}(\mathbf{F})\)</span> is the pairwise euclidean matrix between features.
If part_method in {‘GW’, ‘FGW’}, a (F)GW projection is used.
If the louvain algorithm is used, the requested number of partitions is
ignored.</p></li>
<li><p><strong>rep_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'pagerank'.</em>) – Selection method for node representant in each partition.
Can be either ‘random’ i.e random sampling within each partition,
{‘pagerank’, ‘pagerank_fused’} to select a node with maximal pagerank w.r.t
<span class="math notranslate nohighlight">\(\mathbf{C}\)</span> or <span class="math notranslate nohighlight">\(\alpha \mathbf{C} + (1 - \alpha) \mathbf{D}(\mathbf{F})\)</span>.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research. Else closed form is used.
If there are convergence issues use False.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed for the partitioning algorithm</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>T_global</strong> (array-like, shape (<cite>npart1</cite>, <cite>npart2</cite>)) – Fused Gromov-Wasserstein alignment <span class="math notranslate nohighlight">\(\mathbf{T}^{g}\)</span> between representants.</p></li>
<li><p><strong>Ts_local</strong> (<em>dict of local OT matrices.</em>) – Dictionary with keys <span class="math notranslate nohighlight">\((i, j)\)</span> corresponding to 1D OT between
<span class="math notranslate nohighlight">\(\mathbf{P_{1, i}}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{P_{2, j}}\)</span> if <span class="math notranslate nohighlight">\(T^{g}_{ij} \neq 0\)</span>.</p></li>
<li><p><strong>T</strong> (array-like, shape <cite>(ns, nt)</cite>) – Coupling between the two spaces.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Convergence information for inner problems and qGW loss.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id84" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>68<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., Miller, D., &amp; Needham, T. (2021).
Quantized gromov-wasserstein. ECML PKDD 2021. Springer International Publishing.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.quantized_fused_gromov_wasserstein_partitioned">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">quantized_fused_gromov_wasserstein_partitioned</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">CR1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">CR2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_R1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_R2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_p1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_p2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">MR</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">build_OT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_quantized.html#quantized_fused_gromov_wasserstein_partitioned"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.quantized_fused_gromov_wasserstein_partitioned" title="Link to this definition"></a></dt>
<dd><p>Returns the quantized Fused Gromov-Wasserstein transport between
<span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{F_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2},
\mathbf{F_2}, \mathbf{q})\)</span>, whose samples are assigned to partitions and representants
<span class="math notranslate nohighlight">\(\mathcal{P_1} = \{(\mathbf{P_{1, i}}, \mathbf{r_{1, i}})\}_{i \leq npart1}\)</span>
and <span class="math notranslate nohighlight">\(\mathcal{P_2} = \{(\mathbf{P_{2, j}}, \mathbf{r_{2, j}})\}_{j \leq npart2}\)</span>.
The latter must be precomputed and encoded e.g for the source as: <span class="math notranslate nohighlight">\(\mathbf{CR_1}\)</span>
structure matrix between representants; <cite>list_R1</cite> a list of relations between
representants and their associated samples; <cite>list_p1</cite> a list of nodes
distribution within each partition; <span class="math notranslate nohighlight">\(\mathbf{FR_1}\)</span> feature matrix
of representants.</p>
<p>The function estimates the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_\mathbf{T} \quad \alpha \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}
+ (1-\alpha) \langle \mathbf{T}, M\rangle_F
s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\\     \mathbf{T}_{|\mathbf{P_{1, i}}, \mathbf{P_{2, j}}} &amp;= T^{g}_{ij} \mathbf{T}^{(i,j)}\end{aligned}\end{align} \]</div>
<p>using a two-step strategy computing: i) a global alignment <span class="math notranslate nohighlight">\(\mathbf{T}^{g}\)</span>
between representants joint structure and feature spaces; ii) local alignments
<span class="math notranslate nohighlight">\(\mathbf{T}^{(i, j)}\)</span> between partitions <span class="math notranslate nohighlight">\(\mathbf{P_{1, i}}\)</span>
and <span class="math notranslate nohighlight">\(\mathbf{P_{2, j}}\)</span> seen as 1D measures.</p>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{F_1}\)</span>: Feature matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{F_2}\)</span>: Feature matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span>: Pairwise similarity matrix between features</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(L\)</span>: quadratic loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the Gromov-Wasserstein conjugate gradient solver
are done with numpy to limit memory overhead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>CR1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>npart1</em><em>, </em><em>npart1</em><em>)</em>) – Structure matrix between partition representants in the source space.</p></li>
<li><p><strong>CR2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>npart2</em><em>, </em><em>npart2</em><em>)</em>) – Structure matrix between partition representants in the target space.</p></li>
<li><p><strong>list_R1</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>npart1 arrays</em><em>,</em>) – List of relations between representants and their associated samples in the source space.</p></li>
<li><p><strong>list_R2</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>npart2 arrays</em><em>,</em>) – List of relations between representants and their associated samples in the target space.</p></li>
<li><p><strong>list_p1</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>npart1 arrays</em><em>,</em>) – List of node distributions within each partition of the source space.</p></li>
<li><p><strong>list_p</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>npart2 arrays</em><em>,</em>) – List of node distributions within each partition of the target space.</p></li>
<li><p><strong>MR</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>npart1</em><em>, </em><em>npart2</em><em>)</em><em>, </em><em>optional.</em><em> (</em><em>Default is None</em><em>)</em>) – Metric cost matrix between features of representants across spaces.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional. Default is None.</em>) – FGW trade-off parameter in <span class="math notranslate nohighlight">\(]0, 1]\)</span> between structure and features.
If <cite>alpha = 1</cite> features are ignored hence computing qGW.</p></li>
<li><p><strong>build_OT</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional. Default is False</em>) – Either to build or not the OT between non-partitioned structures.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional. Default is False</em>) – record log if True</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research. Else closed form is used.
If there are convergence issues use False.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – POT backend</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>T_global</strong> (array-like, shape (<cite>npart1</cite>, <cite>npart2</cite>)) – Gromov-Wasserstein alignment <span class="math notranslate nohighlight">\(\mathbf{T}^{g}\)</span> between representants.</p></li>
<li><p><strong>Ts_local</strong> (<em>dict of local OT matrices.</em>) – Dictionary with keys <span class="math notranslate nohighlight">\((i, j)\)</span> corresponding to 1D OT between
<span class="math notranslate nohighlight">\(\mathbf{P_{1, i}}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{P_{2, j}}\)</span> if <span class="math notranslate nohighlight">\(T^{g}_{ij} \neq 0\)</span>.</p></li>
<li><p><strong>T</strong> (array-like, shape <cite>(ns, nt)</cite>) – Coupling between the two spaces if <cite>build_OT=True</cite> else None.</p></li>
<li><p><strong>log</strong> (dict, if <cite>log=True</cite>.) – Convergence information and losses of inner OT problems.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id85" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>68<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., Miller, D., &amp; Needham, T. (2021).
Quantized gromov-wasserstein. ECML PKDD 2021. Springer International Publishing.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.quantized_fused_gromov_wasserstein_samples">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">quantized_fused_gromov_wasserstein_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">npart1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">npart2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'kmeans'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">armijo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_quantized.html#quantized_fused_gromov_wasserstein_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.quantized_fused_gromov_wasserstein_samples" title="Link to this definition"></a></dt>
<dd><p>Returns the quantized Fused Gromov-Wasserstein transport between samples
endowed with their respective euclidean geometry <span class="math notranslate nohighlight">\((\mathbf{D}(\mathbf{X_1}), \mathbf{F_1}, \mathbf{p})\)</span>
and <span class="math notranslate nohighlight">\((\mathbf{D}(\mathbf{X_1}), \mathbf{F_2}, \mathbf{q})\)</span>, whose samples are assigned to partitions and
representants <span class="math notranslate nohighlight">\(\mathcal{P_1} = \{(\mathbf{P_{1, i}}, \mathbf{r_{1, i}})\}_{i \leq npart1}\)</span>
and <span class="math notranslate nohighlight">\(\mathcal{P_2} = \{(\mathbf{P_{2, j}}, \mathbf{r_{2, j}})\}_{j \leq npart2}\)</span>.</p>
<p>The function estimates the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_\mathbf{T} \quad \alpha \sum_{i,j,k,l}
L(\mathbf{D}(\mathbf{X_1})_{i,k}, \mathbf{D}(\mathbf{X_2})_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}
+ (1-\alpha) \langle \mathbf{T}, \mathbf{D}(\mathbf{F_1}, \mathbf{F}_2) \rangle_F
s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\     \mathbf{T} &amp;\geq 0\\     \mathbf{T}_{|\mathbf{P_{1, i}}, \mathbf{P_{2, j}}} &amp;= T^{g}_{ij} \mathbf{T}^{(i,j)}\end{aligned}\end{align} \]</div>
<p>using a two-step strategy computing: i) a global alignment <span class="math notranslate nohighlight">\(\mathbf{T}^{g}\)</span>
between representants across joint structure and feature spaces;
ii) local alignments <span class="math notranslate nohighlight">\(\mathbf{T}^{(i, j)}\)</span> between partitions
<span class="math notranslate nohighlight">\(\mathbf{P_{1, i}}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{P_{2, j}}\)</span> seen as 1D measures.</p>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{X_1}\)</span>: Samples in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{X_2}\)</span>: Samples in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{F_1}\)</span>: Feature matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{F_2}\)</span>: Feature matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{D}(\mathbf{F_1}, \mathbf{F_2})\)</span>: Pairwise euclidean distance matrix between features</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(L\)</span>: quadratic loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. But the algorithm uses the C++ CPU backend
which can lead to copy overhead on GPU arrays.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All computations in the conjugate gradient solver are done with
numpy to limit memory overhead.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ds</em><em>)</em>) – Samples in the source space.</p></li>
<li><p><strong>X2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>dt</em><em>)</em>) – Samples in the target space.</p></li>
<li><p><strong>npart1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>,</em>) – number of partition in the source space.</p></li>
<li><p><strong>npart2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>,</em>) – number of partition in the target space.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the target space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>F1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>d</em><em>)</em><em>, </em><em>optional. Default is None.</em>) – Feature matrix in the source space.</p></li>
<li><p><strong>F2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>d</em><em>)</em><em>, </em><em>optional. Default is None.</em>) – Feature matrix in the target space</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional. Default is 1.</em>) – FGW trade-off parameter in <span class="math notranslate nohighlight">\(]0, 1]\)</span> between structure and features.
If <cite>alpha = 1</cite> features are ignored hence computing qGW, if <cite>alpha=0</cite>
structures are ignored and we compute the quantized Wasserstein transport.</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'kmeans'.</em>) – Partitioning and representant selection algorithms to use among
{‘random’, ‘kmeans’, ‘kmeans_fused’}.
If <cite>part_method == ‘kmeans_fused’</cite>, kmeans is performed on augmented
samples <span class="math notranslate nohighlight">\([\alpha \mathbf{X}; (1 - \alpha) \mathbf{F}]\)</span>.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the step of the line-search is found via an armijo research. Else closed form is used.
If there are convergence issues use False.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed for the partitioning algorithm</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>T_global</strong> (array-like, shape (<cite>npart1</cite>, <cite>npart2</cite>)) – Fused Gromov-Wasserstein alignment <span class="math notranslate nohighlight">\(\mathbf{T}^{g}\)</span> between representants.</p></li>
<li><p><strong>Ts_local</strong> (<em>dict of local OT matrices.</em>) – Dictionary with keys <span class="math notranslate nohighlight">\((i, j)\)</span> corresponding to 1D OT between
<span class="math notranslate nohighlight">\(\mathbf{P_{1, i}}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{P_{2, j}}\)</span> if <span class="math notranslate nohighlight">\(T^{g}_{ij} \neq 0\)</span>.</p></li>
<li><p><strong>T</strong> (array-like, shape <cite>(ns, nt)</cite>) – Coupling between the two spaces.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Convergence information for inner problems and qGW loss.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id86" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>68<span class="fn-bracket">]</span></span>
<p>Chowdhury, S., Miller, D., &amp; Needham, T. (2021).
Quantized gromov-wasserstein. ECML PKDD 2021. Springer International Publishing.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.sampled_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">sampled_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_samples_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_estimators.html#sampled_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.sampled_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the gromov-wasserstein transport between <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> and <span class="math notranslate nohighlight">\((\mathbf{C_2}, \mathbf{q})\)</span> using a 1-stochastic Frank-Wolfe.
This method has a <span class="math notranslate nohighlight">\(\mathcal{O}(\mathrm{max\_iter} \times N \log(N))\)</span> time complexity by relying on the 1D Optimal Transport solver.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{GW} = \mathop{\arg \min}_\mathbf{T} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\        \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}\\        \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}\)</span>: distribution in the target space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>loss_fun</strong> (function: <span class="math notranslate nohighlight">\(\mathbb{R} \times \mathbb{R} \mapsto \mathbb{R}\)</span>) – Loss function used for the distance, the transport plan does not depend on the loss function</p></li>
<li><p><strong>nb_samples_grad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Number of samples to approximate the gradient</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Weight of the Kullback-Leibler regularization</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Gives the distance estimated and the standard deviation</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two spaces</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id87" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></span>
<p>Kerdoncuff, Tanguy, Emonet, Rémi, Sebban, Marc
“Sampled Gromov Wasserstein.”
Machine Learning Journal (MLJ). 2021.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.semirelaxed_fgw_barycenters">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_fgw_barycenters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ys</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_structure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'barycenter'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstartT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_X</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'product'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#semirelaxed_fgw_barycenters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.semirelaxed_fgw_barycenters" title="Link to this definition"></a></dt>
<dd><p>Returns the Semi-relaxed Fused Gromov-Wasserstein barycenters of <cite>S</cite> measurable networks
with node features <span class="math notranslate nohighlight">\((\mathbf{C}_s, \mathbf{Y}_s, \mathbf{p}_s)_{1 \leq s \leq S}\)</span>
(see eq (44) in <span class="xref std std-ref">[48]</span>, estimated using the semi-relaxed FGW transports from Conditional Gradient solvers.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^*, \mathbf{Y}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}, \mathbf{Y}\in \mathbb{Y}^{N \times d}}
\quad \sum_s \lambda_s \mathrm{srFGW}_{\alpha}(\mathbf{C}_s, \mathbf{Y}_s, \mathbf{p}_s, \mathbf{C}, \mathbf{Y})\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}_s\)</span>: input feature matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}_s\)</span>: input metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}_s\)</span>: input distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Desired number of samples of the target barycenter</p></li>
<li><p><strong>Ys</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>array-like</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Features of all samples</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>array-like</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Structure matrices of all samples</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>array-like</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Masses of all samples.
If let to its default value None, uniform distributions are taken.</p></li>
<li><p><strong>lambdas</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>S</em><em>,</em><em>) </em><em>, </em><em>optional</em>) – List of the <cite>S</cite> spaces’ weights.
If let to its default value None, uniform weights are taken.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Alpha parameter for the srFGW divergence in <span class="math notranslate nohighlight">\(]0, 1[\)</span>.</p></li>
<li><p><strong>fixed_structure</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to fix the structure of the barycenter during the updates.</p></li>
<li><p><strong>fixed_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to fix the feature of the barycenter during the updates</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either structures are to be assumed symmetric or not. Default value is True.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>stop_criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'barycenter'.</em>) – Stop criterion taking values in [‘barycenter’, ‘loss’]. If set to ‘barycenter’
uses absolute norm variations of estimated barycenters. Else if set to ‘loss’
uses the relative variations of the loss.</p></li>
<li><p><strong>warmstartT</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of transport plans in the successive
fused gromov-wasserstein transport problems.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>N</em><em>)</em><em>, </em><em>optional</em>) – Initialization for the barycenters’ structure matrix. If not set
a random init is used.</p></li>
<li><p><strong>init_X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>d</em><em>)</em><em>, </em><em>optional</em>) – Initialization for the barycenters’ features. If not set a
random init is used.</p></li>
<li><p><strong>G0</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is &quot;product&quot;.</em>) – Initialization method for transport plans calling <a class="reference internal" href="#ot.gromov.semirelaxed_init_plan" title="ot.gromov.semirelaxed_init_plan"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.gromov.semirelaxed_init_plan()</span></code></a>,
and taking values in “product”, “random_product”, “random”, “fluid”,
“fluid_soft”, “spectral”, “spectral_soft”, “kmeans”, “kmeans_soft”.
Transport plans are used to deduce an initial barycenter structure
if <cite>init_C=None</cite>.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X</strong> (array-like, shape (<cite>N</cite>, <cite>d</cite>)) – Barycenters’ features</p></li>
<li><p><strong>C</strong> (array-like, shape (<cite>N</cite>, <cite>N</cite>)) – Barycenters’ structure matrix</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Only returned when log=True. It contains the keys:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}_s\)</span>: list of (<cite>N</cite>, <cite>ns</cite>) transport matrices from which target masses can be deduced.</p></li>
<li><p><span class="math notranslate nohighlight">\((\mathbf{M}_s)_s\)</span>: all distance matrices between the feature of the barycenter and the other features <span class="math notranslate nohighlight">\((dist(\mathbf{X}, \mathbf{Y}_s))_s\)</span> shape (<cite>N</cite>, <cite>ns</cite>)</p></li>
<li><p>values used in convergence evaluation.</p></li>
</ul>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id88" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.semirelaxed_fused_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_fused_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#semirelaxed_fused_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.semirelaxed_fused_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Computes the semi-relaxed Fused Gromov-Wasserstein transport between two graphs (see [48]).</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_{\mathbf{T}} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) T_{i,j} T_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> source weights (sum to 1)</p></li>
<li><p><cite>L</cite> is a loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<p>The algorithm used for solving the problem is conditional gradient as discussed in <span class="xref std std-ref">[48]</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>) or </em><em>string</em><em>, </em><em>optional</em>) – If <cite>G0=None</cite> the initial transport plan of the solver is <span class="math notranslate nohighlight">\(\mathbf{p} \frac{\mathbf{1}_{nt}}{nt}^\top\)</span>.
If G0 is a tensor it must satisfy marginal constraints and will be
used as initial transport of the solver.
if G0 is a string it will be interpreted as a method for
<a class="reference internal" href="#ot.gromov.semirelaxed_init_plan" title="ot.gromov.semirelaxed_init_plan"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.gromov.semirelaxed_init_plan()</span></code></a> taking values in “product”,
“random_product”, “random”, “fluid”, “fluid_soft”, “spectral”,
“spectral_soft”, “kmeans”, “kmeans_soft”.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed used in stochastic initialization methods.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) – Optimal transportation matrix for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id89">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id90" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id91" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
<aside class="footnote brackets" id="id92" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>62<span class="fn-bracket">]</span></span>
<p>H. Van Assel, C. Vincent-Cuaz, T. Vayer, R. Flamary, N. Courty.
“Interpolating between Clustering and Dimensionality Reduction with
Gromov-Wasserstein”. NeurIPS 2023 Workshop OTML.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.semirelaxed_fused_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_fused_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#semirelaxed_fused_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.semirelaxed_fused_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Computes the semi-relaxed FGW divergence between two graphs (see [48]).</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{srFGW}_{\alpha} = \min_{\mathbf{T}} \quad (1 - \alpha) \langle \mathbf{T}, \mathbf{M} \rangle_F +
\alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) T_{i,j} T_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{M}\)</span> is the (<cite>ns</cite>, <cite>nt</cite>) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span> source weights (sum to 1)</p></li>
<li><p><cite>L</cite> is a loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<p>The algorithm used for solving the problem is conditional gradient as
discussed in <span class="xref std std-ref">[48]</span></p>
<p>Note that when using backends, this loss function is differentiable wrt the
matrices (C1, C2) but not yet for the weights p.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space.</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>) or </em><em>string</em><em>, </em><em>optional</em>) – If <cite>G0=None</cite> the initial transport plan of the solver is <span class="math notranslate nohighlight">\(\mathbf{p} \frac{\mathbf{1}_{nt}}{nt}^\top\)</span>.
If G0 is a tensor it must satisfy marginal constraints and will be
used as initial transport of the solver.
if G0 is a string it will be interpreted as a method for
<a class="reference internal" href="#ot.gromov.semirelaxed_init_plan" title="ot.gromov.semirelaxed_init_plan"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.gromov.semirelaxed_init_plan()</span></code></a> taking values in “product”,
“random_product”, “random”, “fluid”, “fluid_soft”, “spectral”,
“spectral_soft”, “kmeans”, “kmeans_soft”.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed used in stochastic initialization methods.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Parameters can be directly passed to the ot.optim.cg solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>srfgw-divergence</strong> (<em>float</em>) – Semi-relaxed Fused Gromov-Wasserstein divergence for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="id93">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id94" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id95" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
<aside class="footnote brackets" id="id96" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>62<span class="fn-bracket">]</span></span>
<p>H. Van Assel, C. Vincent-Cuaz, T. Vayer, R. Flamary, N. Courty.
“Interpolating between Clustering and Dimensionality Reduction with
Gromov-Wasserstein”. NeurIPS 2023 Workshop OTML.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.semirelaxed_gromov_barycenters">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_gromov_barycenters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'barycenter'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmstartT</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'product'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#semirelaxed_gromov_barycenters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.semirelaxed_gromov_barycenters" title="Link to this definition"></a></dt>
<dd><p>Returns the Semi-relaxed Gromov-Wasserstein barycenters of <cite>S</cite> measured similarity matrices
<span class="math notranslate nohighlight">\((\mathbf{C}_s)_{1 \leq s \leq S}\)</span></p>
<p>The function solves the following optimization problem with block coordinate descent:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}} \quad \sum_s \lambda_s \mathrm{srGW}(\mathbf{C}_s, \mathbf{p}_s, \mathbf{C})\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}_s\)</span>: input metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}_s\)</span>: distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Size of the targeted barycenter</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrices</p></li>
<li><p><strong>ps</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Sample weights in the <cite>S</cite> spaces.
If let to its default value None, uniform distributions are taken.</p></li>
<li><p><strong>lambdas</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>S</em><em>,</em><em>) </em><em>, </em><em>optional</em>) – List of the <cite>S</cite> spaces’ weights.
If let to its default value None, uniform weights are taken.</p></li>
<li><p><strong>loss_fun</strong> (<em>callable</em><em>, </em><em>optional</em>) – tensor-matrix multiplication function based on specific loss function</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional.</em>) – Either structures are to be assumed symmetric or not. Default value is True.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>stop_criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'barycenter'.</em>) – Stop criterion taking values in [‘barycenter’, ‘loss’]. If set to ‘barycenter’
uses absolute norm variations of estimated barycenters. Else if set to ‘loss’
uses the relative variations of the loss.</p></li>
<li><p><strong>warmstartT</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either to perform warmstart of transport plans in the successive
fused gromov-wasserstein transport problems.s</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>N</em><em>)</em><em>, </em><em>optional.</em>) – Random initial value for the <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix provided by user.
Default is None and relies <cite>G0</cite> to produce an initial structure.</p></li>
<li><p><strong>G0</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'product'.</em>) – Initialization method for transport plans calling <a class="reference internal" href="#ot.gromov.semirelaxed_init_plan" title="ot.gromov.semirelaxed_init_plan"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.gromov.semirelaxed_init_plan()</span></code></a>,
and taking values in “product”, “random_product”, “random”, “fluid”,
“fluid_soft”, “spectral”, “spectral_soft”, “kmeans”, “kmeans_soft”.
Transport plans are used to deduce an initial barycenter structure
if <cite>init_C=None</cite>.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><em>RandomState instance</em><em>, </em><em>optional</em>) – Fix the seed for reproducibility</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>C</strong> (array-like, shape (<cite>N</cite>, <cite>N</cite>)) – Barycenters’ structure matrix</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Only returned when log=True. It contains the keys:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{T}\)</span>: list of (<cite>N</cite>, <cite>ns</cite>) transport matrices</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: (<cite>N</cite>,) barycenter weights</p></li>
<li><p>values used in convergence evaluation.</p></li>
</ul>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id97" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.semirelaxed_gromov_wasserstein">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_gromov_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#semirelaxed_gromov_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.semirelaxed_gromov_wasserstein" title="Link to this definition"></a></dt>
<dd><p>Returns the semi-relaxed Gromov-Wasserstein divergence transport from <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> to <span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span> (see [48]).</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{T}^* \in \mathop{\arg \min}_{\mathbf{T}} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity matrices</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>) or </em><em>string</em><em>, </em><em>optional</em>) – If <cite>G0=None</cite> the initial transport plan of the solver is <span class="math notranslate nohighlight">\(\mathbf{p} \frac{\mathbf{1}_{nt}}{nt}^\top\)</span>.
If G0 is a tensor it must satisfy marginal constraints and will be
used as initial transport of the solver.
if G0 is a string it will be interpreted as a method for
<a class="reference internal" href="#ot.gromov.semirelaxed_init_plan" title="ot.gromov.semirelaxed_init_plan"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.gromov.semirelaxed_init_plan()</span></code></a> taking values in “product”,
“random_product”, “random”, “fluid”, “fluid_soft”, “spectral”,
“spectral_soft”, “kmeans”, “kmeans_soft”.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed used in stochastic initialization methods.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><p><strong>T</strong> (array-like, shape (<cite>ns</cite>, <cite>nt</cite>)) –</p>
<p>Coupling between the two spaces that minimizes:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\)</span></p>
</div></blockquote>
</li>
<li><p><strong>log</strong> (<em>dict</em>) – Convergence information and loss.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id98" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
<aside class="footnote brackets" id="id99" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>62<span class="fn-bracket">]</span></span>
<p>H. Van Assel, C. Vincent-Cuaz, T. Vayer, R. Flamary, N. Courty.
“Interpolating between Clustering and Dimensionality Reduction with
Gromov-Wasserstein”. NeurIPS 2023 Workshop OTML.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.semirelaxed_gromov_wasserstein2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_gromov_wasserstein2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">G0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_rel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_abs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#semirelaxed_gromov_wasserstein2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.semirelaxed_gromov_wasserstein2" title="Link to this definition"></a></dt>
<dd><p>Returns the semi-relaxed Gromov-Wasserstein divergence from <span class="math notranslate nohighlight">\((\mathbf{C_1}, \mathbf{p})\)</span> to <span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span> (see [48]).</p>
<p>The function solves the following optimization problem using Conditional Gradient:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\text{srGW} = \min_{\mathbf{T}} \quad \sum_{i,j,k,l}
L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}\\s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}\\     \mathbf{T} &amp;\geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_1}\)</span>: Metric cost matrix in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C_2}\)</span>: Metric cost matrix in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{p}\)</span>: distribution in the source space</p></li>
<li><p><cite>L</cite>: loss function to account for the misfit between the similarity
matrices</p></li>
</ul>
<p>Note that when using backends, this loss function is differentiable wrt the
matrices (C1, C2) but not yet for the weights p.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is backend-compatible and will work on arrays
from all compatible backends. However all the steps in the conditional
gradient are not differentiable.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional</em>) – Distribution in the source space.
If let to its default value None, uniform distribution is taken.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either C1 and C2 are to be assumed symmetric or not.
If let to its default None value, a symmetry test will be conducted.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>G0</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>) or </em><em>string</em><em>, </em><em>optional</em>) – If <cite>G0=None</cite> the initial transport plan of the solver is <span class="math notranslate nohighlight">\(\mathbf{p} \frac{\mathbf{1}_{nt}}{nt}^\top\)</span>.
If G0 is a tensor it must satisfy marginal constraints and will be
used as initial transport of the solver.
if G0 is a string it will be interpreted as a method for
<a class="reference internal" href="#ot.gromov.semirelaxed_init_plan" title="ot.gromov.semirelaxed_init_plan"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.gromov.semirelaxed_init_plan()</span></code></a> taking values in “product”,
“random_product”, “random”, “fluid”, “fluid_soft”, “spectral”,
“spectral_soft”, “kmeans”, “kmeans_soft”.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol_rel</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative error (&gt;0)</p></li>
<li><p><strong>tol_abs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on absolute error (&gt;0)</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed used in stochastic initialization methods.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>srgw</strong> (<em>float</em>) – Semi-relaxed Gromov-Wasserstein divergence</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – convergence information and Coupling matrix</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id100" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
<aside class="footnote brackets" id="id101" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>62<span class="fn-bracket">]</span></span>
<p>H. Van Assel, C. Vincent-Cuaz, T. Vayer, R. Flamary, N. Courty.
“Interpolating between Clustering and Dimensionality Reduction with
Gromov-Wasserstein”. NeurIPS 2023 Workshop OTML.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.semirelaxed_init_plan">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">semirelaxed_init_plan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'product'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_target</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#semirelaxed_init_plan"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.semirelaxed_init_plan" title="Link to this definition"></a></dt>
<dd><p>Heuristics to initialize the semi-relaxed (F)GW transport plan
<span class="math notranslate nohighlight">\(\mathbf{T} \in \mathcal{U}_{nt}(\mathbf{p})\)</span>, between a graph
<span class="math notranslate nohighlight">\((\mathbf{C1}, \mathbf{p})\)</span> and a structure matrix <span class="math notranslate nohighlight">\(\mathbf{C2}\)</span>,
where <span class="math notranslate nohighlight">\(\mathcal{U}_{nt}(\mathbf{p}) = \{\mathbf{T} \in \mathbb{R}_{+}^{ns * nt}, \mathbf{T} \mathbf{1}_{nt} = \mathbf{p} \}\)</span>.
Available methods are:</p>
<blockquote>
<div><ul class="simple">
<li><p>“product” or “random_product”: <span class="math notranslate nohighlight">\(\mathbf{T} = \mathbf{pq}^{T}\)</span>
with <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> uniform or randomly samples in the nt probability simplex.</p></li>
<li><p>“random”: random sampling in <span class="math notranslate nohighlight">\(\mathcal{U}_{nt}(\mathbf{p})\)</span>.</p></li>
<li><p>“fluid”: Fluid algorithm from networkx for graph partitioning.</p></li>
<li><p>“spectral”, “kmeans” : Spectral or Kmeans clustering from sklearn.</p></li>
<li><p>“fluid_soft”, “spectral_soft”, “kmeans_soft”: <span class="math notranslate nohighlight">\(\mathbf{T}_0\)</span> given
by corresponding clustering with target marginal <span class="math notranslate nohighlight">\(\mathbf{q}_0\)</span>, further
centered as <span class="math notranslate nohighlight">\(\mathbf{T} = (\mathbf{T}_0 + \mathbf{pq}_0^T) / 2\)</span> .</p></li>
</ul>
</div></blockquote>
<p>If a metric cost matrix between features across domains <span class="math notranslate nohighlight">\(\mathbf{M}\)</span>
is a provided, it will be used as cost matrix in a semi-relaxed Wasserstein
problem providing <span class="math notranslate nohighlight">\(\mathbf{T}_M \in \mathcal{U}_{nt}(\mathbf{p})\)</span>. Then
the outputted transport plan is <span class="math notranslate nohighlight">\(\alpha \mathbf{T}  + (1 - \alpha ) \mathbf{T}_{M}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space.</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>, </em><em>optional.</em>) – Probability distribution in the source space. If let to None, uniform
weights are assumed on C1.</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional.</em>) – Metric cost matrix between features across domains.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt;= alpha &lt;= 1)</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Method to initialize the transport plan. The default is ‘product’.</p></li>
<li><p><strong>use_target</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional.</em>) – Whether or not to use the target structure/features to further align
transport plan provided by the <cite>method</cite>.</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Random seed used for stochastic methods.</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – POT backend.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>T</strong> – Admissible transport plan for the sr(F)GW problems.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (ns, ns)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id102" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.solve_gromov_linesearch">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">solve_gromov_linesearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltaG</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">symmetric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_gw.html#solve_gromov_linesearch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.solve_gromov_linesearch" title="Link to this definition"></a></dt>
<dd><p>Solve the linesearch in the FW iterations for any inner loss that decomposes as in Proposition 1 in <a class="reference internal" href="#references-solve-linesearch"><span class="std std-ref">[12]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>G</strong> (<em>array-like</em><em>, </em><em>shape</em><em>(</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – The transport map at a given iteration of the FW</p></li>
<li><p><strong>deltaG</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – Difference between the optimal map found by linearization in the FW algorithm and the value at a given iteration</p></li>
<li><p><strong>cost_G</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Value of the cost at <cite>G</cite></p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em><em>, </em><em>optional</em>) – Transformed Structure matrix in the source domain.
For the ‘square_loss’ and ‘kl_loss’, we provide hC1 from ot.gromov.init_matrix</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em> (</em><em>nt</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Transformed Structure matrix in the source domain.
For the ‘square_loss’ and ‘kl_loss’, we provide hC2 from ot.gromov.init_matrix</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – Cost matrix between the features.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization parameter.</p></li>
<li><p><strong>alpha_min</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Minimum value for alpha</p></li>
<li><p><strong>alpha_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Maximum value for alpha</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
<li><p><strong>symmetric</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Either structures are to be assumed symmetric or not. Default value is False.
Else if set to True (resp. False), C1 and C2 will be assumed symmetric (resp. asymmetric).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>) – The optimal step size of the FW</p></li>
<li><p><strong>fc</strong> (<em>int</em>) – nb of function call. Useless here</p></li>
<li><p><strong>cost_G</strong> (<em>float</em>) – The value of the cost for the next iteration</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric" id="references-solve-linesearch">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id103" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain and Courty Nicolas
“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id104" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.solve_partial_gromov_linesearch">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">solve_partial_gromov_linesearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltaG</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df_G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df_Gc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_partial.html#solve_partial_gromov_linesearch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.solve_partial_gromov_linesearch" title="Link to this definition"></a></dt>
<dd><p>Solve the linesearch in the FW iterations of partial (F)GW following eq.5 of <span class="xref std std-ref">[29]</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>G</strong> (<em>array-like</em><em>, </em><em>shape</em><em>(</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – The transport map at a given iteration of the FW</p></li>
<li><p><strong>deltaG</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Difference between the optimal map <cite>Gc</cite> found by linearization in the
FW algorithm and the value at a given iteration</p></li>
<li><p><strong>cost_G</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Value of the cost at <cite>G</cite></p></li>
<li><p><strong>df_G</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Gradient of the GW cost at <cite>G</cite></p></li>
<li><p><strong>df_Gc</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Gradient of the GW cost at <cite>Gc</cite></p></li>
<li><p><strong>M</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Cost matrix between the features.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization parameter.</p></li>
<li><p><strong>alpha_min</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Minimum value for alpha</p></li>
<li><p><strong>alpha_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Maximum value for alpha</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>) – The optimal step size of the FW</p></li>
<li><p><strong>fc</strong> (<em>int</em>) – nb of function call. Useless here</p></li>
<li><p><strong>cost_G</strong> (<em>float</em>) – The value of the cost for the next iteration</p></li>
<li><p><strong>df_G</strong> (<em>array-like, shape (ns, nt)</em>) – Updated gradient of the GW cost</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id105" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></span>
<p>Chapel, L., Alaya, M., Gasso, G. (2020). “Partial Optimal
Transport with Applications on Positive-Unlabeled Learning”.
NeurIPS.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.solve_semirelaxed_gromov_linesearch">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">solve_semirelaxed_gromov_linesearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltaG</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_G</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ones_p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fC2t</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_semirelaxed.html#solve_semirelaxed_gromov_linesearch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.solve_semirelaxed_gromov_linesearch" title="Link to this definition"></a></dt>
<dd><p>Solve the linesearch in the Conditional Gradient iterations for the semi-relaxed Gromov-Wasserstein divergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>G</strong> (<em>array-like</em><em>, </em><em>shape</em><em>(</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – The transport map at a given iteration of the FW</p></li>
<li><p><strong>deltaG</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – Difference between the optimal map found by linearization in the FW algorithm and the value at a given iteration</p></li>
<li><p><strong>cost_G</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Value of the cost at <cite>G</cite></p></li>
<li><p><strong>C1</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em><em>, </em><em>optional</em>) – Transformed Structure matrix in the source domain.
Note that for the ‘square_loss’ and ‘kl_loss’, we provide hC1 from ot.gromov.init_matrix_semirelaxed</p></li>
<li><p><strong>C2</strong> (<em>array-like</em><em> (</em><em>nt</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Transformed Structure matrix in the source domain.
Note that for the ‘square_loss’ and ‘kl_loss’, we provide hC2 from ot.gromov.init_matrix_semirelaxed</p></li>
<li><p><strong>ones_p</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>1</em><em>)</em>) – Array of ones of size ns</p></li>
<li><p><strong>M</strong> (<em>array-like</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – Cost matrix between the features.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Regularization parameter.</p></li>
<li><p><strong>fC2t</strong> (<em>array-like</em><em> (</em><em>nt</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Transformed Structure matrix in the source domain.
Note that for the ‘square_loss’ and ‘kl_loss’, we provide fC2t from ot.gromov.init_matrix_semirelaxed.
If fC2t is not provided, it is by default fC2t corresponding to the ‘square_loss’.</p></li>
<li><p><strong>alpha_min</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Minimum value for alpha</p></li>
<li><p><strong>alpha_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Maximum value for alpha</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>) – The optimal step size of the FW</p></li>
<li><p><strong>fc</strong> (<em>int</em>) – nb of function call. Useless here</p></li>
<li><p><strong>cost_G</strong> (<em>float</em>) – The value of the cost for the next iteration</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id106" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2021.</p>
</aside>
<aside class="footnote brackets" id="id107" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>62<span class="fn-bracket">]</span></span>
<p>H. Van Assel, C. Vincent-Cuaz, T. Vayer, R. Flamary, N. Courty.
“Interpolating between Clustering and Dimensionality Reduction with
Gromov-Wasserstein”. NeurIPS 2023 Workshop OTML.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.tensor_product">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">tensor_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constC</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hC1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hC2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#tensor_product"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.tensor_product" title="Link to this definition"></a></dt>
<dd><p>Return the tensor for Gromov-Wasserstein fast computation</p>
<p>The tensor is computed as described in Proposition 1 Eq. (6) in <a class="reference internal" href="#references-tensor-product"><span class="std std-ref">[12]</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constC</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Constant <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC1</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h1}(\mathbf{C1})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – <span class="math notranslate nohighlight">\(\mathbf{h2}(\mathbf{C2})\)</span> matrix in Eq. (6)</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>tens</strong> – <span class="math notranslate nohighlight">\(\mathcal{L}(\mathbf{C_1}, \mathbf{C_2}) \otimes \mathbf{T}\)</span> tensor-matrix multiplication result</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>ns</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric" id="references-tensor-product">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id108" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.unbalanced_co_optimal_transport">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">unbalanced_co_optimal_transport</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wx_samp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wx_feat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wy_samp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wy_feat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_marginals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">divergence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'kl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unbalanced_solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M_samp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M_feat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rescale_plan</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_pi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_duals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_ot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_ot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs_solve</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_unbalanced.html#unbalanced_co_optimal_transport"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.unbalanced_co_optimal_transport" title="Link to this definition"></a></dt>
<dd><p>Compute the unbalanced Co-Optimal Transport between two Euclidean point clouds
(represented as matrices whose rows are samples and columns are the features/dimensions).</p>
<p>More precisely, this function returns the sample and feature transport plans between
<span class="math notranslate nohighlight">\((\mathbf{X}, \mathbf{w}_{xs}, \mathbf{w}_{xf})\)</span> and
<span class="math notranslate nohighlight">\((\mathbf{Y}, \mathbf{w}_{ys}, \mathbf{w}_{yf})\)</span>,
by solving the following problem using Block Coordinate Descent algorithm:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathop{\arg \min}_{\mathbf{P}, \mathbf{Q}} &amp;\quad \sum_{i,j,k,l}
(\mathbf{X}_{i,k} - \mathbf{Y}_{j,l})^2 \mathbf{P}_{i,j} \mathbf{Q}_{k,l} \\
&amp;+ \rho_s \mathbf{Div}(\mathbf{P}_{\# 1} \mathbf{Q}_{\# 1}^T | \mathbf{w}_{xs} \mathbf{w}_{ys}^T)
+ \rho_f \mathbf{Div}(\mathbf{P}_{\# 2} \mathbf{Q}_{\# 2}^T | \mathbf{w}_{xf} \mathbf{w}_{yf}^T) \\
&amp;+ \alpha_s \sum_{i,j} \mathbf{P}_{i,j} \mathbf{M^{(s)}}_{i, j}
+ \alpha_f \sum_{k, l} \mathbf{Q}_{k,l} \mathbf{M^{(f)}}_{k, l} \\
&amp;+ \varepsilon_s \mathbf{Div}(\mathbf{P} | \mathbf{w}_{xs} \mathbf{w}_{ys}^T)
+ \varepsilon_f \mathbf{Div}(\mathbf{Q} | \mathbf{w}_{xf} \mathbf{w}_{yf}^T)\end{split}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{X}\)</span>: Source input (arbitrary-size) matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}\)</span>: Target input (arbitrary-size) matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M^{(s)}}\)</span>: Additional sample matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M^{(f)}}\)</span>: Additional feature matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}_{xs}\)</span>: Distribution of the samples in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}_{xf}\)</span>: Distribution of the features in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}_{ys}\)</span>: Distribution of the samples in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}_{yf}\)</span>: Distribution of the features in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Div}\)</span>: Either Kullback-Leibler divergence or half-squared L2 norm.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function allows <cite>epsilon</cite> to be zero. In that case, <cite>unbalanced_method</cite> must be either “mm” or “lbfgsb”.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>n_feature_x</em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Source input matrix.</p></li>
<li><p><strong>Y</strong> (<em>(</em><em>n_sample_y</em><em>, </em><em>n_feature_y</em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Target input matrix.</p></li>
<li><p><strong>wx_samp</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on rows (samples) of matrix X.
Uniform distribution by default.</p></li>
<li><p><strong>wx_feat</strong> (<em>(</em><em>n_feature_x</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on columns (features) of matrix X.
Uniform distribution by default.</p></li>
<li><p><strong>wy_samp</strong> (<em>(</em><em>n_sample_y</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on rows (samples) of matrix Y.
Uniform distribution by default.</p></li>
<li><p><strong>wy_feat</strong> (<em>(</em><em>n_feature_y</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on columns (features) of matrix Y.
Uniform distribution by default.</p></li>
<li><p><strong>reg_marginals</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><em>indexable object</em><em> of </em><em>length 1</em><em> or </em><em>2</em>) – Marginal relaxation terms for sample and feature couplings.
If <cite>reg_marginals is a scalar</cite> or an indexable object of length 1,
then the same value is applied to both marginal relaxations.</p></li>
<li><p><strong>epsilon</strong> (<em>scalar</em><em> or </em><em>indexable object</em><em> of </em><em>length 2</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 0</em><em>)</em>) – Regularization parameters for entropic approximation of sample and feature couplings.
Allow the case where <cite>epsilon</cite> contains 0. In that case, the MM solver is used by default
instead of Sinkhorn solver. If <cite>epsilon</cite> is scalar, then the same value is applied to
both regularization of sample and feature couplings.</p></li>
<li><p><strong>divergence</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default = &quot;kl&quot;</em><em>)</em>) – <ul>
<li><p>If <cite>divergence</cite> = “kl”, then Div is the Kullback-Leibler divergence.</p></li>
<li><p>If <cite>divergence</cite> = “l2”, then Div is the half squared Euclidean norm.</p></li>
</ul>
</p></li>
<li><p><strong>unbalanced_solver</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default = &quot;sinkhorn&quot;</em><em>)</em>) – <p>Solver for the unbalanced OT subroutine.</p>
<ul>
<li><p>If <cite>divergence</cite> = “kl”, then <cite>unbalanced_solver</cite> can be: “sinkhorn”, “sinkhorn_log”, “mm”, “lbfgsb”</p></li>
<li><p>If <cite>divergence</cite> = “l2”, then <cite>unbalanced_solver</cite> can be “mm”, “lbfgsb”</p></li>
</ul>
</p></li>
<li><p><strong>alpha</strong> (<em>scalar</em><em> or </em><em>indexable object</em><em> of </em><em>length 2</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 0</em><em>)</em>) – Coeffficient parameter of linear terms with respect to the sample and feature couplings.
If alpha is scalar, then the same alpha is applied to both linear terms.</p></li>
<li><p><strong>M_samp</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>n_sample_y</em><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Sample matrix associated to the Wasserstein linear term on sample coupling.</p></li>
<li><p><strong>M_feat</strong> (<em>(</em><em>n_feature_x</em><em>, </em><em>n_feature_y</em><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Feature matrix associated to the Wasserstein linear term on feature coupling.</p></li>
<li><p><strong>rescale_plan</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default = True</em><em>)</em>) – If True, then rescale the sample and feature transport plans within each BCD iteration,
so that they always have equal mass.</p></li>
<li><p><strong>init_pi</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>two matrices</em><em> of </em><em>size</em><em> (</em><em>n_sample_x</em><em>, </em><em>n_sample_y</em><em>) </em><em>and</em>) – (n_feature_x, n_feature_y), optional (default = None).
Initialization of sample and feature couplings.
Uniform distributions by default.</p></li>
<li><p><strong>init_duals</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>two tuples</em><em> (</em><em>(</em><em>n_sample_x</em><em>, </em><em>)</em><em>, </em><em>(</em><em>n_sample_y</em><em>, </em><em>)</em><em>) </em><em>and</em><em> (</em><em>(</em><em>n_feature_x</em><em>, </em><em>)</em><em>, </em><em>(</em><em>n_feature_y</em><em>, </em><em>)</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em><em>.</em>) – Initialization of sample and feature dual vectors
if using Sinkhorn algorithm. Zero vectors by default.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 100</em><em>)</em>) – Number of Block Coordinate Descent (BCD) iterations.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = 1e-7</em><em>)</em>) – Tolerance of BCD scheme. If the L1-norm between the current and previous
sample couplings is under this threshold, then stop BCD scheme.</p></li>
<li><p><strong>max_iter_ot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 100</em><em>)</em>) – Number of iterations to solve each of the
two unbalanced optimal transport problems in each BCD iteration.</p></li>
<li><p><strong>tol_ot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = 1e-7</em><em>)</em>) – Tolerance of unbalanced solver for each of the
two unbalanced optimal transport problems in each BCD iteration.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default = False</em><em>)</em>) – If True then the cost and four dual vectors, including
two from sample and two from feature couplings, are recorded.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default = False</em><em>)</em>) – If True then print the COOT cost at every multiplier of <cite>eval_bcd</cite>-th iteration.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><p><strong>pi_samp</strong> (<em>(n_sample_x, n_sample_y) array-like, float</em>) – Sample coupling matrix.</p></li>
<li><p><strong>pi_feat</strong> (<em>(n_feature_x, n_feature_y) array-like, float</em>) – Feature coupling matrix.</p></li>
<li><p><strong>log</strong> (<em>dictionary, optional</em>) –</p>
<p>Returned if <cite>log</cite> is True. The keys are:</p>
<blockquote>
<div><dl class="simple">
<dt>error<span class="classifier">array-like, float</span></dt><dd><p>list of L1 norms between the current and previous sample coupling.</p>
</dd>
<dt>duals_sample<span class="classifier">(n_sample_x, n_sample_y)-tuple, float</span></dt><dd><p>Pair of dual vectors when solving OT problem w.r.t the sample coupling.</p>
</dd>
<dt>duals_feature<span class="classifier">(n_feature_x, n_feature_y)-tuple, float</span></dt><dd><p>Pair of dual vectors when solving OT problem w.r.t the feature coupling.</p>
</dd>
<dt>linear<span class="classifier">float</span></dt><dd><p>Linear part of the cost.</p>
</dd>
<dt>ucoot<span class="classifier">float</span></dt><dd><p>Total cost.</p>
</dd>
</dl>
</div></blockquote>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id109" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>71<span class="fn-bracket">]</span></span>
<p>Tran, H., Janati, H., Courty, N., Flamary, R., Redko, I., Demetci, P., &amp; Singh, R.
Unbalanced Co-Optimal Transport. AAAI Conference on Artificial Intelligence, 2023.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.unbalanced_co_optimal_transport2">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">unbalanced_co_optimal_transport2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wx_samp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wx_feat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wy_samp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wy_feat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_marginals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">divergence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'kl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unbalanced_solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sinkhorn'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M_samp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M_feat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rescale_plan</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_pi</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_duals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_ot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol_ot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs_solve</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_unbalanced.html#unbalanced_co_optimal_transport2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.unbalanced_co_optimal_transport2" title="Link to this definition"></a></dt>
<dd><p>Compute the unbalanced Co-Optimal Transport between two Euclidean point clouds
(represented as matrices whose rows are samples and columns are the features/dimensions).</p>
<p>More precisely, this function returns the unbalanced Co-Optimal Transport cost between
<span class="math notranslate nohighlight">\((\mathbf{X}, \mathbf{w}_{xs}, \mathbf{w}_{xf})\)</span> and
<span class="math notranslate nohighlight">\((\mathbf{Y}, \mathbf{w}_{ys}, \mathbf{w}_{yf})\)</span>,
by solving the following problem using Block Coordinate Descent algorithm:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathop{\min}_{\mathbf{P}, \mathbf{Q}} &amp;\quad \sum_{i,j,k,l}
(\mathbf{X}_{i,k} - \mathbf{Y}_{j,l})^2 \mathbf{P}_{i,j} \mathbf{Q}_{k,l} \\
&amp;+ \rho_s \mathbf{Div}(\mathbf{P}_{\# 1} \mathbf{Q}_{\# 1}^T | \mathbf{w}_{xs} \mathbf{w}_{ys}^T)
+ \rho_f \mathbf{Div}(\mathbf{P}_{\# 2} \mathbf{Q}_{\# 2}^T | \mathbf{w}_{xf} \mathbf{w}_{yf}^T) \\
&amp;+ \alpha_s \sum_{i,j} \mathbf{P}_{i,j} \mathbf{M^{(s)}}_{i, j}
+ \alpha_f \sum_{k, l} \mathbf{Q}_{k,l} \mathbf{M^{(f)}}_{k, l} \\
&amp;+ \varepsilon_s \mathbf{Div}(\mathbf{P} | \mathbf{w}_{xs} \mathbf{w}_{ys}^T)
+ \varepsilon_f \mathbf{Div}(\mathbf{Q} | \mathbf{w}_{xf} \mathbf{w}_{yf}^T)\end{split}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{X}\)</span>: Source input (arbitrary-size) matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}\)</span>: Target input (arbitrary-size) matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M^{(s)}}\)</span>: Additional sample matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{M^{(f)}}\)</span>: Additional feature matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}_{xs}\)</span>: Distribution of the samples in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}_{xf}\)</span>: Distribution of the features in the source space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}_{ys}\)</span>: Distribution of the samples in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}_{yf}\)</span>: Distribution of the features in the target space</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Div}\)</span>: Either Kullback-Leibler divergence or half-squared L2 norm.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function allows <cite>epsilon</cite> to be zero. In that case, <cite>unbalanced_method</cite> must be either “mm” or “lbfgsb”.
Also the computation of gradients is only supported for KL divergence. The case of half squared-L2 norm uses those of KL divergence.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>n_feature_x</em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Source input matrix.</p></li>
<li><p><strong>Y</strong> (<em>(</em><em>n_sample_y</em><em>, </em><em>n_feature_y</em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – Target input matrix.</p></li>
<li><p><strong>wx_samp</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on rows (samples) of matrix X.
Uniform distribution by default.</p></li>
<li><p><strong>wx_feat</strong> (<em>(</em><em>n_feature_x</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on columns (features) of matrix X.
Uniform distribution by default.</p></li>
<li><p><strong>wy_samp</strong> (<em>(</em><em>n_sample_y</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on rows (samples) of matrix Y.
Uniform distribution by default.</p></li>
<li><p><strong>wy_feat</strong> (<em>(</em><em>n_feature_y</em><em>, </em><em>) </em><em>array-like</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Histogram assigned on columns (features) of matrix Y.
Uniform distribution by default.</p></li>
<li><p><strong>reg_marginals</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><em>indexable object</em><em> of </em><em>length 1</em><em> or </em><em>2</em>) – Marginal relaxation terms for sample and feature couplings.
If <cite>reg_marginals</cite> is a scalar or an indexable object of length 1,
then the same value is applied to both marginal relaxations.</p></li>
<li><p><strong>epsilon</strong> (<em>scalar</em><em> or </em><em>indexable object</em><em> of </em><em>length 2</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 0</em><em>)</em>) – Regularization parameters for entropic approximation of sample and feature couplings.
Allow the case where <cite>epsilon</cite> contains 0. In that case, the MM solver is used by default
instead of Sinkhorn solver. If <cite>epsilon</cite> is scalar, then the same value is applied to
both regularization of sample and feature couplings.</p></li>
<li><p><strong>divergence</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default = &quot;kl&quot;</em><em>)</em>) – <ul>
<li><p>If <cite>divergence</cite> = “kl”, then Div is the Kullback-Leibler divergence.</p></li>
<li><p>If <cite>divergence</cite> = “l2”, then Div is the half squared Euclidean norm.</p></li>
</ul>
</p></li>
<li><p><strong>unbalanced_solver</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default = &quot;sinkhorn&quot;</em><em>)</em>) – <p>Solver for the unbalanced OT subroutine.</p>
<ul>
<li><p>If <cite>divergence</cite> = “kl”, then <cite>unbalanced_solver</cite> can be: “sinkhorn”, “sinkhorn_log”, “mm”, “lbfgsb”</p></li>
<li><p>If <cite>divergence</cite> = “l2”, then <cite>unbalanced_solver</cite> can be “mm”, “lbfgsb”</p></li>
</ul>
</p></li>
<li><p><strong>alpha</strong> (<em>scalar</em><em> or </em><em>indexable object</em><em> of </em><em>length 2</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 0</em><em>)</em>) – Coeffficient parameter of linear terms with respect to the sample and feature couplings.
If alpha is scalar, then the same alpha is applied to both linear terms.</p></li>
<li><p><strong>M_samp</strong> (<em>(</em><em>n_sample_x</em><em>, </em><em>n_sample_y</em><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Sample matrix associated to the Wasserstein linear term on sample coupling.</p></li>
<li><p><strong>M_feat</strong> (<em>(</em><em>n_feature_x</em><em>, </em><em>n_feature_y</em><em>)</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em>) – Feature matrix associated to the Wasserstein linear term on feature coupling.</p></li>
<li><p><strong>rescale_plan</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default = True</em><em>)</em>) – If True, then rescale the transport plans in each BCD iteration,
so that they always have equal mass.</p></li>
<li><p><strong>init_pi</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>two matrices</em><em> of </em><em>size</em><em> (</em><em>n_sample_x</em><em>, </em><em>n_sample_y</em><em>) </em><em>and</em>) – (n_feature_x, n_feature_y), optional (default = None).
Initialization of sample and feature couplings.
Uniform distributions by default.</p></li>
<li><p><strong>init_duals</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>two tuples</em><em> (</em><em>(</em><em>n_sample_x</em><em>, </em><em>)</em><em>, </em><em>(</em><em>n_sample_y</em><em>, </em><em>)</em><em>) </em><em>and</em><em> (</em><em>(</em><em>n_feature_x</em><em>, </em><em>)</em><em>, </em><em>(</em><em>n_feature_y</em><em>, </em><em>)</em><em>)</em><em>, </em><em>optional</em><em> (</em><em>default = None</em><em>)</em><em>.</em>) – Initialization of sample and feature dual vectors
if using Sinkhorn algorithm. Zero vectors by default.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 100</em><em>)</em>) – Number of Block Coordinate Descent (BCD) iterations.</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = 1e-7</em><em>)</em>) – Tolerance of BCD scheme. If the L1-norm between the current and previous
sample couplings is under this threshold, then stop BCD scheme.</p></li>
<li><p><strong>max_iter_ot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default = 100</em><em>)</em>) – Number of iterations to solve each of the
two unbalanced optimal transport problems in each BCD iteration.</p></li>
<li><p><strong>tol_ot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default = 1e-7</em><em>)</em>) – Tolerance of unbalanced solver for each of the
two unbalanced optimal transport problems in each BCD iteration.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default = False</em><em>)</em>) – If True then the cost and four dual vectors, including
two from sample and two from feature couplings, are recorded.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default = False</em><em>)</em>) – If True then print the COOT cost at every multiplier of <cite>eval_bcd</cite>-th iteration.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><p><strong>ucoot</strong> (<em>float</em>) – UCOOT cost.</p></li>
<li><p><strong>log</strong> (<em>dictionary, optional</em>) –</p>
<p>Returned if <cite>log</cite> is True. The keys are:</p>
<blockquote>
<div><dl class="simple">
<dt>error<span class="classifier">array-like, float</span></dt><dd><p>list of L1 norms between the current and previous sample coupling.</p>
</dd>
<dt>duals_sample<span class="classifier">(n_sample_x, n_sample_y)-tuple, float</span></dt><dd><p>Pair of dual vectors when solving OT problem w.r.t the sample coupling.</p>
</dd>
<dt>duals_feature<span class="classifier">(n_feature_x, n_feature_y)-tuple, float</span></dt><dd><p>Pair of dual vectors when solving OT problem w.r.t the feature coupling.</p>
</dd>
<dt>linear<span class="classifier">float</span></dt><dd><p>Linear part of UCOOT cost.</p>
</dd>
<dt>ucoot<span class="classifier">float</span></dt><dd><p>UCOOT cost.</p>
</dd>
<dt>backend</dt><dd><p>The proper backend for all input arrays</p>
</dd>
</dl>
</div></blockquote>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id110" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>71<span class="fn-bracket">]</span></span>
<p>Tran, H., Janati, H., Courty, N., Flamary, R., Redko, I., Demetci, P., &amp; Singh, R.
Unbalanced Co-Optimal Transport. AAAI Conference on Artificial Intelligence, 2023.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.uot_cost_matrix">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">uot_cost_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tuple_p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">divergence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#uot_cost_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.uot_cost_matrix" title="Link to this definition"></a></dt>
<dd><p>The Block Coordinate Descent algorithm for FUGW and UCOOT
requires solving an UOT problem in each iteration.
In particular, we need to specify the following inputs:</p>
<ul class="simple">
<li><p>Cost matrix</p></li>
<li><p>Hyperparameters (marginal-relaxations and regularization)</p></li>
<li><p>Reference measures in the marginal-relaxation and regularization terms</p></li>
</ul>
<p>This method returns the cost matrix.
The method <a class="reference internal" href="#ot.gromov.uot_parameters_and_measures" title="ot.gromov.uot_parameters_and_measures"><code class="xref any py py-func docutils literal notranslate"><span class="pre">ot.gromov.uot_parameters_and_measures</span></code></a> returns the rest of the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>arrays</em>) – vector or matrix</p></li>
<li><p><strong>pi</strong> (<em>array-like</em>) – vector or matrix</p></li>
<li><p><strong>tuple_p</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>arrays</em>) – Tuple of reference measures in the marginal-relaxation terms
w.r.t the (either sample or feature) coupling</p></li>
<li><p><strong>hyperparams</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>floats</em>) – Hyperparameters of marginal-relaxation and regularization terms
in the fused unbalanced across-domain divergence</p></li>
<li><p><strong>divergence</strong> (<em>string</em><em>, </em><em>default = &quot;kl&quot;</em>) – Bregman divergence, either “kl” (Kullback-Leibler divergence) or “l2” (half-squared L2 divergence)</p></li>
<li><p><strong>reg_type</strong> (<em>string</em><em>,</em>) – <p>Type of regularization term in the fused unbalanced across-domain divergence</p>
<ul>
<li><p><cite>reg_type = “joint”</cite> corresponds to FUGW</p></li>
<li><p><cite>reg_type = “independent”</cite> corresponds to UCOOT</p></li>
</ul>
</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Cost matrix of the UOT subroutine for UCOOT and FUGW</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.uot_parameters_and_measures">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">uot_parameters_and_measures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tuple_weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyperparams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">divergence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#uot_parameters_and_measures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.uot_parameters_and_measures" title="Link to this definition"></a></dt>
<dd><p>The Block Coordinate Descent algorithm for FUGW and UCOOT
requires solving an UOT problem in each iteration.
In particular, we need to specify the following inputs:</p>
<ul class="simple">
<li><p>Cost matrix</p></li>
<li><p>Hyperparameters (marginal-relaxations and regularization)</p></li>
<li><p>Reference measures in the marginal-relaxation and regularization terms</p></li>
</ul>
<p>The method <a class="reference internal" href="#ot.gromov.uot_cost_matrix" title="ot.gromov.uot_cost_matrix"><code class="xref any py py-func docutils literal notranslate"><span class="pre">ot.gromov.uot_cost_matrix</span></code></a> returns the cost matrix.
This method returns the rest of the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pi</strong> (<em>array-like</em>) – vector or matrix</p></li>
<li><p><strong>tuple_weights</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>arrays</em>) – Tuple of reference measures in the marginal-relaxation and regularization terms
w.r.t the (either sample or feature) coupling</p></li>
<li><p><strong>hyperparams</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em> of </em><em>floats</em>) – Hyperparameters of marginal-relaxation and regularization terms
in the fused unbalanced across-domain divergence</p></li>
<li><p><strong>reg_type</strong> (<em>string</em><em>,</em>) – <p>Type of regularization term in the fused unbalanced across-domain divergence</p>
<ul>
<li><p><cite>reg_type = “joint”</cite> corresponds to FUGW</p></li>
<li><p><cite>reg_type = “independent”</cite> corresponds to UCOOT</p></li>
</ul>
</p></li>
<li><p><strong>divergence</strong> (<em>string</em><em>, </em><em>default = &quot;kl&quot;</em>) – Bregman divergence, either “kl” (Kullback-Leibler divergence) or “l2” (half-squared L2 divergence)</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of hyperparameters and distributions (weights)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.update_barycenter_feature">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">update_barycenter_feature</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Ts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ys</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_zeros</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#update_barycenter_feature"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.update_barycenter_feature" title="Link to this definition"></a></dt>
<dd><p>Updates the feature with respect to the <cite>S</cite> <span class="math notranslate nohighlight">\(\mathbf{T}_s\)</span>
couplings calculated at each iteration of variants of the FGW
barycenter problem with inner wasserstein loss <cite>loss_fun</cite>
(e.g FGW <span class="xref std std-ref">[24]</span>, srFGW <span class="xref std std-ref">[48]</span>).
If <cite>target=True</cite> the barycenter is considered as the target else as the source.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Ts</strong> (list of S array-like of shape (ns, N) if <cite>target=True</cite> else (N, ns).) – The <cite>S</cite> <span class="math notranslate nohighlight">\(\mathbf{T}_s\)</span> couplings calculated at each iteration.</p></li>
<li><p><strong>Ys</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>d</em><em>)</em>) – Feature matrices.</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>) – List of the <cite>S</cite> spaces’ weights</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>) or </em><em>(</em><em>S</em><em>,</em><em>N</em><em>)</em>) – Masses or list of masses in the targeted barycenter.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'square_loss'</em>) – Name of loss function to use in [‘square_loss’].</p></li>
<li><p><strong>target</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional. Default is True.</em>) – Whether the barycenter is positioned as target (True) or source (False).</p></li>
<li><p><strong>check_zeros</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional. Default is True.</em>) – Whether to check if marginals on the barycenter contains zeros or not.
Can be set to False to gain time if marginals are known to be positive.</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>X</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (N, d)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id111" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain and Courty Nicolas
“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</aside>
<aside class="footnote brackets" id="id112" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ot.gromov.update_barycenter_structure">
<span class="sig-prename descclassname"><span class="pre">ot.gromov.</span></span><span class="sig-name descname"><span class="pre">update_barycenter_structure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Ts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Cs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_fun</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square_loss'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_zeros</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ot/gromov/_utils.html#update_barycenter_structure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ot.gromov.update_barycenter_structure" title="Link to this definition"></a></dt>
<dd><p>Updates <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> according to the inner loss L with the <cite>S</cite>
<span class="math notranslate nohighlight">\(\mathbf{T}_s\)</span> couplings calculated at each iteration of variants of
the GW barycenter problem (e.g GW <span class="xref std std-ref">[12]</span>, srGW <span class="xref std std-ref">[48]</span>).
If <cite>target=True</cite> it solves for:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}} \quad
\sum_s \lambda_s \sum_{i,j,k,l}
L(\mathbf{C}^{(s)}_{i,k}, \mathbf{C}_{j,l}) \mathbf{T}^{(s)}_{i,j} \mathbf{T}^{(s)}_{k,l}\]</div>
<p>Else it solves the symmetric problem:</p>
<div class="math notranslate nohighlight">
\[\mathbf{C}^* = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}} \quad
\sum_s \lambda_s \sum_{i,j,k,l}
L(\mathbf{C}_{j,l}, \mathbf{C}^{(s)}_{i,k}) \mathbf{T}^{(s)}_{i,j} \mathbf{T}^{(s)}_{k,l}\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}^{(s)}\)</span>: pairwise matrix in the s^{th} source space .</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{C}\)</span>: pairwise matrix in the target space.</p></li>
<li><p><span class="math notranslate nohighlight">\(L\)</span>: inner divergence for the GW loss</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Ts</strong> (list of S array-like of shape (ns, N) if <cite>target=True</cite> else (N, ns).) – The <cite>S</cite> <span class="math notranslate nohighlight">\(\mathbf{T}_s\)</span> couplings calculated at each iteration.</p></li>
<li><p><strong>Cs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><em>S array-like</em><em>, </em><em>shape</em><em>(</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrices.</p></li>
<li><p><strong>lambdas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> of </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>,</em>) – List of the <cite>S</cite> spaces’ weights.</p></li>
<li><p><strong>p</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>) or </em><em>(</em><em>S</em><em>,</em><em>N</em><em>)</em>) – Masses or list of masses in the targeted barycenter.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional. Default is 'square_loss'</em>) – Name of loss function to use in [‘square_loss’, ‘kl_loss’].</p></li>
<li><p><strong>target</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional. Default is True.</em>) – Whether the barycenter is positioned as target (True) or source (False).</p></li>
<li><p><strong>check_zeros</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional. Default is True.</em>) – Whether to check if marginals on the barycenter contains zeros or not.
Can be set to False to gain time if marginals are known to be positive.</p></li>
<li><p><strong>nx</strong> (<em>backend</em><em>, </em><em>optional</em>) – If let to its default value None, a backend test will be conducted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>C</strong> – Updated <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> matrix.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>array-like, shape (<cite>nt</cite>, <cite>nt</cite>)</p>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id113" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Gabriel Peyré, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</aside>
<aside class="footnote brackets" id="id114" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty.
“Semi-relaxed Gromov-Wasserstein divergence and applications on graphs”
International Conference on Learning Representations (ICLR), 2022.</p>
</aside>
</aside>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ot.gnn.html" class="btn btn-neutral float-left" title="ot.gnn" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ot.lowrank.html" class="btn btn-neutral float-right" title="ot.lowrank" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016-2025, POT Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note"
aria-label="versions">
  <!--  add shift_up to the class for force viewing ,
  data-toggle="rst-current-version" -->
    <span class="rst-current-version"  style="margin-bottom:1mm;">
      <span class="fa fa-book"> Python Optimal Transport</span> 0.9.6dev0
      <hr  style="margin-bottom:1.5mm;margin-top:5mm;">
     <!--  versions
      <span class="fa fa-caret-down"></span>-->
      <span class="rst-current-version" style="display: inline-block;padding:
      0px;color:#fcfcfcab;float:left;font-size: 100%;">
        Versions: 
        <a href="https://pythonot.github.io/" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Release</a>
        <a href="https://pythonot.github.io/master" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Development</a>
        <a href="https://github.com/PythonOT/POT"
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Code</a>

      </span>

     
    </span>
  
     <!--
    <div class="rst-other-versions">

      

<div class="injected">

    
  <dl>
    <dt>Versions</dt>

    <dd><a href="https://pythonot.github.io/">Release</a></dd>
    
    <dd><a href="https://pythonot.github.io/master">Development</a></dd>
   
    

    <dt><a href="https://github.com/PythonOT/POT">Code on Github</a></dt>       

    
  </dl>
  <hr>

</div> 
</div>-->
  </div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>