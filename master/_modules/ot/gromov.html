<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ot.gromov &mdash; POT Python Optimal Transport 0.8.0dev documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> POT Python Optimal Transport
          </a>
              <div class="version">
                0.8.0dev
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">POT: Python Optimal Transport</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quick start guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../all.html">API and modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Examples gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../releases.html">Releases</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">POT Python Optimal Transport</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Module code</a> &raquo;</li>
      <li>ot.gromov</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for ot.gromov</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Gromov-Wasserstein and Fused-Gromov-Wasserstein solvers</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Author: Erwan Vautier &lt;erwan.vautier@gmail.com&gt;</span>
<span class="c1">#         Nicolas Courty &lt;ncourty@irisa.fr&gt;</span>
<span class="c1">#         Rémi Flamary &lt;remi.flamary@unice.fr&gt;</span>
<span class="c1">#         Titouan Vayer &lt;titouan.vayer@irisa.fr&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: MIT License</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="kn">from</span> <span class="nn">.bregman</span> <span class="kn">import</span> <span class="n">sinkhorn</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">dist</span><span class="p">,</span> <span class="n">UndefinedParameter</span><span class="p">,</span> <span class="n">list_to_array</span>
<span class="kn">from</span> <span class="nn">.optim</span> <span class="kn">import</span> <span class="n">cg</span>
<span class="kn">from</span> <span class="nn">.lp</span> <span class="kn">import</span> <span class="n">emd_1d</span><span class="p">,</span> <span class="n">emd</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">check_random_state</span>
<span class="kn">from</span> <span class="nn">.backend</span> <span class="kn">import</span> <span class="n">get_backend</span>


<div class="viewcode-block" id="init_matrix"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.init_matrix">[docs]</a><span class="k">def</span> <span class="nf">init_matrix</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="s1">&#39;square_loss&#39;</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return loss matrices and tensors for Gromov-Wasserstein fast computation</span>

<span class="sd">    Returns the value of :math:`\mathcal{L}(\mathbf{C_1}, \mathbf{C_2}) \otimes \mathbf{T}` with the</span>
<span class="sd">    selected loss function as the loss function of Gromow-Wasserstein discrepancy.</span>

<span class="sd">    The matrices are computed as described in Proposition 1 in :ref:`[12] &lt;references-init-matrix&gt;`</span>

<span class="sd">    Where :</span>

<span class="sd">    - :math:`\mathbf{C_1}`: Metric cost matrix in the source space</span>
<span class="sd">    - :math:`\mathbf{C_2}`: Metric cost matrix in the target space</span>
<span class="sd">    - :math:`\mathbf{T}`: A coupling between those two spaces</span>

<span class="sd">    The square-loss function :math:`L(a, b) = |a - b|^2` is read as :</span>

<span class="sd">    .. math::</span>

<span class="sd">        L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)</span>

<span class="sd">        \mathrm{with} \ f_1(a) &amp;= a^2</span>

<span class="sd">                        f_2(b) &amp;= b^2</span>

<span class="sd">                        h_1(a) &amp;= a</span>

<span class="sd">                        h_2(b) &amp;= 2b</span>

<span class="sd">    The kl-loss function :math:`L(a, b) = a \log\left(\frac{a}{b}\right) - a + b` is read as :</span>

<span class="sd">    .. math::</span>

<span class="sd">        L(a, b) = f_1(a) + f_2(b) - h_1(a) h_2(b)</span>

<span class="sd">        \mathrm{with} \ f_1(a) &amp;= a \log(a) - a</span>

<span class="sd">                        f_2(b) &amp;= b</span>

<span class="sd">                        h_1(a) &amp;= a</span>

<span class="sd">                        h_2(b) &amp;= \log(b)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : array-like, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : array-like, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix in the target space</span>
<span class="sd">    T :  array-like, shape (ns, nt)</span>
<span class="sd">        Coupling between source and target spaces</span>
<span class="sd">    p : array-like, shape (ns,)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    constC : array-like, shape (ns, nt)</span>
<span class="sd">        Constant :math:`\mathbf{C}` matrix in Eq. (6)</span>
<span class="sd">    hC1 : array-like, shape (ns, ns)</span>
<span class="sd">        :math:`\mathbf{h1}(\mathbf{C1})` matrix in Eq. (6)</span>
<span class="sd">    hC2 : array-like, shape (nt, nt)</span>
<span class="sd">        :math:`\mathbf{h2}(\mathbf{C2})` matrix in Eq. (6)</span>


<span class="sd">    .. _references-init-matrix:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Gabriel Peyré, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;square_loss&#39;</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">f1</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">a</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">f2</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">b</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">h1</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">a</span>

        <span class="k">def</span> <span class="nf">h2</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">b</span>
    <span class="k">elif</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;kl_loss&#39;</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">f1</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="mf">1e-15</span><span class="p">)</span> <span class="o">-</span> <span class="n">a</span>

        <span class="k">def</span> <span class="nf">f2</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">b</span>

        <span class="k">def</span> <span class="nf">h1</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">a</span>

        <span class="k">def</span> <span class="nf">h2</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="mf">1e-15</span><span class="p">)</span>

    <span class="n">constC1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
        <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">f1</span><span class="p">(</span><span class="n">C1</span><span class="p">),</span> <span class="n">nx</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))),</span>
        <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">)),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">q</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">constC2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
        <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">p</span><span class="p">),</span>
        <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">f2</span><span class="p">(</span><span class="n">C2</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">constC</span> <span class="o">=</span> <span class="n">constC1</span> <span class="o">+</span> <span class="n">constC2</span>
    <span class="n">hC1</span> <span class="o">=</span> <span class="n">h1</span><span class="p">(</span><span class="n">C1</span><span class="p">)</span>
    <span class="n">hC2</span> <span class="o">=</span> <span class="n">h2</span><span class="p">(</span><span class="n">C2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span></div>


<div class="viewcode-block" id="tensor_product"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.tensor_product">[docs]</a><span class="k">def</span> <span class="nf">tensor_product</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return the tensor for Gromov-Wasserstein fast computation</span>

<span class="sd">    The tensor is computed as described in Proposition 1 Eq. (6) in :ref:`[12] &lt;references-tensor-product&gt;`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    constC : array-like, shape (ns, nt)</span>
<span class="sd">        Constant :math:`\mathbf{C}` matrix in Eq. (6)</span>
<span class="sd">    hC1 : array-like, shape (ns, ns)</span>
<span class="sd">        :math:`\mathbf{h1}(\mathbf{C1})` matrix in Eq. (6)</span>
<span class="sd">    hC2 : array-like, shape (nt, nt)</span>
<span class="sd">        :math:`\mathbf{h2}(\mathbf{C2})` matrix in Eq. (6)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tens : array-like, shape (`ns`, `nt`)</span>
<span class="sd">        :math:`\mathcal{L}(\mathbf{C_1}, \mathbf{C_2}) \otimes \mathbf{T}` tensor-matrix multiplication result</span>


<span class="sd">    .. _references-tensor-product:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Gabriel Peyré, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>

    <span class="n">A</span> <span class="o">=</span> <span class="o">-</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
        <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hC1</span><span class="p">,</span> <span class="n">T</span><span class="p">),</span> <span class="n">hC2</span><span class="o">.</span><span class="n">T</span>
    <span class="p">)</span>
    <span class="n">tens</span> <span class="o">=</span> <span class="n">constC</span> <span class="o">+</span> <span class="n">A</span>
    <span class="c1"># tens -= tens.min()</span>
    <span class="k">return</span> <span class="n">tens</span></div>


<div class="viewcode-block" id="gwloss"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.gwloss">[docs]</a><span class="k">def</span> <span class="nf">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return the Loss for Gromov-Wasserstein</span>

<span class="sd">    The loss is computed as described in Proposition 1 Eq. (6) in :ref:`[12] &lt;references-gwloss&gt;`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    constC : array-like, shape (ns, nt)</span>
<span class="sd">        Constant :math:`\mathbf{C}` matrix in Eq. (6)</span>
<span class="sd">    hC1 : array-like, shape (ns, ns)</span>
<span class="sd">        :math:`\mathbf{h1}(\mathbf{C1})` matrix in Eq. (6)</span>
<span class="sd">    hC2 : array-like, shape (nt, nt)</span>
<span class="sd">        :math:`\mathbf{h2}(\mathbf{C2})` matrix in Eq. (6)</span>
<span class="sd">    T : array-like, shape (ns, nt)</span>
<span class="sd">        Current value of transport matrix :math:`\mathbf{T}`</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    loss : float</span>
<span class="sd">        Gromov Wasserstein loss</span>


<span class="sd">    .. _references-gwloss:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Gabriel Peyré, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">tens</span> <span class="o">=</span> <span class="n">tensor_product</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>

    <span class="n">tens</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">tens</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">tens</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tens</span> <span class="o">*</span> <span class="n">T</span><span class="p">)</span></div>


<div class="viewcode-block" id="gwggrad"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.gwggrad">[docs]</a><span class="k">def</span> <span class="nf">gwggrad</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return the gradient for Gromov-Wasserstein</span>

<span class="sd">    The gradient is computed as described in Proposition 2 in :ref:`[12] &lt;references-gwggrad&gt;`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    constC : array-like, shape (ns, nt)</span>
<span class="sd">        Constant :math:`\mathbf{C}` matrix in Eq. (6)</span>
<span class="sd">    hC1 : array-like, shape (ns, ns)</span>
<span class="sd">        :math:`\mathbf{h1}(\mathbf{C1})` matrix in Eq. (6)</span>
<span class="sd">    hC2 : array-like, shape (nt, nt)</span>
<span class="sd">        :math:`\mathbf{h2}(\mathbf{C2})` matrix in Eq. (6)</span>
<span class="sd">    T : array-like, shape (ns, nt)</span>
<span class="sd">        Current value of transport matrix :math:`\mathbf{T}`</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    grad : array-like, shape (`ns`, `nt`)</span>
<span class="sd">           Gromov Wasserstein gradient</span>


<span class="sd">    .. _references-gwggrad:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Gabriel Peyré, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">tensor_product</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span>
                              <span class="n">T</span><span class="p">)</span>  <span class="c1"># [12] Prop. 2 misses a 2 factor</span></div>


<div class="viewcode-block" id="update_square_loss"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.update_square_loss">[docs]</a><span class="k">def</span> <span class="nf">update_square_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updates :math:`\mathbf{C}` according to the L2 Loss kernel with the `S` :math:`\mathbf{T}_s`</span>
<span class="sd">    couplings calculated at each iteration</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p : array-like, shape (N,)</span>
<span class="sd">        Masses in the targeted barycenter.</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the `S` spaces&#39; weights.</span>
<span class="sd">    T : list of S array-like of shape (ns,N)</span>
<span class="sd">        The `S` :math:`\mathbf{T}_s` couplings calculated at each iteration.</span>
<span class="sd">    Cs : list of S array-like, shape(ns,ns)</span>
<span class="sd">        Metric cost matrices.</span>

<span class="sd">    Returns</span>
<span class="sd">    ----------</span>
<span class="sd">    C : array-like, shape (`nt`, `nt`)</span>
<span class="sd">        Updated :math:`\mathbf{C}` matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">T</span><span class="p">)</span>
    <span class="n">Cs</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">Cs</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="o">*</span><span class="n">T</span><span class="p">,</span> <span class="o">*</span><span class="n">Cs</span><span class="p">)</span>

    <span class="n">tmpsum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span>
        <span class="n">lambdas</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
            <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">]),</span>
            <span class="n">T</span><span class="p">[</span><span class="n">s</span><span class="p">]</span>
        <span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">T</span><span class="p">))</span>
    <span class="p">])</span>
    <span class="n">ppt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tmpsum</span> <span class="o">/</span> <span class="n">ppt</span></div>


<div class="viewcode-block" id="update_kl_loss"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.update_kl_loss">[docs]</a><span class="k">def</span> <span class="nf">update_kl_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updates :math:`\mathbf{C}` according to the KL Loss kernel with the `S` :math:`\mathbf{T}_s` couplings calculated at each iteration</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p  : array-like, shape (N,)</span>
<span class="sd">        Weights in the targeted barycenter.</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the `S` spaces&#39; weights</span>
<span class="sd">    T : list of S array-like of shape (ns,N)</span>
<span class="sd">        The `S` :math:`\mathbf{T}_s` couplings calculated at each iteration.</span>
<span class="sd">    Cs : list of S array-like, shape(ns,ns)</span>
<span class="sd">        Metric cost matrices.</span>

<span class="sd">    Returns</span>
<span class="sd">    ----------</span>
<span class="sd">    C : array-like, shape (`ns`, `ns`)</span>
<span class="sd">        updated :math:`\mathbf{C}` matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Cs</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">Cs</span><span class="p">)</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">T</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="o">*</span><span class="n">T</span><span class="p">,</span> <span class="o">*</span><span class="n">Cs</span><span class="p">)</span>

    <span class="n">tmpsum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span>
        <span class="n">lambdas</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
            <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">]),</span>
            <span class="n">T</span><span class="p">[</span><span class="n">s</span><span class="p">]</span>
        <span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">T</span><span class="p">))</span>
    <span class="p">])</span>
    <span class="n">ppt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">tmpsum</span> <span class="o">/</span> <span class="n">ppt</span><span class="p">)</span></div>


<div class="viewcode-block" id="gromov_wasserstein"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.gromov_wasserstein">[docs]</a><span class="k">def</span> <span class="nf">gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="s1">&#39;square_loss&#39;</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the gromov-wasserstein transport between :math:`(\mathbf{C_1}, \mathbf{p})` and :math:`(\mathbf{C_2}, \mathbf{q})`</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \mathbf{GW} = \mathop{\arg \min}_\mathbf{T} \quad \sum_{i,j,k,l}</span>
<span class="sd">        L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}</span>

<span class="sd">    Where :</span>

<span class="sd">    - :math:`\mathbf{C_1}`: Metric cost matrix in the source space</span>
<span class="sd">    - :math:`\mathbf{C_2}`: Metric cost matrix in the target space</span>
<span class="sd">    - :math:`\mathbf{p}`: distribution in the source space</span>
<span class="sd">    - :math:`\mathbf{q}`: distribution in the target space</span>
<span class="sd">    - `L`: loss function to account for the misfit between the similarity matrices</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : array-like, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : array-like, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix in the target space</span>
<span class="sd">    p : array-like, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q : array-like, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    loss_fun : str</span>
<span class="sd">        loss function used for the solver either &#39;square_loss&#39; or &#39;kl_loss&#39;</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>
<span class="sd">    armijo : bool, optional</span>
<span class="sd">        If True the step of the line-search is found via an armijo research. Else closed form is used.</span>
<span class="sd">        If there are convergence issues use False.</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        parameters can be directly passed to the ot.optim.cg solver</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    T : array-like, shape (`ns`, `nt`)</span>
<span class="sd">        Coupling between the two spaces that minimizes:</span>

<span class="sd">            :math:`\sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}`</span>
<span class="sd">    log : dict</span>
<span class="sd">        Convergence information and loss.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Gabriel Peyré, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    .. [13] Mémoli, Facundo. Gromov–Wasserstein distances and the</span>
<span class="sd">        metric approach to object matching. Foundations of computational</span>
<span class="sd">        mathematics 11.4 (2011): 417-487.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

    <span class="n">p0</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">C10</span><span class="p">,</span> <span class="n">C20</span> <span class="o">=</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">C10</span><span class="p">,</span> <span class="n">C20</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
    <span class="n">C1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">C10</span><span class="p">)</span>
    <span class="n">C2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">C20</span><span class="p">)</span>

    <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span> <span class="o">=</span> <span class="n">init_matrix</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">)</span>

    <span class="n">G0</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwggrad</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">res</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="n">armijo</span><span class="p">,</span> <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">constC</span><span class="o">=</span><span class="n">constC</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">res</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">),</span> <span class="n">log</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">cg</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="n">armijo</span><span class="p">,</span> <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">constC</span><span class="o">=</span><span class="n">constC</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span></div>


<div class="viewcode-block" id="gromov_wasserstein2"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.gromov_wasserstein2">[docs]</a><span class="k">def</span> <span class="nf">gromov_wasserstein2</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="s1">&#39;square_loss&#39;</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the gromov-wasserstein discrepancy between :math:`(\mathbf{C_1}, \mathbf{p})` and :math:`(\mathbf{C_2}, \mathbf{q})`</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        GW = \min_\mathbf{T} \quad \sum_{i,j,k,l}</span>
<span class="sd">        L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}</span>

<span class="sd">    Where :</span>

<span class="sd">    - :math:`\mathbf{C_1}`: Metric cost matrix in the source space</span>
<span class="sd">    - :math:`\mathbf{C_2}`: Metric cost matrix in the target space</span>
<span class="sd">    - :math:`\mathbf{p}`: distribution in the source space</span>
<span class="sd">    - :math:`\mathbf{q}`: distribution in the target space</span>
<span class="sd">    - `L`: loss function to account for the misfit between the similarity</span>
<span class="sd">      matrices</span>

<span class="sd">    Note that when using backends, this loss function is differentiable wrt the</span>
<span class="sd">    marices and weights for quadratic loss using the gradients from [38]_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : array-like, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : array-like, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix in the target space</span>
<span class="sd">    p : array-like, shape (ns,)</span>
<span class="sd">        Distribution in the source space.</span>
<span class="sd">    q :  array-like, shape (nt,)</span>
<span class="sd">        Distribution in the target space.</span>
<span class="sd">    loss_fun :  str</span>
<span class="sd">        loss function used for the solver either &#39;square_loss&#39; or &#39;kl_loss&#39;</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>
<span class="sd">    armijo : bool, optional</span>
<span class="sd">        If True the step of the line-search is found via an armijo research. Else closed form is used.</span>
<span class="sd">        If there are convergence issues use False.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gw_dist : float</span>
<span class="sd">        Gromov-Wasserstein distance</span>
<span class="sd">    log : dict</span>
<span class="sd">        convergence information and Coupling marix</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Gabriel Peyré, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    .. [13] Mémoli, Facundo. Gromov–Wasserstein distances and the</span>
<span class="sd">        metric approach to object matching. Foundations of computational</span>
<span class="sd">        mathematics 11.4 (2011): 417-487.</span>

<span class="sd">    .. [38] C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online</span>
<span class="sd">        Graph Dictionary Learning, International Conference on Machine Learning</span>
<span class="sd">        (ICML), 2021.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

    <span class="n">p0</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">C10</span><span class="p">,</span> <span class="n">C20</span> <span class="o">=</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">C10</span><span class="p">,</span> <span class="n">C20</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
    <span class="n">C1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">C10</span><span class="p">)</span>
    <span class="n">C2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">C20</span><span class="p">)</span>

    <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span> <span class="o">=</span> <span class="n">init_matrix</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">)</span>

    <span class="n">G0</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwggrad</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="n">T</span><span class="p">,</span> <span class="n">log_gw</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="n">armijo</span><span class="p">,</span> <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">constC</span><span class="o">=</span><span class="n">constC</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">T0</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>

    <span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>
    <span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>
    <span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>
    <span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">T0</span>

    <span class="n">gw</span> <span class="o">=</span> <span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;square_loss&#39;</span><span class="p">:</span>
        <span class="n">gC1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">C1</span> <span class="o">*</span> <span class="p">(</span><span class="n">p</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">C2</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
        <span class="n">gC2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">C2</span> <span class="o">*</span> <span class="p">(</span><span class="n">q</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">T</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">C1</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">))</span>
        <span class="n">gw</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">set_gradients</span><span class="p">(</span><span class="n">gw</span><span class="p">,</span> <span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">C10</span><span class="p">,</span> <span class="n">C20</span><span class="p">),</span>
                              <span class="p">(</span><span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">],</span> <span class="n">log_gw</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">],</span> <span class="n">gC1</span><span class="p">,</span> <span class="n">gC2</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gw</span><span class="p">,</span> <span class="n">log_gw</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gw</span></div>


<div class="viewcode-block" id="fused_gromov_wasserstein"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.fused_gromov_wasserstein">[docs]</a><span class="k">def</span> <span class="nf">fused_gromov_wasserstein</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="s1">&#39;square_loss&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the FGW transport between two graphs (see :ref:`[24] &lt;references-fused-gromov-wasserstein&gt;`)</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_\gamma \quad (1 - \alpha) \langle \gamma, \mathbf{M} \rangle_F +</span>
<span class="sd">        \alpha \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}</span>

<span class="sd">        s.t. \ \mathbf{\gamma} \mathbf{1} &amp;= \mathbf{p}</span>

<span class="sd">             \mathbf{\gamma}^T \mathbf{1} &amp;= \mathbf{q}</span>

<span class="sd">             \mathbf{\gamma} &amp;\geq 0</span>

<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the (`ns`, `nt`) metric cost matrix</span>
<span class="sd">    - :math:`\mathbf{p}` and :math:`\mathbf{q}` are source and target weights (sum to 1)</span>
<span class="sd">    - `L` is a loss function to account for the misfit between the similarity matrices</span>

<span class="sd">    The algorithm used for solving the problem is conditional gradient as discussed in :ref:`[24] &lt;references-fused-gromov-wasserstein&gt;`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    M : array-like, shape (ns, nt)</span>
<span class="sd">        Metric cost matrix between features across domains</span>
<span class="sd">    C1 : array-like, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix representative of the structure in the source space</span>
<span class="sd">    C2 : array-like, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix representative of the structure in the target space</span>
<span class="sd">    p : array-like, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q : array-like, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    loss_fun : str, optional</span>
<span class="sd">        Loss function used for the solver</span>
<span class="sd">    alpha : float, optional</span>
<span class="sd">        Trade-off parameter (0 &lt; alpha &lt; 1)</span>
<span class="sd">    armijo : bool, optional</span>
<span class="sd">        If True the step of the line-search is found via an armijo research. Else closed form is used.</span>
<span class="sd">        If there are convergence issues use False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        parameters can be directly passed to the ot.optim.cg solver</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : array-like, shape (`ns`, `nt`)</span>
<span class="sd">        Optimal transportation matrix for the given parameters.</span>
<span class="sd">    log : dict</span>
<span class="sd">        Log dictionary return only if log==True in parameters.</span>


<span class="sd">    .. _references-fused-gromov-wasserstein:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [24] Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain</span>
<span class="sd">        and Courty Nicolas &quot;Optimal Transport for structured data with</span>
<span class="sd">        application on graphs&quot;, International Conference on Machine Learning</span>
<span class="sd">        (ICML). 2019.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

    <span class="n">p0</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">C10</span><span class="p">,</span> <span class="n">C20</span><span class="p">,</span> <span class="n">M0</span> <span class="o">=</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">M</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">C10</span><span class="p">,</span> <span class="n">C20</span><span class="p">,</span> <span class="n">M0</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
    <span class="n">C1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">C10</span><span class="p">)</span>
    <span class="n">C2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">C20</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">M0</span><span class="p">)</span>

    <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span> <span class="o">=</span> <span class="n">init_matrix</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">)</span>

    <span class="n">G0</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwggrad</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">res</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">M</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="n">armijo</span><span class="p">,</span> <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">constC</span><span class="o">=</span><span class="n">constC</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">fgw_dist</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>

        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;fgw_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fgw_dist</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">),</span> <span class="n">log</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">cg</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">M</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="n">armijo</span><span class="p">,</span> <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">constC</span><span class="o">=</span><span class="n">constC</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span></div>


<div class="viewcode-block" id="fused_gromov_wasserstein2"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.fused_gromov_wasserstein2">[docs]</a><span class="k">def</span> <span class="nf">fused_gromov_wasserstein2</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="s1">&#39;square_loss&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the FGW distance between two graphs see (see :ref:`[24] &lt;references-fused-gromov-wasserstein2&gt;`)</span>

<span class="sd">    .. math::</span>
<span class="sd">        \min_\gamma \quad (1 - \alpha) \langle \gamma, \mathbf{M} \rangle_F + \alpha \sum_{i,j,k,l}</span>
<span class="sd">        L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}</span>

<span class="sd">        s.t. \ \mathbf{\gamma} \mathbf{1} &amp;= \mathbf{p}</span>

<span class="sd">             \mathbf{\gamma}^T \mathbf{1} &amp;= \mathbf{q}</span>

<span class="sd">             \mathbf{\gamma} &amp;\geq 0</span>

<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the (`ns`, `nt`) metric cost matrix</span>
<span class="sd">    - :math:`\mathbf{p}` and :math:`\mathbf{q}` are source and target weights (sum to 1)</span>
<span class="sd">    - `L` is a loss function to account for the misfit between the similarity matrices</span>

<span class="sd">    The algorithm used for solving the problem is conditional gradient as</span>
<span class="sd">    discussed in :ref:`[24] &lt;references-fused-gromov-wasserstein2&gt;`</span>

<span class="sd">    Note that when using backends, this loss function is differentiable wrt the</span>
<span class="sd">    marices and weights for quadratic loss using the gradients from [38]_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    M : array-like, shape (ns, nt)</span>
<span class="sd">        Metric cost matrix between features across domains</span>
<span class="sd">    C1 : array-like, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix representative of the structure in the source space.</span>
<span class="sd">    C2 : array-like, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix representative of the structure in the target space.</span>
<span class="sd">    p :  array-like, shape (ns,)</span>
<span class="sd">        Distribution in the source space.</span>
<span class="sd">    q :  array-like, shape (nt,)</span>
<span class="sd">        Distribution in the target space.</span>
<span class="sd">    loss_fun : str, optional</span>
<span class="sd">        Loss function used for the solver.</span>
<span class="sd">    alpha : float, optional</span>
<span class="sd">        Trade-off parameter (0 &lt; alpha &lt; 1)</span>
<span class="sd">    armijo : bool, optional</span>
<span class="sd">        If True the step of the line-search is found via an armijo research.</span>
<span class="sd">        Else closed form is used. If there are convergence issues use False.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Record log if True.</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        Parameters can be directly passed to the ot.optim.cg solver.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fgw-distance : float</span>
<span class="sd">        Fused gromov wasserstein distance for the given parameters.</span>
<span class="sd">    log : dict</span>
<span class="sd">        Log dictionary return only if log==True in parameters.</span>


<span class="sd">    .. _references-fused-gromov-wasserstein2:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [24] Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain</span>
<span class="sd">        and Courty Nicolas</span>
<span class="sd">        &quot;Optimal Transport for structured data with application on graphs&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2019.</span>

<span class="sd">    .. [38] C. Vincent-Cuaz, T. Vayer, R. Flamary, M. Corneli, N. Courty, Online</span>
<span class="sd">        Graph Dictionary Learning, International Conference on Machine Learning</span>
<span class="sd">        (ICML), 2021.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

    <span class="n">p0</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">C10</span><span class="p">,</span> <span class="n">C20</span><span class="p">,</span> <span class="n">M0</span> <span class="o">=</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">M</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">C10</span><span class="p">,</span> <span class="n">C20</span><span class="p">,</span> <span class="n">M0</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
    <span class="n">C1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">C10</span><span class="p">)</span>
    <span class="n">C2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">C20</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">M0</span><span class="p">)</span>

    <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span> <span class="o">=</span> <span class="n">init_matrix</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">)</span>

    <span class="n">G0</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gwggrad</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

    <span class="n">T</span><span class="p">,</span> <span class="n">log_fgw</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">M</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">armijo</span><span class="o">=</span><span class="n">armijo</span><span class="p">,</span> <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">constC</span><span class="o">=</span><span class="n">constC</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">fgw_dist</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">log_fgw</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>

    <span class="n">T0</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>

    <span class="n">log_fgw</span><span class="p">[</span><span class="s1">&#39;fgw_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fgw_dist</span>
    <span class="n">log_fgw</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">log_fgw</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>
    <span class="n">log_fgw</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">log_fgw</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">C10</span><span class="p">)</span>
    <span class="n">log_fgw</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">T0</span>

    <span class="k">if</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;square_loss&#39;</span><span class="p">:</span>
        <span class="n">gC1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">C1</span> <span class="o">*</span> <span class="p">(</span><span class="n">p</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">C2</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
        <span class="n">gC2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">C2</span> <span class="o">*</span> <span class="p">(</span><span class="n">q</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">q</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">T</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">C1</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">))</span>
        <span class="n">fgw_dist</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">set_gradients</span><span class="p">(</span><span class="n">fgw_dist</span><span class="p">,</span> <span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">C10</span><span class="p">,</span> <span class="n">C20</span><span class="p">,</span> <span class="n">M0</span><span class="p">),</span>
                                    <span class="p">(</span><span class="n">log_fgw</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">],</span> <span class="n">log_fgw</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">gC1</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">gC2</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">T0</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fgw_dist</span><span class="p">,</span> <span class="n">log_fgw</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fgw_dist</span></div>


<div class="viewcode-block" id="GW_distance_estimation"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.GW_distance_estimation">[docs]</a><span class="k">def</span> <span class="nf">GW_distance_estimation</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span>
                           <span class="n">nb_samples_p</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nb_samples_q</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns an approximation of the gromov-wasserstein cost between :math:`(\mathbf{C_1}, \mathbf{p})` and :math:`(\mathbf{C_2}, \mathbf{q})`</span>
<span class="sd">    with a fixed transport plan :math:`\mathbf{T}`.</span>

<span class="sd">    The function gives an unbiased approximation of the following equation:</span>

<span class="sd">    .. math::</span>

<span class="sd">        GW = \sum_{i,j,k,l} L(\mathbf{C_{1}}_{i,k}, \mathbf{C_{2}}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}</span>

<span class="sd">    Where :</span>

<span class="sd">    - :math:`\mathbf{C_1}`: Metric cost matrix in the source space</span>
<span class="sd">    - :math:`\mathbf{C_2}`: Metric cost matrix in the target space</span>
<span class="sd">    - `L` : Loss function to account for the misfit between the similarity matrices</span>
<span class="sd">    - :math:`\mathbf{T}`: Matrix with marginal :math:`\mathbf{p}` and :math:`\mathbf{q}`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : array-like, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : array-like, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix in the target space</span>
<span class="sd">    p :  array-like, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q :  array-like, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    loss_fun :  function: :math:`\mathbb{R} \times \mathbb{R} \mapsto \mathbb{R}`</span>
<span class="sd">        Loss function used for the distance, the transport plan does not depend on the loss function</span>
<span class="sd">    T : csr or array-like, shape (ns, nt)</span>
<span class="sd">        Transport plan matrix, either a sparse csr or a dense matrix</span>
<span class="sd">    nb_samples_p : int, optional</span>
<span class="sd">        `nb_samples_p` is the number of samples (without replacement) along the first dimension of :math:`\mathbf{T}`</span>
<span class="sd">    nb_samples_q : int, optional</span>
<span class="sd">        `nb_samples_q` is the number of samples along the second dimension of :math:`\mathbf{T}`, for each sample along the first</span>
<span class="sd">    std : bool, optional</span>
<span class="sd">        Standard deviation associated with the prediction of the gromov-wasserstein cost</span>
<span class="sd">    random_state : int or RandomState instance, optional</span>
<span class="sd">        Fix the seed for reproducibility</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    : float</span>
<span class="sd">        Gromov-wasserstein cost</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [14] Kerdoncuff, Tanguy, Emonet, Rémi, Sebban, Marc</span>
<span class="sd">        &quot;Sampled Gromov Wasserstein.&quot;</span>
<span class="sd">        Machine Learning Journal (MLJ). 2021.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

    <span class="n">generator</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="n">len_p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">len_q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># It is always better to sample from the biggest distribution first.</span>
    <span class="k">if</span> <span class="n">len_p</span> <span class="o">&lt;</span> <span class="n">len_q</span><span class="p">:</span>
        <span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="p">,</span> <span class="n">p</span>
        <span class="n">len_p</span><span class="p">,</span> <span class="n">len_q</span> <span class="o">=</span> <span class="n">len_q</span><span class="p">,</span> <span class="n">len_p</span>
        <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span> <span class="o">=</span> <span class="n">C2</span><span class="p">,</span> <span class="n">C1</span>
        <span class="n">T</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">T</span>

    <span class="k">if</span> <span class="n">nb_samples_p</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
            <span class="c1"># If T is sparse, it probably mean that PoGroW was used, thus the number of sample is reduced</span>
            <span class="n">nb_samples_p</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mi">5</span> <span class="o">*</span> <span class="p">(</span><span class="n">len_p</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">len_p</span><span class="p">))</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">len_p</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nb_samples_p</span> <span class="o">=</span> <span class="n">len_p</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># The number of sample along the first dimension is without replacement.</span>
        <span class="n">nb_samples_p</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">nb_samples_p</span><span class="p">,</span> <span class="n">len_p</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">nb_samples_q</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">nb_samples_q</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">std</span><span class="p">:</span>
        <span class="n">nb_samples_q</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">nb_samples_q</span><span class="p">)</span>

    <span class="n">index_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nb_samples_p</span><span class="p">,</span> <span class="n">nb_samples_q</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">index_l</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nb_samples_p</span><span class="p">,</span> <span class="n">nb_samples_q</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="n">index_i</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">len_p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">nb_samples_p</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">index_j</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">len_p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">nb_samples_p</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_samples_p</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
            <span class="n">T_indexi</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">todense</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">index_i</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="p">:]),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
            <span class="n">T_indexj</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">todense</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">index_j</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="p">:]),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">T_indexi</span> <span class="o">=</span> <span class="n">T</span><span class="p">[</span><span class="n">index_i</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="p">:]</span>
            <span class="n">T_indexj</span> <span class="o">=</span> <span class="n">T</span><span class="p">[</span><span class="n">index_j</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="p">:]</span>
        <span class="c1"># For each of the row sampled, the column is sampled.</span>
        <span class="n">index_k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
            <span class="n">len_q</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="n">nb_samples_q</span><span class="p">,</span>
            <span class="n">p</span><span class="o">=</span><span class="n">T_indexi</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">T_indexi</span><span class="p">),</span>
            <span class="n">replace</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="n">index_l</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
            <span class="n">len_q</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="n">nb_samples_q</span><span class="p">,</span>
            <span class="n">p</span><span class="o">=</span><span class="n">T_indexj</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">T_indexj</span><span class="p">),</span>
            <span class="n">replace</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="n">list_value_sample</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span>
        <span class="n">loss_fun</span><span class="p">(</span>
            <span class="n">C1</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">index_i</span><span class="p">,</span> <span class="n">index_j</span><span class="p">)],</span>
            <span class="n">C2</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">index_k</span><span class="p">[:,</span> <span class="n">n</span><span class="p">],</span> <span class="n">index_l</span><span class="p">[:,</span> <span class="n">n</span><span class="p">])]</span>
        <span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_samples_q</span><span class="p">)</span>
    <span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">std</span><span class="p">:</span>
        <span class="n">std_value</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">list_value_sample</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">list_value_sample</span><span class="p">),</span> <span class="n">std_value</span> <span class="o">/</span> <span class="p">(</span><span class="n">nb_samples_p</span> <span class="o">*</span> <span class="n">nb_samples_p</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">list_value_sample</span><span class="p">)</span></div>


<div class="viewcode-block" id="pointwise_gromov_wasserstein"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.pointwise_gromov_wasserstein">[docs]</a><span class="k">def</span> <span class="nf">pointwise_gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span>
                                 <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">threshold_plan</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the gromov-wasserstein transport between :math:`(\mathbf{C_1}, \mathbf{p})` and :math:`(\mathbf{C_2}, \mathbf{q})` using a stochastic Frank-Wolfe.</span>
<span class="sd">    This method has a :math:`\mathcal{O}(\mathrm{max\_iter} \times PN^2)` time complexity with `P` the number of Sinkhorn iterations.</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \mathbf{GW} = \mathop{\arg \min}_\mathbf{T} \quad \sum_{i,j,k,l}</span>
<span class="sd">        L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}</span>

<span class="sd">        s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}</span>

<span class="sd">                \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}</span>

<span class="sd">                \mathbf{T} &amp;\geq 0</span>

<span class="sd">    Where :</span>

<span class="sd">    - :math:`\mathbf{C_1}`: Metric cost matrix in the source space</span>
<span class="sd">    - :math:`\mathbf{C_2}`: Metric cost matrix in the target space</span>
<span class="sd">    - :math:`\mathbf{p}`: distribution in the source space</span>
<span class="sd">    - :math:`\mathbf{q}`: distribution in the target space</span>
<span class="sd">    - `L`: loss function to account for the misfit between the similarity matrices</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : array-like, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : array-like, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix in the target space</span>
<span class="sd">    p :  array-like, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q :  array-like, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    loss_fun :  function: :math:`\mathbb{R} \times \mathbb{R} \mapsto \mathbb{R}`</span>
<span class="sd">        Loss function used for the distance, the transport plan does not depend on the loss function</span>
<span class="sd">    alpha : float</span>
<span class="sd">        Step of the Frank-Wolfe algorithm, should be between 0 and 1</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    threshold_plan : float, optional</span>
<span class="sd">        Deleting very small values in the transport plan. If above zero, it violates the marginal constraints.</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Gives the distance estimated and the standard deviation</span>
<span class="sd">    random_state : int or RandomState instance, optional</span>
<span class="sd">        Fix the seed for reproducibility</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    T : array-like, shape (`ns`, `nt`)</span>
<span class="sd">        Optimal coupling between the two spaces</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [14] Kerdoncuff, Tanguy, Emonet, Rémi, Sebban, Marc</span>
<span class="sd">        &quot;Sampled Gromov Wasserstein.&quot;</span>
<span class="sd">        Machine Learning Journal (MLJ). 2021.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

    <span class="n">len_p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">len_q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">generator</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Initialize with default marginal</span>
    <span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">len_p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
    <span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">len_q</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">q</span><span class="p">)</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">tocsr</span><span class="p">(</span><span class="n">emd_1d</span><span class="p">(</span><span class="n">C1</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">C2</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">a</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">dense</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

    <span class="n">best_gw_dist_estimated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="k">for</span> <span class="n">cpt</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">len_p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
        <span class="n">T_index0</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">todense</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:]),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
        <span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">len_q</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">T_index0</span> <span class="o">/</span> <span class="n">T_index0</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">alpha</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">T</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">tocsr</span><span class="p">(</span>
                <span class="n">emd_1d</span><span class="p">(</span><span class="n">C1</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">C2</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">a</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">dense</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_T</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">tocsr</span><span class="p">(</span>
                <span class="n">emd_1d</span><span class="p">(</span><span class="n">C1</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">C2</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">a</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">dense</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">T</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">T</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">new_T</span>
            <span class="c1"># To limit the number of non 0, the values below the threshold are set to 0.</span>
            <span class="n">T</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">eliminate_zeros</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold_plan</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">cpt</span> <span class="o">==</span> <span class="p">(</span><span class="n">max_iter</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">gw_dist_estimated</span> <span class="o">=</span> <span class="n">GW_distance_estimation</span><span class="p">(</span>
                <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="n">loss_fun</span><span class="p">,</span>
                <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">generator</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">gw_dist_estimated</span> <span class="o">&lt;</span> <span class="n">best_gw_dist_estimated</span><span class="p">:</span>
                <span class="n">best_gw_dist_estimated</span> <span class="o">=</span> <span class="n">gw_dist_estimated</span>
                <span class="n">best_T</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Best gw estimated&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">19</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">best_gw_dist_estimated</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">log</span><span class="p">[</span><span class="s2">&quot;gw_dist_estimated&quot;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s2">&quot;gw_dist_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">GW_distance_estimation</span><span class="p">(</span>
            <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="n">loss_fun</span><span class="p">,</span>
            <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">best_T</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">generator</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">best_T</span><span class="p">,</span> <span class="n">log</span>
    <span class="k">return</span> <span class="n">best_T</span></div>


<div class="viewcode-block" id="sampled_gromov_wasserstein"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.sampled_gromov_wasserstein">[docs]</a><span class="k">def</span> <span class="nf">sampled_gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span>
                               <span class="n">nb_samples_grad</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                               <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the gromov-wasserstein transport between :math:`(\mathbf{C_1}, \mathbf{p})` and :math:`(\mathbf{C_2}, \mathbf{q})` using a 1-stochastic Frank-Wolfe.</span>
<span class="sd">    This method has a :math:`\mathcal{O}(\mathrm{max\_iter} \times N \log(N))` time complexity by relying on the 1D Optimal Transport solver.</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \mathbf{GW} = \mathop{\arg \min}_\mathbf{T} \quad \sum_{i,j,k,l}</span>
<span class="sd">        L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l}</span>

<span class="sd">        s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}</span>

<span class="sd">                \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}</span>

<span class="sd">                \mathbf{T} &amp;\geq 0</span>

<span class="sd">    Where :</span>

<span class="sd">    - :math:`\mathbf{C_1}`: Metric cost matrix in the source space</span>
<span class="sd">    - :math:`\mathbf{C_2}`: Metric cost matrix in the target space</span>
<span class="sd">    - :math:`\mathbf{p}`: distribution in the source space</span>
<span class="sd">    - :math:`\mathbf{q}`: distribution in the target space</span>
<span class="sd">    - `L`: loss function to account for the misfit between the similarity matrices</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : array-like, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : array-like, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix in the target space</span>
<span class="sd">    p :  array-like, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q :  array-like, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    loss_fun :  function: :math:`\mathbb{R} \times \mathbb{R} \mapsto \mathbb{R}`</span>
<span class="sd">        Loss function used for the distance, the transport plan does not depend on the loss function</span>
<span class="sd">    nb_samples_grad : int</span>
<span class="sd">        Number of samples to approximate the gradient</span>
<span class="sd">    epsilon : float</span>
<span class="sd">        Weight of the Kullback-Leibler regularization</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Gives the distance estimated and the standard deviation</span>
<span class="sd">    random_state : int or RandomState instance, optional</span>
<span class="sd">        Fix the seed for reproducibility</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    T : array-like, shape (`ns`, `nt`)</span>
<span class="sd">        Optimal coupling between the two spaces</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [14] Kerdoncuff, Tanguy, Emonet, Rémi, Sebban, Marc</span>
<span class="sd">        &quot;Sampled Gromov Wasserstein.&quot;</span>
<span class="sd">        Machine Learning Journal (MLJ). 2021.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

    <span class="n">len_p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">len_q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">generator</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="c1"># The most natural way to define nb_sample is with a simple integer.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nb_samples_grad</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">nb_samples_grad</span> <span class="o">&gt;</span> <span class="n">len_p</span><span class="p">:</span>
            <span class="c1"># As the sampling along the first dimension is done without replacement, the rest is reported to the second</span>
            <span class="c1"># dimension.</span>
            <span class="n">nb_samples_grad_p</span><span class="p">,</span> <span class="n">nb_samples_grad_q</span> <span class="o">=</span> <span class="n">len_p</span><span class="p">,</span> <span class="n">nb_samples_grad</span> <span class="o">//</span> <span class="n">len_p</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nb_samples_grad_p</span><span class="p">,</span> <span class="n">nb_samples_grad_q</span> <span class="o">=</span> <span class="n">nb_samples_grad</span><span class="p">,</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">nb_samples_grad_p</span><span class="p">,</span> <span class="n">nb_samples_grad_q</span> <span class="o">=</span> <span class="n">nb_samples_grad</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
    <span class="c1"># continue_loop allows to stop the loop if there is several successive small modification of T.</span>
    <span class="n">continue_loop</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># The gradient of GW is more complex if the two matrices are not symmetric.</span>
    <span class="n">C_are_symmetric</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span> <span class="ow">and</span> <span class="n">nx</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">C2</span><span class="p">,</span> <span class="n">C2</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">cpt</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="n">index0</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">len_p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">nb_samples_grad_p</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">Lik</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">index0_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">index0</span><span class="p">):</span>
            <span class="n">index1</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">len_q</span><span class="p">,</span>
                                      <span class="n">size</span><span class="o">=</span><span class="n">nb_samples_grad_q</span><span class="p">,</span>
                                      <span class="n">p</span><span class="o">=</span><span class="n">T</span><span class="p">[</span><span class="n">index0_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">index0_i</span><span class="p">,</span> <span class="p">:]),</span>
                                      <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="c1"># If the matrices C are not symmetric, the gradient has 2 terms, thus the term is chosen randomly.</span>
            <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">C_are_symmetric</span><span class="p">)</span> <span class="ow">and</span> <span class="n">generator</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">Lik</span> <span class="o">+=</span> <span class="n">nx</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_fun</span><span class="p">(</span>
                    <span class="n">C1</span><span class="p">[:,</span> <span class="p">[</span><span class="n">index0</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">*</span> <span class="n">nb_samples_grad_q</span><span class="p">][:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:],</span>
                    <span class="n">C2</span><span class="p">[:,</span> <span class="n">index1</span><span class="p">][</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
                <span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">Lik</span> <span class="o">+=</span> <span class="n">nx</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_fun</span><span class="p">(</span>
                    <span class="n">C1</span><span class="p">[[</span><span class="n">index0</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">*</span> <span class="n">nb_samples_grad_q</span><span class="p">,</span> <span class="p">:][:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">],</span>
                    <span class="n">C2</span><span class="p">[</span><span class="n">index1</span><span class="p">,</span> <span class="p">:][:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
                <span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">max_Lik</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Lik</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_Lik</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="c1"># This division by the max is here to facilitate the choice of epsilon.</span>
        <span class="n">Lik</span> <span class="o">/=</span> <span class="n">max_Lik</span>

        <span class="k">if</span> <span class="n">epsilon</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Set to infinity all the numbers below exp(-200) to avoid log of 0.</span>
            <span class="n">log_T</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">200</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">log_T</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">log_T</span> <span class="o">==</span> <span class="o">-</span><span class="mi">200</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">log_T</span><span class="p">)</span>
            <span class="n">Lik</span> <span class="o">=</span> <span class="n">Lik</span> <span class="o">-</span> <span class="n">epsilon</span> <span class="o">*</span> <span class="n">log_T</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="n">new_T</span> <span class="o">=</span> <span class="n">sinkhorn</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">Lik</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="n">epsilon</span><span class="p">)</span>
            <span class="k">except</span> <span class="p">(</span><span class="ne">RuntimeWarning</span><span class="p">,</span> <span class="ne">UserWarning</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning catched in Sinkhorn: Return last stable T&quot;</span><span class="p">)</span>
                <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_T</span> <span class="o">=</span> <span class="n">emd</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">Lik</span><span class="p">)</span>

        <span class="n">change_T</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">T</span> <span class="o">-</span> <span class="n">new_T</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">change_T</span> <span class="o">&lt;=</span> <span class="mf">10e-20</span><span class="p">:</span>
            <span class="n">continue_loop</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">continue_loop</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">:</span>  <span class="c1"># Number max of low modifications of T</span>
                <span class="n">T</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">new_T</span><span class="p">)</span>
                <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">continue_loop</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;||T_n - T_{n+1}||&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">19</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">change_T</span><span class="p">))</span>
        <span class="n">T</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">new_T</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">log</span><span class="p">[</span><span class="s2">&quot;gw_dist_estimated&quot;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s2">&quot;gw_dist_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">GW_distance_estimation</span><span class="p">(</span>
            <span class="n">C1</span><span class="o">=</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="o">=</span><span class="n">C2</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="n">loss_fun</span><span class="p">,</span>
            <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">generator</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">T</span><span class="p">,</span> <span class="n">log</span>
    <span class="k">return</span> <span class="n">T</span></div>


<div class="viewcode-block" id="entropic_gromov_wasserstein"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.entropic_gromov_wasserstein">[docs]</a><span class="k">def</span> <span class="nf">entropic_gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span>
                                <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the gromov-wasserstein transport between :math:`(\mathbf{C_1}, \mathbf{p})` and :math:`(\mathbf{C_2}, \mathbf{q})`</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \mathbf{GW} = \mathop{\arg\min}_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l}) \mathbf{T}_{i,j} \mathbf{T}_{k,l} - \epsilon(H(\mathbf{T}))</span>

<span class="sd">        s.t. \ \mathbf{T} \mathbf{1} &amp;= \mathbf{p}</span>

<span class="sd">             \mathbf{T}^T \mathbf{1} &amp;= \mathbf{q}</span>

<span class="sd">             \mathbf{T} &amp;\geq 0</span>

<span class="sd">    Where :</span>

<span class="sd">    - :math:`\mathbf{C_1}`: Metric cost matrix in the source space</span>
<span class="sd">    - :math:`\mathbf{C_2}`: Metric cost matrix in the target space</span>
<span class="sd">    - :math:`\mathbf{p}`: distribution in the source space</span>
<span class="sd">    - :math:`\mathbf{q}`: distribution in the target space</span>
<span class="sd">    - `L`: loss function to account for the misfit between the similarity matrices</span>
<span class="sd">    - `H`: entropy</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : array-like, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : array-like, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix in the target space</span>
<span class="sd">    p :  array-like, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q :  array-like, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    loss_fun :  string</span>
<span class="sd">        Loss function used for the solver either &#39;square_loss&#39; or &#39;kl_loss&#39;</span>
<span class="sd">    epsilon : float</span>
<span class="sd">        Regularization term &gt;0</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Record log if True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    T : array-like, shape (`ns`, `nt`)</span>
<span class="sd">        Optimal coupling between the two spaces</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Gabriel Peyré, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

    <span class="n">T</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

    <span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span> <span class="o">=</span> <span class="n">init_matrix</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">)</span>

    <span class="n">cpt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">err</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;err&#39;</span><span class="p">:</span> <span class="p">[]}</span>

    <span class="k">while</span> <span class="p">(</span><span class="n">err</span> <span class="o">&gt;</span> <span class="n">tol</span> <span class="ow">and</span> <span class="n">cpt</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">):</span>

        <span class="n">Tprev</span> <span class="o">=</span> <span class="n">T</span>

        <span class="c1"># compute the gradient</span>
        <span class="n">tens</span> <span class="o">=</span> <span class="n">gwggrad</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>

        <span class="n">T</span> <span class="o">=</span> <span class="n">sinkhorn</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">tens</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;sinkhorn&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># we can speed up the process by checking for the error only all</span>
            <span class="c1"># the 10th iterations</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">T</span> <span class="o">-</span> <span class="n">Tprev</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="n">log</span><span class="p">[</span><span class="s1">&#39;err&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Err&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">19</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>

        <span class="n">cpt</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gwloss</span><span class="p">(</span><span class="n">constC</span><span class="p">,</span> <span class="n">hC1</span><span class="p">,</span> <span class="n">hC2</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">T</span><span class="p">,</span> <span class="n">log</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">T</span></div>


<div class="viewcode-block" id="entropic_gromov_wasserstein2"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.entropic_gromov_wasserstein2">[docs]</a><span class="k">def</span> <span class="nf">entropic_gromov_wasserstein2</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span>
                                 <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the entropic gromov-wasserstein discrepancy between the two measured similarity matrices :math:`(\mathbf{C_1}, \mathbf{p})` and :math:`(\mathbf{C_2}, \mathbf{q})`</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        GW = \min_\mathbf{T} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l})</span>
<span class="sd">        \mathbf{T}_{i,j} \mathbf{T}_{k,l} - \epsilon(H(\mathbf{T}))</span>

<span class="sd">    Where :</span>

<span class="sd">    - :math:`\mathbf{C_1}`: Metric cost matrix in the source space</span>
<span class="sd">    - :math:`\mathbf{C_2}`: Metric cost matrix in the target space</span>
<span class="sd">    - :math:`\mathbf{p}`: distribution in the source space</span>
<span class="sd">    - :math:`\mathbf{q}`: distribution in the target space</span>
<span class="sd">    - `L`: loss function to account for the misfit between the similarity matrices</span>
<span class="sd">    - `H`: entropy</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : array-like, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : array-like, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix in the target space</span>
<span class="sd">    p :  array-like, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q :  array-like, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    loss_fun : str</span>
<span class="sd">        Loss function used for the solver either &#39;square_loss&#39; or &#39;kl_loss&#39;</span>
<span class="sd">    epsilon : float</span>
<span class="sd">        Regularization term &gt;0</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Record log if True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gw_dist : float</span>
<span class="sd">        Gromov-Wasserstein distance</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Gabriel Peyré, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">gw</span><span class="p">,</span> <span class="n">logv</span> <span class="o">=</span> <span class="n">entropic_gromov_wasserstein</span><span class="p">(</span>
        <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">max_iter</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">logv</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gw</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">logv</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">],</span> <span class="n">logv</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">logv</span><span class="p">[</span><span class="s1">&#39;gw_dist&#39;</span><span class="p">]</span></div>


<div class="viewcode-block" id="entropic_gromov_barycenters"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.entropic_gromov_barycenters">[docs]</a><span class="k">def</span> <span class="nf">entropic_gromov_barycenters</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Cs</span><span class="p">,</span> <span class="n">ps</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span>
                                <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">init_C</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the gromov-wasserstein barycenters of `S` measured similarity matrices :math:`(\mathbf{C}_s)_{1 \leq s \leq S}`</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \mathbf{C} = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}} \quad \sum_s \lambda_s \mathrm{GW}(\mathbf{C}, \mathbf{C}_s, \mathbf{p}, \mathbf{p}_s)</span>

<span class="sd">    Where :</span>

<span class="sd">    - :math:`\mathbf{C}_s`: metric cost matrix</span>
<span class="sd">    - :math:`\mathbf{p}_s`: distribution</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    N : int</span>
<span class="sd">        Size of the targeted barycenter</span>
<span class="sd">    Cs : list of S array-like of shape (ns,ns)</span>
<span class="sd">        Metric cost matrices</span>
<span class="sd">    ps : list of S array-like of shape (ns,)</span>
<span class="sd">        Sample weights in the `S` spaces</span>
<span class="sd">    p : array-like, shape(N,)</span>
<span class="sd">        Weights in the targeted barycenter</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the `S` spaces&#39; weights.</span>
<span class="sd">    loss_fun : callable</span>
<span class="sd">        Tensor-matrix multiplication function based on specific loss function.</span>
<span class="sd">    update : callable</span>
<span class="sd">        function(:math:`\mathbf{p}`, lambdas, :math:`\mathbf{T}`, :math:`\mathbf{Cs}`) that updates</span>
<span class="sd">        :math:`\mathbf{C}` according to a specific Kernel with the `S` :math:`\mathbf{T}_s` couplings</span>
<span class="sd">        calculated at each iteration</span>
<span class="sd">    epsilon : float</span>
<span class="sd">        Regularization term &gt;0</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Record log if True.</span>
<span class="sd">    init_C : bool | array-like, shape (N, N)</span>
<span class="sd">        Random initial value for the :math:`\mathbf{C}` matrix provided by user.</span>
<span class="sd">    random_state : int or RandomState instance, optional</span>
<span class="sd">        Fix the seed for reproducibility</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    C : array-like, shape (`N`, `N`)</span>
<span class="sd">        Similarity matrix in the barycenter space (permutated arbitrarily)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Gabriel Peyré, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Cs</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">Cs</span><span class="p">)</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">ps</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="o">*</span><span class="n">Cs</span><span class="p">,</span> <span class="o">*</span><span class="n">ps</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="n">S</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Cs</span><span class="p">)</span>

    <span class="c1"># Initialization of C : random SPD matrix (if not provided by user)</span>
    <span class="k">if</span> <span class="n">init_C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">xalea</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">xalea</span><span class="p">,</span> <span class="n">xalea</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">/=</span> <span class="n">C</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">init_C</span>

    <span class="n">cpt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">err</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">error</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">while</span> <span class="p">(</span><span class="n">err</span> <span class="o">&gt;</span> <span class="n">tol</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">cpt</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">):</span>
        <span class="n">Cprev</span> <span class="o">=</span> <span class="n">C</span>

        <span class="n">T</span> <span class="o">=</span> <span class="p">[</span><span class="n">entropic_gromov_wasserstein</span><span class="p">(</span><span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">C</span><span class="p">,</span> <span class="n">ps</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">p</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span>
                                         <span class="n">max_iter</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;square_loss&#39;</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">update_square_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;kl_loss&#39;</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">update_kl_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># we can speed up the process by checking for the error only all</span>
            <span class="c1"># the 10th iterations</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">C</span> <span class="o">-</span> <span class="n">Cprev</span><span class="p">)</span>
            <span class="n">error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="n">log</span><span class="p">[</span><span class="s1">&#39;err&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Err&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">19</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>

        <span class="n">cpt</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">C</span></div>


<div class="viewcode-block" id="gromov_barycenters"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.gromov_barycenters">[docs]</a><span class="k">def</span> <span class="nf">gromov_barycenters</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Cs</span><span class="p">,</span> <span class="n">ps</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span>
                       <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">init_C</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the gromov-wasserstein barycenters of `S` measured similarity matrices :math:`(\mathbf{C}_s)_{1 \leq s \leq S}`</span>

<span class="sd">    The function solves the following optimization problem with block coordinate descent:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \mathbf{C} = \mathop{\arg \min}_{\mathbf{C}\in \mathbb{R}^{N \times N}} \quad \sum_s \lambda_s \mathrm{GW}(\mathbf{C}, \mathbf{C}_s, \mathbf{p}, \mathbf{p}_s)</span>

<span class="sd">    Where :</span>

<span class="sd">    - :math:`\mathbf{C}_s`: metric cost matrix</span>
<span class="sd">    - :math:`\mathbf{p}_s`: distribution</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    N : int</span>
<span class="sd">        Size of the targeted barycenter</span>
<span class="sd">    Cs : list of S array-like of shape (ns, ns)</span>
<span class="sd">        Metric cost matrices</span>
<span class="sd">    ps : list of S array-like of shape (ns,)</span>
<span class="sd">        Sample weights in the `S` spaces</span>
<span class="sd">    p : array-like, shape (N,)</span>
<span class="sd">        Weights in the targeted barycenter</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the `S` spaces&#39; weights</span>
<span class="sd">    loss_fun : callable</span>
<span class="sd">        tensor-matrix multiplication function based on specific loss function</span>
<span class="sd">    update : callable</span>
<span class="sd">        function(:math:`\mathbf{p}`, lambdas, :math:`\mathbf{T}`, :math:`\mathbf{Cs}`) that updates</span>
<span class="sd">        :math:`\mathbf{C}` according to a specific Kernel with the `S` :math:`\mathbf{T}_s` couplings</span>
<span class="sd">        calculated at each iteration</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0).</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Record log if True.</span>
<span class="sd">    init_C : bool | array-like, shape(N,N)</span>
<span class="sd">        Random initial value for the :math:`\mathbf{C}` matrix provided by user.</span>
<span class="sd">    random_state : int or RandomState instance, optional</span>
<span class="sd">        Fix the seed for reproducibility</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    C : array-like, shape (`N`, `N`)</span>
<span class="sd">        Similarity matrix in the barycenter space (permutated arbitrarily)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Gabriel Peyré, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Cs</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">Cs</span><span class="p">)</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">ps</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="o">*</span><span class="n">Cs</span><span class="p">,</span> <span class="o">*</span><span class="n">ps</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="n">S</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Cs</span><span class="p">)</span>

    <span class="c1"># Initialization of C : random SPD matrix (if not provided by user)</span>
    <span class="k">if</span> <span class="n">init_C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">xalea</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">xalea</span><span class="p">,</span> <span class="n">xalea</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">/=</span> <span class="n">C</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">init_C</span>

    <span class="n">cpt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">err</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">error</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">while</span><span class="p">(</span><span class="n">err</span> <span class="o">&gt;</span> <span class="n">tol</span> <span class="ow">and</span> <span class="n">cpt</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">):</span>
        <span class="n">Cprev</span> <span class="o">=</span> <span class="n">C</span>

        <span class="n">T</span> <span class="o">=</span> <span class="p">[</span><span class="n">gromov_wasserstein</span><span class="p">(</span><span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">C</span><span class="p">,</span> <span class="n">ps</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">p</span><span class="p">,</span> <span class="n">loss_fun</span><span class="p">,</span>
                                <span class="n">numItermax</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;square_loss&#39;</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">update_square_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;kl_loss&#39;</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">update_kl_loss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># we can speed up the process by checking for the error only all</span>
            <span class="c1"># the 10th iterations</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">C</span> <span class="o">-</span> <span class="n">Cprev</span><span class="p">)</span>
            <span class="n">error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="n">log</span><span class="p">[</span><span class="s1">&#39;err&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Err&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">19</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>

        <span class="n">cpt</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">C</span></div>


<div class="viewcode-block" id="fgw_barycenters"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.fgw_barycenters">[docs]</a><span class="k">def</span> <span class="nf">fgw_barycenters</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Ys</span><span class="p">,</span> <span class="n">Cs</span><span class="p">,</span> <span class="n">ps</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">fixed_structure</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fixed_features</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">p</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_fun</span><span class="o">=</span><span class="s1">&#39;square_loss&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">init_C</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">init_X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the fgw barycenter as presented eq (5) in :ref:`[24] &lt;references-fgw-barycenters&gt;`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    N : int</span>
<span class="sd">        Desired number of samples of the target barycenter</span>
<span class="sd">    Ys: list of array-like, each element has shape (ns,d)</span>
<span class="sd">        Features of all samples</span>
<span class="sd">    Cs : list of array-like, each element has shape (ns,ns)</span>
<span class="sd">        Structure matrices of all samples</span>
<span class="sd">    ps : list of array-like, each element has shape (ns,)</span>
<span class="sd">        Masses of all samples.</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the `S` spaces&#39; weights</span>
<span class="sd">    alpha : float</span>
<span class="sd">        Alpha parameter for the fgw distance</span>
<span class="sd">    fixed_structure : bool</span>
<span class="sd">        Whether to fix the structure of the barycenter during the updates</span>
<span class="sd">    fixed_features : bool</span>
<span class="sd">        Whether to fix the feature of the barycenter during the updates</span>
<span class="sd">    loss_fun : str</span>
<span class="sd">        Loss function used for the solver either &#39;square_loss&#39; or &#39;kl_loss&#39;</span>
<span class="sd">    max_iter : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0).</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        Record log if True.</span>
<span class="sd">    init_C : array-like, shape (N,N), optional</span>
<span class="sd">        Initialization for the barycenters&#39; structure matrix. If not set</span>
<span class="sd">        a random init is used.</span>
<span class="sd">    init_X : array-like, shape (N,d), optional</span>
<span class="sd">        Initialization for the barycenters&#39; features. If not set a</span>
<span class="sd">        random init is used.</span>
<span class="sd">    random_state : int or RandomState instance, optional</span>
<span class="sd">        Fix the seed for reproducibility</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    X : array-like, shape (`N`, `d`)</span>
<span class="sd">        Barycenters&#39; features</span>
<span class="sd">    C : array-like, shape (`N`, `N`)</span>
<span class="sd">        Barycenters&#39; structure matrix</span>
<span class="sd">    log : dict</span>
<span class="sd">        Only returned when log=True. It contains the keys:</span>

<span class="sd">        - :math:`\mathbf{T}`: list of (`N`, `ns`) transport matrices</span>
<span class="sd">        - :math:`(\mathbf{M}_s)_s`: all distance matrices between the feature of the barycenter and the other features :math:`(dist(\mathbf{X}, \mathbf{Y}_s))_s` shape (`N`, `ns`)</span>


<span class="sd">    .. _references-fgw-barycenters:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [24] Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain</span>
<span class="sd">        and Courty Nicolas</span>
<span class="sd">        &quot;Optimal Transport for structured data with application on graphs&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2019.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Cs</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">Cs</span><span class="p">)</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">ps</span><span class="p">)</span>
    <span class="n">Ys</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">Ys</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="o">*</span><span class="n">Cs</span><span class="p">,</span> <span class="o">*</span><span class="n">Ys</span><span class="p">,</span> <span class="o">*</span><span class="n">ps</span><span class="p">)</span>

    <span class="n">S</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Cs</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">Ys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># dimension on the node features</span>
    <span class="k">if</span> <span class="n">p</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">Cs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">N</span>

    <span class="k">if</span> <span class="n">fixed_structure</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">init_C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">UndefinedParameter</span><span class="p">(</span><span class="s1">&#39;If C is fixed it must be initialized&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">init_C</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">init_C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">generator</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
            <span class="n">xalea</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">xalea</span><span class="p">,</span> <span class="n">xalea</span><span class="p">)</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">ps</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">C</span> <span class="o">=</span> <span class="n">init_C</span>

    <span class="k">if</span> <span class="n">fixed_features</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">init_X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">UndefinedParameter</span><span class="p">(</span><span class="s1">&#39;If X is fixed it must be initialized&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">init_X</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">init_X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">ps</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">init_X</span>

    <span class="n">T</span> <span class="o">=</span> <span class="p">[</span><span class="n">nx</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">ps</span><span class="p">]</span>

    <span class="n">Ms</span> <span class="o">=</span> <span class="p">[</span><span class="n">dist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Ys</span><span class="p">[</span><span class="n">s</span><span class="p">])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Ys</span><span class="p">))]</span>

    <span class="n">cpt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">err_feature</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">err_structure</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log_</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;err_feature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;err_structure&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;Ts_iter&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">while</span><span class="p">((</span><span class="n">err_feature</span> <span class="o">&gt;</span> <span class="n">tol</span> <span class="ow">or</span> <span class="n">err_structure</span> <span class="o">&gt;</span> <span class="n">tol</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cpt</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">):</span>
        <span class="n">Cprev</span> <span class="o">=</span> <span class="n">C</span>
        <span class="n">Xprev</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">fixed_features</span><span class="p">:</span>
            <span class="n">Ys_temp</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">T</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">Ys</span><span class="p">]</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">update_feature_matrix</span><span class="p">(</span><span class="n">lambdas</span><span class="p">,</span> <span class="n">Ys_temp</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

        <span class="n">Ms</span> <span class="o">=</span> <span class="p">[</span><span class="n">dist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Ys</span><span class="p">[</span><span class="n">s</span><span class="p">])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Ys</span><span class="p">))]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">fixed_structure</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">loss_fun</span> <span class="o">==</span> <span class="s1">&#39;square_loss&#39;</span><span class="p">:</span>
                <span class="n">T_temp</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">T</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">T</span><span class="p">]</span>
                <span class="n">C</span> <span class="o">=</span> <span class="n">update_structure_matrix</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T_temp</span><span class="p">,</span> <span class="n">Cs</span><span class="p">)</span>

        <span class="n">T</span> <span class="o">=</span> <span class="p">[</span><span class="n">fused_gromov_wasserstein</span><span class="p">(</span><span class="n">Ms</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">C</span><span class="p">,</span> <span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">p</span><span class="p">,</span> <span class="n">ps</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">loss_fun</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span>
                                      <span class="n">numItermax</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="p">)]</span>

        <span class="c1"># T is N,ns</span>
        <span class="n">err_feature</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">nx</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Xprev</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">d</span><span class="p">)))</span>
        <span class="n">err_structure</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">C</span> <span class="o">-</span> <span class="n">Cprev</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
            <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;err_feature&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err_feature</span><span class="p">)</span>
            <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;err_structure&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err_structure</span><span class="p">)</span>
            <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;Ts_iter&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Err&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">19</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err_structure</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err_feature</span><span class="p">))</span>

        <span class="n">cpt</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;T&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">T</span>  <span class="c1"># from target to Ys</span>
        <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span>
        <span class="n">log_</span><span class="p">[</span><span class="s1">&#39;Ms&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Ms</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">log_</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">C</span></div>


<div class="viewcode-block" id="update_structure_matrix"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.update_structure_matrix">[docs]</a><span class="k">def</span> <span class="nf">update_structure_matrix</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">lambdas</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Updates :math:`\mathbf{C}` according to the L2 Loss kernel with the `S` :math:`\mathbf{T}_s` couplings.</span>

<span class="sd">    It is calculated at each iteration</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p : array-like, shape (N,)</span>
<span class="sd">        Masses in the targeted barycenter.</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the `S` spaces&#39; weights.</span>
<span class="sd">    T : list of S array-like of shape (ns, N)</span>
<span class="sd">        The `S` :math:`\mathbf{T}_s` couplings calculated at each iteration.</span>
<span class="sd">    Cs : list of S array-like, shape (ns, ns)</span>
<span class="sd">        Metric cost matrices.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    C : array-like, shape (`nt`, `nt`)</span>
<span class="sd">        Updated :math:`\mathbf{C}` matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">T</span><span class="p">)</span>
    <span class="n">Cs</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">Cs</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="o">*</span><span class="n">Cs</span><span class="p">,</span> <span class="o">*</span><span class="n">T</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="n">tmpsum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span>
        <span class="n">lambdas</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
            <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Cs</span><span class="p">[</span><span class="n">s</span><span class="p">]),</span>
            <span class="n">T</span><span class="p">[</span><span class="n">s</span><span class="p">]</span>
        <span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">T</span><span class="p">))</span>
    <span class="p">])</span>
    <span class="n">ppt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tmpsum</span> <span class="o">/</span> <span class="n">ppt</span></div>


<div class="viewcode-block" id="update_feature_matrix"><a class="viewcode-back" href="../../gen_modules/ot.gromov.html#ot.gromov.update_feature_matrix">[docs]</a><span class="k">def</span> <span class="nf">update_feature_matrix</span><span class="p">(</span><span class="n">lambdas</span><span class="p">,</span> <span class="n">Ys</span><span class="p">,</span> <span class="n">Ts</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Updates the feature with respect to the `S` :math:`\mathbf{T}_s` couplings.</span>


<span class="sd">    See &quot;Solving the barycenter problem with Block Coordinate Descent (BCD)&quot;</span>
<span class="sd">    in :ref:`[24] &lt;references-update-feature-matrix&gt;` calculated at each iteration</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p : array-like, shape (N,)</span>
<span class="sd">        masses in the targeted barycenter</span>
<span class="sd">    lambdas : list of float</span>
<span class="sd">        List of the `S` spaces&#39; weights</span>
<span class="sd">    Ts : list of S array-like, shape (ns,N)</span>
<span class="sd">        The `S` :math:`\mathbf{T}_s` couplings calculated at each iteration</span>
<span class="sd">    Ys : list of S array-like, shape (d,ns)</span>
<span class="sd">        The features.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    X : array-like, shape (`d`, `N`)</span>


<span class="sd">    .. _references-update-feature-matrix:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [24] Vayer Titouan, Chapel Laetitia, Flamary Rémi, Tavenard Romain and Courty Nicolas</span>
<span class="sd">        &quot;Optimal Transport for structured data with application on graphs&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2019.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">Ts</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">Ts</span><span class="p">)</span>
    <span class="n">Ys</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="o">*</span><span class="n">Ys</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="o">*</span><span class="n">Ys</span><span class="p">,</span> <span class="o">*</span><span class="n">Ts</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">p</span>
    <span class="n">tmpsum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span>
        <span class="n">lambdas</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ys</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">Ts</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Ts</span><span class="p">))</span>
    <span class="p">])</span>
    <span class="k">return</span> <span class="n">tmpsum</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016-2021, Rémi Flamary, Nicolas Courty.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions shift-up" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Python Optimal Transport</span>
      versions
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions"><!-- Inserted RTD Footer -->

<div class="injected">

      
      
      <dl>
        <dt>Versions</dt>
        
        <dd><a href="https://pythonot.github.io/master">latest</a></dd>
       
        <dd><a href="https://pythonot.github.io/">stable</a></dd>
        
      </dl>
      

    
      
      <dl>
        <dt>On GitHub</dt>
        <dd>
          <a href="https://github.com/PythonOT/POT">Code on Github</a>
        </dd>
        
      </dl>
      
    
      
      

      <hr>
      


</div>
</div>
  </div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>