

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ot.partial &mdash; POT Python Optimal Transport 0.9.6dev0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=6e3d2238"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            POT Python Optimal Transport
              <img src="../../_static/logo_dark.svg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">POT: Python Optimal Transport</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/plot_quickstart_guide.html">Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Examples gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../all.html">API and modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributors.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing to POT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../code_of_conduct.html">Code of conduct</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">POT Python Optimal Transport</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">ot.partial</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for ot.partial</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Partial OT solvers</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Author: Laetitia Chapel &lt;laetitia.chapel@irisa.fr&gt;</span>
<span class="c1">#         Yikun Bai &lt; yikun.bai@vanderbilt.edu &gt;</span>
<span class="c1">#         Cédric Vincent-Cuaz &lt;cedvincentcuaz@gmail.com&gt;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">list_to_array</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.backend</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_backend</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.lp</span><span class="w"> </span><span class="kn">import</span> <span class="n">emd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>

<span class="c1"># License: MIT License</span>


<div class="viewcode-block" id="partial_wasserstein_lagrange">
<a class="viewcode-back" href="../../gen_modules/ot.partial.html#ot.partial.partial_wasserstein_lagrange">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">partial_wasserstein_lagrange</span><span class="p">(</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg_m</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nb_dummies</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solves the partial optimal transport problem for the quadratic cost</span>
<span class="sd">    and returns the OT plan</span>

<span class="sd">    The function considers the following problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, (\mathbf{M} - \lambda) \rangle_F</span>

<span class="sd">    .. math::</span>
<span class="sd">        s.t. \ \gamma \mathbf{1} &amp;\leq \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} &amp;\leq \mathbf{b}</span>

<span class="sd">             \gamma &amp;\geq 0</span>

<span class="sd">             \mathbf{1}^T \gamma^T \mathbf{1} = m &amp;</span>
<span class="sd">             \leq \min\{\|\mathbf{a}\|_1, \|\mathbf{b}\|_1\}</span>


<span class="sd">    or equivalently (see Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X.</span>
<span class="sd">    (2018). An interpolating distance between optimal transport and Fisher–Rao</span>
<span class="sd">    metrics. Foundations of Computational Mathematics, 18(1), 1-44.)</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F  +</span>
<span class="sd">        \sqrt{\frac{\lambda}{2} (\|\gamma \mathbf{1} - \mathbf{a}\|_1 + \|\gamma^T \mathbf{1} - \mathbf{b}\|_1)}</span>

<span class="sd">        s.t. \ \gamma \geq 0</span>


<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the metric cost matrix</span>
<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are source and target unbalanced distributions</span>
<span class="sd">    - :math:`\lambda` is the lagrangian cost. Tuning its value allows attaining</span>
<span class="sd">      a given mass to be transported `m`</span>

<span class="sd">    The formulation of the problem has been proposed in</span>
<span class="sd">    :ref:`[28] &lt;references-partial-wasserstein-lagrange&gt;`</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : np.ndarray (dim_a,)</span>
<span class="sd">        Unnormalized histogram of dimension `dim_a`</span>
<span class="sd">    b : np.ndarray (dim_b,)</span>
<span class="sd">        Unnormalized histograms of dimension `dim_b`</span>
<span class="sd">    M : np.ndarray (dim_a, dim_b)</span>
<span class="sd">        cost matrix for the quadratic cost</span>
<span class="sd">    reg_m : float, optional</span>
<span class="sd">        Lagrangian cost</span>
<span class="sd">    nb_dummies : int, optional, default:1</span>
<span class="sd">        number of reservoir points to be added (to avoid numerical</span>
<span class="sd">        instabilities, increase its value if an error is raised)</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        parameters can be directly passed to the emd solver</span>


<span class="sd">    .. warning::</span>
<span class="sd">        When dealing with a large number of points, the EMD solver may face</span>
<span class="sd">        some instabilities, especially when the mass associated to the dummy</span>
<span class="sd">        point is large. To avoid them, increase the number of dummy points</span>
<span class="sd">        (allows a smoother repartition of the mass over the points).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : (dim_a, dim_b) ndarray</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary returned only if `log` is `True`</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; import ot</span>
<span class="sd">    &gt;&gt;&gt; a = [.1, .2]</span>
<span class="sd">    &gt;&gt;&gt; b = [.1, .1]</span>
<span class="sd">    &gt;&gt;&gt; M = [[0., 1.], [2., 3.]]</span>
<span class="sd">    &gt;&gt;&gt; np.round(partial_wasserstein_lagrange(a,b,M), 2)</span>
<span class="sd">    array([[0.1, 0. ],</span>
<span class="sd">           [0. , 0.1]])</span>
<span class="sd">    &gt;&gt;&gt; np.round(partial_wasserstein_lagrange(a,b,M,reg_m=2), 2)</span>
<span class="sd">    array([[0.1, 0. ],</span>
<span class="sd">           [0. , 0. ]])</span>


<span class="sd">    .. _references-partial-wasserstein-lagrange:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [28] Caffarelli, L. A., &amp; McCann, R. J. (2010) Free boundaries in</span>
<span class="sd">        optimal transport and Monge-Ampere obstacle problems. Annals of</span>
<span class="sd">        mathematics, 673-730.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.partial.partial_wasserstein : Partial Wasserstein with fixed mass</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="o">+</span> <span class="mf">1e-15</span> <span class="ow">or</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="o">+</span> <span class="mf">1e-15</span><span class="p">:</span>  <span class="c1"># 1e-15 for numerical errors</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Problem infeasible. Check that a and b are in the simplex&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">reg_m</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">reg_m</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">reg_m</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">nx</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">)),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>

    <span class="n">a0</span><span class="p">,</span> <span class="n">b0</span><span class="p">,</span> <span class="n">M0</span> <span class="o">=</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span>
    <span class="c1"># convert to humpy</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-20</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">M_star</span> <span class="o">=</span> <span class="n">M</span> <span class="o">-</span> <span class="n">reg_m</span>  <span class="c1"># modified cost matrix</span>

    <span class="c1"># trick to fasten the computation: select only the subset of columns/lines</span>
    <span class="c1"># that can have marginals greater than 0 (that is to say M &lt; 0)</span>
    <span class="n">idx_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">M_star</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">eps</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">idx_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">M_star</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">eps</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># extend a, b, M with &quot;reservoir&quot; or &quot;dummy&quot; points</span>
    <span class="n">M_extended</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">idx_x</span><span class="p">)</span> <span class="o">+</span> <span class="n">nb_dummies</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx_y</span><span class="p">)</span> <span class="o">+</span> <span class="n">nb_dummies</span><span class="p">))</span>
    <span class="n">M_extended</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx_x</span><span class="p">),</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx_y</span><span class="p">)]</span> <span class="o">=</span> <span class="n">M_star</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">idx_x</span><span class="p">,</span> <span class="n">idx_y</span><span class="p">)]</span>

    <span class="n">a_extended</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">a</span><span class="p">[</span><span class="n">idx_x</span><span class="p">],</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">idx_x</span><span class="p">])</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">b</span><span class="p">))</span> <span class="o">/</span> <span class="n">nb_dummies</span><span class="p">]</span> <span class="o">*</span> <span class="n">nb_dummies</span>
    <span class="p">)</span>
    <span class="n">b_extended</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">b</span><span class="p">[</span><span class="n">idx_y</span><span class="p">],</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="n">idx_y</span><span class="p">])</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">))</span> <span class="o">/</span> <span class="n">nb_dummies</span><span class="p">]</span> <span class="o">*</span> <span class="n">nb_dummies</span>
    <span class="p">)</span>

    <span class="n">gamma_extended</span><span class="p">,</span> <span class="n">log_emd</span> <span class="o">=</span> <span class="n">emd</span><span class="p">(</span>
        <span class="n">a_extended</span><span class="p">,</span> <span class="n">b_extended</span><span class="p">,</span> <span class="n">M_extended</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">)))</span>
    <span class="n">gamma</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">idx_x</span><span class="p">,</span> <span class="n">idx_y</span><span class="p">)]</span> <span class="o">=</span> <span class="n">gamma_extended</span><span class="p">[:</span><span class="o">-</span><span class="n">nb_dummies</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="n">nb_dummies</span><span class="p">]</span>

    <span class="c1"># convert back to backend</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">M0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">log_emd</span><span class="p">[</span><span class="s2">&quot;warning&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Error in the EMD resolution: try to increase the number of dummy points&quot;</span>
        <span class="p">)</span>
    <span class="n">log_emd</span><span class="p">[</span><span class="s2">&quot;cost&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">M0</span><span class="p">)</span>
    <span class="n">log_emd</span><span class="p">[</span><span class="s2">&quot;u&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">log_emd</span><span class="p">[</span><span class="s2">&quot;u&quot;</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">a0</span><span class="p">)</span>
    <span class="n">log_emd</span><span class="p">[</span><span class="s2">&quot;v&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">log_emd</span><span class="p">[</span><span class="s2">&quot;v&quot;</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">b0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">log_emd</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gamma</span></div>



<div class="viewcode-block" id="partial_wasserstein">
<a class="viewcode-back" href="../../gen_modules/ot.partial.html#ot.partial.partial_wasserstein">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">partial_wasserstein</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nb_dummies</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solves the partial optimal transport problem for the quadratic cost</span>
<span class="sd">    and returns the OT plan</span>

<span class="sd">    The function considers the following problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F</span>

<span class="sd">    .. math::</span>
<span class="sd">        s.t. \ \gamma \mathbf{1} &amp;\leq \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} &amp;\leq \mathbf{b}</span>

<span class="sd">             \gamma &amp;\geq 0</span>

<span class="sd">             \mathbf{1}^T \gamma^T \mathbf{1} = m &amp;\leq \min\{\|\mathbf{a}\|_1, \|\mathbf{b}\|_1\}</span>


<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the metric cost matrix</span>
<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are source and target unbalanced distributions</span>
<span class="sd">    - `m` is the amount of mass to be transported</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : np.ndarray (dim_a,)</span>
<span class="sd">        Unnormalized histogram of dimension `dim_a`</span>
<span class="sd">    b : np.ndarray (dim_b,)</span>
<span class="sd">        Unnormalized histograms of dimension `dim_b`</span>
<span class="sd">    M : np.ndarray (dim_a, dim_b)</span>
<span class="sd">        cost matrix for the quadratic cost</span>
<span class="sd">    m : float, optional</span>
<span class="sd">        amount of mass to be transported</span>
<span class="sd">    nb_dummies : int, optional, default:1</span>
<span class="sd">        number of reservoir points to be added (to avoid numerical</span>
<span class="sd">        instabilities, increase its value if an error is raised)</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        parameters can be directly passed to the emd solver</span>


<span class="sd">    .. warning::</span>
<span class="sd">        When dealing with a large number of points, the EMD solver may face</span>
<span class="sd">        some instabilities, especially when the mass associated to the dummy</span>
<span class="sd">        point is large. To avoid them, increase the number of dummy points</span>
<span class="sd">        (allows a smoother repartition of the mass over the points).</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : (dim_a, dim_b) ndarray</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary returned only if `log` is `True`</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; import ot</span>
<span class="sd">    &gt;&gt;&gt; a = [.1, .2]</span>
<span class="sd">    &gt;&gt;&gt; b = [.1, .1]</span>
<span class="sd">    &gt;&gt;&gt; M = [[0., 1.], [2., 3.]]</span>
<span class="sd">    &gt;&gt;&gt; np.round(partial_wasserstein(a,b,M), 2)</span>
<span class="sd">    array([[0.1, 0. ],</span>
<span class="sd">           [0. , 0.1]])</span>
<span class="sd">    &gt;&gt;&gt; np.round(partial_wasserstein(a,b,M,m=0.1), 2)</span>
<span class="sd">    array([[0.1, 0. ],</span>
<span class="sd">           [0. , 0. ]])</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    ..  [28] Caffarelli, L. A., &amp; McCann, R. J. (2010) Free boundaries in</span>
<span class="sd">        optimal transport and Monge-Ampere obstacle problems. Annals of</span>
<span class="sd">        mathematics, 673-730.</span>
<span class="sd">    ..  [29] Chapel, L., Alaya, M., Gasso, G. (2020). &quot;Partial Optimal</span>
<span class="sd">        Transport with Applications on Positive-Unlabeled Learning&quot;.</span>
<span class="sd">        NeurIPS.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.partial.partial_wasserstein_lagrange: Partial Wasserstein with</span>
<span class="sd">    regularization on the marginals</span>
<span class="sd">    ot.partial.entropic_partial_wasserstein: Partial Wasserstein with a</span>
<span class="sd">    entropic regularization parameter</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">dim_a</span><span class="p">,</span> <span class="n">dim_b</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim_a</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">dim_a</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim_b</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">dim_b</span>

    <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">partial_wasserstein_lagrange</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">m</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Problem infeasible. Parameter m should be greater than 0.&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="n">nx</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">b</span><span class="p">)))):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Problem infeasible. Parameter m should lower or&quot;</span>
            <span class="s2">&quot; equal than min(|a|_1, |b|_1).&quot;</span>
        <span class="p">)</span>

    <span class="n">b_extension</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">nb_dummies</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">b</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span> <span class="o">/</span> <span class="n">nb_dummies</span>
    <span class="n">b_extended</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">b</span><span class="p">,</span> <span class="n">b_extension</span><span class="p">))</span>
    <span class="n">a_extension</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">nb_dummies</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">a</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span> <span class="o">/</span> <span class="n">nb_dummies</span>
    <span class="n">a_extended</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">a_extension</span><span class="p">))</span>
    <span class="n">M_extension</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">nb_dummies</span><span class="p">,</span> <span class="n">nb_dummies</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">M</span><span class="p">)</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="n">M_extended</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
        <span class="p">(</span>
            <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">M_extension</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M_extension</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span> <span class="n">M_extension</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">),</span>
        <span class="p">),</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">gamma</span><span class="p">,</span> <span class="n">log_emd</span> <span class="o">=</span> <span class="n">emd</span><span class="p">(</span><span class="n">a_extended</span><span class="p">,</span> <span class="n">b_extended</span><span class="p">,</span> <span class="n">M_extended</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">)]</span>

    <span class="k">if</span> <span class="n">log_emd</span><span class="p">[</span><span class="s2">&quot;warning&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Error in the EMD resolution: try to increase the number of dummy points&quot;</span>
        <span class="p">)</span>
    <span class="n">log_emd</span><span class="p">[</span><span class="s2">&quot;partial_w_dist&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">M</span> <span class="o">*</span> <span class="n">gamma</span><span class="p">)</span>
    <span class="n">log_emd</span><span class="p">[</span><span class="s2">&quot;u&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">log_emd</span><span class="p">[</span><span class="s2">&quot;u&quot;</span><span class="p">][:</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)]</span>
    <span class="n">log_emd</span><span class="p">[</span><span class="s2">&quot;v&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">log_emd</span><span class="p">[</span><span class="s2">&quot;v&quot;</span><span class="p">][:</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">)]</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">log_emd</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gamma</span></div>



<div class="viewcode-block" id="partial_wasserstein2">
<a class="viewcode-back" href="../../gen_modules/ot.partial.html#ot.partial.partial_wasserstein2">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">partial_wasserstein2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nb_dummies</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solves the partial optimal transport problem for the quadratic cost</span>
<span class="sd">    and returns the partial GW discrepancy</span>

<span class="sd">    The function considers the following problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \min_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F</span>

<span class="sd">    .. math::</span>
<span class="sd">        s.t. \ \gamma \mathbf{1} &amp;\leq \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} &amp;\leq \mathbf{b}</span>

<span class="sd">             \gamma &amp;\geq 0</span>

<span class="sd">             \mathbf{1}^T \gamma^T \mathbf{1} = m &amp;\leq \min\{\|\mathbf{a}\|_1, \|\mathbf{b}\|_1\}</span>


<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the metric cost matrix</span>
<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are source and target unbalanced distributions</span>
<span class="sd">    - `m` is the amount of mass to be transported</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : np.ndarray (dim_a,)</span>
<span class="sd">        Unnormalized histogram of dimension `dim_a`</span>
<span class="sd">    b : np.ndarray (dim_b,)</span>
<span class="sd">        Unnormalized histograms of dimension `dim_b`</span>
<span class="sd">    M : np.ndarray (dim_a, dim_b)</span>
<span class="sd">        cost matrix for the quadratic cost</span>
<span class="sd">    m : float, optional</span>
<span class="sd">        amount of mass to be transported</span>
<span class="sd">    nb_dummies : int, optional, default:1</span>
<span class="sd">        number of reservoir points to be added (to avoid numerical</span>
<span class="sd">        instabilities, increase its value if an error is raised)</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        parameters can be directly passed to the emd solver</span>


<span class="sd">    .. warning::</span>
<span class="sd">        When dealing with a large number of points, the EMD solver may face</span>
<span class="sd">        some instabilities, especially when the mass associated to the dummy</span>
<span class="sd">        point is large. To avoid them, increase the number of dummy points</span>
<span class="sd">        (allows a smoother repartition of the mass over the points).</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    GW: float</span>
<span class="sd">        partial GW discrepancy</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary returned only if `log` is `True`</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; import ot</span>
<span class="sd">    &gt;&gt;&gt; a=[.1, .2]</span>
<span class="sd">    &gt;&gt;&gt; b=[.1, .1]</span>
<span class="sd">    &gt;&gt;&gt; M=[[0., 1.], [2., 3.]]</span>
<span class="sd">    &gt;&gt;&gt; np.round(partial_wasserstein2(a, b, M), 1)</span>
<span class="sd">    0.3</span>
<span class="sd">    &gt;&gt;&gt; np.round(partial_wasserstein2(a,b,M,m=0.1), 1)</span>
<span class="sd">    0.0</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    ..  [28] Caffarelli, L. A., &amp; McCann, R. J. (2010) Free boundaries in</span>
<span class="sd">        optimal transport and Monge-Ampere obstacle problems. Annals of</span>
<span class="sd">        mathematics, 673-730.</span>
<span class="sd">    ..  [29] Chapel, L., Alaya, M., Gasso, G. (2020). &quot;Partial Optimal</span>
<span class="sd">        Transport with Applications on Positive-Unlabeled Learning&quot;.</span>
<span class="sd">        NeurIPS.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">partial_gw</span><span class="p">,</span> <span class="n">log_w</span> <span class="o">=</span> <span class="n">partial_wasserstein</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">nb_dummies</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">log_w</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial_gw</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">partial_gw</span> <span class="o">*</span> <span class="n">M</span><span class="p">),</span> <span class="n">log_w</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">partial_gw</span> <span class="o">*</span> <span class="n">M</span><span class="p">)</span></div>



<div class="viewcode-block" id="entropic_partial_wasserstein">
<a class="viewcode-back" href="../../gen_modules/ot.partial.html#ot.partial.entropic_partial_wasserstein">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">entropic_partial_wasserstein</span><span class="p">(</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="mf">1e-100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solves the partial optimal transport problem</span>
<span class="sd">    and returns the OT plan</span>

<span class="sd">    The function considers the following problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma,</span>
<span class="sd">                 \mathbf{M} \rangle_F + \mathrm{reg} \cdot\Omega(\gamma)</span>

<span class="sd">        s.t. \gamma \mathbf{1} &amp;\leq \mathbf{a} \\</span>
<span class="sd">             \gamma^T \mathbf{1} &amp;\leq \mathbf{b} \\</span>
<span class="sd">             \gamma &amp;\geq 0 \\</span>
<span class="sd">             \mathbf{1}^T \gamma^T \mathbf{1} = m</span>
<span class="sd">             &amp;\leq \min\{\|\mathbf{a}\|_1, \|\mathbf{b}\|_1\} \\</span>

<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the metric cost matrix</span>
<span class="sd">    - :math:`\Omega`  is the entropic regularization term,</span>
<span class="sd">      :math:`\Omega=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})`</span>
<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are the sample weights</span>
<span class="sd">    - `m` is the amount of mass to be transported</span>

<span class="sd">    The formulation of the problem has been proposed in</span>
<span class="sd">    :ref:`[3] &lt;references-entropic-partial-wasserstein&gt;` (prop. 5)</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : np.ndarray (dim_a,)</span>
<span class="sd">        Unnormalized histogram of dimension `dim_a`</span>
<span class="sd">    b : np.ndarray (dim_b,)</span>
<span class="sd">        Unnormalized histograms of dimension `dim_b`</span>
<span class="sd">    M : np.ndarray (dim_a, dim_b)</span>
<span class="sd">        cost matrix</span>
<span class="sd">    reg : float</span>
<span class="sd">        Regularization term &gt; 0</span>
<span class="sd">    m : float, optional</span>
<span class="sd">        Amount of mass to be transported</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    stopThr : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : (dim_a, dim_b) ndarray</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary returned only if `log` is `True`</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import ot</span>
<span class="sd">    &gt;&gt;&gt; a = [.1, .2]</span>
<span class="sd">    &gt;&gt;&gt; b = [.1, .1]</span>
<span class="sd">    &gt;&gt;&gt; M = [[0., 1.], [2., 3.]]</span>
<span class="sd">    &gt;&gt;&gt; np.round(entropic_partial_wasserstein(a, b, M, 1, 0.1), 2)</span>
<span class="sd">    array([[0.06, 0.02],</span>
<span class="sd">           [0.01, 0.  ]])</span>


<span class="sd">    .. _references-entropic-partial-wasserstein:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [3] Benamou, J. D., Carlier, G., Cuturi, M., Nenna, L., &amp; Peyré, G.</span>
<span class="sd">        (2015). Iterative Bregman projections for regularized transportation</span>
<span class="sd">        problems. SIAM Journal on Scientific Computing, 37(2), A1111-A1138.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.partial.partial_wasserstein: exact Partial Wasserstein</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">dim_a</span><span class="p">,</span> <span class="n">dim_b</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim_a</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">a</span><span class="p">)</span>
    <span class="n">dy</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim_b</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim_a</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">dim_a</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim_b</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">dim_b</span>

    <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">b</span><span class="p">))))</span> <span class="o">*</span> <span class="mf">1.0</span>
    <span class="k">if</span> <span class="n">m</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Problem infeasible. Parameter m should be greater than 0.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="n">nx</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">b</span><span class="p">)))):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Problem infeasible. Parameter m should lower or&quot;</span>
            <span class="s2">&quot; equal than min(|a|_1, |b|_1).&quot;</span>
        <span class="p">)</span>

    <span class="n">log_e</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;err&quot;</span><span class="p">:</span> <span class="p">[]}</span>

    <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;numpy&quot;</span><span class="p">:</span>
        <span class="c1"># Next 3 lines equivalent to K=nx.exp(-M/reg), but faster to compute</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">M</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="o">-</span><span class="n">reg</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">K</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">K</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">m</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="p">),</span> <span class="n">out</span><span class="o">=</span><span class="n">K</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">M</span> <span class="o">/</span> <span class="n">reg</span><span class="p">)</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">K</span> <span class="o">*</span> <span class="n">m</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>

    <span class="n">err</span><span class="p">,</span> <span class="n">cpt</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span>
    <span class="n">q1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">K</span><span class="p">)</span>
    <span class="n">q2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">K</span><span class="p">)</span>
    <span class="n">q3</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">K</span><span class="p">)</span>

    <span class="k">while</span> <span class="n">err</span> <span class="o">&gt;</span> <span class="n">stopThr</span> <span class="ow">and</span> <span class="n">cpt</span> <span class="o">&lt;</span> <span class="n">numItermax</span><span class="p">:</span>
        <span class="n">Kprev</span> <span class="o">=</span> <span class="n">K</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">K</span> <span class="o">*</span> <span class="n">q1</span>
        <span class="n">K1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">a</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dx</span><span class="p">)),</span> <span class="n">K</span><span class="p">)</span>
        <span class="n">q1</span> <span class="o">=</span> <span class="n">q1</span> <span class="o">*</span> <span class="n">Kprev</span> <span class="o">/</span> <span class="n">K1</span>
        <span class="n">K1prev</span> <span class="o">=</span> <span class="n">K1</span>
        <span class="n">K1</span> <span class="o">=</span> <span class="n">K1</span> <span class="o">*</span> <span class="n">q2</span>
        <span class="n">K2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K1</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">b</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">dy</span><span class="p">)))</span>
        <span class="n">q2</span> <span class="o">=</span> <span class="n">q2</span> <span class="o">*</span> <span class="n">K1prev</span> <span class="o">/</span> <span class="n">K2</span>
        <span class="n">K2prev</span> <span class="o">=</span> <span class="n">K2</span>
        <span class="n">K2</span> <span class="o">=</span> <span class="n">K2</span> <span class="o">*</span> <span class="n">q3</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">K2</span> <span class="o">*</span> <span class="p">(</span><span class="n">m</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K2</span><span class="p">))</span>
        <span class="n">q3</span> <span class="o">=</span> <span class="n">q3</span> <span class="o">*</span> <span class="n">K2prev</span> <span class="o">/</span> <span class="n">K</span>

        <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">K</span><span class="p">))</span> <span class="ow">or</span> <span class="n">nx</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">K</span><span class="p">)):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: numerical errors at iteration&quot;</span><span class="p">,</span> <span class="n">cpt</span><span class="p">)</span>
            <span class="k">break</span>
        <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Kprev</span> <span class="o">-</span> <span class="n">K</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="n">log_e</span><span class="p">[</span><span class="s2">&quot;err&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:5s}</span><span class="s2">|</span><span class="si">{:12s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;It.&quot;</span><span class="p">,</span> <span class="s2">&quot;Err&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">11</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:5d}</span><span class="s2">|</span><span class="si">{:8e}</span><span class="s2">|&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err</span><span class="p">))</span>

        <span class="n">cpt</span> <span class="o">=</span> <span class="n">cpt</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">log_e</span><span class="p">[</span><span class="s2">&quot;partial_w_dist&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">M</span> <span class="o">*</span> <span class="n">K</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">log_e</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">K</span></div>



<div class="viewcode-block" id="gwgrad_partial">
<a class="viewcode-back" href="../../gen_modules/ot.partial.html#ot.partial.gwgrad_partial">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">gwgrad_partial</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the GW gradient. Note: we can not use the trick in :ref:`[12] &lt;references-gwgrad-partial&gt;`</span>
<span class="sd">    as the marginals may not sum to 1.</span>

<span class="sd">    .. note:: This function will be deprecated in a near future, please use</span>
<span class="sd">    `ot.gromov.gwggrad` instead.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1: array of shape (n_p,n_p)</span>
<span class="sd">        intra-source (P) cost matrix</span>

<span class="sd">    C2: array of shape (n_u,n_u)</span>
<span class="sd">        intra-target (U) cost matrix</span>

<span class="sd">    T : array of shape(n_p+nb_dummies, n_u) (default: None)</span>
<span class="sd">        Transport matrix</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.array of shape (n_p+nb_dummies, n_u)</span>
<span class="sd">        gradient</span>


<span class="sd">    .. _references-gwgrad-partial:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;This function will be deprecated in a near future, please use &quot;</span>
        <span class="s2">&quot;ot.gromov.gwggrad` instead.&quot;</span><span class="p">,</span>
        <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">cC1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">C1</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">C2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">cC2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">C1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">T</span><span class="p">),</span> <span class="n">C2</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">constC</span> <span class="o">=</span> <span class="n">cC1</span> <span class="o">+</span> <span class="n">cC2</span>
    <span class="n">A</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">C2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">tens</span> <span class="o">=</span> <span class="n">constC</span> <span class="o">+</span> <span class="n">A</span>
    <span class="k">return</span> <span class="n">tens</span> <span class="o">*</span> <span class="mi">2</span></div>



<div class="viewcode-block" id="gwloss_partial">
<a class="viewcode-back" href="../../gen_modules/ot.partial.html#ot.partial.gwloss_partial">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">gwloss_partial</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the GW loss.</span>

<span class="sd">    .. note:: This function will be deprecated in a near future, please use</span>
<span class="sd">    `ot.gromov.gwloss` instead.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1: array of shape (n_p,n_p)</span>
<span class="sd">        intra-source (P) cost matrix</span>

<span class="sd">    C2: array of shape (n_u,n_u)</span>
<span class="sd">        intra-target (U) cost matrix</span>

<span class="sd">    T : array of shape(n_p+nb_dummies, n_u) (default: None)</span>
<span class="sd">        Transport matrix</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    GW loss</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;This function will be deprecated in a near future, please use &quot;</span>
        <span class="s2">&quot;ot.gromov.gwloss` instead.&quot;</span><span class="p">,</span>
        <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">g</span> <span class="o">=</span> <span class="n">gwgrad_partial</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">g</span> <span class="o">*</span> <span class="n">T</span><span class="p">)</span></div>



<div class="viewcode-block" id="partial_gromov_wasserstein">
<a class="viewcode-back" href="../../gen_modules/ot.partial.html#ot.partial.partial_gromov_wasserstein">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">partial_gromov_wasserstein</span><span class="p">(</span>
    <span class="n">C1</span><span class="p">,</span>
    <span class="n">C2</span><span class="p">,</span>
    <span class="n">p</span><span class="p">,</span>
    <span class="n">q</span><span class="p">,</span>
    <span class="n">m</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">nb_dummies</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">G0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">thres</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">numItermax</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solves the partial optimal transport problem</span>
<span class="sd">    and returns the OT plan</span>

<span class="sd">    The function considers the following problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F</span>

<span class="sd">    .. math::</span>
<span class="sd">        s.t. \ \gamma \mathbf{1} &amp;\leq \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} &amp;\leq \mathbf{b}</span>

<span class="sd">             \gamma &amp;\geq 0</span>

<span class="sd">             \mathbf{1}^T \gamma^T \mathbf{1} = m &amp;\leq \min\{\|\mathbf{a}\|_1, \|\mathbf{b}\|_1\}</span>

<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the metric cost matrix</span>
<span class="sd">    - :math:`\Omega` is the entropic regularization term, :math:`\Omega(\gamma) = \sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})`</span>
<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are the sample weights</span>
<span class="sd">    - `m` is the amount of mass to be transported</span>

<span class="sd">    The formulation of the problem has been proposed in</span>
<span class="sd">    :ref:`[29] &lt;references-partial-gromov-wasserstein&gt;`</span>

<span class="sd">    .. note:: This function will be deprecated in a near future, please use</span>
<span class="sd">    `ot.gromov.partial_gromov_wasserstein` instead.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : ndarray, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : ndarray, shape (nt, nt)</span>
<span class="sd">        Metric costfr matrix in the target space</span>
<span class="sd">    p : ndarray, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q : ndarray, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    m : float, optional</span>
<span class="sd">        Amount of mass to be transported</span>
<span class="sd">        (default: :math:`\min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}`)</span>
<span class="sd">    nb_dummies : int, optional</span>
<span class="sd">        Number of dummy points to add (avoid instabilities in the EMD solver)</span>
<span class="sd">    G0 : ndarray, shape (ns, nt), optional</span>
<span class="sd">        Initialization of the transportation matrix</span>
<span class="sd">    thres : float, optional</span>
<span class="sd">        quantile of the gradient matrix to populate the cost matrix when 0</span>
<span class="sd">        (default: 1)</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        tolerance for stopping iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        return log if True</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        parameters can be directly passed to the emd solver</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : (dim_a, dim_b) ndarray</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary returned only if `log` is `True`</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import ot</span>
<span class="sd">    &gt;&gt;&gt; import scipy as sp</span>
<span class="sd">    &gt;&gt;&gt; a = np.array([0.25] * 4)</span>
<span class="sd">    &gt;&gt;&gt; b = np.array([0.25] * 4)</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([1,2,100,200]).reshape((-1,1))</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([3,2,98,199]).reshape((-1,1))</span>
<span class="sd">    &gt;&gt;&gt; C1 = sp.spatial.distance.cdist(x, x)</span>
<span class="sd">    &gt;&gt;&gt; C2 = sp.spatial.distance.cdist(y, y)</span>
<span class="sd">    &gt;&gt;&gt; np.round(partial_gromov_wasserstein(C1, C2, a, b),2)</span>
<span class="sd">    array([[0.  , 0.25, 0.  , 0.  ],</span>
<span class="sd">           [0.25, 0.  , 0.  , 0.  ],</span>
<span class="sd">           [0.  , 0.  , 0.25, 0.  ],</span>
<span class="sd">           [0.  , 0.  , 0.  , 0.25]])</span>
<span class="sd">    &gt;&gt;&gt; np.round(partial_gromov_wasserstein(C1, C2, a, b, m=0.25),2)</span>
<span class="sd">    array([[0.  , 0.  , 0.  , 0.  ],</span>
<span class="sd">           [0.  , 0.  , 0.  , 0.  ],</span>
<span class="sd">           [0.  , 0.  , 0.25, 0.  ],</span>
<span class="sd">           [0.  , 0.  , 0.  , 0.  ]])</span>


<span class="sd">    .. _references-partial-gromov-wasserstein:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [29] Chapel, L., Alaya, M., Gasso, G. (2020). &quot;Partial Optimal</span>
<span class="sd">        Transport with Applications on Positive-Unlabeled Learning&quot;.</span>
<span class="sd">        NeurIPS.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;This function will be deprecated in a near future, please use &quot;</span>
        <span class="s2">&quot;ot.gromov.partial_gromov_wasserstein` instead.&quot;</span><span class="p">,</span>
        <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">q</span><span class="p">)))</span>
    <span class="k">elif</span> <span class="n">m</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Problem infeasible. Parameter m should be greater than 0.&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">q</span><span class="p">))):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Problem infeasible. Parameter m should lower or&quot;</span>
            <span class="s2">&quot; equal than min(|a|_1, |b|_1).&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">G0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">G0</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span> <span class="o">*</span> <span class="n">m</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">q</span><span class="p">))</span>
        <span class="p">)</span>  <span class="c1"># make sure |G0|=m, G01_m\leq p, G0.T1_n\leq q.</span>

    <span class="n">dim_G_extended</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">nb_dummies</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">)</span> <span class="o">+</span> <span class="n">nb_dummies</span><span class="p">)</span>
    <span class="n">q_extended</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span> <span class="o">/</span> <span class="n">nb_dummies</span><span class="p">]</span> <span class="o">*</span> <span class="n">nb_dummies</span><span class="p">)</span>
    <span class="n">p_extended</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">q</span><span class="p">)</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span> <span class="o">/</span> <span class="n">nb_dummies</span><span class="p">]</span> <span class="o">*</span> <span class="n">nb_dummies</span><span class="p">)</span>

    <span class="n">cpt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">err</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;err&quot;</span><span class="p">:</span> <span class="p">[]}</span>

    <span class="k">while</span> <span class="n">err</span> <span class="o">&gt;</span> <span class="n">tol</span> <span class="ow">and</span> <span class="n">cpt</span> <span class="o">&lt;</span> <span class="n">numItermax</span><span class="p">:</span>
        <span class="n">Gprev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">G0</span><span class="p">)</span>

        <span class="n">M</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">gwgrad_partial</span><span class="p">(</span>
            <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">G0</span>
        <span class="p">)</span>  <span class="c1"># rescaling the gradient with 0.5 for line-search while not changing Gc</span>
        <span class="n">M_emd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dim_G_extended</span><span class="p">)</span>
        <span class="n">M_emd</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">)]</span> <span class="o">=</span> <span class="n">M</span>
        <span class="n">M_emd</span><span class="p">[</span><span class="o">-</span><span class="n">nb_dummies</span><span class="p">:,</span> <span class="o">-</span><span class="n">nb_dummies</span><span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e2</span>
        <span class="n">M_emd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">M_emd</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="n">Gc</span><span class="p">,</span> <span class="n">logemd</span> <span class="o">=</span> <span class="n">emd</span><span class="p">(</span><span class="n">p_extended</span><span class="p">,</span> <span class="n">q_extended</span><span class="p">,</span> <span class="n">M_emd</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">logemd</span><span class="p">[</span><span class="s2">&quot;warning&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Error in the EMD resolution: try to increase the&quot;</span>
                <span class="s2">&quot; number of dummy points&quot;</span>
            <span class="p">)</span>

        <span class="n">G0</span> <span class="o">=</span> <span class="n">Gc</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">)]</span>

        <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># to speed up the computations</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">G0</span> <span class="o">-</span> <span class="n">Gprev</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="n">log</span><span class="p">[</span><span class="s2">&quot;err&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="s2">&quot;</span><span class="si">{:5s}</span><span class="s2">|</span><span class="si">{:12s}</span><span class="s2">|</span><span class="si">{:12s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;It.&quot;</span><span class="p">,</span> <span class="s2">&quot;Err&quot;</span><span class="p">,</span> <span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
                        <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">31</span>
                    <span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:5d}</span><span class="s2">|</span><span class="si">{:8e}</span><span class="s2">|</span><span class="si">{:8e}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err</span><span class="p">,</span> <span class="n">gwloss_partial</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">G0</span><span class="p">)))</span>

        <span class="n">deltaG</span> <span class="o">=</span> <span class="n">G0</span> <span class="o">-</span> <span class="n">Gprev</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">gwloss_partial</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">deltaG</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">M</span> <span class="o">*</span> <span class="n">deltaG</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">b</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># due to numerical precision</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">cpt</span> <span class="o">=</span> <span class="n">numItermax</span>
        <span class="k">elif</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="o">-</span><span class="n">b</span><span class="p">,</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">a</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">gamma</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">gamma</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">cpt</span> <span class="o">=</span> <span class="n">numItermax</span>

        <span class="n">G0</span> <span class="o">=</span> <span class="n">Gprev</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">deltaG</span>
        <span class="n">cpt</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span><span class="p">[</span><span class="s2">&quot;partial_gw_dist&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gwloss_partial</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">G0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">G0</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">)],</span> <span class="n">log</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">G0</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">)]</span></div>



<div class="viewcode-block" id="partial_gromov_wasserstein2">
<a class="viewcode-back" href="../../gen_modules/ot.partial.html#ot.partial.partial_gromov_wasserstein2">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">partial_gromov_wasserstein2</span><span class="p">(</span>
    <span class="n">C1</span><span class="p">,</span>
    <span class="n">C2</span><span class="p">,</span>
    <span class="n">p</span><span class="p">,</span>
    <span class="n">q</span><span class="p">,</span>
    <span class="n">m</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">nb_dummies</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">G0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">thres</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">numItermax</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solves the partial optimal transport problem</span>
<span class="sd">    and returns the partial Gromov-Wasserstein discrepancy</span>

<span class="sd">    The function considers the following problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        GW = \min_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F</span>

<span class="sd">    .. math::</span>
<span class="sd">        s.t. \ \gamma \mathbf{1} &amp;\leq \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} &amp;\leq \mathbf{b}</span>

<span class="sd">             \gamma &amp;\geq 0</span>

<span class="sd">             \mathbf{1}^T \gamma^T \mathbf{1} = m</span>
<span class="sd">             &amp;\leq \min\{\|\mathbf{a}\|_1, \|\mathbf{b}\|_1\}</span>

<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the metric cost matrix</span>
<span class="sd">    - :math:`\Omega` is the entropic regularization term,</span>
<span class="sd">      :math:`\Omega(\gamma) = \sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})`</span>
<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are the sample weights</span>
<span class="sd">    - `m` is the amount of mass to be transported</span>

<span class="sd">    The formulation of the problem has been proposed in</span>
<span class="sd">    :ref:`[29] &lt;references-partial-gromov-wasserstein2&gt;`</span>

<span class="sd">    .. note:: This function will be deprecated in a near future, please use</span>
<span class="sd">    `ot.gromov.partial_gromov_wasserstein2` instead.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : ndarray, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : ndarray, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix in the target space</span>
<span class="sd">    p : ndarray, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q : ndarray, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    m : float, optional</span>
<span class="sd">        Amount of mass to be transported</span>
<span class="sd">        (default: :math:`\min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}`)</span>
<span class="sd">    nb_dummies : int, optional</span>
<span class="sd">        Number of dummy points to add (avoid instabilities in the EMD solver)</span>
<span class="sd">    G0 : ndarray, shape (ns, nt), optional</span>
<span class="sd">        Initialization of the transportation matrix</span>
<span class="sd">    thres : float, optional</span>
<span class="sd">        quantile of the gradient matrix to populate the cost matrix when 0</span>
<span class="sd">        (default: 1)</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        tolerance for stopping iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        return log if True</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        parameters can be directly passed to the emd solver</span>


<span class="sd">    .. warning::</span>
<span class="sd">        When dealing with a large number of points, the EMD solver may face</span>
<span class="sd">        some instabilities, especially when the mass associated to the dummy</span>
<span class="sd">        point is large. To avoid them, increase the number of dummy points</span>
<span class="sd">        (allows a smoother repartition of the mass over the points).</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    partial_gw_dist : float</span>
<span class="sd">        partial GW discrepancy</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary returned only if `log` is `True`</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import ot</span>
<span class="sd">    &gt;&gt;&gt; import scipy as sp</span>
<span class="sd">    &gt;&gt;&gt; a = np.array([0.25] * 4)</span>
<span class="sd">    &gt;&gt;&gt; b = np.array([0.25] * 4)</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([1,2,100,200]).reshape((-1,1))</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([3,2,98,199]).reshape((-1,1))</span>
<span class="sd">    &gt;&gt;&gt; C1 = sp.spatial.distance.cdist(x, x)</span>
<span class="sd">    &gt;&gt;&gt; C2 = sp.spatial.distance.cdist(y, y)</span>
<span class="sd">    &gt;&gt;&gt; np.round(partial_gromov_wasserstein2(C1, C2, a, b),2)</span>
<span class="sd">    1.69</span>
<span class="sd">    &gt;&gt;&gt; np.round(partial_gromov_wasserstein2(C1, C2, a, b, m=0.25),2)</span>
<span class="sd">    0.0</span>


<span class="sd">    .. _references-partial-gromov-wasserstein2:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [29] Chapel, L., Alaya, M., Gasso, G. (2020). &quot;Partial Optimal</span>
<span class="sd">        Transport with Applications on Positive-Unlabeled Learning&quot;.</span>
<span class="sd">        NeurIPS.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;This function will be deprecated in a near future, please use &quot;</span>
        <span class="s2">&quot;ot.gromov.partial_gromov_wasserstein2` instead.&quot;</span><span class="p">,</span>
        <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">partial_gw</span><span class="p">,</span> <span class="n">log_gw</span> <span class="o">=</span> <span class="n">partial_gromov_wasserstein</span><span class="p">(</span>
        <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">nb_dummies</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">thres</span><span class="p">,</span> <span class="n">numItermax</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span>

    <span class="n">log_gw</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial_gw</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">log_gw</span><span class="p">[</span><span class="s2">&quot;partial_gw_dist&quot;</span><span class="p">],</span> <span class="n">log_gw</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">log_gw</span><span class="p">[</span><span class="s2">&quot;partial_gw_dist&quot;</span><span class="p">]</span></div>



<div class="viewcode-block" id="entropic_partial_gromov_wasserstein">
<a class="viewcode-back" href="../../gen_modules/ot.partial.html#ot.partial.entropic_partial_gromov_wasserstein">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">entropic_partial_gromov_wasserstein</span><span class="p">(</span>
    <span class="n">C1</span><span class="p">,</span>
    <span class="n">C2</span><span class="p">,</span>
    <span class="n">p</span><span class="p">,</span>
    <span class="n">q</span><span class="p">,</span>
    <span class="n">reg</span><span class="p">,</span>
    <span class="n">m</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">G0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">numItermax</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the partial Gromov-Wasserstein transport between</span>
<span class="sd">    :math:`(\mathbf{C_1}, \mathbf{p})` and :math:`(\mathbf{C_2}, \mathbf{q})`</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_{\gamma} \quad \sum_{i,j,k,l}</span>
<span class="sd">        L(\mathbf{C_1}_{i,k}, \mathbf{C_2}_{j,l})\cdot</span>
<span class="sd">        \gamma_{i,j}\cdot\gamma_{k,l} + \mathrm{reg} \cdot\Omega(\gamma)</span>

<span class="sd">    .. math::</span>
<span class="sd">        s.t. \ \gamma &amp;\geq 0</span>

<span class="sd">             \gamma \mathbf{1} &amp;\leq \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} &amp;\leq \mathbf{b}</span>

<span class="sd">             \mathbf{1}^T \gamma^T \mathbf{1} = m</span>
<span class="sd">             &amp;\leq \min\{\|\mathbf{a}\|_1, \|\mathbf{b}\|_1\}</span>

<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{C_1}` is the metric cost matrix in the source space</span>
<span class="sd">    - :math:`\mathbf{C_2}` is the metric cost matrix in the target space</span>
<span class="sd">    - :math:`\mathbf{p}` and :math:`\mathbf{q}` are the sample weights</span>
<span class="sd">    - `L`: quadratic loss function</span>
<span class="sd">    - :math:`\Omega` is the entropic regularization term,</span>
<span class="sd">      :math:`\Omega=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})`</span>
<span class="sd">    - `m` is the amount of mass to be transported</span>

<span class="sd">    The formulation of the GW problem has been proposed in</span>
<span class="sd">    :ref:`[12] &lt;references-entropic-partial-gromov-wasserstein&gt;` and the</span>
<span class="sd">    partial GW in :ref:`[29] &lt;references-entropic-partial-gromov-wasserstein&gt;`</span>

<span class="sd">    .. note:: This function will be deprecated in a near future, please use</span>
<span class="sd">    `ot.gromov.entropic_partial_gromov_wasserstein` instead.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : ndarray, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : ndarray, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix in the target space</span>
<span class="sd">    p : ndarray, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q : ndarray, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    reg: float</span>
<span class="sd">        entropic regularization parameter</span>
<span class="sd">    m : float, optional</span>
<span class="sd">        Amount of mass to be transported (default:</span>
<span class="sd">        :math:`\min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}`)</span>
<span class="sd">    G0 : ndarray, shape (ns, nt), optional</span>
<span class="sd">        Initialization of the transportation matrix</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        return log if True</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import ot</span>
<span class="sd">    &gt;&gt;&gt; import scipy as sp</span>
<span class="sd">    &gt;&gt;&gt; a = np.array([0.25] * 4)</span>
<span class="sd">    &gt;&gt;&gt; b = np.array([0.25] * 4)</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([1,2,100,200]).reshape((-1,1))</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([3,2,98,199]).reshape((-1,1))</span>
<span class="sd">    &gt;&gt;&gt; C1 = sp.spatial.distance.cdist(x, x)</span>
<span class="sd">    &gt;&gt;&gt; C2 = sp.spatial.distance.cdist(y, y)</span>
<span class="sd">    &gt;&gt;&gt; np.round(entropic_partial_gromov_wasserstein(C1, C2, a, b, 50), 2)</span>
<span class="sd">    array([[0.12, 0.13, 0.  , 0.  ],</span>
<span class="sd">           [0.13, 0.12, 0.  , 0.  ],</span>
<span class="sd">           [0.  , 0.  , 0.25, 0.  ],</span>
<span class="sd">           [0.  , 0.  , 0.  , 0.25]])</span>
<span class="sd">    &gt;&gt;&gt; np.round(entropic_partial_gromov_wasserstein(C1, C2, a, b, 50,0.25), 2)</span>
<span class="sd">    array([[0.02, 0.03, 0.  , 0.03],</span>
<span class="sd">           [0.03, 0.03, 0.  , 0.03],</span>
<span class="sd">           [0.  , 0.  , 0.03, 0.  ],</span>
<span class="sd">           [0.02, 0.02, 0.  , 0.03]])</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    :math:`gamma` : ndarray, shape (dim_a, dim_b)</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary returned only if `log` is `True`</span>


<span class="sd">    .. _references-entropic-partial-gromov-wasserstein:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    .. [29] Chapel, L., Alaya, M., Gasso, G. (2020). &quot;Partial Optimal</span>
<span class="sd">        Transport with Applications on Positive-Unlabeled Learning&quot;.</span>
<span class="sd">        NeurIPS.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.partial.partial_gromov_wasserstein: exact Partial Gromov-Wasserstein</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;This function will be deprecated in a near future, please use &quot;</span>
        <span class="s2">&quot;ot.gromov.entropic_partial_gromov_wasserstein` instead.&quot;</span><span class="p">,</span>
        <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">G0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">G0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">q</span><span class="p">)))</span>
    <span class="k">elif</span> <span class="n">m</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Problem infeasible. Parameter m should be greater than 0.&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">q</span><span class="p">))):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Problem infeasible. Parameter m should lower or&quot;</span>
            <span class="s2">&quot; equal than min(|a|_1, |b|_1).&quot;</span>
        <span class="p">)</span>

    <span class="n">cpt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">err</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">loge</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;err&quot;</span><span class="p">:</span> <span class="p">[]}</span>

    <span class="k">while</span> <span class="n">err</span> <span class="o">&gt;</span> <span class="n">tol</span> <span class="ow">and</span> <span class="n">cpt</span> <span class="o">&lt;</span> <span class="n">numItermax</span><span class="p">:</span>
        <span class="n">Gprev</span> <span class="o">=</span> <span class="n">G0</span>
        <span class="n">M_entr</span> <span class="o">=</span> <span class="n">gwgrad_partial</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">G0</span><span class="p">)</span>
        <span class="n">G0</span> <span class="o">=</span> <span class="n">entropic_partial_wasserstein</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">M_entr</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># to speed up the computations</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">G0</span> <span class="o">-</span> <span class="n">Gprev</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
                <span class="n">loge</span><span class="p">[</span><span class="s2">&quot;err&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">cpt</span> <span class="o">%</span> <span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="s2">&quot;</span><span class="si">{:5s}</span><span class="s2">|</span><span class="si">{:12s}</span><span class="s2">|</span><span class="si">{:12s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;It.&quot;</span><span class="p">,</span> <span class="s2">&quot;Err&quot;</span><span class="p">,</span> <span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
                        <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">31</span>
                    <span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:5d}</span><span class="s2">|</span><span class="si">{:8e}</span><span class="s2">|</span><span class="si">{:8e}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cpt</span><span class="p">,</span> <span class="n">err</span><span class="p">,</span> <span class="n">gwloss_partial</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">G0</span><span class="p">)))</span>

        <span class="n">cpt</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">loge</span><span class="p">[</span><span class="s2">&quot;partial_gw_dist&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gwloss_partial</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">G0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">G0</span><span class="p">,</span> <span class="n">loge</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">G0</span></div>



<div class="viewcode-block" id="entropic_partial_gromov_wasserstein2">
<a class="viewcode-back" href="../../gen_modules/ot.partial.html#ot.partial.entropic_partial_gromov_wasserstein2">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">entropic_partial_gromov_wasserstein2</span><span class="p">(</span>
    <span class="n">C1</span><span class="p">,</span>
    <span class="n">C2</span><span class="p">,</span>
    <span class="n">p</span><span class="p">,</span>
    <span class="n">q</span><span class="p">,</span>
    <span class="n">reg</span><span class="p">,</span>
    <span class="n">m</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">G0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">numItermax</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the partial Gromov-Wasserstein discrepancy between</span>
<span class="sd">    :math:`(\mathbf{C_1}, \mathbf{p})` and :math:`(\mathbf{C_2}, \mathbf{q})`</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        GW = \min_{\gamma} \quad \sum_{i,j,k,l} L(\mathbf{C_1}_{i,k},</span>
<span class="sd">             \mathbf{C_2}_{j,l})\cdot</span>
<span class="sd">             \gamma_{i,j}\cdot\gamma_{k,l} + \mathrm{reg} \cdot\Omega(\gamma)</span>

<span class="sd">    .. math::</span>
<span class="sd">        s.t. \ \gamma &amp;\geq 0</span>

<span class="sd">             \gamma \mathbf{1} &amp;\leq \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} &amp;\leq \mathbf{b}</span>

<span class="sd">             \mathbf{1}^T \gamma^T \mathbf{1} = m &amp;\leq \min\{\|\mathbf{a}\|_1, \|\mathbf{b}\|_1\}</span>

<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{C_1}` is the metric cost matrix in the source space</span>
<span class="sd">    - :math:`\mathbf{C_2}` is the metric cost matrix in the target space</span>
<span class="sd">    - :math:`\mathbf{p}` and :math:`\mathbf{q}` are the sample weights</span>
<span class="sd">    - `L` : quadratic loss function</span>
<span class="sd">    - :math:`\Omega` is the entropic regularization term,</span>
<span class="sd">      :math:`\Omega=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})`</span>
<span class="sd">    - `m` is the amount of mass to be transported</span>

<span class="sd">    The formulation of the GW problem has been proposed in</span>
<span class="sd">    :ref:`[12] &lt;references-entropic-partial-gromov-wasserstein2&gt;` and the</span>
<span class="sd">    partial GW in :ref:`[29] &lt;references-entropic-partial-gromov-wasserstein2&gt;`</span>

<span class="sd">    .. note:: This function will be deprecated in a near future, please use</span>
<span class="sd">    `ot.gromov.entropic_partial_gromov_wasserstein2` instead.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    C1 : ndarray, shape (ns, ns)</span>
<span class="sd">        Metric cost matrix in the source space</span>
<span class="sd">    C2 : ndarray, shape (nt, nt)</span>
<span class="sd">        Metric cost matrix in the target space</span>
<span class="sd">    p : ndarray, shape (ns,)</span>
<span class="sd">        Distribution in the source space</span>
<span class="sd">    q : ndarray, shape (nt,)</span>
<span class="sd">        Distribution in the target space</span>
<span class="sd">    reg: float</span>
<span class="sd">        entropic regularization parameter</span>
<span class="sd">    m : float, optional</span>
<span class="sd">        Amount of mass to be transported (default:</span>
<span class="sd">        :math:`\min\{\|\mathbf{p}\|_1, \|\mathbf{q}\|_1\}`)</span>
<span class="sd">    G0 : ndarray, shape (ns, nt), optional</span>
<span class="sd">        Initialization of the transportation matrix</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    tol : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        return log if True</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    partial_gw_dist: float</span>
<span class="sd">        Gromov-Wasserstein distance</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary returned only if `log` is `True`</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import ot</span>
<span class="sd">    &gt;&gt;&gt; import scipy as sp</span>
<span class="sd">    &gt;&gt;&gt; a = np.array([0.25] * 4)</span>
<span class="sd">    &gt;&gt;&gt; b = np.array([0.25] * 4)</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([1,2,100,200]).reshape((-1,1))</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([3,2,98,199]).reshape((-1,1))</span>
<span class="sd">    &gt;&gt;&gt; C1 = sp.spatial.distance.cdist(x, x)</span>
<span class="sd">    &gt;&gt;&gt; C2 = sp.spatial.distance.cdist(y, y)</span>
<span class="sd">    &gt;&gt;&gt; np.round(entropic_partial_gromov_wasserstein2(C1, C2, a, b,50), 2)</span>
<span class="sd">    1.87</span>


<span class="sd">    .. _references-entropic-partial-gromov-wasserstein2:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [12] Peyré, Gabriel, Marco Cuturi, and Justin Solomon,</span>
<span class="sd">        &quot;Gromov-Wasserstein averaging of kernel and distance matrices.&quot;</span>
<span class="sd">        International Conference on Machine Learning (ICML). 2016.</span>

<span class="sd">    ..  [29] Chapel, L., Alaya, M., Gasso, G. (2020). &quot;Partial Optimal</span>
<span class="sd">        Transport with Applications on Positive-Unlabeled Learning&quot;.</span>
<span class="sd">        NeurIPS.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;This function will be deprecated in a near future, please use &quot;</span>
        <span class="s2">&quot;ot.gromov.entropic_partial_gromov_wasserstein2` instead.&quot;</span><span class="p">,</span>
        <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">partial_gw</span><span class="p">,</span> <span class="n">log_gw</span> <span class="o">=</span> <span class="n">entropic_partial_gromov_wasserstein</span><span class="p">(</span>
        <span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">G0</span><span class="p">,</span> <span class="n">numItermax</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span>
    <span class="p">)</span>

    <span class="n">log_gw</span><span class="p">[</span><span class="s2">&quot;T&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial_gw</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">log_gw</span><span class="p">[</span><span class="s2">&quot;partial_gw_dist&quot;</span><span class="p">],</span> <span class="n">log_gw</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">log_gw</span><span class="p">[</span><span class="s2">&quot;partial_gw_dist&quot;</span><span class="p">]</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016-2023, POT Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note"
aria-label="versions">
  <!--  add shift_up to the class for force viewing ,
  data-toggle="rst-current-version" -->
    <span class="rst-current-version"  style="margin-bottom:1mm;">
      <span class="fa fa-book"> Python Optimal Transport</span> 0.9.6dev0
      <hr  style="margin-bottom:1.5mm;margin-top:5mm;">
     <!--  versions
      <span class="fa fa-caret-down"></span>-->
      <span class="rst-current-version" style="display: inline-block;padding:
      0px;color:#fcfcfcab;float:left;font-size: 100%;">
        Versions: 
        <a href="https://pythonot.github.io/" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Release</a>
        <a href="https://pythonot.github.io/master" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Development</a>
        <a href="https://github.com/PythonOT/POT"
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Code</a>

      </span>

     
    </span>
  
     <!--
    <div class="rst-other-versions">

      

<div class="injected">

    
  <dl>
    <dt>Versions</dt>

    <dd><a href="https://pythonot.github.io/">Release</a></dd>
    
    <dd><a href="https://pythonot.github.io/master">Development</a></dd>
   
    

    <dt><a href="https://github.com/PythonOT/POT">Code on Github</a></dt>       

    
  </dl>
  <hr>

</div> 
</div>-->
  </div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>