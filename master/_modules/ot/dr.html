<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ot.dr &mdash; POT Python Optimal Transport 0.9.1dev documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            POT Python Optimal Transport
              <img src="../../_static/logo_dark.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.9.1dev
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">POT: Python Optimal Transport</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quick start guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../all.html">API and modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Examples gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributors.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing to POT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../code_of_conduct.html">Code of conduct</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">POT Python Optimal Transport</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">ot.dr</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for ot.dr</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Dimension reduction with OT</span>


<span class="sd">.. warning::</span>
<span class="sd">    Note that by default the module is not imported in :mod:`ot`. In order to</span>
<span class="sd">    use it you need to explicitly import :mod:`ot.dr`</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Author: Remi Flamary &lt;remi.flamary@unice.fr&gt;</span>
<span class="c1">#         Minhui Huang &lt;mhhuang@ucdavis.edu&gt;</span>
<span class="c1">#         Jakub Zadrozny &lt;jakub.r.zadrozny@gmail.com&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: MIT License</span>

<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">linalg</span>
<span class="kn">import</span> <span class="nn">autograd.numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">pymanopt</span>
<span class="kn">import</span> <span class="nn">pymanopt.manifolds</span>
<span class="kn">import</span> <span class="nn">pymanopt.optimizers</span>


<div class="viewcode-block" id="dist"><a class="viewcode-back" href="../../gen_modules/ot.dr.html#ot.dr.dist">[docs]</a><span class="k">def</span> <span class="nf">dist</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot; Compute squared euclidean distance between samples (autograd)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x1p2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x2p2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x2</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x1p2</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="n">x2p2</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span></div>


<div class="viewcode-block" id="sinkhorn"><a class="viewcode-back" href="../../gen_modules/ot.dr.html#ot.dr.sinkhorn">[docs]</a><span class="k">def</span> <span class="nf">sinkhorn</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sinkhorn algorithm with fixed number of iteration (autograd)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">M</span> <span class="o">/</span> <span class="n">reg</span><span class="p">)</span>
    <span class="n">ui</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
    <span class="n">vi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">vi</span> <span class="o">=</span> <span class="n">w2</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">ui</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-50</span><span class="p">)</span>
        <span class="n">ui</span> <span class="o">=</span> <span class="n">w1</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">vi</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-50</span><span class="p">)</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">ui</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">K</span> <span class="o">*</span> <span class="n">vi</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">G</span></div>


<div class="viewcode-block" id="logsumexp"><a class="viewcode-back" href="../../gen_modules/ot.dr.html#ot.dr.logsumexp">[docs]</a><span class="k">def</span> <span class="nf">logsumexp</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Log-sum-exp reduction compatible with autograd (no numpy implementation)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">amax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">M</span> <span class="o">-</span> <span class="n">amax</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">amax</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span></div>


<div class="viewcode-block" id="sinkhorn_log"><a class="viewcode-back" href="../../gen_modules/ot.dr.html#ot.dr.sinkhorn_log">[docs]</a><span class="k">def</span> <span class="nf">sinkhorn_log</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Sinkhorn algorithm in log-domain with fixed number of iteration (autograd)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Mr</span> <span class="o">=</span> <span class="o">-</span><span class="n">M</span> <span class="o">/</span> <span class="n">reg</span>
    <span class="n">ui</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
    <span class="n">vi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span>
    <span class="n">log_w1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">w1</span><span class="p">)</span>
    <span class="n">log_w2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">w2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">vi</span> <span class="o">=</span> <span class="n">log_w2</span> <span class="o">-</span> <span class="n">logsumexp</span><span class="p">(</span><span class="n">Mr</span> <span class="o">+</span> <span class="n">ui</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">ui</span> <span class="o">=</span> <span class="n">log_w1</span> <span class="o">-</span> <span class="n">logsumexp</span><span class="p">(</span><span class="n">Mr</span> <span class="o">+</span> <span class="n">vi</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">ui</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">Mr</span> <span class="o">+</span> <span class="n">vi</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span>
    <span class="k">return</span> <span class="n">G</span></div>


<div class="viewcode-block" id="split_classes"><a class="viewcode-back" href="../../gen_modules/ot.dr.html#ot.dr.split_classes">[docs]</a><span class="k">def</span> <span class="nf">split_classes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;split samples in :math:`\mathbf{X}` by classes in :math:`\mathbf{y}`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lstsclass</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">lstsclass</span><span class="p">]</span></div>


<div class="viewcode-block" id="fda"><a class="viewcode-back" href="../../gen_modules/ot.dr.html#ot.dr.fda">[docs]</a><span class="k">def</span> <span class="nf">fda</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">1e-16</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fisher Discriminant Analysis</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : ndarray, shape (n, d)</span>
<span class="sd">        Training samples.</span>
<span class="sd">    y : ndarray, shape (n,)</span>
<span class="sd">        Labels for training samples.</span>
<span class="sd">    p : int, optional</span>
<span class="sd">        Size of dimensionality reduction.</span>
<span class="sd">    reg : float, optional</span>
<span class="sd">        Regularization term &gt;0 (ridge regularization)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    P : ndarray, shape (d, p)</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    proj : callable</span>
<span class="sd">        projection function including mean centering</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">mx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">-=</span> <span class="n">mx</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="c1"># data split between classes</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">xc</span> <span class="o">=</span> <span class="n">split_classes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">nc</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xc</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">nc</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="n">Cw</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xc</span><span class="p">:</span>
        <span class="n">Cw</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">Cw</span> <span class="o">/=</span> <span class="n">nc</span>

    <span class="n">mxc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="n">nc</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nc</span><span class="p">):</span>
        <span class="n">mxc</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="n">mx0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mxc</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">Cb</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nc</span><span class="p">):</span>
        <span class="n">Cb</span> <span class="o">+=</span> <span class="p">(</span><span class="n">mxc</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">mx0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> \
            <span class="p">(</span><span class="n">mxc</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">mx0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">w</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">Cb</span><span class="p">,</span> <span class="n">Cw</span> <span class="o">+</span> <span class="n">reg</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>

    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">real</span><span class="p">)</span>

    <span class="n">Popt</span> <span class="o">=</span> <span class="n">V</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">[</span><span class="o">-</span><span class="n">p</span><span class="p">:]]</span>

    <span class="k">def</span> <span class="nf">proj</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mx</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Popt</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Popt</span><span class="p">,</span> <span class="n">proj</span></div>


<div class="viewcode-block" id="wda"><a class="viewcode-back" href="../../gen_modules/ot.dr.html#ot.dr.wda">[docs]</a><span class="k">def</span> <span class="nf">wda</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sinkhorn_method</span><span class="o">=</span><span class="s1">&#39;sinkhorn&#39;</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">P0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wasserstein Discriminant Analysis :ref:`[11] &lt;references-wda&gt;`</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \mathbf{P} = \mathop{\arg \min}_\mathbf{P} \quad</span>
<span class="sd">        \frac{\sum\limits_i W(P \mathbf{X}^i, P \mathbf{X}^i)}{\sum\limits_{i, j \neq i} W(P \mathbf{X}^i, P \mathbf{X}^j)}</span>

<span class="sd">    where :</span>

<span class="sd">    - :math:`P` is a linear projection operator in the Stiefel(`p`, `d`) manifold</span>
<span class="sd">    - :math:`W` is entropic regularized Wasserstein distances</span>
<span class="sd">    - :math:`\mathbf{X}^i` are samples in the dataset corresponding to class i</span>

<span class="sd">    **Choosing a Sinkhorn solver**</span>

<span class="sd">    By default and when using a regularization parameter that is not too small</span>
<span class="sd">    the default sinkhorn solver should be enough. If you need to use a small</span>
<span class="sd">    regularization to get sparse cost matrices, you should use the</span>
<span class="sd">    :py:func:`ot.dr.sinkhorn_log` solver that will avoid numerical</span>
<span class="sd">    errors, but can be slow in practice.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : ndarray, shape (n, d)</span>
<span class="sd">        Training samples.</span>
<span class="sd">    y : ndarray, shape (n,)</span>
<span class="sd">        Labels for training samples.</span>
<span class="sd">    p : int, optional</span>
<span class="sd">        Size of dimensionality reduction.</span>
<span class="sd">    reg : float, optional</span>
<span class="sd">        Regularization term &gt;0 (entropic regularization)</span>
<span class="sd">    solver : None | str, optional</span>
<span class="sd">        None for steepest descent or &#39;TrustRegions&#39; for trust regions algorithm</span>
<span class="sd">        else should be a pymanopt.solvers</span>
<span class="sd">    sinkhorn_method : str</span>
<span class="sd">        method used for the Sinkhorn solver, either &#39;sinkhorn&#39; or &#39;sinkhorn_log&#39;</span>
<span class="sd">    P0 : ndarray, shape (d, p)</span>
<span class="sd">        Initial starting point for projection.</span>
<span class="sd">    normalize : bool, optional</span>
<span class="sd">        Normalize the Wasserstaiun distance by the average distance on P0 (default : False)</span>
<span class="sd">    verbose : int, optional</span>
<span class="sd">        Print information along iterations.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    P : ndarray, shape (d, p)</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    proj : callable</span>
<span class="sd">        Projection function including mean centering.</span>


<span class="sd">    .. _references-wda:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [11] Flamary, R., Cuturi, M., Courty, N., &amp; Rakotomamonjy, A. (2016).</span>
<span class="sd">            Wasserstein Discriminant Analysis. arXiv preprint arXiv:1608.08063.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>

    <span class="k">if</span> <span class="n">sinkhorn_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;sinkhorn&#39;</span><span class="p">:</span>
        <span class="n">sinkhorn_solver</span> <span class="o">=</span> <span class="n">sinkhorn</span>
    <span class="k">elif</span> <span class="n">sinkhorn_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;sinkhorn_log&#39;</span><span class="p">:</span>
        <span class="n">sinkhorn_solver</span> <span class="o">=</span> <span class="n">sinkhorn_log</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown Sinkhorn method &#39;</span><span class="si">%s</span><span class="s2">&#39;.&quot;</span> <span class="o">%</span> <span class="n">sinkhorn_method</span><span class="p">)</span>

    <span class="n">mx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">-=</span> <span class="n">mx</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="c1"># data split between classes</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">xc</span> <span class="o">=</span> <span class="n">split_classes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="c1"># compute uniform weighs</span>
    <span class="n">wc</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xc</span><span class="p">]</span>

    <span class="c1"># pre-compute reg_c,c&#39;</span>
    <span class="k">if</span> <span class="n">P0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="n">regmean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">xc</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xc</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">xi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xc</span><span class="p">):</span>
            <span class="n">xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">P0</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">xj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xc</span><span class="p">[</span><span class="n">i</span><span class="p">:]):</span>
                <span class="n">xj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xj</span><span class="p">,</span> <span class="n">P0</span><span class="p">)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">xj</span><span class="p">)</span>
                <span class="n">regmean</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">M</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">xj</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">regmean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">xc</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xc</span><span class="p">)))</span>

    <span class="n">manifold</span> <span class="o">=</span> <span class="n">pymanopt</span><span class="o">.</span><span class="n">manifolds</span><span class="o">.</span><span class="n">Stiefel</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="nd">@pymanopt</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">autograd</span><span class="p">(</span><span class="n">manifold</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">P</span><span class="p">):</span>
        <span class="c1"># wda loss</span>
        <span class="n">loss_b</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">loss_w</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">xi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xc</span><span class="p">):</span>
            <span class="n">xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">xj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xc</span><span class="p">[</span><span class="n">i</span><span class="p">:]):</span>
                <span class="n">xj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xj</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">xj</span><span class="p">)</span>
                <span class="n">G</span> <span class="o">=</span> <span class="n">sinkhorn_solver</span><span class="p">(</span><span class="n">wc</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">wc</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="n">i</span><span class="p">],</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span> <span class="o">*</span> <span class="n">regmean</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">k</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">loss_w</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">G</span> <span class="o">*</span> <span class="n">M</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">loss_b</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">G</span> <span class="o">*</span> <span class="n">M</span><span class="p">)</span>

        <span class="c1"># loss inversed because minimization</span>
        <span class="k">return</span> <span class="n">loss_w</span> <span class="o">/</span> <span class="n">loss_b</span>

    <span class="c1"># declare manifold and problem</span>

    <span class="n">problem</span> <span class="o">=</span> <span class="n">pymanopt</span><span class="o">.</span><span class="n">Problem</span><span class="p">(</span><span class="n">manifold</span><span class="o">=</span><span class="n">manifold</span><span class="p">,</span> <span class="n">cost</span><span class="o">=</span><span class="n">cost</span><span class="p">)</span>

    <span class="c1"># declare solver and solve</span>
    <span class="k">if</span> <span class="n">solver</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">solver</span> <span class="o">=</span> <span class="n">pymanopt</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SteepestDescent</span><span class="p">(</span><span class="n">max_iterations</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span> <span class="n">log_verbosity</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">solver</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;tr&#39;</span><span class="p">,</span> <span class="s1">&#39;TrustRegions&#39;</span><span class="p">]:</span>
        <span class="n">solver</span> <span class="o">=</span> <span class="n">pymanopt</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">TrustRegions</span><span class="p">(</span><span class="n">max_iterations</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span> <span class="n">log_verbosity</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>

    <span class="n">Popt</span> <span class="o">=</span> <span class="n">solver</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">problem</span><span class="p">,</span> <span class="n">initial_point</span><span class="o">=</span><span class="n">P0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">proj</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mx</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Popt</span><span class="o">.</span><span class="n">point</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Popt</span><span class="o">.</span><span class="n">point</span><span class="p">,</span> <span class="n">proj</span></div>


<div class="viewcode-block" id="projection_robust_wasserstein"><a class="viewcode-back" href="../../gen_modules/ot.dr.html#ot.dr.projection_robust_wasserstein">[docs]</a><span class="k">def</span> <span class="nf">projection_robust_wasserstein</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">U0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Projection Robust Wasserstein Distance :ref:`[32] &lt;references-projection-robust-wasserstein&gt;`</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \max_{U \in St(d, k)} \ \min_{\pi \in \Pi(\mu,\nu)} \quad \sum_{i,j} \pi_{i,j}</span>
<span class="sd">        \|U^T(\mathbf{x}_i - \mathbf{y}_j)\|^2 - \mathrm{reg} \cdot H(\pi)</span>

<span class="sd">    - :math:`U` is a linear projection operator in the Stiefel(`d`, `k`) manifold</span>
<span class="sd">    - :math:`H(\pi)` is entropy regularizer</span>
<span class="sd">    - :math:`\mathbf{x}_i`, :math:`\mathbf{y}_j` are samples of measures :math:`\mu` and :math:`\nu` respectively</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : ndarray, shape (n, d)</span>
<span class="sd">        Samples from measure :math:`\mu`</span>
<span class="sd">    Y : ndarray, shape (n, d)</span>
<span class="sd">        Samples from measure :math:`\nu`</span>
<span class="sd">    a : ndarray, shape (n, )</span>
<span class="sd">        weights for measure :math:`\mu`</span>
<span class="sd">    b : ndarray, shape (n, )</span>
<span class="sd">        weights for measure :math:`\nu`</span>
<span class="sd">    tau : float</span>
<span class="sd">        stepsize for Riemannian Gradient Descent</span>
<span class="sd">    U0 : ndarray, shape (d, p)</span>
<span class="sd">        Initial starting point for projection.</span>
<span class="sd">    reg : float, optional</span>
<span class="sd">        Regularization term &gt;0 (entropic regularization)</span>
<span class="sd">    k : int</span>
<span class="sd">        Subspace dimension</span>
<span class="sd">    stopThr : float, optional</span>
<span class="sd">        Stop threshold on error (&gt;0)</span>
<span class="sd">    verbose : int, optional</span>
<span class="sd">        Print information along iterations.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pi : ndarray, shape (n, n)</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    U : ndarray, shape (d, k)</span>
<span class="sd">        Projection operator.</span>


<span class="sd">    .. _references-projection-robust-wasserstein:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [32] Huang, M. , Ma S. &amp; Lai L. (2021).</span>
<span class="sd">            A Riemannian Block Coordinate Descent Method for Computing </span>
<span class="sd">            the Projection Robust Wasserstein Distance, ICML.</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>

    <span class="c1"># initialization</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span>
    <span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">))</span>

    <span class="k">assert</span> <span class="n">d</span> <span class="o">&gt;</span> <span class="n">k</span>

    <span class="k">if</span> <span class="n">U0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="n">U</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">U</span> <span class="o">=</span> <span class="n">U0</span>

    <span class="k">def</span> <span class="nf">Vpi</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">pi</span><span class="p">):</span>
        <span class="c1"># Return the second order matrix of the displacements: sum_ij { (pi)_ij (X_i-Y_j)(X_i-Y_j)^T }.</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">pi</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="p">))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">-</span> <span class="n">A</span> <span class="o">-</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span>

    <span class="n">err</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="n">err</span> <span class="o">&gt;</span> <span class="n">stopThr</span> <span class="ow">and</span> <span class="nb">iter</span> <span class="o">&lt;</span> <span class="n">maxiter</span><span class="p">:</span>

        <span class="c1"># Projected cost matrix</span>
        <span class="n">UUT</span> <span class="o">=</span> <span class="n">U</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">UUT</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">))))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ones</span><span class="p">)</span> <span class="o">+</span> <span class="n">ones</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">UUT</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">)))))</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">UUT</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>

        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">M</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="o">-</span><span class="n">reg</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">A</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">A</span><span class="p">)</span>

        <span class="c1"># Sinkhorn update</span>
        <span class="n">Ap</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">A</span>
        <span class="n">AtransposeU</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">AtransposeU</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Ap</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="n">pi</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">A</span> <span class="o">*</span> <span class="n">v</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">V</span> <span class="o">=</span> <span class="n">Vpi</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">pi</span><span class="p">)</span>

        <span class="c1"># Riemannian gradient descent</span>
        <span class="n">G</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">reg</span> <span class="o">*</span> <span class="n">V</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>
        <span class="n">GTU</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>
        <span class="n">xi</span> <span class="o">=</span> <span class="n">G</span> <span class="o">-</span> <span class="n">U</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">GTU</span> <span class="o">+</span> <span class="n">GTU</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># Riemannian gradient</span>
        <span class="n">U</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">U</span> <span class="o">+</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">xi</span><span class="p">)</span>  <span class="c1"># Retraction by QR decomposition</span>

        <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
        <span class="n">err</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">reg</span> <span class="o">*</span> <span class="n">grad_norm</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="n">f_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RBCD Iteration: &#39;</span><span class="p">,</span> <span class="nb">iter</span><span class="p">,</span> <span class="s1">&#39; error&#39;</span><span class="p">,</span> <span class="n">err</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1"> fval: &#39;</span><span class="p">,</span> <span class="n">f_val</span><span class="p">)</span>

        <span class="nb">iter</span> <span class="o">=</span> <span class="nb">iter</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">pi</span><span class="p">,</span> <span class="n">U</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016-2021, Rémi Flamary, Nicolas Courty.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note"
aria-label="versions">
  <!--  add shift_up to the class for force viewing ,
  data-toggle="rst-current-version" -->
    <span class="rst-current-version"  style="margin-bottom:1mm;">
      <span class="fa fa-book"> Python Optimal Transport</span>
      <hr  style="margin-bottom:1.5mm;margin-top:5mm;">
     <!--  versions
      <span class="fa fa-caret-down"></span>-->
      <span class="rst-current-version" style="display: inline-block;padding:
      0px;color:#fcfcfcab;float:left;font-size: 100%;">
        Versions: 
        <a href="https://pythonot.github.io/" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Release</a>
        <a href="https://pythonot.github.io/master" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Development</a>
        <a href="https://github.com/PythonOT/POT"
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Code</a>

      </span>

     
    </span>
  
     <!--
    <div class="rst-other-versions">

      

<div class="injected">

    
  <dl>
    <dt>Versions</dt>

    <dd><a href="https://pythonot.github.io/">Release</a></dd>
    
    <dd><a href="https://pythonot.github.io/master">Development</a></dd>
   
    

    <dt><a href="https://github.com/PythonOT/POT">Code on Github</a></dt>       

    
  </dl>
  <hr>

</div> 
</div>-->
  </div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>