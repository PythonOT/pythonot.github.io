<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ot.da &mdash; POT Python Optimal Transport 0.8.2dev documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> POT Python Optimal Transport
            <img src="../../_static/logo_dark.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.8.2dev
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">POT: Python Optimal Transport</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quick start guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../all.html">API and modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Examples gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../.github/CONTRIBUTING.html">Contributing to POT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../.github/CODE_OF_CONDUCT.html">Code of Conduct</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">POT Python Optimal Transport</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Module code</a> &raquo;</li>
      <li>ot.da</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for ot.da</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Domain adaptation with optimal transport</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Author: Remi Flamary &lt;remi.flamary@unice.fr&gt;</span>
<span class="c1">#         Nicolas Courty &lt;ncourty@irisa.fr&gt;</span>
<span class="c1">#         Michael Perrot &lt;michael.perrot@univ-st-etienne.fr&gt;</span>
<span class="c1">#         Nathalie Gayraud &lt;nat.gayraud@gmail.com&gt;</span>
<span class="c1">#         Ievgen Redko &lt;ievgen.redko@univ-st-etienne.fr&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: MIT License</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">.backend</span> <span class="kn">import</span> <span class="n">get_backend</span>
<span class="kn">from</span> <span class="nn">.bregman</span> <span class="kn">import</span> <span class="n">sinkhorn</span><span class="p">,</span> <span class="n">jcpot_barycenter</span>
<span class="kn">from</span> <span class="nn">.lp</span> <span class="kn">import</span> <span class="n">emd</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">unif</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">cost_normalization</span><span class="p">,</span> <span class="n">label_normalization</span><span class="p">,</span> <span class="n">laplacian</span><span class="p">,</span> <span class="n">dots</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">list_to_array</span><span class="p">,</span> <span class="n">check_params</span><span class="p">,</span> <span class="n">BaseEstimator</span>
<span class="kn">from</span> <span class="nn">.unbalanced</span> <span class="kn">import</span> <span class="n">sinkhorn_unbalanced</span>
<span class="kn">from</span> <span class="nn">.optim</span> <span class="kn">import</span> <span class="n">cg</span>
<span class="kn">from</span> <span class="nn">.optim</span> <span class="kn">import</span> <span class="n">gcg</span>


<div class="viewcode-block" id="sinkhorn_lpl1_mm"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.sinkhorn_lpl1_mm">[docs]</a><span class="k">def</span> <span class="nf">sinkhorn_lpl1_mm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                     <span class="n">numInnerItermax</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">stopInnerThr</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solve the entropic regularization optimal transport problem with nonconvex</span>
<span class="sd">    group lasso regularization</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +</span>
<span class="sd">        \mathrm{reg} \cdot \Omega_e(\gamma) + \eta \ \Omega_g(\gamma)</span>

<span class="sd">        s.t. \ \gamma \mathbf{1} = \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} = \mathbf{b}</span>

<span class="sd">             \gamma \geq 0</span>


<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the (`ns`, `nt`) metric cost matrix</span>
<span class="sd">    - :math:`\Omega_e` is the entropic regularization term :math:`\Omega_e</span>
<span class="sd">      (\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})`</span>
<span class="sd">    - :math:`\Omega_g` is the group lasso  regularization term</span>
<span class="sd">      :math:`\Omega_g(\gamma)=\sum_{i,c} \|\gamma_{i,\mathcal{I}_c}\|^{1/2}_1`</span>
<span class="sd">      where  :math:`\mathcal{I}_c` are the index of samples from class `c`</span>
<span class="sd">      in the source domain.</span>
<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are source and target weights (sum to 1)</span>

<span class="sd">    The algorithm used for solving the problem is the generalized conditional</span>
<span class="sd">    gradient as proposed in :ref:`[5, 7] &lt;references-sinkhorn-lpl1-mm&gt;`.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array-like (ns,)</span>
<span class="sd">        samples weights in the source domain</span>
<span class="sd">    labels_a : array-like (ns,)</span>
<span class="sd">        labels of samples in the source domain</span>
<span class="sd">    b : array-like (nt,)</span>
<span class="sd">        samples weights in the target domain</span>
<span class="sd">    M : array-like (ns,nt)</span>
<span class="sd">        loss matrix</span>
<span class="sd">    reg : float</span>
<span class="sd">        Regularization term for entropic regularization &gt;0</span>
<span class="sd">    eta : float, optional</span>
<span class="sd">        Regularization term  for group lasso regularization &gt;0</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    numInnerItermax : int, optional</span>
<span class="sd">        Max number of iterations (inner sinkhorn solver)</span>
<span class="sd">    stopInnerThr : float, optional</span>
<span class="sd">        Stop threshold on error (inner sinkhorn solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : (ns, nt) array-like</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary return only if log==True in parameters</span>


<span class="sd">    .. _references-sinkhorn-lpl1-mm:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [5] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">       &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE</span>
<span class="sd">       Transactions on Pattern Analysis and Machine Intelligence ,</span>
<span class="sd">       vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [7] Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).</span>
<span class="sd">       Generalized conditional gradient: analysis of convergence</span>
<span class="sd">       and applications. arXiv preprint arXiv:1510.06567.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.lp.emd : Unregularized OT</span>
<span class="sd">    ot.bregman.sinkhorn : Entropic regularized OT</span>
<span class="sd">    ot.optim.cg : General regularized OT</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-3</span>

    <span class="n">indices_labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels_a</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
        <span class="n">idxc</span><span class="p">,</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">labels_a</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>
        <span class="n">indices_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idxc</span><span class="p">)</span>

    <span class="n">W</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">cpt</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numItermax</span><span class="p">):</span>
        <span class="n">Mreg</span> <span class="o">=</span> <span class="n">M</span> <span class="o">+</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">W</span>
        <span class="n">transp</span> <span class="o">=</span> <span class="n">sinkhorn</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">Mreg</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="n">numInnerItermax</span><span class="p">,</span>
                          <span class="n">stopThr</span><span class="o">=</span><span class="n">stopInnerThr</span><span class="p">)</span>
        <span class="c1"># the transport has been computed. Check if classes are really</span>
        <span class="c1"># separated</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">classes</span><span class="p">):</span>
            <span class="n">majs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">transp</span><span class="p">[</span><span class="n">indices_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">majs</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="p">((</span><span class="n">majs</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">W</span><span class="p">[</span><span class="n">indices_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">majs</span>

    <span class="k">return</span> <span class="n">transp</span></div>


<div class="viewcode-block" id="sinkhorn_l1l2_gl"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.sinkhorn_l1l2_gl">[docs]</a><span class="k">def</span> <span class="nf">sinkhorn_l1l2_gl</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                     <span class="n">numInnerItermax</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">stopInnerThr</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solve the entropic regularization optimal transport problem with group</span>
<span class="sd">    lasso regularization</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +</span>
<span class="sd">        \mathrm{reg} \cdot \Omega_e(\gamma) + \eta \ \Omega_g(\gamma)</span>

<span class="sd">        s.t. \ \gamma \mathbf{1} = \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} = \mathbf{b}</span>

<span class="sd">             \gamma \geq 0</span>


<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the (`ns`, `nt`) metric cost matrix</span>
<span class="sd">    - :math:`\Omega_e` is the entropic regularization term</span>
<span class="sd">      :math:`\Omega_e(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})`</span>
<span class="sd">    - :math:`\Omega_g` is the group lasso regulaization term</span>
<span class="sd">      :math:`\Omega_g(\gamma)=\sum_{i,c} \|\gamma_{i,\mathcal{I}_c}\|^2`</span>
<span class="sd">      where  :math:`\mathcal{I}_c` are the index of samples from class</span>
<span class="sd">      `c` in the source domain.</span>
<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are source and target weights (sum to 1)</span>

<span class="sd">    The algorithm used for solving the problem is the generalised conditional</span>
<span class="sd">    gradient as proposed in :ref:`[5, 7] &lt;references-sinkhorn-l1l2-gl&gt;`.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array-like (ns,)</span>
<span class="sd">        samples weights in the source domain</span>
<span class="sd">    labels_a : array-like (ns,)</span>
<span class="sd">        labels of samples in the source domain</span>
<span class="sd">    b : array-like (nt,)</span>
<span class="sd">        samples in the target domain</span>
<span class="sd">    M : array-like (ns,nt)</span>
<span class="sd">        loss matrix</span>
<span class="sd">    reg : float</span>
<span class="sd">        Regularization term for entropic regularization &gt;0</span>
<span class="sd">    eta : float, optional</span>
<span class="sd">        Regularization term  for group lasso regularization &gt;0</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    numInnerItermax : int, optional</span>
<span class="sd">        Max number of iterations (inner sinkhorn solver)</span>
<span class="sd">    stopInnerThr : float, optional</span>
<span class="sd">        Stop threshold on error (inner sinkhorn solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : (ns, nt) array-like</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary return only if log==True in parameters</span>


<span class="sd">    .. _references-sinkhorn-l1l2-gl:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [5] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">       &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE Transactions</span>
<span class="sd">       on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [7] Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).</span>
<span class="sd">       Generalized conditional gradient: analysis of convergence and</span>
<span class="sd">       applications. arXiv preprint arXiv:1510.06567.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.optim.gcg : Generalized conditional gradient for OT problems</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">lstlab</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels_a</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">lab</span> <span class="ow">in</span> <span class="n">lstlab</span><span class="p">:</span>
                <span class="n">temp</span> <span class="o">=</span> <span class="n">G</span><span class="p">[</span><span class="n">labels_a</span> <span class="o">==</span> <span class="n">lab</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
                <span class="n">res</span> <span class="o">+=</span> <span class="n">nx</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">G</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">lab</span> <span class="ow">in</span> <span class="n">lstlab</span><span class="p">:</span>
                <span class="n">temp</span> <span class="o">=</span> <span class="n">G</span><span class="p">[</span><span class="n">labels_a</span> <span class="o">==</span> <span class="n">lab</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
                <span class="n">n</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">n</span><span class="p">:</span>
                    <span class="n">W</span><span class="p">[</span><span class="n">labels_a</span> <span class="o">==</span> <span class="n">lab</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span> <span class="o">/</span> <span class="n">n</span>
        <span class="k">return</span> <span class="n">W</span>

    <span class="k">return</span> <span class="n">gcg</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="n">numItermax</span><span class="p">,</span>
               <span class="n">numInnerItermax</span><span class="o">=</span><span class="n">numInnerItermax</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="n">stopInnerThr</span><span class="p">,</span>
               <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">)</span></div>


<div class="viewcode-block" id="joint_OT_mapping_linear"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.joint_OT_mapping_linear">[docs]</a><span class="k">def</span> <span class="nf">joint_OT_mapping_linear</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">verbose2</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">numInnerItermax</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                            <span class="n">stopInnerThr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Joint OT and linear mapping estimation as proposed in</span>
<span class="sd">    :ref:`[8] &lt;references-joint-OT-mapping-linear&gt;`.</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \min_{\gamma,L}\quad \|L(\mathbf{X_s}) - n_s\gamma \mathbf{X_t} \|^2_F +</span>
<span class="sd">          \mu \langle \gamma, \mathbf{M} \rangle_F + \eta \|L - \mathbf{I}\|^2_F</span>

<span class="sd">        s.t. \ \gamma \mathbf{1} = \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} = \mathbf{b}</span>

<span class="sd">             \gamma \geq 0</span>

<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the (`ns`, `nt`) squared euclidean cost matrix between samples in</span>
<span class="sd">      :math:`\mathbf{X_s}` and :math:`\mathbf{X_t}` (scaled by :math:`n_s`)</span>
<span class="sd">    - :math:`L` is a :math:`d\times d` linear operator that approximates the barycentric</span>
<span class="sd">      mapping</span>
<span class="sd">    - :math:`\mathbf{I}` is the identity matrix (neutral linear mapping)</span>
<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are uniform source and target weights</span>

<span class="sd">    The problem consist in solving jointly an optimal transport matrix</span>
<span class="sd">    :math:`\gamma` and a linear mapping that fits the barycentric mapping</span>
<span class="sd">    :math:`n_s\gamma \mathbf{X_t}`.</span>

<span class="sd">    One can also estimate a mapping with constant bias (see supplementary</span>
<span class="sd">    material of :ref:`[8] &lt;references-joint-OT-mapping-linear&gt;`) using the bias optional argument.</span>

<span class="sd">    The algorithm used for solving the problem is the block coordinate</span>
<span class="sd">    descent that alternates between updates of :math:`\mathbf{G}` (using conditionnal gradient)</span>
<span class="sd">    and the update of :math:`\mathbf{L}` using a classical least square solver.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    xs : array-like (ns,d)</span>
<span class="sd">        samples in the source domain</span>
<span class="sd">    xt : array-like (nt,d)</span>
<span class="sd">        samples in the target domain</span>
<span class="sd">    mu : float,optional</span>
<span class="sd">        Weight for the linear OT loss (&gt;0)</span>
<span class="sd">    eta : float, optional</span>
<span class="sd">        Regularization term  for the linear mapping L (&gt;0)</span>
<span class="sd">    bias : bool,optional</span>
<span class="sd">        Estimate linear mapping with constant bias</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of BCD iterations</span>
<span class="sd">    stopThr : float, optional</span>
<span class="sd">        Stop threshold on relative loss decrease (&gt;0)</span>
<span class="sd">    numInnerItermax : int, optional</span>
<span class="sd">        Max number of iterations (inner CG solver)</span>
<span class="sd">    stopInnerThr : float, optional</span>
<span class="sd">        Stop threshold on error (inner CG solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : (ns, nt) array-like</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    L : (d, d) array-like</span>
<span class="sd">        Linear mapping matrix ((:math:`d+1`, `d`) if bias)</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary return only if log==True in parameters</span>


<span class="sd">    .. _references-joint-OT-mapping-linear:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [8] M. Perrot, N. Courty, R. Flamary, A. Habrard,</span>
<span class="sd">        &quot;Mapping estimation for discrete optimal transport&quot;,</span>
<span class="sd">        Neural Information Processing Systems (NIPS), 2016.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.lp.emd : Unregularized OT</span>
<span class="sd">    ot.optim.cg : General regularized OT</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>

    <span class="n">ns</span><span class="p">,</span> <span class="n">nt</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
        <span class="n">xs1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">xs</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">ns</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">xstxs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xs1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">xs1</span><span class="p">)</span>
        <span class="n">Id</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">d</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)</span>
        <span class="n">Id</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">I0</span> <span class="o">=</span> <span class="n">Id</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">sel</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">xs1</span> <span class="o">=</span> <span class="n">xs</span>
        <span class="n">xstxs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xs1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">xs1</span><span class="p">)</span>
        <span class="n">Id</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)</span>
        <span class="n">I0</span> <span class="o">=</span> <span class="n">Id</span>

        <span class="k">def</span> <span class="nf">sel</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">x</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;err&#39;</span><span class="p">:</span> <span class="p">[]}</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">unif</span><span class="p">(</span><span class="n">ns</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">unif</span><span class="p">(</span><span class="n">nt</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xt</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span> <span class="o">*</span> <span class="n">ns</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">emd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">vloss</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">G</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute full loss&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xs1</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span> <span class="o">-</span> <span class="n">ns</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">xt</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">mu</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">G</span> <span class="o">*</span> <span class="n">M</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sel</span><span class="p">(</span><span class="n">L</span> <span class="o">-</span> <span class="n">I0</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">solve_L</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; solve L problem with fixed G (least square)&quot;&quot;&quot;</span>
        <span class="n">xst</span> <span class="o">=</span> <span class="n">ns</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">xstxs</span> <span class="o">+</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">Id</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xs1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">xst</span><span class="p">)</span> <span class="o">+</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">I0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">solve_G</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">G0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update G with CG algorithm&quot;&quot;&quot;</span>
        <span class="n">xsi</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xs1</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">xsi</span> <span class="o">-</span> <span class="n">ns</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">xt</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
            <span class="k">return</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">ns</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xsi</span> <span class="o">-</span> <span class="n">ns</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">xt</span><span class="p">),</span> <span class="n">xt</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="n">G</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">mu</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="o">=</span><span class="n">G0</span><span class="p">,</span>
               <span class="n">numItermax</span><span class="o">=</span><span class="n">numInnerItermax</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="n">stopInnerThr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">G</span>

    <span class="n">L</span> <span class="o">=</span> <span class="n">solve_L</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

    <span class="n">vloss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">G</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">|</span><span class="si">{:8s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="s1">&#39;Delta loss&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">32</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>

    <span class="c1"># init loop</span>
    <span class="k">if</span> <span class="n">numItermax</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">loop</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loop</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">it</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="n">loop</span><span class="p">:</span>

        <span class="n">it</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># update G</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">solve_G</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

        <span class="c1"># update L</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">solve_L</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

        <span class="n">vloss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">G</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">it</span> <span class="o">&gt;=</span> <span class="n">numItermax</span><span class="p">:</span>
            <span class="n">loop</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">stopThr</span><span class="p">:</span>
            <span class="n">loop</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">it</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">|</span><span class="si">{:8s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="s1">&#39;Delta loss&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">32</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">it</span><span class="p">,</span> <span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])))</span>
    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">vloss</span>
        <span class="k">return</span> <span class="n">G</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">log</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">G</span><span class="p">,</span> <span class="n">L</span></div>


<div class="viewcode-block" id="joint_OT_mapping_kernel"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.joint_OT_mapping_kernel">[docs]</a><span class="k">def</span> <span class="nf">joint_OT_mapping_kernel</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">kerneltype</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span>
                            <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose2</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">numItermax</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">numInnerItermax</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                            <span class="n">stopInnerThr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Joint OT and nonlinear mapping estimation with kernels as proposed in</span>
<span class="sd">    :ref:`[8] &lt;references-joint-OT-mapping-kernel&gt;`.</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \min_{\gamma, L\in\mathcal{H}}\quad \|L(\mathbf{X_s}) -</span>
<span class="sd">        n_s\gamma \mathbf{X_t}\|^2_F + \mu \langle \gamma, \mathbf{M} \rangle_F +</span>
<span class="sd">        \eta \|L\|^2_\mathcal{H}</span>

<span class="sd">        s.t. \ \gamma \mathbf{1} = \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} = \mathbf{b}</span>

<span class="sd">             \gamma \geq 0</span>


<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the (`ns`, `nt`) squared euclidean cost matrix between samples in</span>
<span class="sd">      :math:`\mathbf{X_s}` and :math:`\mathbf{X_t}` (scaled by :math:`n_s`)</span>
<span class="sd">    - :math:`L` is a :math:`n_s \times d` linear operator on a kernel matrix that</span>
<span class="sd">      approximates the barycentric mapping</span>
<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are uniform source and target weights</span>

<span class="sd">    The problem consist in solving jointly an optimal transport matrix</span>
<span class="sd">    :math:`\gamma` and the nonlinear mapping that fits the barycentric mapping</span>
<span class="sd">    :math:`n_s\gamma \mathbf{X_t}`.</span>

<span class="sd">    One can also estimate a mapping with constant bias (see supplementary</span>
<span class="sd">    material of :ref:`[8] &lt;references-joint-OT-mapping-kernel&gt;`) using the bias optional argument.</span>

<span class="sd">    The algorithm used for solving the problem is the block coordinate</span>
<span class="sd">    descent that alternates between updates of :math:`\mathbf{G}` (using conditionnal gradient)</span>
<span class="sd">    and the update of :math:`\mathbf{L}` using a classical kernel least square solver.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    xs : array-like (ns,d)</span>
<span class="sd">        samples in the source domain</span>
<span class="sd">    xt : array-like (nt,d)</span>
<span class="sd">        samples in the target domain</span>
<span class="sd">    mu : float,optional</span>
<span class="sd">        Weight for the linear OT loss (&gt;0)</span>
<span class="sd">    eta : float, optional</span>
<span class="sd">        Regularization term  for the linear mapping L (&gt;0)</span>
<span class="sd">    kerneltype : str,optional</span>
<span class="sd">        kernel used by calling function :py:func:`ot.utils.kernel` (gaussian by default)</span>
<span class="sd">    sigma : float, optional</span>
<span class="sd">        Gaussian kernel bandwidth.</span>
<span class="sd">    bias : bool,optional</span>
<span class="sd">        Estimate linear mapping with constant bias</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    verbose2 : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of BCD iterations</span>
<span class="sd">    numInnerItermax : int, optional</span>
<span class="sd">        Max number of iterations (inner CG solver)</span>
<span class="sd">    stopInnerThr : float, optional</span>
<span class="sd">        Stop threshold on error (inner CG solver) (&gt;0)</span>
<span class="sd">    stopThr : float, optional</span>
<span class="sd">        Stop threshold on relative loss decrease (&gt;0)</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : (ns, nt) array-like</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    L : (ns, d) array-like</span>
<span class="sd">        Nonlinear mapping matrix ((:math:`n_s+1`, `d`) if bias)</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary return only if log==True in parameters</span>


<span class="sd">    .. _references-joint-OT-mapping-kernel:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [8] M. Perrot, N. Courty, R. Flamary, A. Habrard,</span>
<span class="sd">       &quot;Mapping estimation for discrete optimal transport&quot;,</span>
<span class="sd">       Neural Information Processing Systems (NIPS), 2016.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.lp.emd : Unregularized OT</span>
<span class="sd">    ot.optim.cg : General regularized OT</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>

    <span class="n">ns</span><span class="p">,</span> <span class="n">nt</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">K</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">kerneltype</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
        <span class="n">K1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">ns</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">Id</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">ns</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)</span>
        <span class="n">Id</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">Kp</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">ns</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)</span>
        <span class="n">Kp</span><span class="p">[:</span><span class="n">ns</span><span class="p">,</span> <span class="p">:</span><span class="n">ns</span><span class="p">]</span> <span class="o">=</span> <span class="n">K</span>

        <span class="c1"># ls regu</span>
        <span class="c1"># K0 = K1.T.dot(K1)+eta*I</span>
        <span class="c1"># Kreg=I</span>

        <span class="c1"># RKHS regul</span>
        <span class="n">K0</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">K1</span><span class="p">)</span> <span class="o">+</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">Kp</span>
        <span class="n">Kreg</span> <span class="o">=</span> <span class="n">Kp</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">K1</span> <span class="o">=</span> <span class="n">K</span>
        <span class="n">Id</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">ns</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)</span>

        <span class="c1"># ls regul</span>
        <span class="c1"># K0 = K1.T.dot(K1)+eta*I</span>
        <span class="c1"># Kreg=I</span>

        <span class="c1"># proper kernel ridge</span>
        <span class="n">K0</span> <span class="o">=</span> <span class="n">K</span> <span class="o">+</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">Id</span>
        <span class="n">Kreg</span> <span class="o">=</span> <span class="n">K</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;err&#39;</span><span class="p">:</span> <span class="p">[]}</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">unif</span><span class="p">(</span><span class="n">ns</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">unif</span><span class="p">(</span><span class="n">nt</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xt</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span> <span class="o">*</span> <span class="n">ns</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">emd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">vloss</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">G</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute full loss&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K1</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span> <span class="o">-</span> <span class="n">ns</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">xt</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">mu</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">G</span> <span class="o">*</span> <span class="n">M</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">dots</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Kreg</span><span class="p">,</span> <span class="n">L</span><span class="p">))</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">solve_L_nobias</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; solve L problem with fixed G (least square)&quot;&quot;&quot;</span>
        <span class="n">xst</span> <span class="o">=</span> <span class="n">ns</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">K0</span><span class="p">,</span> <span class="n">xst</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">solve_L_bias</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; solve L problem with fixed G (least square)&quot;&quot;&quot;</span>
        <span class="n">xst</span> <span class="o">=</span> <span class="n">ns</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">K0</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">xst</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">solve_G</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">G0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update G with CG algorithm&quot;&quot;&quot;</span>
        <span class="n">xsi</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K1</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">xsi</span> <span class="o">-</span> <span class="n">ns</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">xt</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
            <span class="k">return</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">ns</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xsi</span> <span class="o">-</span> <span class="n">ns</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">xt</span><span class="p">),</span> <span class="n">xt</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="n">G</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">mu</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="o">=</span><span class="n">G0</span><span class="p">,</span>
               <span class="n">numItermax</span><span class="o">=</span><span class="n">numInnerItermax</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="n">stopInnerThr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">G</span>

    <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
        <span class="n">solve_L</span> <span class="o">=</span> <span class="n">solve_L_bias</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">solve_L</span> <span class="o">=</span> <span class="n">solve_L_nobias</span>

    <span class="n">L</span> <span class="o">=</span> <span class="n">solve_L</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

    <span class="n">vloss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">G</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">|</span><span class="si">{:8s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="s1">&#39;Delta loss&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">32</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>

    <span class="c1"># init loop</span>
    <span class="k">if</span> <span class="n">numItermax</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">loop</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loop</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">it</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="n">loop</span><span class="p">:</span>

        <span class="n">it</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># update G</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">solve_G</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">G</span><span class="p">)</span>

        <span class="c1"># update L</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">solve_L</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

        <span class="n">vloss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">G</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">it</span> <span class="o">&gt;=</span> <span class="n">numItermax</span><span class="p">:</span>
            <span class="n">loop</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">stopThr</span><span class="p">:</span>
            <span class="n">loop</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">it</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5s}</span><span class="s1">|</span><span class="si">{:12s}</span><span class="s1">|</span><span class="si">{:8s}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="s1">&#39;It.&#39;</span><span class="p">,</span> <span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="s1">&#39;Delta loss&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">32</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:5d}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">|</span><span class="si">{:8e}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">it</span><span class="p">,</span> <span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">vloss</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])))</span>
    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">vloss</span>
        <span class="k">return</span> <span class="n">G</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">log</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">G</span><span class="p">,</span> <span class="n">L</span></div>


<div class="viewcode-block" id="OT_mapping_linear"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.OT_mapping_linear">[docs]</a><span class="k">def</span> <span class="nf">OT_mapping_linear</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">ws</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                      <span class="n">wt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return OT linear operator between samples.</span>

<span class="sd">    The function estimates the optimal linear operator that aligns the two</span>
<span class="sd">    empirical distributions. This is equivalent to estimating the closed</span>
<span class="sd">    form mapping between two Gaussian distributions :math:`\mathcal{N}(\mu_s,\Sigma_s)`</span>
<span class="sd">    and :math:`\mathcal{N}(\mu_t,\Sigma_t)` as proposed in</span>
<span class="sd">    :ref:`[14] &lt;references-OT-mapping-linear&gt;` and discussed in remark 2.29 in</span>
<span class="sd">    :ref:`[15] &lt;references-OT-mapping-linear&gt;`.</span>

<span class="sd">    The linear operator from source to target :math:`M`</span>

<span class="sd">    .. math::</span>
<span class="sd">        M(\mathbf{x})= \mathbf{A} \mathbf{x} + \mathbf{b}</span>

<span class="sd">    where :</span>

<span class="sd">    .. math::</span>
<span class="sd">        \mathbf{A} &amp;= \Sigma_s^{-1/2} \left(\Sigma_s^{1/2}\Sigma_t\Sigma_s^{1/2} \right)^{1/2}</span>
<span class="sd">        \Sigma_s^{-1/2}</span>

<span class="sd">        \mathbf{b} &amp;= \mu_t - \mathbf{A} \mu_s</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    xs : array-like (ns,d)</span>
<span class="sd">        samples in the source domain</span>
<span class="sd">    xt : array-like (nt,d)</span>
<span class="sd">        samples in the target domain</span>
<span class="sd">    reg : float,optional</span>
<span class="sd">        regularization added to the diagonals of covariances (&gt;0)</span>
<span class="sd">    ws : array-like (ns,1), optional</span>
<span class="sd">        weights for the source samples</span>
<span class="sd">    wt : array-like (ns,1), optional</span>
<span class="sd">        weights for the target samples</span>
<span class="sd">    bias: boolean, optional</span>
<span class="sd">        estimate bias :math:`\mathbf{b}` else :math:`\mathbf{b} = 0` (default:True)</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    A : (d, d) array-like</span>
<span class="sd">        Linear operator</span>
<span class="sd">    b : (1, d) array-like</span>
<span class="sd">        bias</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary return only if log==True in parameters</span>


<span class="sd">    .. _references-OT-mapping-linear:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [14] Knott, M. and Smith, C. S. &quot;On the optimal mapping of</span>
<span class="sd">        distributions&quot;, Journal of Optimization Theory and Applications</span>
<span class="sd">        Vol 43, 1984</span>

<span class="sd">    .. [15] Peyr, G., &amp; Cuturi, M. (2017). &quot;Computational Optimal</span>
<span class="sd">        Transport&quot;, 2018.</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>

    <span class="n">d</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
        <span class="n">mxs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">mxt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

        <span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span> <span class="o">-</span> <span class="n">mxs</span>
        <span class="n">xt</span> <span class="o">=</span> <span class="n">xt</span> <span class="o">-</span> <span class="n">mxt</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">mxs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)</span>
        <span class="n">mxt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">ws</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ws</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)</span> <span class="o">/</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">wt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">wt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">xt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xt</span><span class="p">)</span> <span class="o">/</span> <span class="n">xt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">Cs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">xs</span> <span class="o">*</span> <span class="n">ws</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ws</span><span class="p">)</span> <span class="o">+</span> <span class="n">reg</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">Ct</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">xt</span> <span class="o">*</span> <span class="n">wt</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">wt</span><span class="p">)</span> <span class="o">+</span> <span class="n">reg</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xt</span><span class="p">)</span>

    <span class="n">Cs12</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">sqrtm</span><span class="p">(</span><span class="n">Cs</span><span class="p">)</span>
    <span class="n">Cs_12</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Cs12</span><span class="p">)</span>

    <span class="n">M0</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">sqrtm</span><span class="p">(</span><span class="n">dots</span><span class="p">(</span><span class="n">Cs12</span><span class="p">,</span> <span class="n">Ct</span><span class="p">,</span> <span class="n">Cs12</span><span class="p">))</span>

    <span class="n">A</span> <span class="o">=</span> <span class="n">dots</span><span class="p">(</span><span class="n">Cs_12</span><span class="p">,</span> <span class="n">M0</span><span class="p">,</span> <span class="n">Cs_12</span><span class="p">)</span>

    <span class="n">b</span> <span class="o">=</span> <span class="n">mxt</span> <span class="o">-</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">mxs</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;Cs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Cs</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;Ct&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Ct</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;Cs12&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Cs12</span>
        <span class="n">log</span><span class="p">[</span><span class="s1">&#39;Cs_12&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Cs_12</span>
        <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">log</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span></div>


<div class="viewcode-block" id="emd_laplace"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.emd_laplace">[docs]</a><span class="k">def</span> <span class="nf">emd_laplace</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">sim</span><span class="o">=</span><span class="s1">&#39;knn&#39;</span><span class="p">,</span> <span class="n">sim_param</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="s1">&#39;pos&#39;</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span>
                <span class="n">numItermax</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">numInnerItermax</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
                <span class="n">stopInnerThr</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Solve the optimal transport problem (OT) with Laplacian regularization</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +</span>
<span class="sd">        \eta \cdot \Omega_\alpha(\gamma)</span>

<span class="sd">        s.t. \ \gamma \mathbf{1} = \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} = \mathbf{b}</span>

<span class="sd">             \gamma \geq 0</span>

<span class="sd">    where:</span>

<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are source and target weights (sum to 1)</span>
<span class="sd">    - :math:`\mathbf{x_s}` and :math:`\mathbf{x_t}` are source and target samples</span>
<span class="sd">    - :math:`\mathbf{M}` is the (`ns`, `nt`) metric cost matrix</span>
<span class="sd">    - :math:`\Omega_\alpha` is the Laplacian regularization term</span>

<span class="sd">    .. math::</span>
<span class="sd">        \Omega_\alpha = \frac{1 - \alpha}{n_s^2} \sum_{i,j}</span>
<span class="sd">        \mathbf{S^s}_{i,j} \|T(\mathbf{x}^s_i) - T(\mathbf{x}^s_j) \|^2 +</span>
<span class="sd">        \frac{\alpha}{n_t^2} \sum_{i,j}</span>
<span class="sd">        \mathbf{S^t}_{i,j} \|T(\mathbf{x}^t_i) - T(\mathbf{x}^t_j) \|^2</span>


<span class="sd">    with :math:`\mathbf{S^s}_{i,j}, \mathbf{S^t}_{i,j}` denoting source and target similarity</span>
<span class="sd">    matrices and :math:`T(\cdot)` being a barycentric mapping.</span>

<span class="sd">    The algorithm used for solving the problem is the conditional gradient algorithm as proposed in</span>
<span class="sd">    :ref:`[5] &lt;references-emd-laplace&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array-like (ns,)</span>
<span class="sd">        samples weights in the source domain</span>
<span class="sd">    b : array-like (nt,)</span>
<span class="sd">        samples weights in the target domain</span>
<span class="sd">    xs : array-like (ns,d)</span>
<span class="sd">        samples in the source domain</span>
<span class="sd">    xt : array-like (nt,d)</span>
<span class="sd">        samples in the target domain</span>
<span class="sd">    M : array-like (ns,nt)</span>
<span class="sd">        loss matrix</span>
<span class="sd">    sim : string, optional</span>
<span class="sd">        Type of similarity (&#39;knn&#39; or &#39;gauss&#39;) used to construct the Laplacian.</span>
<span class="sd">    sim_param : int or float, optional</span>
<span class="sd">        Parameter (number of the nearest neighbors for sim=&#39;knn&#39;</span>
<span class="sd">        or bandwidth for sim=&#39;gauss&#39;) used to compute the Laplacian.</span>
<span class="sd">    reg : string</span>
<span class="sd">        Type of Laplacian regularization</span>
<span class="sd">    eta : float</span>
<span class="sd">        Regularization term for Laplacian regularization</span>
<span class="sd">    alpha : float</span>
<span class="sd">        Regularization term  for source domain&#39;s importance in regularization</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    stopThr : float, optional</span>
<span class="sd">        Stop threshold on error (inner emd solver) (&gt;0)</span>
<span class="sd">    numInnerItermax : int, optional</span>
<span class="sd">        Max number of iterations (inner CG solver)</span>
<span class="sd">    stopInnerThr : float, optional</span>
<span class="sd">        Stop threshold on error (inner CG solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : (ns, nt) array-like</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary return only if log==True in parameters</span>


<span class="sd">    .. _references-emd-laplace:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [5] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">       &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE</span>
<span class="sd">       Transactions on Pattern Analysis and Machine Intelligence,</span>
<span class="sd">       vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [30] R. Flamary, N. Courty, D. Tuia, A. Rakotomamonjy,</span>
<span class="sd">        &quot;Optimal transport with Laplacian regularization: Applications to domain adaptation and shape matching,&quot;</span>
<span class="sd">        in NIPS Workshop on Optimal Transport and Machine Learning OTML, 2014.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.lp.emd : Unregularized OT</span>
<span class="sd">    ot.optim.cg : General regularized OT</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sim_param</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">))):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;Similarity parameter should be an int or a float. Got </span><span class="si">{type}</span><span class="s1"> instead.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="nb">type</span><span class="p">(</span><span class="n">sim_param</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">))</span>

    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sim</span> <span class="o">==</span> <span class="s1">&#39;gauss&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">sim_param</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sim_param</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="s1">&#39;sqeuclidean&#39;</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">sS</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">sim</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sim_param</span><span class="p">)</span>
        <span class="n">sT</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">sim</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sim_param</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">sim</span> <span class="o">==</span> <span class="s1">&#39;knn&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">sim_param</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sim_param</span> <span class="o">=</span> <span class="mi">3</span>

        <span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">kneighbors_graph</span>

        <span class="n">sS</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">kneighbors_graph</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">xs</span><span class="p">),</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">sim_param</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">)</span>
        <span class="n">sS</span> <span class="o">=</span> <span class="p">(</span><span class="n">sS</span> <span class="o">+</span> <span class="n">sS</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">sT</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">kneighbors_graph</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">xt</span><span class="p">),</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">sim_param</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">xt</span><span class="p">)</span>
        <span class="n">sT</span> <span class="o">=</span> <span class="p">(</span><span class="n">sT</span> <span class="o">+</span> <span class="n">sT</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unknown similarity type </span><span class="si">{sim}</span><span class="s1">. Currently supported similarity types are &quot;knn&quot; and &quot;gauss&quot;.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sim</span><span class="o">=</span><span class="n">sim</span><span class="p">))</span>

    <span class="n">lS</span> <span class="o">=</span> <span class="n">laplacian</span><span class="p">(</span><span class="n">sS</span><span class="p">)</span>
    <span class="n">lT</span> <span class="o">=</span> <span class="n">laplacian</span><span class="p">(</span><span class="n">sT</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">alpha</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">dots</span><span class="p">(</span><span class="n">xt</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">lS</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">xt</span><span class="p">))</span>
            <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">dots</span><span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">lT</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">xs</span><span class="p">))</span>
        <span class="p">)</span>

    <span class="n">ls2</span> <span class="o">=</span> <span class="n">lS</span> <span class="o">+</span> <span class="n">lS</span><span class="o">.</span><span class="n">T</span>
    <span class="n">lt2</span> <span class="o">=</span> <span class="n">lT</span> <span class="o">+</span> <span class="n">lT</span><span class="o">.</span><span class="n">T</span>
    <span class="n">xt2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">xt</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">reg</span> <span class="o">==</span> <span class="s1">&#39;disp&#39;</span><span class="p">:</span>
        <span class="n">Cs</span> <span class="o">=</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dots</span><span class="p">(</span><span class="n">ls2</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">Ct</span> <span class="o">=</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="n">xt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dots</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">lt2</span><span class="p">)</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">M</span> <span class="o">+</span> <span class="n">Cs</span> <span class="o">+</span> <span class="n">Ct</span>

    <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">alpha</span> <span class="o">*</span> <span class="n">dots</span><span class="p">(</span><span class="n">ls2</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">xt2</span><span class="p">)</span>
            <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">dots</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xs</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">lt2</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">cg</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">G0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="n">numItermax</span><span class="p">,</span> <span class="n">numItermaxEmd</span><span class="o">=</span><span class="n">numInnerItermax</span><span class="p">,</span>
              <span class="n">stopThr</span><span class="o">=</span><span class="n">stopThr</span><span class="p">,</span> <span class="n">stopThr2</span><span class="o">=</span><span class="n">stopInnerThr</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">)</span></div>


<div class="viewcode-block" id="distribution_estimation_uniform"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.distribution_estimation_uniform">[docs]</a><span class="k">def</span> <span class="nf">distribution_estimation_uniform</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;estimates a uniform distribution from an array of samples :math:`\mathbf{X}`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape (n_samples, n_features)</span>
<span class="sd">        The array of samples</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mu : array-like, shape (n_samples,)</span>
<span class="sd">        The uniform distribution estimated from :math:`\mathbf{X}`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">unif</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">X</span><span class="p">)</span></div>


<div class="viewcode-block" id="BaseTransport"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport">[docs]</a><span class="k">class</span> <span class="nc">BaseTransport</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Base class for OTDA objects</span>

<span class="sd">    .. note::</span>
<span class="sd">        All estimators should specify all the parameters that can be set</span>
<span class="sd">        at the class level in their ``__init__`` as explicit keyword</span>
<span class="sd">        arguments (no ``*args`` or ``**kwargs``).</span>

<span class="sd">    The fit method should:</span>

<span class="sd">    - estimate a cost matrix and store it in a `cost_` attribute</span>
<span class="sd">    - estimate a coupling matrix and store it in a `coupling_` attribute</span>
<span class="sd">    - estimate distributions from source and target data and store them in</span>
<span class="sd">      `mu_s` and `mu_t` attributes</span>
<span class="sd">    - store `Xs` and `Xt` in attributes to be used later on in `transform` and</span>
<span class="sd">      `inverse_transform` methods</span>

<span class="sd">    `transform` method should always get as input a `Xs` parameter</span>

<span class="sd">    `inverse_transform` method should always get as input a `Xt` parameter</span>

<span class="sd">    `transform_labels` method should always get as input a `ys` parameter</span>

<span class="sd">    `inverse_transform_labels` method should always get as input a `yt` parameter</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseTransport.fit"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The training class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_backend</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">):</span>

            <span class="c1"># pairwise distance</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cost_</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cost_</span> <span class="o">=</span> <span class="n">cost_normalization</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">)</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">ys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">yt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">infty</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">)</span>

                <span class="c1"># assumes labeled source samples occupy the first rows</span>
                <span class="c1"># and labeled target samples occupy the first columns</span>
                <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span> <span class="k">if</span> <span class="n">c</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
                    <span class="n">idx_s</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">ys</span> <span class="o">!=</span> <span class="n">c</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">ys</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                    <span class="n">idx_t</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">yt</span> <span class="o">==</span> <span class="n">c</span><span class="p">)</span>

                    <span class="c1"># all the coefficients corresponding to a source sample</span>
                    <span class="c1"># and a target sample :</span>
                    <span class="c1"># with different labels get a infinite</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">idx_t</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">[</span><span class="n">idx_s</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span>

            <span class="c1"># distribution estimation</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>

            <span class="c1"># store arrays of samples</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span> <span class="o">=</span> <span class="n">Xs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span> <span class="o">=</span> <span class="n">Xt</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="BaseTransport.fit_transform"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport.fit_transform">[docs]</a>    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>
<span class="sd">        and transports source samples :math:`\mathbf{X_s}` onto target ones :math:`\mathbf{X_t}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels for training samples</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The source samples samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTransport.transform"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports source samples :math:`\mathbf{X_s}` onto target ones :math:`\mathbf{X_t}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The source input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels for source samples</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The target input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels for target. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>
<span class="sd">        batch_size : int, optional (default=128)</span>
<span class="sd">            The batch size for out of sample inverse transform</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The transport source samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">):</span>

            <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">Xs</span><span class="p">):</span>

                <span class="c1"># perform standard barycentric mapping</span>
                <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="c1"># set nans to 0</span>
                <span class="n">transp</span><span class="p">[</span><span class="o">~</span> <span class="n">nx</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">transp</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="c1"># compute transported samples</span>
                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># perform out of sample mapping</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">batch_ind</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)]</span>

                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">bi</span> <span class="ow">in</span> <span class="n">batch_ind</span><span class="p">:</span>
                    <span class="c1"># get the nearest neighbor in the source domain</span>
                    <span class="n">D0</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">Xs</span><span class="p">[</span><span class="n">bi</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">)</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">D0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                    <span class="c1"># transport the source samples</span>
                    <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
                    <span class="n">transp</span><span class="p">[</span><span class="o">~</span> <span class="n">nx</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">transp</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">transp_Xs_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">)</span>

                    <span class="c1"># define the transported points</span>
                    <span class="n">transp_Xs_</span> <span class="o">=</span> <span class="n">transp_Xs_</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">Xs</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>

                    <span class="n">transp_Xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transp_Xs_</span><span class="p">)</span>

                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">transp_Xs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_Xs</span></div>

<div class="viewcode-block" id="BaseTransport.transform_labels"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport.transform_labels">[docs]</a>    <span class="k">def</span> <span class="nf">transform_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Propagate source labels :math:`\mathbf{y_s}` to obtain estimated target labels as in</span>
<span class="sd">        :ref:`[27] &lt;references-basetransport-transform-labels&gt;`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The source class labels</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_ys : array-like, shape (n_target_samples, nb_classes)</span>
<span class="sd">            Estimated soft target labels.</span>


<span class="sd">        .. _references-basetransport-transform-labels:</span>
<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        .. [27] Ievgen Redko, Nicolas Courty, Rmi Flamary, Devis Tuia</span>
<span class="sd">           &quot;Optimal transport for multi-source domain adaptation under target shift&quot;,</span>
<span class="sd">           International Conference on Artificial Intelligence and Statistics (AISTATS), 2019.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">ys</span><span class="o">=</span><span class="n">ys</span><span class="p">):</span>

            <span class="n">ysTemp</span> <span class="o">=</span> <span class="n">label_normalization</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">ys</span><span class="p">))</span>
            <span class="n">classes</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">ysTemp</span><span class="p">)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>
            <span class="n">D1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ysTemp</span><span class="p">)),</span> <span class="n">type_as</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">)</span>

            <span class="c1"># perform label propagation</span>
            <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

            <span class="c1"># set nans to 0</span>
            <span class="n">transp</span><span class="p">[</span><span class="o">~</span> <span class="n">nx</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">transp</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
                <span class="n">D1</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="n">ysTemp</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="c1"># compute propagated labels</span>
            <span class="n">transp_ys</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">D1</span><span class="p">,</span> <span class="n">transp</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_ys</span><span class="o">.</span><span class="n">T</span></div>

<div class="viewcode-block" id="BaseTransport.inverse_transform"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport.inverse_transform">[docs]</a>    <span class="k">def</span> <span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                          <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports target samples :math:`\mathbf{X_t}` onto source samples :math:`\mathbf{X_s}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The source input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The source class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The target input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The target class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>
<span class="sd">        batch_size : int, optional (default=128)</span>
<span class="sd">            The batch size for out of sample inverse transform</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xt : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The transported target samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">):</span>

            <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">,</span> <span class="n">Xt</span><span class="p">):</span>

                <span class="c1"># perform standard barycentric mapping</span>
                <span class="n">transp_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="mi">0</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="c1"># set nans to 0</span>
                <span class="n">transp_</span><span class="p">[</span><span class="o">~</span> <span class="n">nx</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">transp_</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="c1"># compute transported samples</span>
                <span class="n">transp_Xt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># perform out of sample mapping</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Xt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">batch_ind</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)]</span>

                <span class="n">transp_Xt</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">bi</span> <span class="ow">in</span> <span class="n">batch_ind</span><span class="p">:</span>
                    <span class="n">D0</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">Xt</span><span class="p">[</span><span class="n">bi</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">)</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">D0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                    <span class="c1"># transport the target samples</span>
                    <span class="n">transp_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="mi">0</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
                    <span class="n">transp_</span><span class="p">[</span><span class="o">~</span> <span class="n">nx</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">transp_</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">transp_Xt_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">)</span>

                    <span class="c1"># define the transported points</span>
                    <span class="n">transp_Xt_</span> <span class="o">=</span> <span class="n">transp_Xt_</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">Xt</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>

                    <span class="n">transp_Xt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transp_Xt_</span><span class="p">)</span>

                <span class="n">transp_Xt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">transp_Xt</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_Xt</span></div>

<div class="viewcode-block" id="BaseTransport.inverse_transform_labels"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport.inverse_transform_labels">[docs]</a>    <span class="k">def</span> <span class="nf">inverse_transform_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Propagate target labels :math:`\mathbf{y_t}` to obtain estimated source labels</span>
<span class="sd">        :math:`\mathbf{y_s}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_ys : array-like, shape (n_source_samples, nb_classes)</span>
<span class="sd">            Estimated soft source labels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">yt</span><span class="o">=</span><span class="n">yt</span><span class="p">):</span>

            <span class="n">ytTemp</span> <span class="o">=</span> <span class="n">label_normalization</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">yt</span><span class="p">))</span>
            <span class="n">classes</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">ytTemp</span><span class="p">)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>
            <span class="n">D1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ytTemp</span><span class="p">)),</span> <span class="n">type_as</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">)</span>

            <span class="c1"># perform label propagation</span>
            <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

            <span class="c1"># set nans to 0</span>
            <span class="n">transp</span><span class="p">[</span><span class="o">~</span> <span class="n">nx</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">transp</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
                <span class="n">D1</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="n">ytTemp</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="c1"># compute propagated samples</span>
            <span class="n">transp_ys</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">D1</span><span class="p">,</span> <span class="n">transp</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_ys</span><span class="o">.</span><span class="n">T</span></div></div>


<div class="viewcode-block" id="LinearTransport"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.LinearTransport">[docs]</a><span class="k">class</span> <span class="nc">LinearTransport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot; OT linear operator between empirical distributions</span>

<span class="sd">    The function estimates the optimal linear operator that aligns the two</span>
<span class="sd">    empirical distributions. This is equivalent to estimating the closed</span>
<span class="sd">    form mapping between two Gaussian distributions :math:`\mathcal{N}(\mu_s,\Sigma_s)`</span>
<span class="sd">    and :math:`\mathcal{N}(\mu_t,\Sigma_t)` as proposed in</span>
<span class="sd">    :ref:`[14] &lt;references-lineartransport&gt;` and discussed in remark 2.29 in</span>
<span class="sd">    :ref:`[15] &lt;references-lineartransport&gt;`.</span>

<span class="sd">    The linear operator from source to target :math:`M`</span>

<span class="sd">    .. math::</span>
<span class="sd">        M(\mathbf{x})= \mathbf{A} \mathbf{x} + \mathbf{b}</span>

<span class="sd">    where :</span>

<span class="sd">    .. math::</span>
<span class="sd">        \mathbf{A} &amp;= \Sigma_s^{-1/2} \left(\Sigma_s^{1/2}\Sigma_t\Sigma_s^{1/2} \right)^{1/2}</span>
<span class="sd">        \Sigma_s^{-1/2}</span>

<span class="sd">        \mathbf{b} &amp;= \mu_t - \mathbf{A} \mu_s</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg : float,optional</span>
<span class="sd">        regularization added to the daigonals of covariances (&gt;0)</span>
<span class="sd">    bias: boolean, optional</span>
<span class="sd">        estimate bias :math:`\mathbf{b}` else :math:`\mathbf{b} = 0` (default:True)</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>


<span class="sd">    .. _references-lineartransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [14] Knott, M. and Smith, C. S. &quot;On the optimal mapping of</span>
<span class="sd">        distributions&quot;, Journal of Optimization Theory and Applications</span>
<span class="sd">        Vol 43, 1984</span>

<span class="sd">    .. [15]  Peyr, G., &amp; Cuturi, M. (2017). &quot;Computational Optimal</span>
<span class="sd">        Transport&quot;, 2018.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg</span> <span class="o">=</span> <span class="n">reg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>

<div class="viewcode-block" id="LinearTransport.fit"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.LinearTransport.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_backend</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>

        <span class="c1"># coupling estimation</span>
        <span class="n">returned_</span> <span class="o">=</span> <span class="n">OT_mapping_linear</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg</span><span class="p">,</span>
                                      <span class="n">ws</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                                      <span class="n">wt</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                                      <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">)</span>

        <span class="c1"># deal with the value of log</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_</span><span class="p">,</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="c1"># re compute inverse mapping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A1_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">B1_</span> <span class="o">=</span> <span class="o">-</span><span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A1_</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="LinearTransport.transform"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.LinearTransport.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports source samples :math:`\mathbf{X_s}` onto target ones :math:`\mathbf{X_t}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>
<span class="sd">        batch_size : int, optional (default=128)</span>
<span class="sd">            The batch size for out of sample inverse transform</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The transport source samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">):</span>
            <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_</span>

            <span class="k">return</span> <span class="n">transp_Xs</span></div>

<div class="viewcode-block" id="LinearTransport.inverse_transform"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.LinearTransport.inverse_transform">[docs]</a>    <span class="k">def</span> <span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                          <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports target samples :math:`\mathbf{X_t}` onto source samples :math:`\mathbf{X_s}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>
<span class="sd">        batch_size : int, optional (default=128)</span>
<span class="sd">            The batch size for out of sample inverse transform</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xt : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The transported target samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">):</span>
            <span class="n">transp_Xt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A1_</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">B1_</span>

            <span class="k">return</span> <span class="n">transp_Xt</span></div></div>


<div class="viewcode-block" id="SinkhornTransport"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornTransport">[docs]</a><span class="k">class</span> <span class="nc">SinkhornTransport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Domain Adaptation OT method based on Sinkhorn Algorithm</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg_e : float, optional (default=1)</span>
<span class="sd">        Entropic regularization parameter</span>
<span class="sd">    max_iter : int, float, optional (default=1000)</span>
<span class="sd">        The minimum number of iteration before stopping the optimization</span>
<span class="sd">        algorithm if it has not converged</span>
<span class="sd">    tol : float, optional (default=10e-9)</span>
<span class="sd">        The precision required to stop the optimization algorithm.</span>
<span class="sd">    verbose : bool, optional (default=False)</span>
<span class="sd">        Controls the verbosity of the optimization algorithm</span>
<span class="sd">    log : int, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-sinkhorntransport&gt;`.</span>
<span class="sd">    limit_max: float, optional (default=np.infty)</span>
<span class="sd">        Controls the semi supervised mode. Transport between labeled source</span>
<span class="sd">        and target samples of different classes will exhibit an cost defined</span>
<span class="sd">        by this variable</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>
<span class="sd">    log_ : dictionary</span>
<span class="sd">        The dictionary of log, empty dict if parameter log is not True</span>


<span class="sd">    .. _references-sinkhorntransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">           &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE Transactions</span>
<span class="sd">           on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [2] M. Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal</span>
<span class="sd">           Transport, Advances in Neural Information Processing Systems (NIPS)</span>
<span class="sd">           26, 2013</span>

<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">            Regularized discrete optimal transport. SIAM Journal on Imaging</span>
<span class="sd">            Sciences, 7(3), 1853-1882.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_e</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                 <span class="n">tol</span><span class="o">=</span><span class="mf">10e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
                 <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s1">&#39;ferradans&#39;</span><span class="p">,</span> <span class="n">limit_max</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">infty</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span> <span class="o">=</span> <span class="n">reg_e</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">=</span> <span class="n">limit_max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>

<div class="viewcode-block" id="SinkhornTransport.fit"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornTransport.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">SinkhornTransport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="c1"># coupling estimation</span>
        <span class="n">returned_</span> <span class="o">=</span> <span class="n">sinkhorn</span><span class="p">(</span>
            <span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span><span class="p">,</span>
            <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">)</span>

        <span class="c1"># deal with the value of log</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div></div>


<div class="viewcode-block" id="EMDTransport"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.EMDTransport">[docs]</a><span class="k">class</span> <span class="nc">EMDTransport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Domain Adaptation OT method based on Earth Mover&#39;s Distance</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    log : int, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-emdtransport&gt;`.</span>
<span class="sd">    limit_max: float, optional (default=10)</span>
<span class="sd">        Controls the semi supervised mode. Transport between labeled source</span>
<span class="sd">        and target samples of different classes will exhibit an infinite cost</span>
<span class="sd">        (10 times the maximum value of the cost matrix)</span>
<span class="sd">    max_iter : int, optional (default=100000)</span>
<span class="sd">        The maximum number of iterations before stopping the optimization</span>
<span class="sd">        algorithm if it has not converged.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>


<span class="sd">    .. _references-emdtransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">        &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE Transactions</span>
<span class="sd">        on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</span>
<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">        Regularized discrete optimal transport. SIAM Journal on Imaging</span>
<span class="sd">        Sciences, 7(3), 1853-1882.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
                 <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s1">&#39;ferradans&#39;</span><span class="p">,</span> <span class="n">limit_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                 <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">=</span> <span class="n">limit_max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>

<div class="viewcode-block" id="EMDTransport.fit"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.EMDTransport.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">EMDTransport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="n">returned_</span> <span class="o">=</span> <span class="n">emd</span><span class="p">(</span>
            <span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">)</span>

        <span class="c1"># coupling estimation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div></div>


<div class="viewcode-block" id="SinkhornLpl1Transport"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornLpl1Transport">[docs]</a><span class="k">class</span> <span class="nc">SinkhornLpl1Transport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Domain Adaptation OT method based on sinkhorn algorithm +</span>
<span class="sd">    LpL1 class regularization.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg_e : float, optional (default=1)</span>
<span class="sd">        Entropic regularization parameter</span>
<span class="sd">    reg_cl : float, optional (default=0.1)</span>
<span class="sd">        Class regularization parameter</span>
<span class="sd">    max_iter : int, float, optional (default=10)</span>
<span class="sd">        The minimum number of iteration before stopping the optimization</span>
<span class="sd">        algorithm if it has not converged</span>
<span class="sd">    max_inner_iter : int, float, optional (default=200)</span>
<span class="sd">        The number of iteration in the inner loop</span>
<span class="sd">    log : bool, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    tol : float, optional (default=10e-9)</span>
<span class="sd">        Stop threshold on error (inner sinkhorn solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional (default=False)</span>
<span class="sd">        Controls the verbosity of the optimization algorithm</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-sinkhornlpl1transport&gt;`.</span>
<span class="sd">    limit_max: float, optional (default=np.infty)</span>
<span class="sd">        Controls the semi supervised mode. Transport between labeled source</span>
<span class="sd">        and target samples of different classes will exhibit a cost defined by</span>
<span class="sd">        limit_max.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>


<span class="sd">    .. _references-sinkhornlpl1transport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">       &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE</span>
<span class="sd">       Transactions on Pattern Analysis and Machine Intelligence ,</span>
<span class="sd">       vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [2] Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).</span>
<span class="sd">       Generalized conditional gradient: analysis of convergence</span>
<span class="sd">       and applications. arXiv preprint arXiv:1510.06567.</span>

<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">            Regularized discrete optimal transport. SIAM Journal on Imaging</span>
<span class="sd">            Sciences, 7(3), 1853-1882.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_e</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">reg_cl</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_inner_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">tol</span><span class="o">=</span><span class="mf">10e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
                 <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s1">&#39;ferradans&#39;</span><span class="p">,</span> <span class="n">limit_max</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">infty</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span> <span class="o">=</span> <span class="n">reg_e</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_cl</span> <span class="o">=</span> <span class="n">reg_cl</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span> <span class="o">=</span> <span class="n">max_inner_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">=</span> <span class="n">limit_max</span>

<div class="viewcode-block" id="SinkhornLpl1Transport.fit"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornLpl1Transport.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="n">ys</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">SinkhornLpl1Transport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

            <span class="n">returned_</span> <span class="o">=</span> <span class="n">sinkhorn_lpl1_mm</span><span class="p">(</span>
                <span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span> <span class="n">labels_a</span><span class="o">=</span><span class="n">ys</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span>
                <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_cl</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                <span class="n">numInnerItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span><span class="p">,</span> <span class="n">stopInnerThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">)</span>

        <span class="c1"># deal with the value of log</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div></div>


<div class="viewcode-block" id="EMDLaplaceTransport"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.EMDLaplaceTransport">[docs]</a><span class="k">class</span> <span class="nc">EMDLaplaceTransport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Domain Adaptation OT method based on Earth Mover&#39;s Distance with Laplacian regularization</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg_type : string optional (default=&#39;pos&#39;)</span>
<span class="sd">        Type of the regularization term: &#39;pos&#39; and &#39;disp&#39; for</span>
<span class="sd">        regularization term defined in :ref:`[2] &lt;references-emdlaplacetransport&gt;` and</span>
<span class="sd">        :ref:`[6] &lt;references-emdlaplacetransport&gt;`, respectively.</span>
<span class="sd">    reg_lap : float, optional (default=1)</span>
<span class="sd">        Laplacian regularization parameter</span>
<span class="sd">    reg_src : float, optional (default=0.5)</span>
<span class="sd">        Source relative importance in regularization</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    similarity : string, optional (default=&quot;knn&quot;)</span>
<span class="sd">        The similarity to use either knn or gaussian</span>
<span class="sd">    similarity_param : int or float, optional (default=None)</span>
<span class="sd">        Parameter for the similarity: number of nearest neighbors or bandwidth</span>
<span class="sd">        if similarity=&quot;knn&quot; or &quot;gaussian&quot;, respectively. If None is provided,</span>
<span class="sd">        it is set to 3 or the average pairwise squared Euclidean distance, respectively.</span>
<span class="sd">    max_iter : int, optional (default=100)</span>
<span class="sd">        Max number of BCD iterations</span>
<span class="sd">    tol : float, optional (default=1e-5)</span>
<span class="sd">        Stop threshold on relative loss decrease (&gt;0)</span>
<span class="sd">    max_inner_iter : int, optional (default=10)</span>
<span class="sd">        Max number of iterations (inner CG solver)</span>
<span class="sd">    inner_tol : float, optional (default=1e-6)</span>
<span class="sd">        Stop threshold on error (inner CG solver) (&gt;0)</span>
<span class="sd">    log : int, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-emdlaplacetransport&gt;`.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>


<span class="sd">    .. _references-emdlaplacetransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">           &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE Transactions</span>
<span class="sd">           on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [2] R. Flamary, N. Courty, D. Tuia, A. Rakotomamonjy,</span>
<span class="sd">        &quot;Optimal transport with Laplacian regularization: Applications to domain adaptation and shape matching,&quot;</span>
<span class="sd">        in NIPS Workshop on Optimal Transport and Machine Learning OTML, 2014.</span>

<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">        Regularized discrete optimal transport. SIAM Journal on Imaging Sciences, 7(3), 1853-1882.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_type</span><span class="o">=</span><span class="s1">&#39;pos&#39;</span><span class="p">,</span> <span class="n">reg_lap</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">reg_src</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span>
                 <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">similarity</span><span class="o">=</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">similarity_param</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span>
                 <span class="n">max_inner_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">inner_tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
                 <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s1">&#39;ferradans&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg</span> <span class="o">=</span> <span class="n">reg_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_lap</span> <span class="o">=</span> <span class="n">reg_lap</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_src</span> <span class="o">=</span> <span class="n">reg_src</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">similarity</span> <span class="o">=</span> <span class="n">similarity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sim_param</span> <span class="o">=</span> <span class="n">similarity_param</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span> <span class="o">=</span> <span class="n">max_inner_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_tol</span> <span class="o">=</span> <span class="n">inner_tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>

<div class="viewcode-block" id="EMDLaplaceTransport.fit"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.EMDLaplaceTransport.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">EMDLaplaceTransport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="n">returned_</span> <span class="o">=</span> <span class="n">emd_laplace</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span> <span class="n">xs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span>
                                <span class="n">xt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span> <span class="n">sim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">similarity</span><span class="p">,</span> <span class="n">sim_param</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sim_param</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lap</span><span class="p">,</span>
                                <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_src</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span> <span class="n">numInnerItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span><span class="p">,</span>
                                <span class="n">stopInnerThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_tol</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

        <span class="c1"># coupling estimation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div></div>


<div class="viewcode-block" id="SinkhornL1l2Transport"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornL1l2Transport">[docs]</a><span class="k">class</span> <span class="nc">SinkhornL1l2Transport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Domain Adaptation OT method based on sinkhorn algorithm +</span>
<span class="sd">    L1L2 class regularization.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg_e : float, optional (default=1)</span>
<span class="sd">        Entropic regularization parameter</span>
<span class="sd">    reg_cl : float, optional (default=0.1)</span>
<span class="sd">        Class regularization parameter</span>
<span class="sd">    max_iter : int, float, optional (default=10)</span>
<span class="sd">        The minimum number of iteration before stopping the optimization</span>
<span class="sd">        algorithm if it has not converged</span>
<span class="sd">    max_inner_iter : int, float, optional (default=200)</span>
<span class="sd">        The number of iteration in the inner loop</span>
<span class="sd">    tol : float, optional (default=10e-9)</span>
<span class="sd">        Stop threshold on error (inner sinkhorn solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional (default=False)</span>
<span class="sd">        Controls the verbosity of the optimization algorithm</span>
<span class="sd">    log : bool, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-sinkhornl1l2transport&gt;`.</span>
<span class="sd">    limit_max: float, optional (default=10)</span>
<span class="sd">        Controls the semi supervised mode. Transport between labeled source</span>
<span class="sd">        and target samples of different classes will exhibit an infinite cost</span>
<span class="sd">        (10 times the maximum value of the cost matrix)</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>
<span class="sd">    log_ : dictionary</span>
<span class="sd">        The dictionary of log, empty dict if parameter log is not True</span>


<span class="sd">    .. _references-sinkhornl1l2transport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">       &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE</span>
<span class="sd">       Transactions on Pattern Analysis and Machine Intelligence ,</span>
<span class="sd">       vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [2] Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).</span>
<span class="sd">       Generalized conditional gradient: analysis of convergence</span>
<span class="sd">       and applications. arXiv preprint arXiv:1510.06567.</span>

<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">            Regularized discrete optimal transport. SIAM Journal on Imaging</span>
<span class="sd">            Sciences, 7(3), 1853-1882.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_e</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">reg_cl</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_inner_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                 <span class="n">tol</span><span class="o">=</span><span class="mf">10e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
                 <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s1">&#39;ferradans&#39;</span><span class="p">,</span> <span class="n">limit_max</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span> <span class="o">=</span> <span class="n">reg_e</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_cl</span> <span class="o">=</span> <span class="n">reg_cl</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span> <span class="o">=</span> <span class="n">max_inner_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">=</span> <span class="n">limit_max</span>

<div class="viewcode-block" id="SinkhornL1l2Transport.fit"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornL1l2Transport.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="n">ys</span><span class="p">):</span>

            <span class="nb">super</span><span class="p">(</span><span class="n">SinkhornL1l2Transport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

            <span class="n">returned_</span> <span class="o">=</span> <span class="n">sinkhorn_l1l2_gl</span><span class="p">(</span>
                <span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span> <span class="n">labels_a</span><span class="o">=</span><span class="n">ys</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span>
                <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_cl</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                <span class="n">numInnerItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span><span class="p">,</span> <span class="n">stopInnerThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">)</span>

            <span class="c1"># deal with the value of log</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div></div>


<div class="viewcode-block" id="MappingTransport"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.MappingTransport">[docs]</a><span class="k">class</span> <span class="nc">MappingTransport</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;MappingTransport: DA methods that aims at jointly estimating a optimal</span>
<span class="sd">    transport coupling and the associated mapping</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    mu : float, optional (default=1)</span>
<span class="sd">        Weight for the linear OT loss (&gt;0)</span>
<span class="sd">    eta : float, optional (default=0.001)</span>
<span class="sd">        Regularization term for the linear mapping `L` (&gt;0)</span>
<span class="sd">    bias : bool, optional (default=False)</span>
<span class="sd">        Estimate linear mapping with constant bias</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    kernel : string, optional (default=&quot;linear&quot;)</span>
<span class="sd">        The kernel to use either linear or gaussian</span>
<span class="sd">    sigma : float, optional (default=1)</span>
<span class="sd">        The gaussian kernel parameter</span>
<span class="sd">    max_iter : int, optional (default=100)</span>
<span class="sd">        Max number of BCD iterations</span>
<span class="sd">    tol : float, optional (default=1e-5)</span>
<span class="sd">        Stop threshold on relative loss decrease (&gt;0)</span>
<span class="sd">    max_inner_iter : int, optional (default=10)</span>
<span class="sd">        Max number of iterations (inner CG solver)</span>
<span class="sd">    inner_tol : float, optional (default=1e-6)</span>
<span class="sd">        Stop threshold on error (inner CG solver) (&gt;0)</span>
<span class="sd">    log : bool, optional (default=False)</span>
<span class="sd">        record log if True</span>
<span class="sd">    verbose : bool, optional (default=False)</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    verbose2 : bool, optional (default=False)</span>
<span class="sd">        Print information along iterations</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>
<span class="sd">    mapping_ :</span>
<span class="sd">        The associated mapping</span>

<span class="sd">        - array-like, shape (`n_features` (+ 1), `n_features`),</span>
<span class="sd">          (if bias) for kernel == linear</span>

<span class="sd">        - array-like, shape (`n_source_samples` (+ 1), `n_features`),</span>
<span class="sd">          (if bias) for kernel == gaussian</span>
<span class="sd">    log_ : dictionary</span>
<span class="sd">        The dictionary of log, empty dict if parameter log is not True</span>


<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [8] M. Perrot, N. Courty, R. Flamary, A. Habrard,</span>
<span class="sd">            &quot;Mapping estimation for discrete optimal transport&quot;,</span>
<span class="sd">            Neural Information Processing Systems (NIPS), 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span>
                 <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
                 <span class="n">max_inner_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">inner_tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">verbose2</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">eta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span> <span class="o">=</span> <span class="n">max_inner_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_tol</span> <span class="o">=</span> <span class="n">inner_tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose2</span> <span class="o">=</span> <span class="n">verbose2</span>

<div class="viewcode-block" id="MappingTransport.fit"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.MappingTransport.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Builds an optimal coupling and estimates the associated mapping</span>
<span class="sd">        from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_backend</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">):</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span> <span class="o">=</span> <span class="n">Xs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span> <span class="o">=</span> <span class="n">Xt</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
                <span class="n">returned_</span> <span class="o">=</span> <span class="n">joint_OT_mapping_linear</span><span class="p">(</span>
                    <span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="n">verbose2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose2</span><span class="p">,</span>
                    <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                    <span class="n">numInnerItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                    <span class="n">stopInnerThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_tol</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">)</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">==</span> <span class="s2">&quot;gaussian&quot;</span><span class="p">:</span>
                <span class="n">returned_</span> <span class="o">=</span> <span class="n">joint_OT_mapping_kernel</span><span class="p">(</span>
                    <span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span>
                    <span class="n">sigma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                    <span class="n">verbose2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                    <span class="n">numInnerItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span><span class="p">,</span>
                    <span class="n">stopInnerThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_tol</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                    <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">)</span>

            <span class="c1"># deal with the value of log</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_</span> <span class="o">=</span> <span class="n">returned_</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="MappingTransport.transform"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.MappingTransport.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports source samples :math:`\mathbf{X_s}` onto target ones :math:`\mathbf{X_t}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The transport source samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">):</span>

            <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">Xs</span><span class="p">):</span>
                <span class="c1"># perform standard barycentric mapping</span>
                <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="c1"># set nans to 0</span>
                <span class="n">transp</span><span class="p">[</span><span class="o">~</span> <span class="n">nx</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">transp</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="c1"># compute transported samples</span>
                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">==</span> <span class="s2">&quot;gaussian&quot;</span><span class="p">:</span>
                    <span class="n">K</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span>
                               <span class="n">sigma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma</span><span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
                    <span class="n">K</span> <span class="o">=</span> <span class="n">Xs</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
                    <span class="n">K</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">K</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">Xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">K</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
                    <span class="p">)</span>
                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_Xs</span></div></div>


<div class="viewcode-block" id="UnbalancedSinkhornTransport"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.UnbalancedSinkhornTransport">[docs]</a><span class="k">class</span> <span class="nc">UnbalancedSinkhornTransport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Domain Adaptation unbalanced OT method based on sinkhorn algorithm</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg_e : float, optional (default=1)</span>
<span class="sd">        Entropic regularization parameter</span>
<span class="sd">    reg_m : float, optional (default=0.1)</span>
<span class="sd">        Mass regularization parameter</span>
<span class="sd">    method : str</span>
<span class="sd">        method used for the solver either &#39;sinkhorn&#39;,  &#39;sinkhorn_stabilized&#39; or</span>
<span class="sd">        &#39;sinkhorn_epsilon_scaling&#39;, see those function for specific parameters</span>
<span class="sd">    max_iter : int, float, optional (default=10)</span>
<span class="sd">        The minimum number of iteration before stopping the optimization</span>
<span class="sd">        algorithm if it has not converged</span>
<span class="sd">    tol : float, optional (default=10e-9)</span>
<span class="sd">        Stop threshold on error (inner sinkhorn solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional (default=False)</span>
<span class="sd">        Controls the verbosity of the optimization algorithm</span>
<span class="sd">    log : bool, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-unbalancedsinkhorntransport&gt;`.</span>
<span class="sd">    limit_max: float, optional (default=10)</span>
<span class="sd">        Controls the semi supervised mode. Transport between labeled source</span>
<span class="sd">        and target samples of different classes will exhibit an infinite cost</span>
<span class="sd">        (10 times the maximum value of the cost matrix)</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>
<span class="sd">    log_ : dictionary</span>
<span class="sd">        The dictionary of log, empty dict if parameter log is not True</span>


<span class="sd">    .. _references-unbalancedsinkhorntransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Chizat, L., Peyr, G., Schmitzer, B., &amp; Vialard, F. X. (2016).</span>
<span class="sd">        Scaling algorithms for unbalanced transport problems. arXiv preprint</span>
<span class="sd">        arXiv:1607.05816.</span>

<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">            Regularized discrete optimal transport. SIAM Journal on Imaging</span>
<span class="sd">            Sciences, 7(3), 1853-1882.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_e</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">reg_m</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;sinkhorn&#39;</span><span class="p">,</span>
                 <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
                 <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s1">&#39;ferradans&#39;</span><span class="p">,</span> <span class="n">limit_max</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span> <span class="o">=</span> <span class="n">reg_e</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_m</span> <span class="o">=</span> <span class="n">reg_m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">=</span> <span class="n">limit_max</span>

<div class="viewcode-block" id="UnbalancedSinkhornTransport.fit"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.UnbalancedSinkhornTransport.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">):</span>

            <span class="nb">super</span><span class="p">(</span><span class="n">UnbalancedSinkhornTransport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

            <span class="n">returned_</span> <span class="o">=</span> <span class="n">sinkhorn_unbalanced</span><span class="p">(</span>
                <span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span>
                <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span><span class="p">,</span> <span class="n">reg_m</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_m</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">,</span>
                <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">)</span>

            <span class="c1"># deal with the value of log</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div></div>


<div class="viewcode-block" id="JCPOTTransport"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.JCPOTTransport">[docs]</a><span class="k">class</span> <span class="nc">JCPOTTransport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Domain Adaptation OT method for multi-source target shift based on Wasserstein barycenter algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg_e : float, optional (default=1)</span>
<span class="sd">        Entropic regularization parameter</span>
<span class="sd">    max_iter : int, float, optional (default=10)</span>
<span class="sd">        The minimum number of iteration before stopping the optimization</span>
<span class="sd">        algorithm if it has not converged</span>
<span class="sd">    tol : float, optional (default=10e-9)</span>
<span class="sd">        Stop threshold on error (inner sinkhorn solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional (default=False)</span>
<span class="sd">        Controls the verbosity of the optimization algorithm</span>
<span class="sd">    log : bool, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-jcpottransport&gt;`.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : list of array-like objects, shape K x (n_source_samples, n_target_samples)</span>
<span class="sd">        A set of optimal couplings between each source domain and the target domain</span>
<span class="sd">    proportions_ : array-like, shape (n_classes,)</span>
<span class="sd">        Estimated class proportions in the target domain</span>
<span class="sd">    log_ : dictionary</span>
<span class="sd">        The dictionary of log, empty dict if parameter log is not True</span>


<span class="sd">    .. _references-jcpottransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Ievgen Redko, Nicolas Courty, Rmi Flamary, Devis Tuia</span>
<span class="sd">       &quot;Optimal transport for multi-source domain adaptation under target shift&quot;,</span>
<span class="sd">       International Conference on Artificial Intelligence and Statistics (AISTATS),</span>
<span class="sd">       vol. 89, p.849-858, 2019.</span>

<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">            Regularized discrete optimal transport. SIAM Journal on Imaging</span>
<span class="sd">            Sciences, 7(3), 1853-1882.</span>


<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_e</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                 <span class="n">tol</span><span class="o">=</span><span class="mf">10e-9</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span>
                 <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s1">&#39;ferradans&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span> <span class="o">=</span> <span class="n">reg_e</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>

<div class="viewcode-block" id="JCPOTTransport.fit"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.JCPOTTransport.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Building coupling matrices from a list of source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : list of K array-like objects, shape K x (nk_source_samples, n_features)</span>
<span class="sd">            A list of the training input samples.</span>
<span class="sd">        ys : list of K array-like objects, shape K x (nk_source_samples,)</span>
<span class="sd">            A list of the class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_backend</span><span class="p">(</span><span class="o">*</span><span class="n">Xs</span><span class="p">,</span> <span class="o">*</span><span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="n">ys</span><span class="p">):</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span> <span class="o">=</span> <span class="n">Xs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span> <span class="o">=</span> <span class="n">Xt</span>

            <span class="n">returned_</span> <span class="o">=</span> <span class="n">jcpot_barycenter</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Ys</span><span class="o">=</span><span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span><span class="p">,</span>
                                         <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="p">,</span> <span class="n">distrinumItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                                         <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;gamma&#39;</span><span class="p">]</span>

            <span class="c1"># deal with the value of log</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">proportions_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">proportions_</span> <span class="o">=</span> <span class="n">returned_</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="JCPOTTransport.transform"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.JCPOTTransport.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports source samples :math:`\mathbf{X_s}` onto target ones :math:`\mathbf{X_t}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : list of K array-like objects, shape K x (nk_source_samples, n_features)</span>
<span class="sd">            A list of the training input samples.</span>
<span class="sd">        ys : list of K array-like objects, shape K x (nk_source_samples,)</span>
<span class="sd">            A list of the class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>
<span class="sd">        batch_size : int, optional (default=128)</span>
<span class="sd">            The batch size for out of sample inverse transform</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="n">transp_Xs</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">):</span>

            <span class="k">if</span> <span class="nb">all</span><span class="p">([</span><span class="n">nx</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">Xs</span><span class="p">)]):</span>

                <span class="c1"># perform standard barycentric mapping for each source domain</span>

                <span class="k">for</span> <span class="n">coupling</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">:</span>
                    <span class="n">transp</span> <span class="o">=</span> <span class="n">coupling</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">coupling</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                    <span class="c1"># set nans to 0</span>
                    <span class="n">transp</span><span class="p">[</span><span class="o">~</span> <span class="n">nx</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">transp</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

                    <span class="c1"># compute transported samples</span>
                    <span class="n">transp_Xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>

                <span class="c1"># perform out of sample mapping</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">batch_ind</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)]</span>

                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="k">for</span> <span class="n">bi</span> <span class="ow">in</span> <span class="n">batch_ind</span><span class="p">:</span>
                    <span class="n">transp_Xs_</span> <span class="o">=</span> <span class="p">[]</span>

                    <span class="c1"># get the nearest neighbor in the sources domains</span>
                    <span class="n">xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">(</span><span class="n">Xs</span><span class="p">[</span><span class="n">bi</span><span class="p">],</span> <span class="n">xs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                    <span class="c1"># transport the source samples</span>
                    <span class="k">for</span> <span class="n">coupling</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">:</span>
                        <span class="n">transp</span> <span class="o">=</span> <span class="n">coupling</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">coupling</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
                        <span class="n">transp</span><span class="p">[</span><span class="o">~</span> <span class="n">nx</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">transp</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
                        <span class="n">transp_Xs_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">))</span>

                    <span class="n">transp_Xs_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">transp_Xs_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                    <span class="c1"># define the transported points</span>
                    <span class="n">transp_Xs_</span> <span class="o">=</span> <span class="n">transp_Xs_</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">Xs</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span> <span class="o">-</span> <span class="n">xs</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>
                    <span class="n">transp_Xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transp_Xs_</span><span class="p">)</span>

                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">transp_Xs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_Xs</span></div>

<div class="viewcode-block" id="JCPOTTransport.transform_labels"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.JCPOTTransport.transform_labels">[docs]</a>    <span class="k">def</span> <span class="nf">transform_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Propagate source labels :math:`\mathbf{y_s}` to obtain target labels as in</span>
<span class="sd">        :ref:`[27] &lt;references-jcpottransport-transform-labels&gt;`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ys : list of K array-like objects, shape K x (nk_source_samples,)</span>
<span class="sd">            A list of the class labels</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        yt : array-like, shape (n_target_samples, nb_classes)</span>
<span class="sd">            Estimated soft target labels.</span>


<span class="sd">        .. _references-jcpottransport-transform-labels:</span>
<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        .. [27] Ievgen Redko, Nicolas Courty, Rmi Flamary, Devis Tuia</span>
<span class="sd">           &quot;Optimal transport for multi-source domain adaptation under target shift&quot;,</span>
<span class="sd">           International Conference on Artificial Intelligence and Statistics (AISTATS), 2019.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">ys</span><span class="o">=</span><span class="n">ys</span><span class="p">):</span>
            <span class="n">yt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">ys</span><span class="p">))),</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                <span class="n">type_as</span><span class="o">=</span><span class="n">ys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">)):</span>
                <span class="n">ysTemp</span> <span class="o">=</span> <span class="n">label_normalization</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">ys</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
                <span class="n">classes</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">ysTemp</span><span class="p">)</span>
                <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>
                <span class="n">ns</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ysTemp</span><span class="p">)</span>

                <span class="c1"># perform label propagation</span>
                <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="c1"># set nans to 0</span>
                <span class="n">transp</span><span class="p">[</span><span class="o">~</span> <span class="n">nx</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">transp</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
                    <span class="n">D1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span><span class="p">[</span><span class="s1">&#39;D1&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">D1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">ns</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">transp</span><span class="p">)</span>

                    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
                        <span class="n">D1</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="n">ysTemp</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

                <span class="c1"># compute propagated labels</span>
                <span class="n">yt</span> <span class="o">=</span> <span class="n">yt</span> <span class="o">+</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">D1</span><span class="p">,</span> <span class="n">transp</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">yt</span><span class="o">.</span><span class="n">T</span></div>

<div class="viewcode-block" id="JCPOTTransport.inverse_transform_labels"><a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.JCPOTTransport.inverse_transform_labels">[docs]</a>    <span class="k">def</span> <span class="nf">inverse_transform_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Propagate target labels :math:`\mathbf{y_t}` to obtain estimated source labels</span>
<span class="sd">        :math:`\mathbf{y_s}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The target class labels</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_ys : list of K array-like objects, shape K x (nk_source_samples, nb_classes)</span>
<span class="sd">            A list of estimated soft source labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">yt</span><span class="o">=</span><span class="n">yt</span><span class="p">):</span>
            <span class="n">transp_ys</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">ytTemp</span> <span class="o">=</span> <span class="n">label_normalization</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">yt</span><span class="p">))</span>
            <span class="n">classes</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">ytTemp</span><span class="p">)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>
            <span class="n">D1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ytTemp</span><span class="p">)),</span> <span class="n">type_as</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
                <span class="n">D1</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="n">ytTemp</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">)):</span>

                <span class="c1"># perform label propagation</span>
                <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="c1"># set nans to 0</span>
                <span class="n">transp</span><span class="p">[</span><span class="o">~</span> <span class="n">nx</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">transp</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="c1"># compute propagated labels</span>
                <span class="n">transp_ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">D1</span><span class="p">,</span> <span class="n">transp</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_ys</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016-2021, Rmi Flamary, Nicolas Courty.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note"
aria-label="versions">
  <!--  add shift_up to the class for force viewing -->
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Python Optimal Transport</span>
      versions
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions"><!-- Inserted RTD Footer -->

<div class="injected">

      
      
      <dl>
        <dt>Versions</dt>

        <dd><a href="https://pythonot.github.io/">Release</a></dd>
        
        <dd><a href="https://pythonot.github.io/master">Development</a></dd>
       
        
        
      </dl>
      

    
      
      <dl>
        <dt>On GitHub</dt>
        <dd>
          <a href="https://github.com/PythonOT/POT">Code on Github</a>
        </dd>
        
      </dl>
      
    
      
      

      <hr>
      


</div>
</div>
  </div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>