

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ot.da &mdash; POT Python Optimal Transport 0.9.6dev0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=6e3d2238"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            POT Python Optimal Transport
              <img src="../../_static/logo_dark.svg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">POT: Python Optimal Transport</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quick start guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../all.html">API and modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Examples gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributors.html">Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing to POT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../code_of_conduct.html">Code of conduct</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">POT Python Optimal Transport</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">ot.da</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for ot.da</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Domain adaptation with optimal transport</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Author: Remi Flamary &lt;remi.flamary@unice.fr&gt;</span>
<span class="c1">#         Nicolas Courty &lt;ncourty@irisa.fr&gt;</span>
<span class="c1">#         Michael Perrot &lt;michael.perrot@univ-st-etienne.fr&gt;</span>
<span class="c1">#         Nathalie Gayraud &lt;nat.gayraud@gmail.com&gt;</span>
<span class="c1">#         Ievgen Redko &lt;ievgen.redko@univ-st-etienne.fr&gt;</span>
<span class="c1">#         Eloi Tanguy &lt;eloi.tanguy@u-paris.fr&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: MIT License</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.backend</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_backend</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.bregman</span><span class="w"> </span><span class="kn">import</span> <span class="n">sinkhorn</span><span class="p">,</span> <span class="n">jcpot_barycenter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.lp</span><span class="w"> </span><span class="kn">import</span> <span class="n">emd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">unif</span><span class="p">,</span>
    <span class="n">dist</span><span class="p">,</span>
    <span class="n">kernel</span><span class="p">,</span>
    <span class="n">cost_normalization</span><span class="p">,</span>
    <span class="n">label_normalization</span><span class="p">,</span>
    <span class="n">laplacian</span><span class="p">,</span>
    <span class="n">dots</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">BaseEstimator</span><span class="p">,</span>
    <span class="n">check_params</span><span class="p">,</span>
    <span class="n">deprecated</span><span class="p">,</span>
    <span class="n">labels_to_masks</span><span class="p">,</span>
    <span class="n">list_to_array</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.unbalanced</span><span class="w"> </span><span class="kn">import</span> <span class="n">sinkhorn_unbalanced</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.gaussian</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">empirical_bures_wasserstein_mapping</span><span class="p">,</span>
    <span class="n">empirical_gaussian_gromov_wasserstein_mapping</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">cg</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">gcg</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.mapping</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">nearest_brenier_potential_fit</span><span class="p">,</span>
    <span class="n">nearest_brenier_potential_predict_bounds</span><span class="p">,</span>
    <span class="n">joint_OT_mapping_linear</span><span class="p">,</span>
    <span class="n">joint_OT_mapping_kernel</span><span class="p">,</span>
<span class="p">)</span>


<div class="viewcode-block" id="sinkhorn_lpl1_mm">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.sinkhorn_lpl1_mm">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">sinkhorn_lpl1_mm</span><span class="p">(</span>
    <span class="n">a</span><span class="p">,</span>
    <span class="n">labels_a</span><span class="p">,</span>
    <span class="n">b</span><span class="p">,</span>
    <span class="n">M</span><span class="p">,</span>
    <span class="n">reg</span><span class="p">,</span>
    <span class="n">eta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">numItermax</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">numInnerItermax</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
    <span class="n">stopInnerThr</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solve the entropic regularization optimal transport problem with non-convex</span>
<span class="sd">    group lasso regularization</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +</span>
<span class="sd">        \mathrm{reg} \cdot \Omega_e(\gamma) + \eta \ \Omega_g(\gamma)</span>

<span class="sd">        s.t. \ \gamma \mathbf{1} = \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} = \mathbf{b}</span>

<span class="sd">             \gamma \geq 0</span>


<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the (`ns`, `nt`) metric cost matrix</span>
<span class="sd">    - :math:`\Omega_e` is the entropic regularization term :math:`\Omega_e</span>
<span class="sd">      (\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})`</span>
<span class="sd">    - :math:`\Omega_g` is the group lasso  regularization term</span>
<span class="sd">      :math:`\Omega_g(\gamma)=\sum_{i,c} \|\gamma_{i,\mathcal{I}_c}\|^{1/2}_1`</span>
<span class="sd">      where  :math:`\mathcal{I}_c` are the index of samples from class `c`</span>
<span class="sd">      in the source domain.</span>
<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are source and target weights (sum to 1)</span>

<span class="sd">    The algorithm used for solving the problem is the generalized conditional</span>
<span class="sd">    gradient as proposed in :ref:`[5, 7] &lt;references-sinkhorn-lpl1-mm&gt;`.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array-like (ns,)</span>
<span class="sd">        samples weights in the source domain</span>
<span class="sd">    labels_a : array-like (ns,)</span>
<span class="sd">        labels of samples in the source domain</span>
<span class="sd">    b : array-like (nt,)</span>
<span class="sd">        samples weights in the target domain</span>
<span class="sd">    M : array-like (ns,nt)</span>
<span class="sd">        loss matrix</span>
<span class="sd">    reg : float</span>
<span class="sd">        Regularization term for entropic regularization &gt;0</span>
<span class="sd">    eta : float, optional</span>
<span class="sd">        Regularization term  for group lasso regularization &gt;0</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    numInnerItermax : int, optional</span>
<span class="sd">        Max number of iterations (inner sinkhorn solver)</span>
<span class="sd">    stopInnerThr : float, optional</span>
<span class="sd">        Stop threshold on error (inner sinkhorn solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : (ns, nt) array-like</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary return only if log==True in parameters</span>


<span class="sd">    .. _references-sinkhorn-lpl1-mm:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [5] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">        &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE</span>
<span class="sd">        Transactions on Pattern Analysis and Machine Intelligence ,</span>
<span class="sd">        vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [7] Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).</span>
<span class="sd">        Generalized conditional gradient: analysis of convergence</span>
<span class="sd">        and applications. arXiv preprint arXiv:1510.06567.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.lp.emd : Unregularized OT</span>
<span class="sd">    ot.bregman.sinkhorn : Entropic regularized OT</span>
<span class="sd">    ot.optim.cg : General regularized OT</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-3</span>

    <span class="n">labels_u</span><span class="p">,</span> <span class="n">labels_idx</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels_a</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">n_labels</span> <span class="o">=</span> <span class="n">labels_u</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">unroll_labels_idx</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_labels</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">M</span><span class="p">)[</span><span class="n">labels_idx</span><span class="p">]</span>

    <span class="n">W</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numItermax</span><span class="p">):</span>
        <span class="n">Mreg</span> <span class="o">=</span> <span class="n">M</span> <span class="o">+</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">W</span>
        <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
            <span class="n">transp</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="n">sinkhorn</span><span class="p">(</span>
                <span class="n">a</span><span class="p">,</span>
                <span class="n">b</span><span class="p">,</span>
                <span class="n">Mreg</span><span class="p">,</span>
                <span class="n">reg</span><span class="p">,</span>
                <span class="n">numItermax</span><span class="o">=</span><span class="n">numInnerItermax</span><span class="p">,</span>
                <span class="n">stopThr</span><span class="o">=</span><span class="n">stopInnerThr</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">transp</span> <span class="o">=</span> <span class="n">sinkhorn</span><span class="p">(</span>
                <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">Mreg</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="n">numInnerItermax</span><span class="p">,</span> <span class="n">stopThr</span><span class="o">=</span><span class="n">stopInnerThr</span>
            <span class="p">)</span>
        <span class="c1"># the transport has been computed</span>
        <span class="c1"># check if classes are really separated</span>
        <span class="n">W</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">nx</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">transp</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">n_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="o">*</span> <span class="n">unroll_labels_idx</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="p">)</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">unroll_labels_idx</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="p">((</span><span class="n">W</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">transp</span><span class="p">,</span> <span class="n">log</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">transp</span></div>



<div class="viewcode-block" id="sinkhorn_l1l2_gl">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.sinkhorn_l1l2_gl">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">sinkhorn_l1l2_gl</span><span class="p">(</span>
    <span class="n">a</span><span class="p">,</span>
    <span class="n">labels_a</span><span class="p">,</span>
    <span class="n">b</span><span class="p">,</span>
    <span class="n">M</span><span class="p">,</span>
    <span class="n">reg</span><span class="p">,</span>
    <span class="n">eta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">numItermax</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">numInnerItermax</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
    <span class="n">stopInnerThr</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solve the entropic regularization optimal transport problem with group</span>
<span class="sd">    lasso regularization</span>

<span class="sd">    The function solves the following optimization problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +</span>
<span class="sd">        \mathrm{reg} \cdot \Omega_e(\gamma) + \eta \ \Omega_g(\gamma)</span>

<span class="sd">        s.t. \ \gamma \mathbf{1} = \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} = \mathbf{b}</span>

<span class="sd">             \gamma \geq 0</span>


<span class="sd">    where :</span>

<span class="sd">    - :math:`\mathbf{M}` is the (`ns`, `nt`) metric cost matrix</span>
<span class="sd">    - :math:`\Omega_e` is the entropic regularization term</span>
<span class="sd">      :math:`\Omega_e(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})`</span>
<span class="sd">    - :math:`\Omega_g` is the group lasso regularization term</span>
<span class="sd">      :math:`\Omega_g(\gamma)=\sum_{i,c} \|\gamma_{i,\mathcal{I}_c}\|^2`</span>
<span class="sd">      where  :math:`\mathcal{I}_c` are the index of samples from class</span>
<span class="sd">      `c` in the source domain.</span>
<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are source and target weights (sum to 1)</span>

<span class="sd">    The algorithm used for solving the problem is the generalized conditional</span>
<span class="sd">    gradient as proposed in :ref:`[5, 7] &lt;references-sinkhorn-l1l2-gl&gt;`.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array-like (ns,)</span>
<span class="sd">        samples weights in the source domain</span>
<span class="sd">    labels_a : array-like (ns,)</span>
<span class="sd">        labels of samples in the source domain</span>
<span class="sd">    b : array-like (nt,)</span>
<span class="sd">        samples in the target domain</span>
<span class="sd">    M : array-like (ns,nt)</span>
<span class="sd">        loss matrix</span>
<span class="sd">    reg : float</span>
<span class="sd">        Regularization term for entropic regularization &gt;0</span>
<span class="sd">    eta : float, optional</span>
<span class="sd">        Regularization term  for group lasso regularization &gt;0</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    numInnerItermax : int, optional</span>
<span class="sd">        Max number of iterations (inner sinkhorn solver)</span>
<span class="sd">    stopInnerThr : float, optional</span>
<span class="sd">        Stop threshold on error (inner sinkhorn solver) (&gt;0)</span>
<span class="sd">    eps: float, optional (default=1e-12)</span>
<span class="sd">        Small value to avoid division by zero</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : (ns, nt) array-like</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary return only if log==True in parameters</span>


<span class="sd">    .. _references-sinkhorn-l1l2-gl:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [5] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">        &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE Transactions</span>
<span class="sd">        on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [7] Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).</span>
<span class="sd">        Generalized conditional gradient: analysis of convergence and</span>
<span class="sd">        applications. arXiv preprint arXiv:1510.06567.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.optim.gcg : Generalized conditional gradient for OT problems</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">labels_a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="n">labels_u</span><span class="p">,</span> <span class="n">labels_idx</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels_a</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">n_labels</span> <span class="o">=</span> <span class="n">labels_u</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">unroll_labels_idx</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_labels</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">labels_u</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels_idx</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="n">G_split</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">n_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">G_split</span> <span class="o">*</span> <span class="n">unroll_labels_idx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="n">G_split</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">n_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">unroll_labels_idx</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">G_split</span> <span class="o">*</span> <span class="n">unroll_labels_idx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">G_norm</span> <span class="o">=</span> <span class="n">G_split</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">G_norm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

    <span class="k">return</span> <span class="n">gcg</span><span class="p">(</span>
        <span class="n">a</span><span class="p">,</span>
        <span class="n">b</span><span class="p">,</span>
        <span class="n">M</span><span class="p">,</span>
        <span class="n">reg</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">,</span>
        <span class="n">f</span><span class="p">,</span>
        <span class="n">df</span><span class="p">,</span>
        <span class="n">G0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">numItermax</span><span class="o">=</span><span class="n">numItermax</span><span class="p">,</span>
        <span class="n">numInnerItermax</span><span class="o">=</span><span class="n">numInnerItermax</span><span class="p">,</span>
        <span class="n">stopThr</span><span class="o">=</span><span class="n">stopInnerThr</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
    <span class="p">)</span></div>



<span class="n">OT_mapping_linear</span> <span class="o">=</span> <span class="n">deprecated</span><span class="p">(</span><span class="n">empirical_bures_wasserstein_mapping</span><span class="p">)</span>


<div class="viewcode-block" id="emd_laplace">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.emd_laplace">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">emd_laplace</span><span class="p">(</span>
    <span class="n">a</span><span class="p">,</span>
    <span class="n">b</span><span class="p">,</span>
    <span class="n">xs</span><span class="p">,</span>
    <span class="n">xt</span><span class="p">,</span>
    <span class="n">M</span><span class="p">,</span>
    <span class="n">sim</span><span class="o">=</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span>
    <span class="n">sim_param</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reg</span><span class="o">=</span><span class="s2">&quot;pos&quot;</span><span class="p">,</span>
    <span class="n">eta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">numItermax</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">stopThr</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span>
    <span class="n">numInnerItermax</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
    <span class="n">stopInnerThr</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Solve the optimal transport problem (OT) with Laplacian regularization</span>

<span class="sd">    .. math::</span>
<span class="sd">        \gamma = \mathop{\arg \min}_\gamma \quad \langle \gamma, \mathbf{M} \rangle_F +</span>
<span class="sd">        \eta \cdot \Omega_\alpha(\gamma)</span>

<span class="sd">        s.t. \ \gamma \mathbf{1} = \mathbf{a}</span>

<span class="sd">             \gamma^T \mathbf{1} = \mathbf{b}</span>

<span class="sd">             \gamma \geq 0</span>

<span class="sd">    where:</span>

<span class="sd">    - :math:`\mathbf{a}` and :math:`\mathbf{b}` are source and target weights (sum to 1)</span>
<span class="sd">    - :math:`\mathbf{x_s}` and :math:`\mathbf{x_t}` are source and target samples</span>
<span class="sd">    - :math:`\mathbf{M}` is the (`ns`, `nt`) metric cost matrix</span>
<span class="sd">    - :math:`\Omega_\alpha` is the Laplacian regularization term</span>

<span class="sd">    .. math::</span>
<span class="sd">        \Omega_\alpha = \frac{1 - \alpha}{n_s^2} \sum_{i,j}</span>
<span class="sd">        \mathbf{S^s}_{i,j} \|T(\mathbf{x}^s_i) - T(\mathbf{x}^s_j) \|^2 +</span>
<span class="sd">        \frac{\alpha}{n_t^2} \sum_{i,j}</span>
<span class="sd">        \mathbf{S^t}_{i,j} \|T(\mathbf{x}^t_i) - T(\mathbf{x}^t_j) \|^2</span>


<span class="sd">    with :math:`\mathbf{S^s}_{i,j}, \mathbf{S^t}_{i,j}` denoting source and target similarity</span>
<span class="sd">    matrices and :math:`T(\cdot)` being a barycentric mapping.</span>

<span class="sd">    The algorithm used for solving the problem is the conditional gradient algorithm as proposed in</span>
<span class="sd">    :ref:`[5] &lt;references-emd-laplace&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array-like (ns,)</span>
<span class="sd">        samples weights in the source domain</span>
<span class="sd">    b : array-like (nt,)</span>
<span class="sd">        samples weights in the target domain</span>
<span class="sd">    xs : array-like (ns,d)</span>
<span class="sd">        samples in the source domain</span>
<span class="sd">    xt : array-like (nt,d)</span>
<span class="sd">        samples in the target domain</span>
<span class="sd">    M : array-like (ns,nt)</span>
<span class="sd">        loss matrix</span>
<span class="sd">    sim : string, optional</span>
<span class="sd">        Type of similarity (&#39;knn&#39; or &#39;gauss&#39;) used to construct the Laplacian.</span>
<span class="sd">    sim_param : int or float, optional</span>
<span class="sd">        Parameter (number of the nearest neighbors for sim=&#39;knn&#39;</span>
<span class="sd">        or bandwidth for sim=&#39;gauss&#39;) used to compute the Laplacian.</span>
<span class="sd">    reg : string</span>
<span class="sd">        Type of Laplacian regularization</span>
<span class="sd">    eta : float</span>
<span class="sd">        Regularization term for Laplacian regularization</span>
<span class="sd">    alpha : float</span>
<span class="sd">        Regularization term  for source domain&#39;s importance in regularization</span>
<span class="sd">    numItermax : int, optional</span>
<span class="sd">        Max number of iterations</span>
<span class="sd">    stopThr : float, optional</span>
<span class="sd">        Stop threshold on error (inner emd solver) (&gt;0)</span>
<span class="sd">    numInnerItermax : int, optional</span>
<span class="sd">        Max number of iterations (inner CG solver)</span>
<span class="sd">    stopInnerThr : float, optional</span>
<span class="sd">        Stop threshold on error (inner CG solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gamma : (ns, nt) array-like</span>
<span class="sd">        Optimal transportation matrix for the given parameters</span>
<span class="sd">    log : dict</span>
<span class="sd">        log dictionary return only if log==True in parameters</span>


<span class="sd">    .. _references-emd-laplace:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [5] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">        &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE</span>
<span class="sd">        Transactions on Pattern Analysis and Machine Intelligence,</span>
<span class="sd">        vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [30] R. Flamary, N. Courty, D. Tuia, A. Rakotomamonjy,</span>
<span class="sd">        &quot;Optimal transport with Laplacian regularization: Applications to domain adaptation and shape matching,&quot;</span>
<span class="sd">        in NIPS Workshop on Optimal Transport and Machine Learning OTML, 2014.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.lp.emd : Unregularized OT</span>
<span class="sd">    ot.optim.cg : General regularized OT</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sim_param</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">))):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Similarity parameter should be an int or a float. Got </span><span class="si">{type}</span><span class="s2"> instead.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="nb">type</span><span class="o">=</span><span class="nb">type</span><span class="p">(</span><span class="n">sim_param</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">list_to_array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">get_backend</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sim</span> <span class="o">==</span> <span class="s2">&quot;gauss&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">sim_param</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sim_param</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="s2">&quot;sqeuclidean&quot;</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">sS</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">sim</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sim_param</span><span class="p">)</span>
        <span class="n">sT</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">sim</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sim_param</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">sim</span> <span class="o">==</span> <span class="s2">&quot;knn&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">sim_param</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sim_param</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">kneighbors_graph</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;scikit-learn must be installed to use knn similarity. Install with `$pip install scikit-learn`.&quot;</span>
            <span class="p">)</span>

        <span class="n">sS</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span>
            <span class="n">kneighbors_graph</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">xs</span><span class="p">),</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">sim_param</span><span class="p">))</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span>
            <span class="n">type_as</span><span class="o">=</span><span class="n">xs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">sS</span> <span class="o">=</span> <span class="p">(</span><span class="n">sS</span> <span class="o">+</span> <span class="n">sS</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">sT</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span>
            <span class="n">kneighbors_graph</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">xt</span><span class="p">),</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">sim_param</span><span class="p">))</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span>
            <span class="n">type_as</span><span class="o">=</span><span class="n">xt</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">sT</span> <span class="o">=</span> <span class="p">(</span><span class="n">sT</span> <span class="o">+</span> <span class="n">sT</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;Unknown similarity type </span><span class="si">{sim}</span><span class="s1">. Currently supported similarity types are &quot;knn&quot; and &quot;gauss&quot;.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">sim</span><span class="o">=</span><span class="n">sim</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">lS</span> <span class="o">=</span> <span class="n">laplacian</span><span class="p">(</span><span class="n">sS</span><span class="p">)</span>
    <span class="n">lT</span> <span class="o">=</span> <span class="n">laplacian</span><span class="p">(</span><span class="n">sT</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">dots</span><span class="p">(</span><span class="n">xt</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">lS</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">xt</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span>
            <span class="n">dots</span><span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">lT</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="n">ls2</span> <span class="o">=</span> <span class="n">lS</span> <span class="o">+</span> <span class="n">lS</span><span class="o">.</span><span class="n">T</span>
    <span class="n">lt2</span> <span class="o">=</span> <span class="n">lT</span> <span class="o">+</span> <span class="n">lT</span><span class="o">.</span><span class="n">T</span>
    <span class="n">xt2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">xt</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">reg</span> <span class="o">==</span> <span class="s2">&quot;disp&quot;</span><span class="p">:</span>
        <span class="n">Cs</span> <span class="o">=</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dots</span><span class="p">(</span><span class="n">ls2</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">Ct</span> <span class="o">=</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="n">xt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dots</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">lt2</span><span class="p">)</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">M</span> <span class="o">+</span> <span class="n">Cs</span> <span class="o">+</span> <span class="n">Ct</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">df</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">dots</span><span class="p">(</span><span class="n">ls2</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">xt2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">dots</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xs</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">lt2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cg</span><span class="p">(</span>
        <span class="n">a</span><span class="p">,</span>
        <span class="n">b</span><span class="p">,</span>
        <span class="n">M</span><span class="p">,</span>
        <span class="n">reg</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
        <span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">,</span>
        <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
        <span class="n">G0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">numItermax</span><span class="o">=</span><span class="n">numItermax</span><span class="p">,</span>
        <span class="n">numItermaxEmd</span><span class="o">=</span><span class="n">numInnerItermax</span><span class="p">,</span>
        <span class="n">stopThr</span><span class="o">=</span><span class="n">stopThr</span><span class="p">,</span>
        <span class="n">stopThr2</span><span class="o">=</span><span class="n">stopInnerThr</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="distribution_estimation_uniform">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.distribution_estimation_uniform">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">distribution_estimation_uniform</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;estimates a uniform distribution from an array of samples :math:`\mathbf{X}`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape (n_samples, n_features)</span>
<span class="sd">        The array of samples</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mu : array-like, shape (n_samples,)</span>
<span class="sd">        The uniform distribution estimated from :math:`\mathbf{X}`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">unif</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">type_as</span><span class="o">=</span><span class="n">X</span><span class="p">)</span></div>



<div class="viewcode-block" id="BaseTransport">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BaseTransport</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for OTDA objects</span>

<span class="sd">    .. note::</span>
<span class="sd">        All estimators should specify all the parameters that can be set</span>
<span class="sd">        at the class level in their ``__init__`` as explicit keyword</span>
<span class="sd">        arguments (no ``*args`` or ``**kwargs``).</span>

<span class="sd">    The fit method should:</span>

<span class="sd">    - estimate a cost matrix and store it in a `cost_` attribute</span>
<span class="sd">    - estimate a coupling matrix and store it in a `coupling_` attribute</span>
<span class="sd">    - estimate distributions from source and target data and store them in</span>
<span class="sd">      `mu_s` and `mu_t` attributes</span>
<span class="sd">    - store `Xs` and `Xt` in attributes to be used later on in `transform` and</span>
<span class="sd">      `inverse_transform` methods</span>

<span class="sd">    `transform` method should always get as input a `Xs` parameter</span>

<span class="sd">    `inverse_transform` method should always get as input a `Xt` parameter</span>

<span class="sd">    `transform_labels` method should always get as input a `ys` parameter</span>

<span class="sd">    `inverse_transform_labels` method should always get as input a `yt` parameter</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseTransport.fit">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The training class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_backend</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">):</span>
            <span class="c1"># pairwise distance</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cost_</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_cost_</span> <span class="o">=</span> <span class="n">cost_normalization</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">,</span> <span class="n">return_value</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">ys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">yt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">*</span> <span class="n">nx</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">)</span>

                <span class="c1"># missing_labels is a (ns, nt) matrix of {0, 1} such that</span>
                <span class="c1"># the cells (i, j) has 0 iff either ys[i] or yt[j] is masked</span>
                <span class="n">missing_ys</span> <span class="o">=</span> <span class="p">(</span><span class="n">ys</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">ys</span><span class="p">)</span>
                <span class="n">missing_yt</span> <span class="o">=</span> <span class="p">(</span><span class="n">yt</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">yt</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">yt</span><span class="p">)</span>
                <span class="n">missing_labels</span> <span class="o">=</span> <span class="n">missing_ys</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">@</span> <span class="n">missing_yt</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
                <span class="c1"># labels_match is a (ns, nt) matrix of {True, False} such that</span>
                <span class="c1"># the cells (i, j) has False if ys[i] != yt[i]</span>
                <span class="n">label_match</span> <span class="o">=</span> <span class="p">(</span><span class="n">ys</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">-</span> <span class="n">yt</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">!=</span> <span class="mi">0</span>
                <span class="c1"># cost correction is a (ns, nt) matrix of {-Inf, float, Inf} such</span>
                <span class="c1"># that he cells (i, j) has -Inf where there&#39;s no correction necessary</span>
                <span class="c1"># by &#39;correction&#39; we mean setting cost to a large value when</span>
                <span class="c1"># labels do not match</span>
                <span class="c1"># we suppress potential RuntimeWarning caused by Inf multiplication</span>
                <span class="c1"># (as we explicitly cover potential NANs later)</span>
                <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">RuntimeWarning</span><span class="p">)</span>
                    <span class="n">cost_correction</span> <span class="o">=</span> <span class="n">label_match</span> <span class="o">*</span> <span class="n">missing_labels</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span>
                <span class="c1"># this operation is necessary because 0 * Inf = NAN</span>
                <span class="c1"># thus is irrelevant when limit_max is finite</span>
                <span class="n">cost_correction</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">cost_correction</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cost_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span> <span class="n">cost_correction</span><span class="p">)</span>

            <span class="c1"># distribution estimation</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>

            <span class="c1"># store arrays of samples</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span> <span class="o">=</span> <span class="n">Xs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span> <span class="o">=</span> <span class="n">Xt</span>

        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="BaseTransport.fit_transform">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport.fit_transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>
<span class="sd">        and transports source samples :math:`\mathbf{X_s}` onto target ones :math:`\mathbf{X_t}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels for training samples</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The source samples samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span></div>


<div class="viewcode-block" id="BaseTransport.transform">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport.transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports source samples :math:`\mathbf{X_s}` onto target ones :math:`\mathbf{X_t}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The source input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels for source samples</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The target input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels for target. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>
<span class="sd">        batch_size : int, optional (default=128)</span>
<span class="sd">            The batch size for out of sample inverse transform</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The transport source samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">Xs</span><span class="p">):</span>
                <span class="c1"># perform standard barycentric mapping</span>
                <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="c1"># set nans to 0</span>
                <span class="n">transp</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># compute transported samples</span>
                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># perform out of sample mapping</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">batch_ind</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">indices</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
                <span class="p">]</span>

                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">bi</span> <span class="ow">in</span> <span class="n">batch_ind</span><span class="p">:</span>
                    <span class="c1"># get the nearest neighbor in the source domain</span>
                    <span class="n">D0</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">Xs</span><span class="p">[</span><span class="n">bi</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">)</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">D0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                    <span class="c1"># transport the source samples</span>
                    <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
                    <span class="n">transp</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">transp_Xs_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">)</span>

                    <span class="c1"># define the transported points</span>
                    <span class="n">transp_Xs_</span> <span class="o">=</span> <span class="n">transp_Xs_</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">Xs</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>

                    <span class="n">transp_Xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transp_Xs_</span><span class="p">)</span>

                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">transp_Xs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_Xs</span></div>


<div class="viewcode-block" id="BaseTransport.transform_labels">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport.transform_labels">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Propagate source labels :math:`\mathbf{y_s}` to obtain estimated target labels as in</span>
<span class="sd">        :ref:`[27] &lt;references-basetransport-transform-labels&gt;`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The source class labels</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_ys : array-like, shape (n_target_samples, nb_classes)</span>
<span class="sd">            Estimated soft target labels.</span>


<span class="sd">        .. _references-basetransport-transform-labels:</span>
<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        .. [27] Ievgen Redko, Nicolas Courty, Rmi Flamary, Devis Tuia</span>
<span class="sd">            &quot;Optimal transport for multi-source domain adaptation under target shift&quot;,</span>
<span class="sd">            International Conference on Artificial Intelligence and Statistics (AISTATS), 2019.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">ys</span><span class="o">=</span><span class="n">ys</span><span class="p">):</span>
            <span class="c1"># perform label propagation</span>
            <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

            <span class="c1"># set nans to 0</span>
            <span class="n">transp</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># compute propagated labels</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">label_normalization</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="n">labels_to_masks</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">nx</span><span class="o">=</span><span class="n">nx</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">transp</span><span class="p">)</span>
            <span class="n">transp_ys</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">masks</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">transp</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_ys</span><span class="o">.</span><span class="n">T</span></div>


<div class="viewcode-block" id="BaseTransport.inverse_transform">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport.inverse_transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports target samples :math:`\mathbf{X_t}` onto source samples :math:`\mathbf{X_s}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The source input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The source class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The target input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The target class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>
<span class="sd">        batch_size : int, optional (default=128)</span>
<span class="sd">            The batch size for out of sample inverse transform</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xt : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The transported target samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">,</span> <span class="n">Xt</span><span class="p">):</span>
                <span class="c1"># perform standard barycentric mapping</span>
                <span class="n">transp_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="mi">0</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="c1"># set nans to 0</span>
                <span class="n">transp_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">transp_</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># compute transported samples</span>
                <span class="n">transp_Xt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># perform out of sample mapping</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Xt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">batch_ind</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">indices</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
                <span class="p">]</span>

                <span class="n">transp_Xt</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">bi</span> <span class="ow">in</span> <span class="n">batch_ind</span><span class="p">:</span>
                    <span class="n">D0</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">Xt</span><span class="p">[</span><span class="n">bi</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">)</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">D0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                    <span class="c1"># transport the target samples</span>
                    <span class="n">transp_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="mi">0</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
                    <span class="n">transp_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">transp_</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">transp_Xt_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">)</span>

                    <span class="c1"># define the transported points</span>
                    <span class="n">transp_Xt_</span> <span class="o">=</span> <span class="n">transp_Xt_</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">Xt</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>

                    <span class="n">transp_Xt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transp_Xt_</span><span class="p">)</span>

                <span class="n">transp_Xt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">transp_Xt</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_Xt</span></div>


<div class="viewcode-block" id="BaseTransport.inverse_transform_labels">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.BaseTransport.inverse_transform_labels">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">inverse_transform_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Propagate target labels :math:`\mathbf{y_t}` to obtain estimated source labels</span>
<span class="sd">        :math:`\mathbf{y_s}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_ys : array-like, shape (n_source_samples, nb_classes)</span>
<span class="sd">            Estimated soft source labels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">yt</span><span class="o">=</span><span class="n">yt</span><span class="p">):</span>
            <span class="c1"># perform label propagation</span>
            <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
            <span class="c1"># set nans to 0</span>
            <span class="n">transp</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># compute propagated labels</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">label_normalization</span><span class="p">(</span><span class="n">yt</span><span class="p">)</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="n">labels_to_masks</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">nx</span><span class="o">=</span><span class="n">nx</span><span class="p">,</span> <span class="n">type_as</span><span class="o">=</span><span class="n">transp</span><span class="p">)</span>
            <span class="n">transp_ys</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">masks</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">transp</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_ys</span><span class="o">.</span><span class="n">T</span></div>
</div>



<div class="viewcode-block" id="LinearTransport">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.LinearTransport">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LinearTransport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;OT linear operator between empirical distributions</span>

<span class="sd">    The function estimates the optimal linear operator that aligns the two</span>
<span class="sd">    empirical distributions. This is equivalent to estimating the closed</span>
<span class="sd">    form mapping between two Gaussian distributions :math:`\mathcal{N}(\mu_s,\Sigma_s)`</span>
<span class="sd">    and :math:`\mathcal{N}(\mu_t,\Sigma_t)` as proposed in</span>
<span class="sd">    :ref:`[14] &lt;references-lineartransport&gt;` and discussed in remark 2.29 in</span>
<span class="sd">    :ref:`[15] &lt;references-lineartransport&gt;`.</span>

<span class="sd">    The linear operator from source to target :math:`M`</span>

<span class="sd">    .. math::</span>
<span class="sd">        M(\mathbf{x})= \mathbf{A} \mathbf{x} + \mathbf{b}</span>

<span class="sd">    where :</span>

<span class="sd">    .. math::</span>
<span class="sd">        \mathbf{A} &amp;= \Sigma_s^{-1/2} \left(\Sigma_s^{1/2}\Sigma_t\Sigma_s^{1/2} \right)^{1/2}</span>
<span class="sd">        \Sigma_s^{-1/2}</span>

<span class="sd">        \mathbf{b} &amp;= \mu_t - \mathbf{A} \mu_s</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg : float,optional</span>
<span class="sd">        regularization added to the daigonals of covariances (&gt;0)</span>
<span class="sd">    bias: boolean, optional</span>
<span class="sd">        estimate bias :math:`\mathbf{b}` else :math:`\mathbf{b} = 0` (default:True)</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>


<span class="sd">    .. _references-lineartransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [14] Knott, M. and Smith, C. S. &quot;On the optimal mapping of</span>
<span class="sd">        distributions&quot;, Journal of Optimization Theory and Applications</span>
<span class="sd">        Vol 43, 1984</span>

<span class="sd">    .. [15]  Peyr, G., &amp; Cuturi, M. (2017). &quot;Computational Optimal</span>
<span class="sd">        Transport&quot;, 2018.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reg</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg</span> <span class="o">=</span> <span class="n">reg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>

<div class="viewcode-block" id="LinearTransport.fit">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.LinearTransport.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_backend</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nx</span> <span class="o">=</span> <span class="n">nx</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>

        <span class="c1"># coupling estimation</span>
        <span class="n">returned_</span> <span class="o">=</span> <span class="n">empirical_bures_wasserstein_mapping</span><span class="p">(</span>
            <span class="n">Xs</span><span class="p">,</span>
            <span class="n">Xt</span><span class="p">,</span>
            <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg</span><span class="p">,</span>
            <span class="n">ws</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">wt</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span>
            <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># deal with the value of log</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">B_</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="c1"># re compute inverse mapping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A1_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">B1_</span> <span class="o">=</span> <span class="o">-</span><span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A1_</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="LinearTransport.transform">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.LinearTransport.transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports source samples :math:`\mathbf{X_s}` onto target ones :math:`\mathbf{X_t}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>
<span class="sd">        batch_size : int, optional (default=128)</span>
<span class="sd">            The batch size for out of sample inverse transform</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The transport source samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">):</span>
            <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_</span>

            <span class="k">return</span> <span class="n">transp_Xs</span></div>


<div class="viewcode-block" id="LinearTransport.inverse_transform">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.LinearTransport.inverse_transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports target samples :math:`\mathbf{X_t}` onto source samples :math:`\mathbf{X_s}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>
<span class="sd">        batch_size : int, optional (default=128)</span>
<span class="sd">            The batch size for out of sample inverse transform</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xt : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The transported target samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">):</span>
            <span class="n">transp_Xt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A1_</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">B1_</span>

            <span class="k">return</span> <span class="n">transp_Xt</span></div>
</div>



<div class="viewcode-block" id="LinearGWTransport">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.LinearGWTransport">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LinearGWTransport</span><span class="p">(</span><span class="n">LinearTransport</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;OT Gaussian Gromov-Wasserstein linear operator between empirical distributions</span>

<span class="sd">    The function estimates the optimal linear operator that aligns the two</span>
<span class="sd">    empirical distributions optimally wrt the Gromov-Wasserstein distance. This is equivalent to estimating the closed</span>
<span class="sd">    form mapping between two Gaussian distributions :math:`\mathcal{N}(\mu_s,\Sigma_s)`</span>
<span class="sd">    and :math:`\mathcal{N}(\mu_t,\Sigma_t)` as proposed in</span>
<span class="sd">    :ref:`[57] &lt;references-lineargwtransport&gt;`.</span>

<span class="sd">    The linear operator from source to target :math:`M`</span>

<span class="sd">    .. math::</span>
<span class="sd">        M(\mathbf{x})= \mathbf{A} \mathbf{x} + \mathbf{b}</span>

<span class="sd">    where the matrix :math:`\mathbf{A}` and the vector :math:`\mathbf{b}` are</span>
<span class="sd">    defined in :ref:`[57] &lt;references-lineargwtransport&gt;`.</span>



<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sign_eigs : array-like (n_features), str, optional</span>
<span class="sd">        sign of the eigenvalues of the mapping matrix, by default all signs will</span>
<span class="sd">        be positive. If &#39;skewness&#39; is provided, the sign of the eigenvalues is</span>
<span class="sd">        selected as the product of the sign of the skewness of the projected data.</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if True</span>


<span class="sd">    .. _references-lineargwtransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [57] Delon, J., Desolneux, A., &amp; Salmona, A. (2022). GromovWasserstein</span>
<span class="sd">        distances between Gaussian distributions. Journal of Applied Probability,</span>
<span class="sd">        59(4), 1178-1198.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">sign_eigs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sign_eigs</span> <span class="o">=</span> <span class="n">sign_eigs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>

<div class="viewcode-block" id="LinearGWTransport.fit">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.LinearGWTransport.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_backend</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nx</span> <span class="o">=</span> <span class="n">nx</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>

        <span class="c1"># coupling estimation</span>
        <span class="n">returned_</span> <span class="o">=</span> <span class="n">empirical_gaussian_gromov_wasserstein_mapping</span><span class="p">(</span>
            <span class="n">Xs</span><span class="p">,</span>
            <span class="n">Xt</span><span class="p">,</span>
            <span class="n">ws</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span>
            <span class="n">wt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span>
            <span class="n">sign_eigs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sign_eigs</span><span class="p">,</span>
            <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># deal with the value of log</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">A_</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">B_</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="c1"># re compute inverse mapping</span>
        <span class="n">returned_1_</span> <span class="o">=</span> <span class="n">empirical_gaussian_gromov_wasserstein_mapping</span><span class="p">(</span>
            <span class="n">Xt</span><span class="p">,</span>
            <span class="n">Xs</span><span class="p">,</span>
            <span class="n">ws</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span>
            <span class="n">wt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span>
            <span class="n">sign_eigs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sign_eigs</span><span class="p">,</span>
            <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">A1_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">B1_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_1_</span> <span class="o">=</span> <span class="n">returned_1_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">A1_</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">B1_</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">returned_1_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div>
</div>



<div class="viewcode-block" id="SinkhornTransport">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornTransport">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SinkhornTransport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Domain Adaptation OT method based on Sinkhorn Algorithm</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg_e : float, optional (default=1)</span>
<span class="sd">        Entropic regularization parameter</span>
<span class="sd">    max_iter : int, float, optional (default=1000)</span>
<span class="sd">        The minimum number of iteration before stopping the optimization</span>
<span class="sd">        algorithm if it has not converged</span>
<span class="sd">    tol : float, optional (default=10e-9)</span>
<span class="sd">        The precision required to stop the optimization algorithm.</span>
<span class="sd">    verbose : bool, optional (default=False)</span>
<span class="sd">        Controls the verbosity of the optimization algorithm</span>
<span class="sd">    log : int, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values. Accepted values are  &#39;median&#39;,</span>
<span class="sd">        &#39;max&#39;, &#39;log&#39; and &#39;loglog&#39;.</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;continuous&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the nearest neighbor method proposed in :ref:`[6]</span>
<span class="sd">        &lt;references-sinkhorntransport&gt;` while &quot;continuous&quot; use the out of sample</span>
<span class="sd">        method from :ref:`[66]</span>
<span class="sd">        &lt;references-sinkhorntransport&gt;` and :ref:`[19]</span>
<span class="sd">        &lt;references-sinkhorntransport&gt;`.</span>
<span class="sd">    limit_max: float, optional (default=np.inf)</span>
<span class="sd">        Controls the semi supervised mode. Transport between labeled source</span>
<span class="sd">        and target samples of different classes will exhibit an cost defined</span>
<span class="sd">        by this variable</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>
<span class="sd">    log_ : dictionary</span>
<span class="sd">        The dictionary of log, empty dict if parameter log is not True</span>


<span class="sd">    .. _references-sinkhorntransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">           &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE Transactions</span>
<span class="sd">           on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [2] M. Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal</span>
<span class="sd">           Transport, Advances in Neural Information Processing Systems (NIPS)</span>
<span class="sd">           26, 2013</span>

<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">            Regularized discrete optimal transport. SIAM Journal on Imaging</span>
<span class="sd">            Sciences, 7(3), 1853-1882.</span>

<span class="sd">    .. [19] Seguy, V., Bhushan Damodaran, B., Flamary, R., Courty, N., Rolet, A.</span>
<span class="sd">             &amp; Blondel, M. Large-scale Optimal Transport and Mapping Estimation.</span>
<span class="sd">             International Conference on Learning Representation (2018)</span>

<span class="sd">    .. [66] Pooladian, Aram-Alexandre, and Jonathan Niles-Weed. &quot;Entropic</span>
<span class="sd">            estimation of optimal transport maps.&quot; arXiv preprint</span>
<span class="sd">            arXiv:2109.12004 (2021).</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reg_e</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;sinkhorn_log&quot;</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">10e-9</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
        <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s2">&quot;continuous&quot;</span><span class="p">,</span>
        <span class="n">limit_max</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">out_of_sample_map</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;ferradans&quot;</span><span class="p">,</span> <span class="s2">&quot;continuous&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown out_of_sample_map method&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span> <span class="o">=</span> <span class="n">reg_e</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">=</span> <span class="n">limit_max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>

<div class="viewcode-block" id="SinkhornTransport.fit">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornTransport.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">SinkhornTransport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">==</span> <span class="s2">&quot;continuous&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;sinkhorn_log&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;sinkhorn_log&quot;</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;The method has been set to &#39;sinkhorn_log&#39; as it is the only method available for out_of_sample_map=&#39;continuous&#39;&quot;</span>
                <span class="p">)</span>

        <span class="c1"># coupling estimation</span>
        <span class="n">returned_</span> <span class="o">=</span> <span class="n">sinkhorn</span><span class="p">(</span>
            <span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span>
            <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span>
            <span class="n">M</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span>
            <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span><span class="p">,</span>
            <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">,</span>
            <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">stopThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># deal with the value of log</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="SinkhornTransport.transform">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornTransport.transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports source samples :math:`\mathbf{X_s}` onto target ones :math:`\mathbf{X_t}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The source input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels for source samples</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The target input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels for target. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>
<span class="sd">        batch_size : int, optional (default=128)</span>
<span class="sd">            The batch size for out of sample inverse transform</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The transport source samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">==</span> <span class="s2">&quot;ferradans&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">SinkhornTransport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>  <span class="c1"># self.out_of_sample_map == &#39;continuous&#39;:</span>
            <span class="c1"># check the necessary inputs parameters are here</span>
            <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span><span class="p">[</span><span class="s2">&quot;log_v&quot;</span><span class="p">]</span>

            <span class="n">indices</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">batch_ind</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">indices</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
            <span class="p">]</span>

            <span class="n">transp_Xs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">bi</span> <span class="ow">in</span> <span class="n">batch_ind</span><span class="p">:</span>
                <span class="c1"># get the nearest neighbor in the source domain</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">Xs</span><span class="p">[</span><span class="n">bi</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="p">)</span>

                <span class="n">M</span> <span class="o">=</span> <span class="n">cost_normalization</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_cost_</span><span class="p">)</span>

                <span class="n">K</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">M</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span> <span class="o">+</span> <span class="n">g</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span>

                <span class="n">transp_Xs_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">)</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="n">transp_Xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transp_Xs_</span><span class="p">)</span>

            <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">transp_Xs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_Xs</span></div>


<div class="viewcode-block" id="SinkhornTransport.inverse_transform">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornTransport.inverse_transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">inverse_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports target samples :math:`\mathbf{X_t}` onto source samples :math:`\mathbf{X_s}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The source input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels for source samples</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The target input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels for target. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>
<span class="sd">        batch_size : int, optional (default=128)</span>
<span class="sd">            The batch size for out of sample inverse transform</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xt : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The transport target samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">==</span> <span class="s2">&quot;ferradans&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">SinkhornTransport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span>
                <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">batch_size</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>  <span class="c1"># self.out_of_sample_map == &#39;continuous&#39;:</span>
            <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span><span class="p">[</span><span class="s2">&quot;log_u&quot;</span><span class="p">]</span>

            <span class="n">indices</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Xt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">batch_ind</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">indices</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
            <span class="p">]</span>

            <span class="n">transp_Xt</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">bi</span> <span class="ow">in</span> <span class="n">batch_ind</span><span class="p">:</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">dist</span><span class="p">(</span><span class="n">Xt</span><span class="p">[</span><span class="n">bi</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="p">)</span>
                <span class="n">M</span> <span class="o">=</span> <span class="n">cost_normalization</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_cost_</span><span class="p">)</span>

                <span class="n">K</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">M</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span> <span class="o">+</span> <span class="n">f</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span>

                <span class="n">transp_Xt_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">)</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="n">transp_Xt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transp_Xt_</span><span class="p">)</span>

            <span class="n">transp_Xt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">transp_Xt</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_Xt</span></div>
</div>



<div class="viewcode-block" id="EMDTransport">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.EMDTransport">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">EMDTransport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Domain Adaptation OT method based on Earth Mover&#39;s Distance</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    log : int, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-emdtransport&gt;`.</span>
<span class="sd">    limit_max: float, optional (default=10)</span>
<span class="sd">        Controls the semi supervised mode. Transport between labeled source</span>
<span class="sd">        and target samples of different classes will exhibit an infinite cost</span>
<span class="sd">        (10 times the maximum value of the cost matrix)</span>
<span class="sd">    max_iter : int, optional (default=100000)</span>
<span class="sd">        The maximum number of iterations before stopping the optimization</span>
<span class="sd">        algorithm if it has not converged.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>


<span class="sd">    .. _references-emdtransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">        &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE Transactions</span>
<span class="sd">        on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</span>
<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">        Regularized discrete optimal transport. SIAM Journal on Imaging</span>
<span class="sd">        Sciences, 7(3), 1853-1882.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
        <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s2">&quot;ferradans&quot;</span><span class="p">,</span>
        <span class="n">limit_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">=</span> <span class="n">limit_max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>

<div class="viewcode-block" id="EMDTransport.fit">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.EMDTransport.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">EMDTransport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="n">returned_</span> <span class="o">=</span> <span class="n">emd</span><span class="p">(</span>
            <span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span>
            <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span>
            <span class="n">M</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span>
            <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># coupling estimation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div>
</div>



<div class="viewcode-block" id="SinkhornLpl1Transport">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornLpl1Transport">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SinkhornLpl1Transport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Domain Adaptation OT method based on sinkhorn algorithm +</span>
<span class="sd">    LpL1 class regularization.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg_e : float, optional (default=1)</span>
<span class="sd">        Entropic regularization parameter</span>
<span class="sd">    reg_cl : float, optional (default=0.1)</span>
<span class="sd">        Class regularization parameter</span>
<span class="sd">    max_iter : int, float, optional (default=10)</span>
<span class="sd">        The minimum number of iteration before stopping the optimization</span>
<span class="sd">        algorithm if it has not converged</span>
<span class="sd">    max_inner_iter : int, float, optional (default=200)</span>
<span class="sd">        The number of iteration in the inner loop</span>
<span class="sd">    log : bool, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    tol : float, optional (default=10e-9)</span>
<span class="sd">        Stop threshold on error (inner sinkhorn solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional (default=False)</span>
<span class="sd">        Controls the verbosity of the optimization algorithm</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-sinkhornlpl1transport&gt;`.</span>
<span class="sd">    limit_max: float, optional (default=np.inf)</span>
<span class="sd">        Controls the semi supervised mode. Transport between labeled source</span>
<span class="sd">        and target samples of different classes will exhibit a cost defined by</span>
<span class="sd">        limit_max.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>


<span class="sd">    .. _references-sinkhornlpl1transport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">        &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE</span>
<span class="sd">        Transactions on Pattern Analysis and Machine Intelligence ,</span>
<span class="sd">        vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [2] Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).</span>
<span class="sd">        Generalized conditional gradient: analysis of convergence</span>
<span class="sd">        and applications. arXiv preprint arXiv:1510.06567.</span>

<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">        Regularized discrete optimal transport. SIAM Journal on Imaging</span>
<span class="sd">        Sciences, 7(3), 1853-1882.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reg_e</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">reg_cl</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">max_inner_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">10e-9</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
        <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s2">&quot;ferradans&quot;</span><span class="p">,</span>
        <span class="n">limit_max</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span> <span class="o">=</span> <span class="n">reg_e</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_cl</span> <span class="o">=</span> <span class="n">reg_cl</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span> <span class="o">=</span> <span class="n">max_inner_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">=</span> <span class="n">limit_max</span>

<div class="viewcode-block" id="SinkhornLpl1Transport.fit">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornLpl1Transport.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="n">ys</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">SinkhornLpl1Transport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

            <span class="n">returned_</span> <span class="o">=</span> <span class="n">sinkhorn_lpl1_mm</span><span class="p">(</span>
                <span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span>
                <span class="n">labels_a</span><span class="o">=</span><span class="n">ys</span><span class="p">,</span>
                <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span>
                <span class="n">M</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span>
                <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span><span class="p">,</span>
                <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_cl</span><span class="p">,</span>
                <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                <span class="n">numInnerItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span><span class="p">,</span>
                <span class="n">stopInnerThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># deal with the value of log</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div>
</div>



<div class="viewcode-block" id="EMDLaplaceTransport">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.EMDLaplaceTransport">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">EMDLaplaceTransport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Domain Adaptation OT method based on Earth Mover&#39;s Distance with Laplacian regularization</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg_type : string optional (default=&#39;pos&#39;)</span>
<span class="sd">        Type of the regularization term: &#39;pos&#39; and &#39;disp&#39; for</span>
<span class="sd">        regularization term defined in :ref:`[2] &lt;references-emdlaplacetransport&gt;` and</span>
<span class="sd">        :ref:`[6] &lt;references-emdlaplacetransport&gt;`, respectively.</span>
<span class="sd">    reg_lap : float, optional (default=1)</span>
<span class="sd">        Laplacian regularization parameter</span>
<span class="sd">    reg_src : float, optional (default=0.5)</span>
<span class="sd">        Source relative importance in regularization</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    similarity : string, optional (default=&quot;knn&quot;)</span>
<span class="sd">        The similarity to use either knn or gaussian</span>
<span class="sd">    similarity_param : int or float, optional (default=None)</span>
<span class="sd">        Parameter for the similarity: number of nearest neighbors or bandwidth</span>
<span class="sd">        if similarity=&quot;knn&quot; or &quot;gaussian&quot;, respectively. If None is provided,</span>
<span class="sd">        it is set to 3 or the average pairwise squared Euclidean distance, respectively.</span>
<span class="sd">    max_iter : int, optional (default=100)</span>
<span class="sd">        Max number of BCD iterations</span>
<span class="sd">    tol : float, optional (default=1e-5)</span>
<span class="sd">        Stop threshold on relative loss decrease (&gt;0)</span>
<span class="sd">    max_inner_iter : int, optional (default=10)</span>
<span class="sd">        Max number of iterations (inner CG solver)</span>
<span class="sd">    inner_tol : float, optional (default=1e-6)</span>
<span class="sd">        Stop threshold on error (inner CG solver) (&gt;0)</span>
<span class="sd">    log : int, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-emdlaplacetransport&gt;`.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>


<span class="sd">    .. _references-emdlaplacetransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">        &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE Transactions</span>
<span class="sd">        on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [2] R. Flamary, N. Courty, D. Tuia, A. Rakotomamonjy,</span>
<span class="sd">        &quot;Optimal transport with Laplacian regularization: Applications to domain adaptation and shape matching,&quot;</span>
<span class="sd">        in NIPS Workshop on Optimal Transport and Machine Learning OTML, 2014.</span>

<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">        Regularized discrete optimal transport. SIAM Journal on Imaging Sciences, 7(3), 1853-1882.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reg_type</span><span class="o">=</span><span class="s2">&quot;pos&quot;</span><span class="p">,</span>
        <span class="n">reg_lap</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">reg_src</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">similarity</span><span class="o">=</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span>
        <span class="n">similarity_param</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span>
        <span class="n">max_inner_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
        <span class="n">inner_tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
        <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s2">&quot;ferradans&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg</span> <span class="o">=</span> <span class="n">reg_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_lap</span> <span class="o">=</span> <span class="n">reg_lap</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_src</span> <span class="o">=</span> <span class="n">reg_src</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">similarity</span> <span class="o">=</span> <span class="n">similarity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sim_param</span> <span class="o">=</span> <span class="n">similarity_param</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span> <span class="o">=</span> <span class="n">max_inner_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_tol</span> <span class="o">=</span> <span class="n">inner_tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>

<div class="viewcode-block" id="EMDLaplaceTransport.fit">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.EMDLaplaceTransport.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">EMDLaplaceTransport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="n">returned_</span> <span class="o">=</span> <span class="n">emd_laplace</span><span class="p">(</span>
            <span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span>
            <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span>
            <span class="n">xs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span>
            <span class="n">xt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">,</span>
            <span class="n">M</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span>
            <span class="n">sim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">similarity</span><span class="p">,</span>
            <span class="n">sim_param</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sim_param</span><span class="p">,</span>
            <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lap</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_src</span><span class="p">,</span>
            <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">stopThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">numInnerItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span><span class="p">,</span>
            <span class="n">stopInnerThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_tol</span><span class="p">,</span>
            <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># coupling estimation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div>
</div>



<div class="viewcode-block" id="SinkhornL1l2Transport">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornL1l2Transport">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SinkhornL1l2Transport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Domain Adaptation OT method based on sinkhorn algorithm +</span>
<span class="sd">    L1L2 class regularization.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg_e : float, optional (default=1)</span>
<span class="sd">        Entropic regularization parameter</span>
<span class="sd">    reg_cl : float, optional (default=0.1)</span>
<span class="sd">        Class regularization parameter</span>
<span class="sd">    max_iter : int, float, optional (default=10)</span>
<span class="sd">        The minimum number of iteration before stopping the optimization</span>
<span class="sd">        algorithm if it has not converged</span>
<span class="sd">    max_inner_iter : int, float, optional (default=200)</span>
<span class="sd">        The number of iteration in the inner loop</span>
<span class="sd">    tol : float, optional (default=10e-9)</span>
<span class="sd">        Stop threshold on error (inner sinkhorn solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional (default=False)</span>
<span class="sd">        Controls the verbosity of the optimization algorithm</span>
<span class="sd">    log : bool, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-sinkhornl1l2transport&gt;`.</span>
<span class="sd">    limit_max: float, optional (default=10)</span>
<span class="sd">        Controls the semi supervised mode. Transport between labeled source</span>
<span class="sd">        and target samples of different classes will exhibit an infinite cost</span>
<span class="sd">        (10 times the maximum value of the cost matrix)</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>
<span class="sd">    log_ : dictionary</span>
<span class="sd">        The dictionary of log, empty dict if parameter log is not True</span>


<span class="sd">    .. _references-sinkhornl1l2transport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,</span>
<span class="sd">        &quot;Optimal Transport for Domain Adaptation,&quot; in IEEE</span>
<span class="sd">        Transactions on Pattern Analysis and Machine Intelligence ,</span>
<span class="sd">        vol.PP, no.99, pp.1-1</span>

<span class="sd">    .. [2] Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).</span>
<span class="sd">        Generalized conditional gradient: analysis of convergence</span>
<span class="sd">        and applications. arXiv preprint arXiv:1510.06567.</span>

<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">            Regularized discrete optimal transport. SIAM Journal on Imaging</span>
<span class="sd">            Sciences, 7(3), 1853-1882.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reg_e</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">reg_cl</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">max_inner_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">10e-9</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
        <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s2">&quot;ferradans&quot;</span><span class="p">,</span>
        <span class="n">limit_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span> <span class="o">=</span> <span class="n">reg_e</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_cl</span> <span class="o">=</span> <span class="n">reg_cl</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span> <span class="o">=</span> <span class="n">max_inner_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">=</span> <span class="n">limit_max</span>

<div class="viewcode-block" id="SinkhornL1l2Transport.fit">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.SinkhornL1l2Transport.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="n">ys</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">SinkhornL1l2Transport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

            <span class="n">returned_</span> <span class="o">=</span> <span class="n">sinkhorn_l1l2_gl</span><span class="p">(</span>
                <span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span>
                <span class="n">labels_a</span><span class="o">=</span><span class="n">ys</span><span class="p">,</span>
                <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span>
                <span class="n">M</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span>
                <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span><span class="p">,</span>
                <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_cl</span><span class="p">,</span>
                <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                <span class="n">numInnerItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span><span class="p">,</span>
                <span class="n">stopInnerThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># deal with the value of log</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div>
</div>



<div class="viewcode-block" id="MappingTransport">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.MappingTransport">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MappingTransport</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;MappingTransport: DA methods that aims at jointly estimating a optimal</span>
<span class="sd">    transport coupling and the associated mapping</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    mu : float, optional (default=1)</span>
<span class="sd">        Weight for the linear OT loss (&gt;0)</span>
<span class="sd">    eta : float, optional (default=0.001)</span>
<span class="sd">        Regularization term for the linear mapping `L` (&gt;0)</span>
<span class="sd">    bias : bool, optional (default=False)</span>
<span class="sd">        Estimate linear mapping with constant bias</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    kernel : string, optional (default=&quot;linear&quot;)</span>
<span class="sd">        The kernel to use either linear or gaussian</span>
<span class="sd">    sigma : float, optional (default=1)</span>
<span class="sd">        The gaussian kernel parameter</span>
<span class="sd">    max_iter : int, optional (default=100)</span>
<span class="sd">        Max number of BCD iterations</span>
<span class="sd">    tol : float, optional (default=1e-5)</span>
<span class="sd">        Stop threshold on relative loss decrease (&gt;0)</span>
<span class="sd">    max_inner_iter : int, optional (default=10)</span>
<span class="sd">        Max number of iterations (inner CG solver)</span>
<span class="sd">    inner_tol : float, optional (default=1e-6)</span>
<span class="sd">        Stop threshold on error (inner CG solver) (&gt;0)</span>
<span class="sd">    log : bool, optional (default=False)</span>
<span class="sd">        record log if True</span>
<span class="sd">    verbose : bool, optional (default=False)</span>
<span class="sd">        Print information along iterations</span>
<span class="sd">    verbose2 : bool, optional (default=False)</span>
<span class="sd">        Print information along iterations</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>
<span class="sd">    mapping_ :</span>
<span class="sd">        The associated mapping</span>

<span class="sd">        - array-like, shape (`n_features` (+ 1), `n_features`),</span>
<span class="sd">          (if bias) for kernel == linear</span>

<span class="sd">        - array-like, shape (`n_source_samples` (+ 1), `n_features`),</span>
<span class="sd">          (if bias) for kernel == gaussian</span>
<span class="sd">    log_ : dictionary</span>
<span class="sd">        The dictionary of log, empty dict if parameter log is not True</span>


<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [8] M. Perrot, N. Courty, R. Flamary, A. Habrard,</span>
<span class="sd">            &quot;Mapping estimation for discrete optimal transport&quot;,</span>
<span class="sd">            Neural Information Processing Systems (NIPS), 2016.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">mu</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">eta</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">max_inner_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">inner_tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">verbose2</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">eta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span> <span class="o">=</span> <span class="n">max_inner_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_tol</span> <span class="o">=</span> <span class="n">inner_tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose2</span> <span class="o">=</span> <span class="n">verbose2</span>

<div class="viewcode-block" id="MappingTransport.fit">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.MappingTransport.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Builds an optimal coupling and estimates the associated mapping</span>
<span class="sd">        from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_backend</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span> <span class="o">=</span> <span class="n">Xs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span> <span class="o">=</span> <span class="n">Xt</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
                <span class="n">returned_</span> <span class="o">=</span> <span class="n">joint_OT_mapping_linear</span><span class="p">(</span>
                    <span class="n">Xs</span><span class="p">,</span>
                    <span class="n">Xt</span><span class="p">,</span>
                    <span class="n">mu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span>
                    <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">,</span>
                    <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                    <span class="n">verbose2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose2</span><span class="p">,</span>
                    <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                    <span class="n">numInnerItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span><span class="p">,</span>
                    <span class="n">stopThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                    <span class="n">stopInnerThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_tol</span><span class="p">,</span>
                    <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">==</span> <span class="s2">&quot;gaussian&quot;</span><span class="p">:</span>
                <span class="n">returned_</span> <span class="o">=</span> <span class="n">joint_OT_mapping_kernel</span><span class="p">(</span>
                    <span class="n">Xs</span><span class="p">,</span>
                    <span class="n">Xt</span><span class="p">,</span>
                    <span class="n">mu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span>
                    <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">,</span>
                    <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span>
                    <span class="n">sigma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                    <span class="n">verbose2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                    <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                    <span class="n">numInnerItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_inner_iter</span><span class="p">,</span>
                    <span class="n">stopInnerThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_tol</span><span class="p">,</span>
                    <span class="n">stopThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                    <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="c1"># deal with the value of log</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_</span> <span class="o">=</span> <span class="n">returned_</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="MappingTransport.transform">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.MappingTransport.transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports source samples :math:`\mathbf{X_s}` onto target ones :math:`\mathbf{X_t}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The transport source samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">Xs</span><span class="p">):</span>
                <span class="c1"># perform standard barycentric mapping</span>
                <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="c1"># set nans to 0</span>
                <span class="n">transp</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># compute transported samples</span>
                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">==</span> <span class="s2">&quot;gaussian&quot;</span><span class="p">:</span>
                    <span class="n">K</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma</span><span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
                    <span class="n">K</span> <span class="o">=</span> <span class="n">Xs</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
                    <span class="n">K</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">K</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">Xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">K</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
                    <span class="p">)</span>
                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapping_</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_Xs</span></div>
</div>



<div class="viewcode-block" id="UnbalancedSinkhornTransport">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.UnbalancedSinkhornTransport">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">UnbalancedSinkhornTransport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Domain Adaptation unbalanced OT method based on sinkhorn algorithm</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg_e : float, optional (default=1)</span>
<span class="sd">        Entropic regularization parameter</span>
<span class="sd">    reg_m : float, optional (default=0.1)</span>
<span class="sd">        Mass regularization parameter</span>
<span class="sd">    method : str</span>
<span class="sd">        method used for the solver either &#39;sinkhorn&#39;,  &#39;sinkhorn_stabilized&#39; or</span>
<span class="sd">        &#39;sinkhorn_epsilon_scaling&#39;, see those function for specific parameters</span>
<span class="sd">    max_iter : int, float, optional (default=10)</span>
<span class="sd">        The minimum number of iteration before stopping the optimization</span>
<span class="sd">        algorithm if it has not converged</span>
<span class="sd">    tol : float, optional (default=10e-9)</span>
<span class="sd">        Stop threshold on error (inner sinkhorn solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional (default=False)</span>
<span class="sd">        Controls the verbosity of the optimization algorithm</span>
<span class="sd">    log : bool, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-unbalancedsinkhorntransport&gt;`.</span>
<span class="sd">    limit_max: float, optional (default=10)</span>
<span class="sd">        Controls the semi supervised mode. Transport between labeled source</span>
<span class="sd">        and target samples of different classes will exhibit an infinite cost</span>
<span class="sd">        (10 times the maximum value of the cost matrix)</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : array-like, shape (n_source_samples, n_target_samples)</span>
<span class="sd">        The optimal coupling</span>
<span class="sd">    log_ : dictionary</span>
<span class="sd">        The dictionary of log, empty dict if parameter log is not True</span>


<span class="sd">    .. _references-unbalancedsinkhorntransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Chizat, L., Peyr, G., Schmitzer, B., &amp; Vialard, F. X. (2016).</span>
<span class="sd">        Scaling algorithms for unbalanced transport problems. arXiv preprint</span>
<span class="sd">        arXiv:1607.05816.</span>

<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">            Regularized discrete optimal transport. SIAM Journal on Imaging</span>
<span class="sd">            Sciences, 7(3), 1853-1882.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reg_e</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">reg_m</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;sinkhorn&quot;</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">distribution_estimation</span><span class="o">=</span><span class="n">distribution_estimation_uniform</span><span class="p">,</span>
        <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s2">&quot;ferradans&quot;</span><span class="p">,</span>
        <span class="n">limit_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span> <span class="o">=</span> <span class="n">reg_e</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_m</span> <span class="o">=</span> <span class="n">reg_m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribution_estimation</span> <span class="o">=</span> <span class="n">distribution_estimation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">limit_max</span> <span class="o">=</span> <span class="n">limit_max</span>

<div class="viewcode-block" id="UnbalancedSinkhornTransport.fit">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.UnbalancedSinkhornTransport.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Build a coupling matrix from source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like, shape (n_source_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        ys : array-like, shape (n_source_samples,)</span>
<span class="sd">            The class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">UnbalancedSinkhornTransport</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

            <span class="n">returned_</span> <span class="o">=</span> <span class="n">sinkhorn_unbalanced</span><span class="p">(</span>
                <span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_s</span><span class="p">,</span>
                <span class="n">b</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mu_t</span><span class="p">,</span>
                <span class="n">M</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_</span><span class="p">,</span>
                <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span><span class="p">,</span>
                <span class="n">reg_m</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_m</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">,</span>
                <span class="n">numItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                <span class="n">stopThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># deal with the value of log</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div>
</div>



<div class="viewcode-block" id="JCPOTTransport">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.JCPOTTransport">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">JCPOTTransport</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Domain Adaptation OT method for multi-source target shift based on Wasserstein barycenter algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reg_e : float, optional (default=1)</span>
<span class="sd">        Entropic regularization parameter</span>
<span class="sd">    max_iter : int, float, optional (default=10)</span>
<span class="sd">        The minimum number of iteration before stopping the optimization</span>
<span class="sd">        algorithm if it has not converged</span>
<span class="sd">    tol : float, optional (default=10e-9)</span>
<span class="sd">        Stop threshold on error (inner sinkhorn solver) (&gt;0)</span>
<span class="sd">    verbose : bool, optional (default=False)</span>
<span class="sd">        Controls the verbosity of the optimization algorithm</span>
<span class="sd">    log : bool, optional (default=False)</span>
<span class="sd">        Controls the logs of the optimization algorithm</span>
<span class="sd">    metric : string, optional (default=&quot;sqeuclidean&quot;)</span>
<span class="sd">        The ground metric for the Wasserstein problem</span>
<span class="sd">    norm : string, optional (default=None)</span>
<span class="sd">        If given, normalize the ground metric to avoid numerical errors that</span>
<span class="sd">        can occur with large metric values.</span>
<span class="sd">    distribution_estimation : callable, optional (defaults to the uniform)</span>
<span class="sd">        The kind of distribution estimation to employ</span>
<span class="sd">    out_of_sample_map : string, optional (default=&quot;ferradans&quot;)</span>
<span class="sd">        The kind of out of sample mapping to apply to transport samples</span>
<span class="sd">        from a domain into another one. Currently the only possible option is</span>
<span class="sd">        &quot;ferradans&quot; which uses the method proposed in :ref:`[6] &lt;references-jcpottransport&gt;`.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    coupling_ : list of array-like objects, shape K x (n_source_samples, n_target_samples)</span>
<span class="sd">        A set of optimal couplings between each source domain and the target domain</span>
<span class="sd">    proportions_ : array-like, shape (n_classes,)</span>
<span class="sd">        Estimated class proportions in the target domain</span>
<span class="sd">    log_ : dictionary</span>
<span class="sd">        The dictionary of log, empty dict if parameter log is not True</span>


<span class="sd">    .. _references-jcpottransport:</span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Ievgen Redko, Nicolas Courty, Rmi Flamary, Devis Tuia</span>
<span class="sd">        &quot;Optimal transport for multi-source domain adaptation under target shift&quot;,</span>
<span class="sd">        International Conference on Artificial Intelligence and Statistics (AISTATS),</span>
<span class="sd">        vol. 89, p.849-858, 2019.</span>

<span class="sd">    .. [6] Ferradans, S., Papadakis, N., Peyr, G., &amp; Aujol, J. F. (2014).</span>
<span class="sd">        Regularized discrete optimal transport. SIAM Journal on Imaging</span>
<span class="sd">        Sciences, 7(3), 1853-1882.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reg_e</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">10e-9</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">,</span>
        <span class="n">out_of_sample_map</span><span class="o">=</span><span class="s2">&quot;ferradans&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span> <span class="o">=</span> <span class="n">reg_e</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_of_sample_map</span> <span class="o">=</span> <span class="n">out_of_sample_map</span>

<div class="viewcode-block" id="JCPOTTransport.fit">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.JCPOTTransport.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Building coupling matrices from a list of source and target sets of samples</span>
<span class="sd">        :math:`(\mathbf{X_s}, \mathbf{y_s})` and :math:`(\mathbf{X_t}, \mathbf{y_t})`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : list of K array-like objects, shape K x (nk_source_samples, n_features)</span>
<span class="sd">            A list of the training input samples.</span>
<span class="sd">        ys : list of K array-like objects, shape K x (nk_source_samples,)</span>
<span class="sd">            A list of the class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_backend</span><span class="p">(</span><span class="o">*</span><span class="n">Xs</span><span class="p">,</span> <span class="o">*</span><span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">)</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="n">ys</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xs_</span> <span class="o">=</span> <span class="n">Xs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span> <span class="o">=</span> <span class="n">Xt</span>

            <span class="n">returned_</span> <span class="o">=</span> <span class="n">jcpot_barycenter</span><span class="p">(</span>
                <span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">,</span>
                <span class="n">Ys</span><span class="o">=</span><span class="n">ys</span><span class="p">,</span>
                <span class="n">Xt</span><span class="o">=</span><span class="n">Xt</span><span class="p">,</span>
                <span class="n">reg</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_e</span><span class="p">,</span>
                <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="p">,</span>
                <span class="n">distrinumItermax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                <span class="n">stopThr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span> <span class="o">=</span> <span class="n">returned_</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;gamma&quot;</span><span class="p">]</span>

            <span class="c1"># deal with the value of log</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">proportions_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="n">returned_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">proportions_</span> <span class="o">=</span> <span class="n">returned_</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="JCPOTTransport.transform">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.JCPOTTransport.transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transports source samples :math:`\mathbf{X_s}` onto target ones :math:`\mathbf{X_t}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : list of K array-like objects, shape K x (nk_source_samples, n_features)</span>
<span class="sd">            A list of the training input samples.</span>
<span class="sd">        ys : list of K array-like objects, shape K x (nk_source_samples,)</span>
<span class="sd">            A list of the class labels</span>
<span class="sd">        Xt : array-like, shape (n_target_samples, n_features)</span>
<span class="sd">            The training input samples.</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The class labels. If some target samples are unlabelled, fill the</span>
<span class="sd">            :math:`\mathbf{y_t}`&#39;s elements with -1.</span>

<span class="sd">            Warning: Note that, due to this convention -1 cannot be used as a</span>
<span class="sd">            class label</span>
<span class="sd">        batch_size : int, optional (default=128)</span>
<span class="sd">            The batch size for out of sample inverse transform</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="n">transp_Xs</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">Xs</span><span class="o">=</span><span class="n">Xs</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">([</span><span class="n">nx</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">Xs</span><span class="p">)]):</span>
                <span class="c1"># perform standard barycentric mapping for each source domain</span>

                <span class="k">for</span> <span class="n">coupling</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">:</span>
                    <span class="n">transp</span> <span class="o">=</span> <span class="n">coupling</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">coupling</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                    <span class="c1"># set nans to 0</span>
                    <span class="n">transp</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                    <span class="c1"># compute transported samples</span>
                    <span class="n">transp_Xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># perform out of sample mapping</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">batch_ind</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">indices</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
                <span class="p">]</span>

                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="k">for</span> <span class="n">bi</span> <span class="ow">in</span> <span class="n">batch_ind</span><span class="p">:</span>
                    <span class="n">transp_Xs_</span> <span class="o">=</span> <span class="p">[]</span>

                    <span class="c1"># get the nearest neighbor in the sources domains</span>
                    <span class="n">xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">(</span><span class="n">Xs</span><span class="p">[</span><span class="n">bi</span><span class="p">],</span> <span class="n">xs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                    <span class="c1"># transport the source samples</span>
                    <span class="k">for</span> <span class="n">coupling</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">:</span>
                        <span class="n">transp</span> <span class="o">=</span> <span class="n">coupling</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">coupling</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
                        <span class="n">transp</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="n">transp_Xs_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="p">))</span>

                    <span class="n">transp_Xs_</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">transp_Xs_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                    <span class="c1"># define the transported points</span>
                    <span class="n">transp_Xs_</span> <span class="o">=</span> <span class="n">transp_Xs_</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">Xs</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span> <span class="o">-</span> <span class="n">xs</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>
                    <span class="n">transp_Xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transp_Xs_</span><span class="p">)</span>

                <span class="n">transp_Xs</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">transp_Xs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_Xs</span></div>


<div class="viewcode-block" id="JCPOTTransport.transform_labels">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.JCPOTTransport.transform_labels">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Propagate source labels :math:`\mathbf{y_s}` to obtain target labels as in</span>
<span class="sd">        :ref:`[27] &lt;references-jcpottransport-transform-labels&gt;`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ys : list of K array-like objects, shape K x (nk_source_samples,)</span>
<span class="sd">            A list of the class labels</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        yt : array-like, shape (n_target_samples, nb_classes)</span>
<span class="sd">            Estimated soft target labels.</span>


<span class="sd">        .. _references-jcpottransport-transform-labels:</span>
<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        .. [27] Ievgen Redko, Nicolas Courty, Rmi Flamary, Devis Tuia</span>
<span class="sd">            &quot;Optimal transport for multi-source domain adaptation under target shift&quot;,</span>
<span class="sd">            International Conference on Artificial Intelligence and Statistics (AISTATS), 2019.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">ys</span><span class="o">=</span><span class="n">ys</span><span class="p">):</span>
            <span class="n">yt</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">ys</span><span class="p">))),</span> <span class="bp">self</span><span class="o">.</span><span class="n">xt_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">ys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">)):</span>
                <span class="n">ysTemp</span> <span class="o">=</span> <span class="n">label_normalization</span><span class="p">(</span><span class="n">ys</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">classes</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">ysTemp</span><span class="p">)</span>
                <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>
                <span class="n">ns</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ysTemp</span><span class="p">)</span>

                <span class="c1"># perform label propagation</span>
                <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="c1"># set nans to 0</span>
                <span class="n">transp</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
                    <span class="n">D1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_</span><span class="p">[</span><span class="s2">&quot;D1&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">D1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">ns</span><span class="p">),</span> <span class="n">type_as</span><span class="o">=</span><span class="n">transp</span><span class="p">)</span>

                    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
                        <span class="n">D1</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="n">ysTemp</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

                <span class="c1"># compute propagated labels</span>
                <span class="n">yt</span> <span class="o">=</span> <span class="n">yt</span> <span class="o">+</span> <span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">D1</span><span class="p">,</span> <span class="n">transp</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">yt</span><span class="o">.</span><span class="n">T</span></div>


<div class="viewcode-block" id="JCPOTTransport.inverse_transform_labels">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.JCPOTTransport.inverse_transform_labels">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">inverse_transform_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Propagate target labels :math:`\mathbf{y_t}` to obtain estimated source labels</span>
<span class="sd">        :math:`\mathbf{y_s}`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        yt : array-like, shape (n_target_samples,)</span>
<span class="sd">            The target class labels</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        transp_ys : list of K array-like objects, shape K x (nk_source_samples, nb_classes)</span>
<span class="sd">            A list of estimated soft source labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nx</span>

        <span class="c1"># check the necessary inputs parameters are here</span>
        <span class="k">if</span> <span class="n">check_params</span><span class="p">(</span><span class="n">yt</span><span class="o">=</span><span class="n">yt</span><span class="p">):</span>
            <span class="n">transp_ys</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">ytTemp</span> <span class="o">=</span> <span class="n">label_normalization</span><span class="p">(</span><span class="n">yt</span><span class="p">)</span>
            <span class="n">classes</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">ytTemp</span><span class="p">)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>
            <span class="n">D1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ytTemp</span><span class="p">)),</span> <span class="n">type_as</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
                <span class="n">D1</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="n">ytTemp</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xs_</span><span class="p">)):</span>
                <span class="c1"># perform label propagation</span>
                <span class="n">transp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">nx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coupling_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

                <span class="c1"># set nans to 0</span>
                <span class="n">transp</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">transp</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># compute propagated labels</span>
                <span class="n">transp_ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">D1</span><span class="p">,</span> <span class="n">transp</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">transp_ys</span></div>
</div>



<div class="viewcode-block" id="NearestBrenierPotential">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.NearestBrenierPotential">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">NearestBrenierPotential</span><span class="p">(</span><span class="n">BaseTransport</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Smooth Strongly Convex Nearest Brenier Potentials (SSNB) is a method from :ref:`[58]` that computes</span>
<span class="sd">    an l-strongly convex potential :math:`\varphi` with an L-Lipschitz gradient such that</span>
<span class="sd">    :math:`\nabla \varphi \# \mu \approx \nu`. This regularity can be enforced only on the components of a partition</span>
<span class="sd">    of the ambient space (encoded by point classes), which is a relaxation compared to imposing global regularity.</span>

<span class="sd">    SSNBs approach the target measure by solving the optimisation problem:</span>

<span class="sd">    .. math::</span>
<span class="sd">        :nowrap:</span>

<span class="sd">        \begin{gather*}</span>
<span class="sd">        \varphi \in \text{argmin}_{\varphi \in \mathcal{F}}\ \text{W}_2(\nabla \varphi \#\mu_s, \mu_t),</span>
<span class="sd">        \end{gather*}</span>

<span class="sd">    where :math:`\mathcal{F}` is the space functions that are on every set :math:`E_k` l-strongly convex</span>
<span class="sd">    with an L-Lipschitz gradient, given :math:`(E_k)_{k \in [K]}` a partition of the ambient source space.</span>

<span class="sd">    The problem is solved on &quot;fitting&quot; source and target data via a convex Quadratically Constrained Quadratic Program,</span>
<span class="sd">    yielding the values :code:`phi` and the gradients :code:`G` at at the source points.</span>
<span class="sd">    The images of &quot;new&quot; source samples are then found by solving a (simpler) Quadratically Constrained Linear Program</span>
<span class="sd">    at each point, using the fitting &quot;parameters&quot; :code:`phi` and :code:`G`. We provide two possible images, which</span>
<span class="sd">    correspond to &quot;lower&quot; and &quot;upper potentials&quot; (:ref:`[59]`, Theorem 3.14). Each of these two images are optimal</span>
<span class="sd">    solutions of the SSNB problem, and can be used in practice.</span>

<span class="sd">    .. warning:: This function requires the CVXPY library</span>
<span class="sd">    .. warning:: Accepts any backend but will convert to Numpy then back to the backend.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    strongly_convex_constant : float, optional</span>
<span class="sd">        constant for the strong convexity of the input potential phi, defaults to 0.6</span>
<span class="sd">    gradient_lipschitz_constant : float, optional</span>
<span class="sd">        constant for the Lipschitz property of the input gradient G, defaults to 1.4</span>
<span class="sd">    its: int, optional</span>
<span class="sd">        number of iterations, defaults to 100</span>
<span class="sd">    log : bool, optional</span>
<span class="sd">        record log if true</span>
<span class="sd">    seed: int or RandomState or None, optional</span>
<span class="sd">        Seed used for random number generator (for the initialisation in :code:`fit`.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    .. [58] Franois-Pierre Paty, Alexandre dAspremont, and Marco Cuturi. Regularity as regularization:</span>
<span class="sd">            Smooth and strongly convex brenier potentials in optimal transport. In International Conference</span>
<span class="sd">            on Artificial Intelligence and Statistics, pages 12221232. PMLR, 2020.</span>

<span class="sd">    .. [59] Adrien B Taylor. Convex interpolation and performance estimation of first-order methods for</span>
<span class="sd">            convex optimization. PhD thesis, Catholic University of Louvain, Louvain-la-Neuve, Belgium,</span>
<span class="sd">            2017.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ot.mapping.nearest_brenier_potential_fit : Fitting the SSNB on source and target data</span>
<span class="sd">    ot.mapping.nearest_brenier_potential_predict_bounds : Predicting SSNB images on new source data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">strongly_convex_constant</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
        <span class="n">gradient_lipschitz_constant</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span>
        <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">its</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strongly_convex_constant</span> <span class="o">=</span> <span class="n">strongly_convex_constant</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_lipschitz_constant</span> <span class="o">=</span> <span class="n">gradient_lipschitz_constant</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">log</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">its</span> <span class="o">=</span> <span class="n">its</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_log</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_log</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_Xs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_ys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_Xt</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

<div class="viewcode-block" id="NearestBrenierPotential.fit">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.NearestBrenierPotential.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Xt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">yt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits the Smooth Strongly Convex Nearest Brenier Potential [58] to the source data :code:`Xs` to the target data</span>
<span class="sd">        :code:`Xt`, with the partition given by the (optional) labels :code:`ys`.</span>

<span class="sd">        Wrapper for :code:`ot.mapping.nearest_brenier_potential_fit`.</span>

<span class="sd">        .. warning:: This function requires the CVXPY library</span>
<span class="sd">        .. warning:: Accepts any backend but will convert to Numpy then back to the backend.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like (n, d)</span>
<span class="sd">            source points used to compute the optimal values phi and G</span>
<span class="sd">        ys : array-like (n,), optional</span>
<span class="sd">            classes of the reference points, defaults to a single class</span>
<span class="sd">        Xt : array-like (n, d)</span>
<span class="sd">            values of the gradients at the reference points X</span>
<span class="sd">        yt : optional</span>
<span class="sd">            ignored.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [58] Franois-Pierre Paty, Alexandre dAspremont, and Marco Cuturi. Regularity as regularization:</span>
<span class="sd">                Smooth and strongly convex brenier potentials in optimal transport. In International Conference</span>
<span class="sd">                on Artificial Intelligence and Statistics, pages 12221232. PMLR, 2020.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        ot.mapping.nearest_brenier_potential_fit : Fitting the SSNB on source and target data</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_Xs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_ys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_Xt</span> <span class="o">=</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xt</span>
        <span class="n">returned</span> <span class="o">=</span> <span class="n">nearest_brenier_potential_fit</span><span class="p">(</span>
            <span class="n">Xs</span><span class="p">,</span>
            <span class="n">Xt</span><span class="p">,</span>
            <span class="n">X_classes</span><span class="o">=</span><span class="n">ys</span><span class="p">,</span>
            <span class="n">strongly_convex_constant</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">strongly_convex_constant</span><span class="p">,</span>
            <span class="n">gradient_lipschitz_constant</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient_lipschitz_constant</span><span class="p">,</span>
            <span class="n">its</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">its</span><span class="p">,</span>
            <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">phi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_log</span> <span class="o">=</span> <span class="n">returned</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">phi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">returned</span>

        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="NearestBrenierPotential.transform">
<a class="viewcode-back" href="../../gen_modules/ot.da.html#ot.NearestBrenierPotential.transform">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the images of the new source samples :code:`Xs` of classes :code:`ys` by the fitted</span>
<span class="sd">        Smooth Strongly Convex Nearest Brenier Potentials (SSNB) :ref:`[58]`. The output is the images of two SSNB optimal</span>
<span class="sd">        maps, called &#39;lower&#39; and &#39;upper&#39; potentials (from :ref:`[59]`, Theorem 3.14).</span>

<span class="sd">        Wrapper for :code:`nearest_brenier_potential_predict_bounds`.</span>

<span class="sd">        .. warning:: This function requires the CVXPY library</span>
<span class="sd">        .. warning:: Accepts any backend but will convert to Numpy then back to the backend.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Xs : array-like (m, d)</span>
<span class="sd">            input source points</span>
<span class="sd">        ys : : array_like (m,), optional</span>
<span class="sd">            classes of the input source points, defaults to a single class</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        G_lu : array-like (2, m, d)</span>
<span class="sd">            gradients of the lower and upper bounding potentials at Y (images of the source inputs)</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        .. [58] Franois-Pierre Paty, Alexandre dAspremont, and Marco Cuturi. Regularity as regularization:</span>
<span class="sd">                Smooth and strongly convex brenier potentials in optimal transport. In International Conference</span>
<span class="sd">                on Artificial Intelligence and Statistics, pages 12221232. PMLR, 2020.</span>

<span class="sd">        .. [59] Adrien B Taylor. Convex interpolation and performance estimation of first-order methods for</span>
<span class="sd">                convex optimization. PhD thesis, Catholic University of Louvain, Louvain-la-Neuve, Belgium,</span>
<span class="sd">                2017.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        ot.mapping.nearest_brenier_potential_predict_bounds : Predicting SSNB images on new source data</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">returned</span> <span class="o">=</span> <span class="n">nearest_brenier_potential_predict_bounds</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_Xs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">phi</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">,</span>
            <span class="n">Xs</span><span class="p">,</span>
            <span class="n">X_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_ys</span><span class="p">,</span>
            <span class="n">Y_classes</span><span class="o">=</span><span class="n">ys</span><span class="p">,</span>
            <span class="n">strongly_convex_constant</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">strongly_convex_constant</span><span class="p">,</span>
            <span class="n">gradient_lipschitz_constant</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient_lipschitz_constant</span><span class="p">,</span>
            <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">G_lu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_log</span> <span class="o">=</span> <span class="n">returned</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">G_lu</span> <span class="o">=</span> <span class="n">returned</span>
        <span class="k">return</span> <span class="n">G_lu</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016-2023, POT Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note"
aria-label="versions">
  <!--  add shift_up to the class for force viewing ,
  data-toggle="rst-current-version" -->
    <span class="rst-current-version"  style="margin-bottom:1mm;">
      <span class="fa fa-book"> Python Optimal Transport</span> 0.9.6dev0
      <hr  style="margin-bottom:1.5mm;margin-top:5mm;">
     <!--  versions
      <span class="fa fa-caret-down"></span>-->
      <span class="rst-current-version" style="display: inline-block;padding:
      0px;color:#fcfcfcab;float:left;font-size: 100%;">
        Versions: 
        <a href="https://pythonot.github.io/" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Release</a>
        <a href="https://pythonot.github.io/master" 
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Development</a>
        <a href="https://github.com/PythonOT/POT"
        style="padding: 3px;color:#fcfcfc;font-size: 100%;">Code</a>

      </span>

     
    </span>
  
     <!--
    <div class="rst-other-versions">

      

<div class="injected">

    
  <dl>
    <dt>Versions</dt>

    <dd><a href="https://pythonot.github.io/">Release</a></dd>
    
    <dd><a href="https://pythonot.github.io/master">Development</a></dd>
   
    

    <dt><a href="https://github.com/PythonOT/POT">Code on Github</a></dt>       

    
  </dl>
  <hr>

</div> 
</div>-->
  </div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>